{"pages":[{"title":"","text":"Sorry…現在、構築中です。。。","link":"/404.html"}],"posts":[{"title":"【Hexo】Icarusテーマで作成される記事のタイトル、h2、h3のデザインを変更","text":"Hexoで作成した記事を読みやすいデザインにしませんか？ 本ブログはIcarus(v3.0)というテーマを採用しておりますが、h2タグやh3タグにborder-leftをつけて記事の可読性を上げたいな、とおもっていました。 本記事では、それらのカスタマイズ方法をまとめました。 ✓目次 この記事の対象者 読みやすい記事とは h2タグ、h3タグのデザイン変更 記事タイトルをsemi-boldに変更 この記事の対象者 HexoにIcarusテーマを適用している方。Icarusはv 3.0.0。 基本的なHTML, CSSを理解している方 読みやすい記事とはそもそも読みやすい記事って、どんな記事なのか。 やはりブログで多くのお金を稼いでいる方のデザインなのかなと思います。 Icarusテーマの配色に近いデザインを用いている有名ブロガーさんとして、manablogさんのデザインを参考（というかほぼ丸パクリ）にしてデザインを当ててみたいと思います。 h2タグ、h3タグのデザイン変更編集するファイルは、\\themes\\icarus\\include\\style\\article.stylです。 以下のように設定すればOKです。 \\themes\\icarus\\include\\style\\article.styl1234567891011121314151617181920212223242526h2 font-size: 25px background: #f7f7f7; padding: 20px 15px 18px border-left: 9px solid #4865b2; line-height: 40px; margin-top: 60pxh3 font-size: 20px letter-spacing: 1.6px; padding: 10px 15px 10px; border-left: 9px solid #4865b2; font-weight: 600 margin-top: 60px;h4 font-size: 16px letter-spacing: 1.6px; padding: 5px 15px 5px; border-left: 9px solid #4865b2; font-weight: 400 margin-top: 60px; ファイルの編集が終わったら、ファイルを保存し、hexo cleanコマンドでキャッシュなどを削除。 hexo generateコマンドを実施し、hexo serverでlocalhost:4000にアクセスしてみましょう。 ちゃんとh2タグ、h3タグにデザインが当てられていればOKです。 記事タイトルをsemi-boldに変更記事のタイトルは\\themes\\icarus\\layout\\common\\article.jsxファイルを変更します。 titleクラスにhas-text-weight-semiboldを追記します。 \\themes\\icarus\\layout\\common\\article.jsx1234{/* Title */}&lt;h1 class=\"title is-3 is-size-4-mobile has-text-weight-semibold\"&gt; {index ? &lt;a class=\"link-muted\" href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title}&lt;/h1&gt; IcarusはBulmaというCSSフレームワークを使っています。 以下に、fontに関連するhelperのリンクを張っておきますので、semibold以外のフォントにしたい場合は、こちらを参照してください。 Typography helpers | Bulma: Free, open source, and modern CSS framework based on Flexbox その他、Icarusのデザイン変更に関する記事","link":"/2020/05/05/Icarus-h2h3title-change/"},{"title":"【簡単】Anaconda Navigatorによるpython環境構築","text":"プログラミング環境の構築で挫折したことありませんか？ 絶対に挫折しない環境構築方法を紹介します。 人気No1プログラミング言語ともいわれるPythonを学ぶための環境構築は、Anacondaを使えば安心です。 人工知能や自然言語処理の勉強のために必要なライブラリのインストール方法もまとめています。 ニューラルネットワークや自然言語処理の勉強のために、Anacondaを使って環境構築したのでその方法をまとめます。 ✓目次 使用しているPCとAnacondaのバージョン 手順①：Anaconda Navigatorのインストール 手順②：ライブラリの導入 使用しているPCとAnacondaのバージョンWindows10 proAnaconda Navigator 1.9.12 手順①：Anaconda Navigatorのインストール anaconda.comにアクセス トップページにDownloadsのリンクがあるのでこれをクリック&lt;br&gt; 環境を選択(Win, Mac, Linux) Python 3.6のバージョンを選択。ダウンロードが始まる。 インストーラがダウンロードされているのでダブルクリック。指示されたとおりにプロセスを進める。 MS VScodeをインストールするかを聞かれるが必要であればOK。すでにVScodeをインストール済みであれば無視してよい。 インストールが完了したら、Anaconda-Navigator.appを開く。 手順②：ライブラリの導入ライブラリは以下を導入しました。(お好みで他のライブラリを導入してもOKです。) NumPy matplotlib TensorFlow Keras nomkl gensim Janome 以降、実際の手順をまとめます。 Anaconda navigatorを起動。Enviromentsを選択。以下のような画面になります。 画面下にある、「create」をクリックする。 新しい仮想環境の名前を聞かれるので任意の名前を設定し、pythonにチェックを入れて、バージョンを3.6に設定する。 createをクリックすると、creating environmetという表記と共に、仮想環境の作成が開始されます。仮想環境の構築が完了したら、タブを「installed」にし、”numpy”と入力して検索。何も表示されない場合、numpyがインストールされていないことを示しています。 タブを「Not installed」に変更して”numpy”と入力するとnumpyが見つかります。numpyを選択して、「Apply」をクリック。 再びApplyをクリックするとnumpyのインストールが開始されます。 この要領で、matplotlib、tensorflow、Keras、gensimをインストール。gensimはword2vecを使うためのライブラリ。 nomklをインストールする際、Enviromentsにnomklが表示されません。(Anaconda Navigatorのバージョンによっては表示されるかもしれません。) Enviromentsにインストールしたいライブラリが表示されない場合は、Anaconda navigatorのterminalからインストールします。terminalは、▶ボタンをクリックして「open terminal」をクリックするとterminalが開きます。 今回はconda install -c anaconda nomklコマンドでインストールします。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950(test_env) C:\\Users\\user&gt;conda install -c anaconda nomklCollecting package metadata (repodata.json): doneSolving environment: done## Package Plan ## environment location: C:\\Users\\omashi\\Anaconda3\\envs\\nlp_bot added / updated specs: - nomklThe following packages will be downloaded: package | build ---------------------------|----------------- ca-certificates-2020.1.1 | 0 165 KB anaconda certifi-2020.4.5.1 | py36_0 159 KB anaconda nomkl-2.0 | 0 2 KB anaconda openssl-1.1.1 | he774522_0 5.7 MB anaconda ------------------------------------------------------------ Total: 6.1 MBThe following NEW packages will be INSTALLED: nomkl anaconda/win-64::nomkl-2.0-0The following packages will be UPDATED: openssl pkgs/main::openssl-1.1.1f-he774522_0 --&gt; anaconda::openssl-1.1.1-he774522_0The following packages will be SUPERSEDED by a higher-priority channel: ca-certificates pkgs/main --&gt; anaconda certifi pkgs/main --&gt; anacondaProceed ([y]/n)? yDownloading and Extracting Packagesopenssl-1.1.1 | 5.7 MB | ############################################################################ | 100%nomkl-2.0 | 2 KB | ############################################################################ | 100%ca-certificates-2020 | 165 KB | ############################################################################ | 100%certifi-2020.4.5.1 | 159 KB | ############################################################################ | 100%Preparing transaction: doneVerifying transaction: doneExecuting transaction: done(test_env) C:\\Users\\user&gt; janomeも同様にterminalからインストールします。janomeは、pip install janomeコマンドでインストールします。 123456(test_env) C:\\Users\\user&gt;pip install janomeCollecting janome Downloading Janome-0.3.10-py2.py3-none-any.whl (21.5 MB) |████████████████████████████████| 21.5 MB 3.3 MB/sInstalling collected packages: janomeSuccessfully installed janome-0.3.10 これで完了です。 自然言語処理の学習にオススメの教材 以下のUdemyのコースはとてもオススメ 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/04/15/anaconda-enviroment/"},{"title":"本ブログについて","text":"本ページをご覧いただきありがとうございます。 IT系企業に勤める技術者が、様々な経験や勉強を通じて得られたこと、学んだことを情報発信するブログです。 著者について 学生時代は、無機材料化学の分野の研究者でした。 試験管使って薬品混ぜたりしてたよ。 大学院修士卒業後、IT・通信企業に研究職として就職。 「プロトコル」って何？←入社時の筆者 独学でプログラミング、ネットワーク、クラウド、AI関連技術を身に着けてきた経験をベースに、効率よく低コストで無理なく学習する方法や、知見などをお届けしたいと思っています。 また、健康、サプリメントに関する資格と日々の論文調査をベースに、ダイエットや健康に関する情報も発信したいと思います。 よく読まれている記事 2021-01-20【85講座受講】技術者が推奨するUdemyのPython講座オススメ集IT 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT 2021-01-18【初心者レベル別】Web系エンジニアを目指すためのUdemyオススメ講座IT 2020-05-08【プログラミング】SkillHacks受講後にオススメのUdemy講座IT 2021-01-21【腰痛解消】人間工学基づいた座椅子がリモートワークに最適過ぎたGoods","link":"/2020/01/08/about-this-blog/"},{"title":"【比較】糖質制限 vs 脂質制限","text":"糖質制限ダイエットと脂質制限ダイエットについてまとめてみました。 ✓目次 結論 論文の内容を簡単にまとめる 結論低炭水化物ダイエットの効果は低脂肪ダイエットと同じ 低脂肪ダイエットと低炭水化物ダイエットの減量効果と参加者の遺伝子パターンやインスリン分泌との関係を調べた結果、減量効果に有意差はなく、遺伝子やインスリンとの関連もみられなかった、という米国スタンフォード大学からの研究報告がありました。 『米国医学会誌(JAMA)』https://jamanetwork.com/ https://www.wsj.com/articles/SB10001424052748703862704575099742545274032 論文の内容を簡単にまとめる18-50才の糖尿病ではなく、BMIが28-40の609名を対象に、2013年1月から2015年4月にかけて介入試験を実施し、その後2016年5月まで追跡調査した結果がまとめられています。 参加者はランダムに、健康的な低脂肪食（HLF）群と健康的な低炭水化物食（HLC）群に振り分けられ12か月間モニタリングを行ったようです。 (色々難しいことは省いて、、、) 介入の結果、12月で、HLF群で平均-5.3kg、HLC群で平均-6.0kgの体重変化が観察されたが、両群間には有意差が見られなかった。また、食事と遺伝子パターン、または食事とインスリン分泌能と、12か月間の体重変化の間にも有意な関連は認められなかったという。 筆頭研究者のクリストファー・ガードナー教授によれば、本研究結果の最大の収穫は、減量においては低脂肪食も低炭水化物食でも、その基本的な戦略が類似していた点であるという。 砂糖を減らし、精製穀類を減らし、野菜を可能な限りたくさん食べる。加工度の低い食品（Whole foods）を主に食べるようにする。 どちらのダイエットでも、最も体重を減らした人々が語っていたのは、様々な食べ物に対する知識、そしてそれらをどのように食べるかについてもっとよく考えるようになったことが大事ということだと筆者(Christopher Gardner氏)は述べています。 ボディメイクのプロの人は、最初に油を断ち切って体重を減らし、それでも目標値まで落ちなかった場合は糖質を制限するというのが一般的であると述べていました。 ダイエット効果が同じなら、油を制限する方を選びますが、結局はバランスよく、加工度の低い食品を自分で選んで食べるのが一番であるということですね。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/04/15/cbnoildiet/"},{"title":"DjangoのUserモデルを使用してみる","text":"DjangoでUserモデルを使用する方法をまとめます。 ✓目次 Userオブジェクトとは HTTPメソッドの適用 views.pyファイルでUserモデルをimportする Userモデルをテーブル化してDB化(migrateコマンド) ユーザ登録 Userデータの表示 UserオブジェクトとはUserオブジェクトとは、認証システムです。Djangoアプリ開発に関わるユーザ情報を登録することができます。 登録ユーザのプロパティは以下の通りです。 username password email first_name last_name 本記事では、htmlファイル(signup.html) のFormにHTTPメソッドを適用し、Userオブジェクトの取得方法をまとめます。 HTTPメソッドの適用HTTPメソッドについては以下の記事でまとめているので参照ください。 Djangoで作成したHTMLファイルのformタグの部分にPOSTメソッドを適用する際は、formタグの内部にmethod='POST'と、csrf_tokenを記述します。 templates/signup.html1&lt;form class=&quot;form-signin&quot; method='POST'&gt;{% csrf_token %} これでPOSTメソッドでデータを送ることができます。 views.pyファイルでUserモデルをimportするUserモデルは、Djangoがデフォルトで具備しているモデルであり、models.pyに自らモデルを記述する必要はありません。 まずは、Djangoの公式ドキュメントに従ってUserモデルをインポートします。 hogehogeapp/views.py1234567from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): return render(request, 'signup.html', {}) Userモデルからオブジェクトデータすべてを抽出する記述にしていきます。 hogehogeapp/views.py12345678910from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.all() print(object_list) return render(request, 'signup.html', {}) User.objects.all()という記述で、Userモデルのすべてのオブジェクトデータを取得できます。 取得して全オブジェクトデータをprint(object_list)として表示させます。 Userモデルをテーブル化してDB化(migrateコマンド)以下の通りmigrateコマンドを実行。 makemigrationコマンドは、models.pyファイルに新しいモデルを定義していないので、実施する必要はありません。 terminal12345678910111213141516171819202122docker-compose exec web python manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying sessions.0001_initial... OK usernameやemailという記述が確認できます。Userモデルが作成されたように見えますね。 ユーザ登録 ここではsatoとtanakaというユーザを作成していきます。Email addressはtanakaさんだけbbb@example.comというアドレスを登録しておきます。他は、ひとまず何も入力せずEnterでOKです。passwordは適当にpasswordと入力しておきます。 terminal12345678910111213141516$ docker-compose exec web python manage.py createsuperuserUsername: tanakaEmail address: bbb@example.comPassword: Password (again): This password is too common.Bypass password validation and create user anyway? [y/N]: ySuperuser created successfully.$ docker-compose exec web python manage.py createsuperuserUsername: satoEmail address: Password: Password (again): This password is too common.Bypass password validation and create user anyway? [y/N]: ySuperuser created successfully. docker-compose psコマンドでWebとDBが起動していることを確認し、chromeなどのブラウザで、localhost:8000/adminにアクセスしてみましょう。ユーザ名はroot, パスワードはpasswordです。 Userデータの表示docker-compose upコマンドで、フォアグラウンドモードでコンテナを起動させ、localhost:8000/signupにアクセスして、GETメソッドを送ってみましょう。 Terminal上に、QuerySetというリストが確認できます。 terminal1web_1 | &lt;QuerySet [&lt;User: root&gt;, &lt;User: tanaka&gt;, &lt;User: sato&gt;]&gt; 次に、個別のデータを取得してみましょう。 個別のデータを取得したい場合は、views.pyにて以下のように.get(username = 'tanaka)'とすればOKです。 hogehogeapp/views.py123456789from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.get(username = 'tanaka') print(object_list) return render(request, 'signup.html', {}) localhost:8000/signupにアクセスすると、tanakaというのがterminal上で確認できます。 terminal1web_1 | tanaka 次にtanakaさんのemailアドレスを取得したい場合は、取得したオブジェクトに対して、emailというプロパティを指定すればOKです。 hogehogeapp/views.py123456789from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.get(username = 'tanaka') print(object_list.email) return render(request, 'signup.html', {}) localhost:8000/signupにアクセスしてGETメソッドを送信してterminalを確認してみましょう。 terminal1web_1 | bbb@example.com Djangoをより深く学びたい方へ(Udemyのオススメ講座) 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） こちらは大橋亮太先生のUdemy講座です。具体例をたくさん入れた解説が好評であり、「なぜ」の説明が丁寧です。 この講座を確認する","link":"/2021/01/24/django-userobject/"},{"title":"本ブログの免責事項","text":"https://omathin.com/（以下、「当サイト」とします。）における免責事項は、下記の通りです。 コメントについて次の各号に掲げる内容を含むコメントは、当サイト管理人の裁量によって承認せず、削除する事があります。 特定の自然人または法人を誹謗し、中傷するもの 極度にわいせつな内容を含むもの 禁制品の取引に関するものや、他者を害する行為の依頼など、法律によって禁止されている物品、行為の依頼や斡旋などに関するもの その他、公序良俗に反し、または管理人によって承認すべきでないと認められるもの 当サイトの情報の正確性について当サイトのコンテンツや情報において、可能な限り正確な情報を掲載するよう努めています。しかし、誤情報が入り込んだり、情報が古くなったりすることもあります。必ずしも正確性を保証するものではありません。また合法性や安全性なども保証しません。 損害等の責任について当サイトに掲載された内容によって生じた損害等の一切の責任を負いかねますので、ご了承ください。また当サイトからリンクやバナーなどによって他のサイトに移動された場合、移動先サイトで提供される情報、サービス等について一切の責任も負いません。当サイトの保守、火災、停電、その他の自然災害、ウィルスや第三者の妨害等行為による不可抗力によって、当サイトによるサービスが停止したことに起因して利用者に生じた損害についても、何ら責任を負うものではありません。当サイトを利用する場合は、自己責任で行う必要があります。 当サイトで掲載している画像の著作権や肖像権等について当サイトで掲載している画像の著作権や肖像権等は、各権利所有者に帰属します。万が一問題がある場合は、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 無断転載の禁止について当サイトに存在する、文章や画像、動画等の著作物の情報を無断転載することを禁止します。引用の範囲を超えるものについては、法的処置を行います。転載する際には、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 Amazonアソシエイトについて当サイトは、amazon.co.jpを宣伝しリンクすることによってサイトが紹介料を獲得できる手段を提供することを目的に設定されたアフィリエイト宣伝プログラムである、 Amazonアソシエイト・プログラムの参加者です 2020年1月6日 策定2020年4月24日 改訂","link":"/2020/01/08/disclaimer/"},{"title":"docker-compose run web rails dbconsoleができない問題の対処","text":"タイトルに記載したコマンドを実行したらうまくいかなかったので備忘録的にまとめます。 ✓目次 環境 問題（エラー内容） エラーの原因 対処 参考記事 環境Windows10 proRuby 2.4.5MySQLの5.7 問題（エラー内容） 以下のようなエラーが発生 terminal1234$ docker-compose run web rails dbconsoleStarting b74e972d_db_1 ... doneCouldn't find database client: mysql, mysql5. Check your $PATH and try again. エラーの原因 ローカルにMySQLアカウントがないからと想定 対処エラーが発生する場合のdockerfileは以下の通り dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 以下のように修正 dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev postgresql-client nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app buildを実施 terminal1$ docker-compose build 同じエラーが発生。dockerfileを以下の通り、修正する。 Dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs mysql-clientRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 再度buildを実施 terminal1$ docker-compose build 成功したので、dbconsoleを実行 terminal1$ docker-compose run web rails dbconsole パスワードを聞かれた場合は、dokcer-compose.ymlに記載されている、MYSQL_ROOT_PASSWORD: に記述されているパスワードを入力。 これで成功するはず。 参考記事 docker-compose で Rails の開発環境を作る - Qiita docker-composeで、rails dbconsoleが使えなくてハマった話。 - Qiita Dockerを専門に学ぶためのオンライン学習講座 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/01/27/docker-compose-run-web-rails-dbconsole-error/"},{"title":"【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説","text":"本記事では、doc2vecというものについてまとめてみます。 ✓目次 doc2vecとは、word2vecを拡張したもの dmpv DBOW dmpvとDBOWの比較 参考にした記事など doc2vecとは、word2vecを拡張したものdoc2vecとは、word2vecを単語レベルではなく、文または文章でも扱えるように拡張したものです。 word2vecって何？何ができるの？という方は、以下の記事を参照いただければと思います。 doc2vecを用いることで何ができるのかというと、文や文章をベクトル化することができます。word2vecを学んだ人向けに言い換えれば、文や文章に対して、分散表現を獲得することができる、ということです。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法でしたね。 word2vecでは、CBOWとskip-gramという、2つのニューラルネットワークを用いますが、doc2vecでは、下記2つのいずれかのニューラルネットワークが用いられます。 dmpv(distributed memory) DBOW(distributed bag-of-words) 以降、dmpv, DBOWについてまとめたいと思います。 dmpvdmpvは、入力層、中間層、出力層があり、入力層と中間層の間と、中間層と出力層の間に重みを表す行列が存在します。 word2vecのCBOWに似ているように見えますが、違いは、入力に各単語とは別に、緑色の四角の文書IDがあることです。 文書IDというのは、この図でいうと、「となりのトトロ」という文章に付与されているID(“012”)というものをone-hot表現で表したものを指しています。※ちょっとややこしい。 文書IDを入力層に加えることで、文書自体をベクトルとして表すことが可能となり、文脈を加味した学習が可能となったのです。 簡単な例で述べましたが、これはあくまでイメージとしてとらえていただければと思います。実際は大量の文章と、文書IDを用いて学習され、dmpvをはじめとする学習モデルが作成されることで、文章のベクトル化がされます。 DBOWDBOWは、word2vecのskip-gramに似ており、入力は文書IDのone-hot表現のみであるのが特徴です。 該当文章内に含まれる単語を予測するように学習が行われ、dmpvと同様に、文書自体を分散表現で表すことができる。 dmpvとDBOWの比較DBOWの方が、シンプルなモデルでメモリをあまり使わないため、高速に計算することが可能と報告されています。しかし、dmpvの方が精度の面で優れているとされています。 [1507.07998] Document Embedding with Paragraph Vectors 参考にした記事など Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル - DeepAge gensimでDoc2Vec - 機械学習・自然言語処理の勉強メモ 以下のUdemyのコースはとてもオススメ 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 本格的にAIを学びたい人へ 以下の何れかに該当する方は、キカガクさんのオンラインスクールがおすすめです。まずは無料のカウンセリングに参加し、自分が目指すキャリアや身に着けたいスキルが学べるか、等確認してみてください。無料カウンセリング予約はこちら ・プログラミング初学者（Pythonで機械学習を学びたい方）・機械学習を学び、キャリアに活かしたい方・何かAIサービスを企画、開発したい方・技術を身に着けて転職したい方・E資格を取得したい方","link":"/2020/04/29/doc2vec-overview/"},{"title":"【Hexo】ブログカード内のファビコンが表示されない問題の対処","text":"Hexo(Icarusテーマ)で、はてなブログカードを使用した際に、faviconがうまく表示されなかったので、解消法を備忘録的にまとめます。 ✓目次 エラーの事象 使用しているプラグイン 原因 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨 対処その②：適用しているIcarus(v3.0)テーマの修正 検証 エラーの事象以下のように、faviconが出てきません。 使用しているプラグインshundroidさんが提供してくれているプラグインを使用させていただきました。 以下のコマンドでインストール可能です。 terminal1npm install shundroid/hexo-embed-hatena-blog-card --save https://kimamamemo.com/Hexo/1563580702/ 記事を作成する際に実施するhexo new &quot;{記事名}&quot;コマンドで生成されるマークダウンファイルに｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝という風に、｛% hatenablogcard (記事のURL) %｝と記述していました。 しかしながら、本記事の冒頭の通り、faviconだけが表示されませんでした。 原因画像のパスがhttps://となっていると、faviconが表示されない場合があるようです。※セキュリティ的によろしくない。 **Icarus v3.0においてOpen Graph Protocolが正常に適用できない状態になっていたようです。 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨自身のブログ記事をChromeで表示し、F12で正常に表示されていないFaviconの箇所を確認すると、以下の通りとなっていました。 html12&lt;img src=\"https://cdn-ak.favicon.st-hatena.com?url=https%3A%2F%2Fomathin.com%2F2020%2F02%2F01%2Fmatsuba%2F\" alt=\"omathin.com\" title=\"omathin.com\" class=\"favicon\"&gt; Chromeのデベロッパーツール上で、試しに、?url= httpsとなっている部分を、?url=httpという形に変更すると、Faviconが表示されました。 よって、ブログ記事を作成するマークダウンファイル上で、｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝と記載していた箇所を、｛% hatenablogcard http://omathin.com/2020/01/16/knee-surgery/ %}という風に、https:形式からhttp:に変更すれば、ブログカード内にFaviconが表示されるようです。 しかしながら、これはセキュリティ的にあまりよろしくないですよね。 他に対策はないのか、とOpen Graph Protocolなどを調査してみると、なんと私が現在使用しているIcarus(v3.0)では、Open Graph Protocolが正常に適用できない状態になっているバグがあったようです。 対処その②：適用しているIcarus(v3.0)テーマの修正私が適用していたIcarusのバージョン3.0では、Open Graph Protocolが正常に適用できない状態になっていたそうです。 修正するコードはgithubを参照し、以下のように修正すればOKです。 layout/common/head.jsx123456789 author={open_graph.author || config.author} description={open_graph.description || page.description || page.excerpt || page.content || config.description} keywords={page.keywords || (page.tags &amp;&amp; page.tags.length ? page.tags : undefined) || config.keywords}- url={open_graph.url || url}+ url={open_graph.url || page.permalink || url} images={openGraphImages} siteName={open_graph.site_name || config.title} language={language} package.json12345678 \"bulma-stylus\": \"0.8.0\", \"deepmerge\": \"^4.2.2\", \"hexo\": \"^4.2.0\",- \"hexo-component-inferno\": \"^0.2.3\",+ \"hexo-component-inferno\": \"^0.2.4\", \"hexo-log\": \"^1.0.0\", \"hexo-pagination\": \"^1.0.0\", \"hexo-renderer-inferno\": \"^0.1.3\", 検証本ブログの別記事のブログカードを以下に張り付けてみると問題なく画像が表示されました。","link":"/2020/04/19/hatenablocard-favicon-error/"},{"title":"【Hexo】Icarusテーマで画像を中心に寄せる方法","text":"Icarus(v3.0)テーマを適用して記事を作成すると、デフォルトの設定で画像を掲載すると、以下のように画像が左に寄ってしまってます。 これを中心に位置付けるための方法をまとめます。 Icarusテーマで画像を中心に寄せる\\themes\\icarus\\include\\style\\article.stylファイルを編集します。 123456789101112131415161718 h4 font-size: 16px letter-spacing: 1.6px; padding: 5px 15px 5px; border-left: 9px solid #4865b2; font-weight: 400 margin-top: 60px; h5 font-size: 1em+ img + margin: auto;+ display: block; pre font-size: .85em 以下のようになります。 画像を中心にする方法は複数ありますが、Icarusの場合は、img要素をブロック要素にして、margin: autoにすると画像が中央に寄ります。 その他、画像を中心に寄せる方法は、以下の記事が参考になりますので、参照いただければと思います。 https://webkcampus.com/201501/949/ おしまい。 Icarusテーマのカスタマイズにご興味がある方は以下も参考になると思います。","link":"/2020/05/28/hexo-image-center/"},{"title":"【Hexo】Icarusテーマに更新日を表示させる方法","text":"Icarus(v3.0)テーマを適用して記事を作成すると、デフォルト設定では以下のようになってると思います。 御覧の通り、作成日として”3日前”という表記があるだけで、更新日がありません。 これを変更したいと思います。 \\themes\\icarus\\layout\\common\\article.jsxを変更すればOKです。 \\themes\\icarus\\layout\\common\\article.jsx12345 {/* Date */}+ &lt;i class=\"fas fa-clock\"&gt;作成日:&lt;/i&gt; &lt;time class=\"level-item\" dateTime={date_xml(page.date)} title={date_xml(page.date)}&gt;{date(page.date)}&lt;/time&gt;+ &lt;i class=\"fas fa-wrench\"&gt;更新日:&lt;/i&gt;+ &lt;time class=\"level-item\" dateTime={date_xml(page.updated)} title={date_xml(page.updated)}&gt;{date(page.updated)}&lt;/time&gt; こちらのコードを反映すると、以下の通りとなります。 アイコンは、Font Awesomeの参照して、&lt;i class=&quot;fas fa-clock&quot;&gt;&lt;/i&gt;等を使えばアイコンを表示させることができます。 https://fontawesome.com/icons?d=gallery 以上です。","link":"/2020/05/21/hexo-icarus-updated/"},{"title":"【Hexo】Icarusテーマに吹き出しを加える方法","text":"✓目次 本記事の対象者 本記事による効果 作成方法(コピペでOK！) 本記事の対象者 ・ Hexo+Github Pagesで無料ブログをやっている方 ・ ブログのデザインをもっと良くしてブログで収益を得たい方 ・ キャラクター付きコメントを加えて、読者にメッセージを訴えかけたい方 本記事による効果 こんな感じで、吹き出しコメントを加えられるようになるよ！ 作成方法(コピペでOK！) IcarulテーマのCSSファイルに以下のコードを貼り付けましょう。 themes/icarus/include/style/article.styl12345678910111213141516171819202122232425262728293031323334353637383940414243444546.balloon5 { width: 100%; margin: 1.5em 0; overflow: hidden;}.balloon5 .faceicon { float: left; margin-right: -90px; width: 80px;}.balloon5 .faceicon img{ width: 100%; height: auto; border: solid 3px #d7ebfe; border-radius: 50%;}.balloon5 .chatting { width: 100%;}.says { display: inline-block; position: relative; margin: 5px 0 0 105px; padding: 17px 13px; border-radius: 12px; background: #d7ebfe;}.says:after { content: &quot;&quot;; display: inline-block; position: absolute; top: 18px; left: -24px; border: 12px solid transparent; border-right: 12px solid #d7ebfe;}.says p { margin: 0; padding: 0;} そして記事作成ファイルに以下のコードを貼り付ければ、完了です。 source/_posts/article.md12345678910&lt;div class=&quot;balloon5&quot;&gt; &lt;div class=&quot;faceicon&quot;&gt; &lt;img src=&quot;/images/xxxx.png&quot;&gt; &lt;/div&gt; &lt;div class=&quot;chatting&quot;&gt; &lt;div class=&quot;says&quot;&gt; &lt;p&gt;ここにセリフを記載&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 以下のサルワカさんのページを参考にさせていただきました。サルワカさんのページには他にも様々なサンプルがありますので、自分好みのデザインを作ってみましょう。CSSで作る！吹き出しデザインのサンプル19選 よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/2021/01/12/hexo-icarus-speech-bubble/"},{"title":"[Hexo landscape]スマホで閲覧した際にInstagramの幅がはみ出る","text":"Hexo landscape themeで、Instagramの投稿を埋め込んだ記事を、スマートフォンで閲覧すると、幅があってない時の対処方法を記載します。 結論としては、/theme/landscape/source/css/_partial/配下のmobile.stylファイルを修正すればOKです。 12$ cd /thema/landscape/source/css/_partial/$ vim mobile.styl 以下のコードを一番下に追記。 mobile.styl12345678910@media screen and (max-width: 728px){ .instagram-media{ width:414px !important; max-width: 100% !important; min-width: initial !important; }} 完了したらhexo d -gでデプロイすればOKです。","link":"/2020/01/19/hexo-landscape-instagram-modify/"},{"title":"Hexo＋github pagesで構築したブログをBoostnoteを用いて更新する方法","text":"備忘的記事です。 Boostnoteのバージョンは、Boostnote 0.11.13です。 _config.ymlの記述 post_asset_folder: falseの状態にしておく。 123456789101112131415161718192021222324(省略)# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: enable: true # Open external links in new tab field: site # Apply to the whole site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: false(省略) [ステップ1]ページの作成 以下のコマンドでページを作成する。ここではimageというページを作成する例。 12$ hexo new &quot;image&quot;INFO Created: ~\\usr\\source\\_posts\\image.md [ステップ2]boostnoteで記事を作成する。 画像を張り付けるなど、boostnoteのお作法で好きなように記事を作成する [ステップ3]記事を出力 File→export→MarkDownを選択 この際、先ほど作成したimage.mdを上書きする形でexportと保存を実行 上述の_config.ymlの44行目のようにpost_asset_folder: falseとなっている場合、以下のようなフォルダ構成になるようにする。 作業としては、sourceフォルダの配下にimagesフォルダを新規作成する。 [ステップ4]画像が出力されるようにファイル編集 上書きする形でexportしたimage.mdを下記のように編集する。適当なエディタを使ってください。 attachements/xxxxx.pngとなっているのを/images/xxxx.pngに変更 attachementsフォルダに配置されているxxxx.pngを/source/images/配下にコピーする。 [ステップ5]記事の確認 hexo serverコマンドで起動し、localhost:4000で確認。 1$ hexo server [ステップ6]記事のアップロード 問題なければ以下のコマンドでgithubにpushする 1$ hexo d -g これで画像が表示されているはずです。 備考githubにpushした際、ページが表示されなくなる場合ブログのドメイン名を記載したCNAMEファイルが、githubのリポジトリから消えている為です。 githubにpushする前に、hexo cleanコマンドでキャッシュの削除をすると、publicフォルダが丸々削除されてしまい、publicフォルダにCNAMEファイルが削除されてしまったことが原因だと思われる。 CNAMEファイルを作成し、publicフォルダに配置し、再度hexo d -gコマンドでgithubにpushしましょう。 またads.txtファイルもpublicフォルダから削除されているので、こちらもpublicフォルダに配置してgithubにpushしましょう。 参考ページNode.js製の静的サイトジェネレータ「Hexo」で無料ブログ開発 vol.1 | dotstudio HEXOを使ってブログを構築しました。 その1 | ant magazine","link":"/2020/01/06/hexo_post/"},{"title":"【Hexo】Icarusテーマで強調メッセージブロックを使う方法","text":"Hexo(Icarus)+Github pagesで無料ブログを作成した際、記事の中でページの一部を強調するために色付きのメッセージブロックを使いたくなる時があります。IcarusはBULMAというCSSフレームワークが適用されているので簡単に導入できます。 本記事の対象者 ・ Hexo + Github pagesでテーマはIcarusの人 ・ Icarusのv3.0.0以上の人 以下のコードをコピペすればOKです。hexo new &quot;hogehoge&quot;(hogehogeはファイル名)でジェネレートしたマークダウンファイル内部に、以下のコードをコピペして、&lt;div class=&quot;message-body&quot;&gt;と&lt;/div&gt;の間に文章などを記述すればOKです。 12345678&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Info&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. &lt;strong&gt;Pellentesque risus mi&lt;/strong&gt;, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum &lt;a&gt;felis venenatis&lt;/a&gt; efficitur. Aenean ac &lt;em&gt;eleifend lacus&lt;/em&gt;, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. &lt;/div&gt;&lt;/article&gt; 上記のコードを使うと以下のような形になります。 Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque risus mi, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum felis venenatis efficitur. Aenean ac eleifend lacus, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. 文章だけでなく、はてなブログカードを埋め込んだり、アフィリエイトリンクを埋め込むことも可能です。 例えば、以下のようなコードでマークダウンファイルに記述した場合、、、 1234567891011&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt;{% hatenablogcard https://omathin.com/2020/05/05/Icarus-h2h3title-change/ %} &lt;/div&gt;&lt;/article&gt; 以下のようになります。 Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓ いくらか見栄えがいい感じになりますね。 ちなみに、はてなブログカードのプラグインは、以下のnpmコマンドで導入が可能です。 1npm install shundroid/hexo-embed-hatena-blog-card --save 他の色を使いたい場合はBULMAのドキュメントを参照してくださいメッセージブロックについては、以下のページに記述されているコードを参照しコピペしながら使いましょう。 こちらも参考になるかもしれません。 積極的にBULMAを活用して、視認性の高い記事を作っていきましょう！ おしまい","link":"/2020/05/19/icarus-bulma/"},{"title":"Hexoのicarusテーマのフォントの変え方","text":"Icarusのテーマを早速適用してみると、中国語っぽいフォントになっているので変更したいな、と思いました。 例えば、「所」だと下図の左側のような表記になっており、日本人からすると「読めなくはないけど変だな」という文字になっています。◆中国語の漢字「簡体字」について（その３） ｜ Chinese－Lab ～中文研究網～ 基本的にChromeのF12キーで編集したい箇所を指定して、どのようなCSSが割り当てられているのかを調べる。 想定通りfont-familyにMicrosoft YaHeiが含まれているのが大きな原因のようでした。 icarusフォルダ内の、どのファイルを変更すればよいかを、icarusのgithubページのリポジトリで検索。ひとまず、”Microsoft YaHei”と入力して検索してみる。 このようにbase.stylファイルか、cyberpunk.stylが該当することが分かる。 パラメータを変更しながら、どちらのファイルを変更すればよいのかを探り、正解はbase.stylであることが分かる。他の人気ブロガーの方のフォントを参考にfamily-sans = Noto, Hiragino Sans, Helvetica, Arial, sans-serifという風に、Microsoft Yaheiがない形式に変更したら、中国語の漢字で表示されなくなりました。 \\themes\\icarus\\include\\style\\base.styl123456789101112131415161718/* --------------------------------- * Override Bulma CSS Framework * --------------------------------- */$body-size ?= 14px$body-background-color ?= #f7f7f7$family-sans-serif ?= Noto, Hiragino Sans, Helvetica, Arial, sans-serif # ←このように変更すればOK$family-code ?= 'Source Code Pro', monospace, 'Microsoft YaHei'$primary ?= $blue$custom-colors ?= { grey-lightest: { '1': $grey-lightest '2': $grey-darker }}","link":"/2020/04/11/icarus-theme-change/"},{"title":"【環境構築】OpenShiftの環境設定方法","text":"✓目次 前提とする環境 設定手順 1. Minishiftユーティリティのダウンロード 2. フォルダをCドライブ直下に移動させコマンド実行 3. OpenShiftのWebコンソールにアクセス 前提とする環境 Windows10 64ビット VirtualBoxをセットアップ済 VirtualBoxをセットアップしてない場合は、VirtualBoxのダウンロードページに移動し、使用しているオペレーティングシステム用のバージョンをダウンロードしてください。ウィザードに従ってインストールを完了させておきましょう。 設定手順 以下、設定方法を順番にまとめていきます。とても簡単です。 1. Minishiftユーティリティのダウンロード 以下のURLにアクセスします。https://www.okd.io/minishift/ Webサイトの下部にGet Startedという欄があります。”Minishift releases”という箇所をクリック。 Githubのページに遷移するので、使用しているプラットフォームに適したバージョンをダウンロードし、フォルダに展開します。 Windows10 64ビットの場合は、minishift-1.34.3-windows-amd64.zipになります。zipファイルを解凍しましょう。 2. フォルダをCドライブ直下に移動させコマンド実行 解凍したフォルダを、cドライブの直下に移動させます。 コマンドプロンプトを開きます。フォルダをエクスプローラで開き、パスの部分に”cmd”と入力すれば、そのフォルダに移動された状態でコマンドプロンプトを開くことができます。 Windowsの場合、MinishiftはデフォルトでHyper-Vを使用してMinishift仮想マシンをデプロイします。そのため--vm-driver virtualboxオプションを指定し、VirtualBoxを使用するように指示する必要があります。 以下のようにminishift.exe start --vm-driver virtualboxコマンドを実行します。 1C:\\minishift-1.34.3-windows-amd64&gt;minishift.exe start --vm-driver virtualbox このコマンドを実行すると、Minishiftはインターネット上に存在するISOイメージを取り出し、VirtualBox上に仮想マシンを作成します。 各種ダウンロードなどが完了し、コマンドプロンプト上に以下のような表示がされたら完了です。 123456789101112131415OpenShift server started.The server is accessible via web console at: https://192.168.99.100:8443/consoleYou are logged in as: User: developer Password: &lt;any value&gt;To login as administrator: oc login -u system:admin-- Exporting of OpenShift images is occuring in background process with pid 27020. VirtualBoxのコンソール画面を確認すると、minishiftという名前の新しいVMが自動的に作成されている状態になります。 3. OpenShiftのWebコンソールにアクセス OpenShiftのWebコンソールにアクセスしてみましょう。 google chrome等のブラウザを用いて、上記で示されているhttps://192.168.99.100:8443/consoleにアクセスしてみましょう。 このログイン画面で、任意のユーザー名、パスワードを使用してログインします。 この認証モードは、開発者がポータルに簡単にログインできるようにするためにMinishiftの為だけに設定されていることを覚えておきましょう。本番環境では使えません。 ユーザー名とパスワードを入力しLog inをクリックすると以下のような画面が表示されます。 これでOpenShiftクラスタを活用することができるようになりました。 OpenShiftをもっと学びたい方 以下のUdemyの講座で、OpenShiftの基礎を学ぶことができます。ビルド、ビルドトリガー、イメージストリーム、デプロイメントの理解などをハンズオンで学ぶことができます。Udemyは30日間の返金保証が付いているため、「ちょっと違うな。」と思ったら返金も可能なので気軽に試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sii7ibQ\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/learn-openshift/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1685508_5cbe_3.jpg?_DOhkU4tHD4sMV2ocoxcydj3RISUqG6hmRkxzTsyxkEw8boc6Fkl0w-awjeYUCaesvaeTxw_LK4rSDiqulHny6bun1wQVKSPbq64Erphfc-ErhgZeHCereo1vY30wHb4\"}});","link":"/2020/12/05/get-start-openshift/"},{"title":"【Hexo】Icarusテーマのサムネイル位置やサイズを変更する方法","text":"サムネイルの位置を変更する方法をまとめました。 デフォルトの設定では、以下のようにタイトルの上部にサムネイル画像が配置されます。 このサムネイルの位置をタイトルの下に配置されるように変更したので、その方法をまとめました。 ✓目次 サムネイルの設定方法 サムネイル位置の変更方法 サムネイルのサイズ変更 サムネイルの設定方法まずサムネイルは、記事を作成するマークダウンファイルの上部にthumbnail: {画像ファイルのパス}を記載することで設定されます。 例えば、以下のような記載になります。 1234567891011121314---title: &quot;【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説&quot;date: 2020-04-29 10:48:30update: categories:- AItags:- 自然言語処理- doc2vec- ニューラルネットワークdescription: &quot;doc2vecとは何か。dmpv, DBOWというdoc2vecの理解に必要な技術をわかりやすくまとめてみました。&quot;thumbnail: images/hogehoge.webp--- Hexoのテーマの一つであるIcarus(v 3.0.0)だと、タイトルの上にサムネイル画像が設置されますが、これをタイトル下に設置するように変更します。 サムネイル位置の変更方法hexo-theme-icarus/layout/common/article.jsxファイルを編集することで、サムネイルの位置を変更することができます。 まず、タイトル上部に表示されるサムネイル画像を非表示にするには、以下のコードの{/* Thumbnail */}というコードブロックを削除すればOKです。 1234567891011121314 return &lt;Fragment&gt; {/* Main content */} &lt;div class=\"card\"&gt;- {/* Thumbnail */}- {has_thumbnail(page) ? &lt;div class=\"card-image\"&gt;- {index ? &lt;a href={url_for(page.link || page.path)} class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/a&gt; : &lt;span class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/span&gt;}- &lt;/div&gt; : null} {/* Metadata */} &lt;article class={`card-content article${'direction' in page ? ' ' + page.direction : ''}`} role=\"article\"&gt; {page.layout !== 'page' ? &lt;div class=\"article-meta size-small is-uppercase level is-mobile\"&gt; 次に、記事タイトルの下にサムネイルを表示されるには、hexo-theme-icarus/layout/common/article.jsxファイルの{/* Title */}というコードブロックの下に、{/* Thumbnail */}コードブロックを追記すればOKです。 123456789101112 {/* Title */} &lt;h1 class=&quot;title is-3 is-size-4-mobile&quot;&gt; {index ? &lt;a class=&quot;link-muted&quot; href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title} &lt;/h1&gt;+ {/* Thumbnail */}+ {has_thumbnail(page) ? &lt;div class=&quot;card-image&quot;&gt;+ {index ? &lt;a href={url_for(page.link || page.path)} class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/a&gt; : &lt;span class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/span&gt;}+ &lt;/div&gt; : null} 以下のように、タイトルの下にサムネイルが表示されるようになりました。 サムネイルのサイズ変更サムネイルの配置を変えましたが、サムネイルの画像サイズによっては、以下のように上下がカットされてしまったり、記事タイトルの文章が見えている状態になっています。 これをうまい具合に変更したい場合は、include/style/article.stylファイルを変更します。 以下のように変更します。 12345.thumbnail object-fit: contain width: 100% !important height: 100% !important background-color: #fff 変更後、以下のようになります。 オススメ Webの仕事に関わる人なら誰でも必要な、「HTML/CSS」とプログラミング言語「JavaScript」の知識をこれ一本で。基礎の基礎から、jQuery/Vue.jsまで学ぶことができます。Hexoブログを自分が思うがままにカスタマイズしたい方は、受講したほうが良い講座だと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXxoT1x\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/html-css-js/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1334522_9c8b_3.jpg\"}}); [HTML/CSS/JavaScript] フロントエンドエンジニアになりたい人の Webプログラミング入門","link":"/2020/04/29/icarus-thumbnail-custom/"},{"title":"EPAと葉酸は精神疾患に有用である可能性がある","text":"精神医学誌に掲載された論文によるとEPAと葉酸が精神疾患に有用であることが分ったので、その内容についてまとめます！ EPAと葉酸は精神疾患に有用である可能性がある。 脳機能の改善や認知症予防にサプリメントの活用が注目されつつあるようです。 学術誌World Psychiatry(世界精神医学誌)の以下の論文で、EPAや葉酸が精神疾患に有用である可能性を指摘しています。 引用文献 (PDF) The efficacy and safety of nutrient supplements in the treatment of mental disorders: a meta-review of meta-analyses of randomized controlled trials In conclusion, clinicians should be informed of the nutrient supplements with established efficacy for certain conditions (such as eicosapentaenoic acid in depression), but also made aware of those currently lacking evidentiary support. Future research should aim to determine which individuals may benefit most from evidence‐based supplements, to further elucidate the underlying mechanisms. EPAとは：魚の油 EPAとは「エイコサペンタエン酸」の略称です。いわし・さば・あじなどの青魚に多く含まれるn-3系脂肪酸のひとつです。主に青魚の油に多く含まれるEPA（エイコサペンタエン酸）は、体内でほとんど作ることができない「必須脂肪酸」の一種です。必須脂肪酸にはほかに、同じく魚油に含まれるDHA（ドコサヘキサエン酸）、肉やリノール酸（植物油のひとつ）に偏った食事により体内に増加するAA（アラキドン酸）などがあります。EPAとは？ | サラサラ生活向上委員会 | ニッスイより 要するに魚の油ですね。 精神疾患だけでなく、血液をサラサラにしてくれたりする効果もあるようです。 毎日魚を食べるのもしんどいので、私はサプリメントで摂取しています。 EPAを手軽にとるならこれ：DHC EPA 30日分【機能性表示食品】 葉酸は枝豆、鶏レバー、焼きのりに多く含まれている。 葉酸を多く含む食べ物は、野菜ではえだまめ、肉は鶏レバー、海藻では焼きのり…などが特に葉酸を多く含む食べ物です。他にも豆類や果物など、多くの食べ物に葉酸は含まれている葉酸とは：どの食べ物に含まれているの？種類や適正量は？｜エレビット (Elevit)｜バイエル薬品より 日常的にえだまめ、や鶏レバーを取るのも正直しんどいですよね。こちらも手軽にサプリメントで取ってしまいましょう。400円前後で購入できます。 500円以下！：大塚製薬 ネイチャーメイド 葉酸 150粒 75日分 サプリメントを上手く活用して健康で健やかな毎日を送りましょう！ おしまい 合わせて読みたい記事 ダルビッシュ有投手も実践する風邪を引かないサプリメントについては以下の記事を参照ください。私もこれを始めてから風邪で寝込んでいません。","link":"/2020/05/15/spl-mental-health/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで③[自宅安静～抜糸～松葉づえ卒業まで]","text":"前の記事で前十字靭帯再建手術後、退院までの1週間をまとめました。 本記事では、その続きとして松葉づえが取れるまでの手術後約1か月をまとめたいと思います。 前の記事は、こちらを参照ください。 以下のようなことが知りたければ参考になると思います。 実体験に基づいた松葉づえが取れるまでの生活を具体的に知りたい 抜糸は痛いのかどうか？？ 自宅での生活は？？ 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 退院直後の生活(退院～抜糸まで) 抜糸後の生活 リハビリで重視されたのは「膝の力入れ」 膝の状態、感覚 松葉づえの卒業 まとめ 退院直後の生活(退院～抜糸まで)基本的に自宅で膝のアイシング、痛み止めを飲みながら、膝を心臓よりも高くして安静です。 自宅では、時間を見つけては膝のお皿を上下左右斜めに動かしたりします。 抜糸は、手術してから2週間後くらいだったと思います。 抜糸自体は少しチクチクするくらいで、そんなに痛くありません。※手術前の麻酔のアレルギーチェックや尿道の管を抜くときのほうが全然痛いです。 尿道の管の苦しさを乗り越えたのなら、全く問題ないと思います。 抜糸したあとも、基本的には傷口にテーピングをして置きます。このとき、傷口に対して垂直にテープを張ると傷跡が残りにくくなるそうです。 抜糸後の生活松葉づえが取れるまでは、手術から40日くらいがたった頃だったと思います。足はものすごい勢いで細くなります。 リハビリは、1週間に2回 or 3回のペースで通院しましたが、自宅でも積極的にリハビリをすることが大事です。膝のお皿動かしや、膝の力入れを積極的にしました。 病院までの通院は、電車やバスなどは使わずになるべく車で送り迎えをしてもらいましょう。電車やバスの場合、急な揺れや人との接触による危険があるため、車で送り迎えしてもらうのが良いと思います。 1回のリハビリは約1時間～1.5時間ほどで、理学療法士によるマッサージ、足上げによる筋トレ、EMS、超音波、患部側の足に体重を徐々にかける練習、歩く練習、あたりがメインでした。 ちなみに、手術後に手術した方の足に体重を乗せるのは緊張するものです。 松葉づえを卒業するためには、最終的に手術したほうの足に全体重が乗っても大丈夫な状態にならなければなりません。 いきなり全体重をかけるのではなく、最初は自分の体重の1/4, 1/2, , 全体重、という風に段階を踏んで徐々に進めていきます。 リハビリで重視されたのは「膝の力入れ」基本的に炎症を抑えることについて変わらないのです。膝を曲げる角度も時期に応じて制限があるので理学療法士の人の指導に従うべきだと思います。 とはいうものの、リハビリのなかでも、膝の力入れは、結構徹底されました。 膝の裏に丸めたタオルを入れて、太ももの前の筋肉を意識して、そのタオルを押しつぶすように力を入れる動作です。ちょっと言い過ぎなのでは？とも思いましたが、「100回でも200回でもいいからいくらでもやりましょう」というぐらいの勢いです。 (実はこの膝の力入れを本気でやることの重要性を、後々知るのでした。このあたりは、続きの記事でまとめようと思います) 注意事項など、参考になる良い動画がYoutubeにあったので、ここに載せておきます。 膝の状態、感覚退院直後は膝からの出血もあるため、松葉づえでトイレに行くときに血液が足先にたまっていく嫌な感覚がありますが、代替術後2週間くらいになるとで嫌な感覚がなくなります。 ※本記事冒頭のように、ふくらはぎ周辺に出血の跡を意味する黄色いシミみたいなのができてきます。 松葉づえの卒業手術してから約1ヵ月後くらいに、手術した方の足に、全体重が乗せられるようになり、かつ、ある程度松葉づえなしで歩けるようになれば、松葉づえ1本の卒業が認められました。 松葉づえなしで歩けるといっても、長い距離を歩いたり、走ったりは全くできないので、1本は持っておいた方が良いだろうという判断でした。 特に下り坂は膝に負担がかかるらしく、結構きつい。。。。そのため、手術から1ヵ月後に会社に復帰する際は、念のため松葉づえをもって出社しました。電車やバスで急な揺れにも備えたほうが良いという判断を理学療法士の方としました。 朝の満員電車はなかなか席を譲ってくれないパタンも多いので、松葉づえを持っていきましょう。 まとめ 松葉づえ期間も基本的には安静。 リハビリは膝の皿動かし、膝の力入れ、EMS、超音波、など。皿動かし、膝の力入れは積極的に自宅でも行いました。 松葉づえの卒業は1ヵ月以上かかる。リハビリや通勤はなるべく車で送迎してもらえると良い。 抜糸は痛くない。 以上です。次は、復帰を早めるためにリハビリ中に工夫したこと、辛かったことなどをまとめようと思います。以下に、7か月のリハビリについてまとめました。 体質改善したいひとにオススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/02/01/matsuba/"},{"title":"「子供を勉強させるにはどうすればいいの？」","text":"「うちの子供、全然勉強しないんだけど、どうすればいいかな？」 保育園や子供の習い事の送り迎えの立ち話で、こんなワードが出てきます。 そんな時は 親である貴方が勉強してないからじゃないの？というと大体納得する親が多い気がしました。 次に出てくるワードも大体見えていて、 「何を勉強すれば良いかな？」 or 「忙しくて勉強する暇がない」 なんですよね。 まず「何を勉強すれば良いかな？」という問いに対しては、 「好きな事というよりかは嫌いじゃない事が何かを整理して、続けられそうなトピックを勉強すれば良いのでは？」と答えます。 たぶん、勉強したいこと、やりたいこと、好きなこと、とかって、基本的になんとなく生活を送っていると、なかなかないものだと思います。 やりたいこと、とか、好きなこと、というのは、「自分ができること」の延長線上にあることが多い例えば、 野球ができる→野球の勉強したい、野球をもっとやりたい 料理ができる→栄養の勉強がしたい、サプリの勉強がしたい 運転ができる→レーサーになりたい、タクシーの運転手になりたい プログラミングができる→ITの仕事をしたい、プログラミングの勉強がしたい 気象予報士の資格を持っている→気象予報士になりたい 介護の資格を持っている→リハビリの勉強をしたい、介護の仕事をしたい という感じで、なんとなく始めた習い事とか学校で取った資格や学んだ知識の延長線上で、やりたいこととかを考えるのが一般的なのだと思います。 あの、東進ハイスクールの林先生も同様のことを言っています。※youtubeで検索すると出てくるかも。 なので、特にやりたいこととか好きなことが無い場合は、まずは、この「できる」という項目をとにかく増やす、という目的で、嫌いじゃないトピックを勉強すれば良いと思います。 私自身も、大学では化学を専門にしていましたが、就職先は、希望の化学系の部署に行けずにIT・通信関連の部署に配属になりました。 最初は何も分からなく挫折の毎日でしたが、プログラミングとかサーバの設定とかは、嫌いではなかったので地道に勉強していきました。 結果、「IT系の仕事で良かったな」と思っています。 言いたいこととしては、特にやりたいことがない、という人は、なんでも良いので嫌いじゃない領域を見つけて、勉強を始めてみるのが良いと思います。 「忙しくて勉強する暇がない」という人もいらっしゃると思います。 でもよくよく考えてみてください。 YoutubeやUdemy等、インターネットとスマホがあれば、いつでもどこでも好きなだけ学べる時代になった今、「忙しくて勉強する暇がない」といわれると、申し訳ないのですが「本当に？」と思ってしまうのです。 私自身も、子供の保育園の送り迎え等をしていますが、Udemyで数十個の講座を受講し、できることの幅を広げられています。学ぶことで、やりたいことが見つけられる、ということを信じて今すぐ勉強を始めてみるのはいかがでしょうか？ 世界最大級のオンライン学習サイトUdemy それでも「これ！」ってものがない場合のおすすめですが、私としては、これからは5Gの時代もやってくることも考えると、やはり動画の編集能力とか、需要が高くなる可能性が高いと思っています。 私もこれから、Udemyのキャンペーンのタイミングで以下の講座を受講して、動画の編集スキルを身に着けたいなとおもっているところです。 業界最先端の動画制作テクニックを制覇！Adobe Premiere Pro オンライン講座 少し値は張るかもしれませんが、以下のMovieHacksも良いと思います。Skill Hacksがとても良かったので、信頼度高めです。 -Movie Hacks- YouTubeに特化した動画編集講座 おしまい","link":"/2020/01/12/study-for-child/"},{"title":"Swagger EditorをDockerで動かす方法","text":"✓目次 この記事の対象者 Swaggerとは 1. Swagger Editor 2. Swagger Codegen 3. Swagger UI Dockerを使って起動してみよう Docker Playgroundで環境構築 この記事の対象者 ・ Swaggerとは何なのかを知りたい人 ・ Swagger Editorを使う環境をDockerを用いて構築したい人 Swaggerとは SwaggerはOpen APIを作成、表示、利用するツール郡です。Open APIとは、WSDLやXMLと比較されるようなフォーマットを意味します。Open APIのフォーマットは、JSONまたはYAML形式になります。 Swaggerは”ツール郡”という通り、様々な機能を有しております。主に以下の3つの機能です。 1. Swagger Editor 2. Swagger Codegen 3. Swagger UI 1. Swagger EditorEditorという名前の通り、Open APIを記述するエディタです。YAMLやJSONで記述します。 2. Swagger CodegenSwagger Editorで作成されたOpen APIを読み取ってスタブであったり、クライアントのソースコードを生成してくれるツールです。 スタブというのは、REST APIのリクエストに対するレスポンスが期待通りの値を返してくれるかをテストするためのモジュールを指します。 3. Swagger UISwagger UIはOpen APIの仕様書を読み取って、綺麗なWebページとして見える化してくれるツールです。 Dockerを使って起動してみよう Swaggerというのがなんとなくわかったところで早速動かしてみましょう。 まずはDockerをインストールしておきましょう。もしDocker環境が無ければ、Docker Playgroundでも試すことができます。以降は、Docker Playgroundを使った方法を紹介します。 Docker Playgroundで環境構築 ブラウザを立ち上げる 「Docker Playground」と検索 DockerHubのアカウントが必要になります。DockerHubのIDとパスワードを持っていなければ発行してログインしてください。 「Add new Instans」という項目をクリック。以下のように、Dockerが使える環境が整います。 コマンドを入力してSwagger Editorを導入しましょう。 コマンドは、docker run -d -p 80:8080 --name editor [コンテナ名:タグ名]という感じです。 コンテナ名は、DockerHubで確認をします。「swagger editor docker hub」と検索しましょう。Swagger Editorのdockerコンテナ名が以下のように把握することができます。この場合だと、swaggerapi/swagger-editorがコンテナ名になります。 次に、タグ名を調べます。DockerHubのTagsをクリック。 以下の通り、v3.11.7であることが分かります。 以上より、以下のコマンドを入力すれば良いことが分かります docker run -d -p 80:8080 --name editor swaggerapi/swagger-editor 注意：80番ポート以外だと、Swagger Codegenが動作しません このコマンドをDocker Playgroundに張り付けて実行します。 Docker Playgroundの場合、ポートを公開すると画面の上部のOpen Portのところに解放されたポート番号が表示されます。これをクリックします。 これでSwagger Editorが起動します。 そもそもDockerって何？という方 以下の記事で、Dockerとは何かをメリット/デメリットを共に解説してますので、こちらを参照ください。","link":"/2020/07/31/swagger-get-start/"},{"title":"Visual Studio CodeでSwagger viewerを導入する方法","text":"✓目次 この記事の対象者 導入手順 この記事の対象者 ・ Visual Studio Codeを使っている人 ・ Swagger EditorをVisual Studio Codeで使いたい人 導入手順 まずはVisual Studio Codeをインストールしましょう。インストール方法は以下の記事を参照ください。 Visual Studio Codeを起動し、左側の拡張機能をクリックし、”Swagger viewer”と検索窓に入力して検索しましょう。 Swagger viewerが表れるので、インストールを実施。 インストールが完了したら、Visual Studio Codeを再起動しましょう。これでインストール完了です。 Openapi specのサンプルをVisual Studio Codeに記述しましょう。Visual Studio Code上で新しいファイルを作成します。openapi.yaml等任意のファイル名でOKです。 新規作成したyamlファイルに、以下の、Open API Spec v3.0のPetStore.yamlをコピペしてください。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111openapi: \"3.0.0\"info: version: 1.0.0 title: Swagger Petstore license: name: MITservers: - url: http://petstore.swagger.io/v1paths: /pets: get: summary: List all pets operationId: listPets tags: - pets parameters: - name: limit in: query description: How many items to return at one time (max 100) required: false schema: type: integer format: int32 responses: '200': description: A paged array of pets headers: x-next: description: A link to the next page of responses schema: type: string content: application/json: schema: $ref: \"#/components/schemas/Pets\" default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\" post: summary: Create a pet operationId: createPets tags: - pets responses: '201': description: Null response default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\" /pets/{petId}: get: summary: Info for a specific pet operationId: showPetById tags: - pets parameters: - name: petId in: path required: true description: The id of the pet to retrieve schema: type: string responses: '200': description: Expected response to a valid request content: application/json: schema: $ref: \"#/components/schemas/Pet\" default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\"components: schemas: Pet: type: object required: - id - name properties: id: type: integer format: int64 name: type: string tag: type: string Pets: type: array items: $ref: \"#/components/schemas/Pet\" Error: type: object required: - code - message properties: code: type: integer format: int32 message: type: string 次にSwagger Viewerを起動します。Shift + Alt + Pの3つのキーを押下してください。するとVisual Studio Codeの右側に、Swagger UIが表示されます。 関連記事 Dockerを用いてSwagger Editorを動作させる方法もまとめています。 REST APIを設計する際に気を付けるべき主なポイントを以下の記事にまとめています。 REST APIの設計を重点的に学びたい方は以下のUdemy講座がおすすめです。質、ボリューム共に豊富で、不明点もWeb経由で質問し講師が直接回答してくれるため、挫折する心配もありません a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-seZAKTG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rest-webapi-development/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2641334_7977_6.jpg?tQnHFB7pu2rjtgmRqdDrZqHnUNTMsGAspswDZd7agOUondO9kbLFpMNfi87HFWc4E1gpBZmlURm7aQ1JvEWRcrcF20SfqIUhFhf5IBU0kYKMsSCOb3M0GImDyz3qvkQ2\"}});","link":"/2020/08/01/visualstudiocode-swagge-viewer/"},{"title":"Gitリポジトリを用いてSwaggerを起動する方法","text":"✓目次 この記事の対象者 導入手順 この記事の対象者 ・ ローカル環境でSwagger Editorを起動させたい人 Visual Studio CodeにSwagger viewerを導入したい人はこちらの記事を参照ください。 Dockerを用いてSwaggerを導入したい人はこちらの記事を参照ください。 導入手順 まずブラウザを立ち上げ、Google検索で「github swagger editor」と検索しましょう。 検索結果の一番上に表示されるリンク「GitHub - swagger-api/swagger-editor: Swagger Editor」をクリック。 以下の「Releases」をクリック タグが付与されたSwagger Editorのリリース情報一覧が表示されます。最新バージョンのSwagger EditorのSource code(zip)をダウンロード ダウンロードしたzipファイルを解凍し、フォルダを開く。 index.htmlファイルが存在するので、これをブラウザにドラック&amp;ドロップ Gitに使い慣れている人は、任意のフォルダでgit cloneコマンドを入力して直接落とすことも可能です。 git clone https://github.com/swagger-api/swagger-editor.git","link":"/2020/08/02/swagger-git/"},{"title":"Visual Studio Codeをインストールし、ターミナルをGit bashに変更する手順","text":"✓目次 Visual Studio Codeのインストール Visual Studio Codeの表記を日本語にする フォントサイズやデザインを変えたいとき Git for windows VScodeのターミナルをGit for Windowsのbashにする 参考 Visual Studio Codeのインストール マイクロソフトが開発したエディタ。Googleで検索してダウンロード。 ダウンロードされたファイルをダブルクリック。Visual Studio Codeセットアップウィザードが開く。 「次へ」を押下 ライセンスを確認して「同意」を押下 インストール先はそのままでOK。「次へ」を押下。 追加タスクの選択のパートで以下の項目に✓をいれて「次へ」を押下。これらにチェックを入れておくと便利。 「エクスプローラーのファイルコンテキストメニューに[Codeで開く]アクションを追加する」 「エクスプローラーのディレクトリコンテキストメニューに[Codeで開く]アクションを追加する」 「サポートされているファイルの種類のエディターとして、Codeを登録する」 「インストール」を押下。 Visual Studio Codeの表記を日本語にする Visual Studio Codeを開き、左側のメニューのExtentionを押下 検索窓に「japanese」と入力し、パッケージを選択して「install」を押下してインストールする VScodeの右下に、以下が出力される。再起動が必要です、ということなので「Restart now」を押下 日本語に変化！ フォントサイズやデザインを変えたいとき ファイル→基本設定→設定、を押下。 ここでフォントサイズを変更する。（お好みで） ファイル→基本設定→配色テーマ ここで見た目の配色を変更できる。 Git for windows ここからはターミナルをGit bashに変えたい人向けの設定です。 ダウンロードする Git for Windows インストールを実行。 改行コードの設定に注意する 仮想マシンからファイルを利用することが想定される場合は、仮想マシン側がUnixスタイルになっている。 ダウンロードしたファイルがUnixスタイルにしておく必要がある。 windows環境の git で改行コードの自動変換に注意 - Qiita VScodeのターミナルをGit for Windowsのbashにする 以下の記事が参考になります WindowsのVSCodeでGit Bashをターミナルに設定する - Qiita インストール後の作業 ~/.bashrcをexport TERM=cygwinを設定する Vagrantファイルの言語モードをRubyに設定する場合は、以下のように設定する。 色分けされるので見やすくなる VScodeのsettingを開き、検索画面でfiles.associationsと入力 jsonファイルの編集画面を開き下記のように書き換える Ctrl + s で保存 123456789{ \"terminal.integrated.shell.windows\": \"C:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\" \"files.associations\": { \"Vagrantfile\": \"ruby\" }} 参考 プログラミング学習についてまとめてみました。 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/01/18/vscode-environment-with-gitbash/"},{"title":"【自然言語処理】Transformerとは何か","text":"✓目次 この記事の対象者 Transformerとは TransformerのEncoderの構造 TransformerのDecoderの構造 まとめ この記事の対象者 ・ ニューラルネットワークの基本的な仕組みを理解している方 ・ RNNやLSTM、Seq2Seqを活用した自然言語処理に関する知識（one-hot表現、分散処理など）を理解している人 RNNの基礎については以下の記事でまとめているので参照してください。 RNNの基礎を学びたい方はこちら↓ Transformerとはディープラーニングモデルの一つで、主に自然言語処理の分野で使用されます。 自然言語処理などの時系列データを処理するように設計されてますが、RNNで用いる再帰を用いていません。 ではどのような仕組みなのかというと、大きくはEncoderとDecorderの２つで構成されています。 もう一つの特徴としては、Attention層のみで構築されています。 以降、EncoderとDecoderに分けて、その構造を解説したいと思います。 TransformerのEncoderの構造Encoderでは、Embedding層により入力文章をベクトルに圧縮変換をしています。要するに、自然言語で記述された文章を、単語の分散表現で一定の次元に変換したベクトルに変換をしています。これを、埋め込みベクトル、といいます。 そして、Positional Encodingによって、単語が文章中のどの位置にあるかの位置情報を加えています。 Multi-Head Attention層とは、その名の通り複数のAttentionが並んでいる領域であり、ここで入力で与えられた各単語との関連度を計算しています。Attentionについては、以下の記事で詳しくまとめていますので、こちらを参照ください。 Add &amp; Normという箇所は、Normalization(正規化)などであり、要はデータの偏りを無くす処理を行っています。 Feed Forwardという部分は、Positionwise fully connected feed-forward networkというものであり、２つの層からなる全結合ニューラルネットワークです。 具体的には、２つの層からなるニューラルネットワークでは、まず入力に重みを掛けてバイアスを足し、活性化関数のReLUに入れる処理を行っています。つまり、0より小さければすべて0にし、0より大きければそのままの値を出力しています。これに重みを掛けて、さらにバイアスを足す、という２層構造のニューラルネットワークになっています。 ちなみにこれらは、単語毎に個別の順伝播を行うニューラルネットワークになっています。こうすることで、他の単語との影響関係を排除することができるのです。 そして再びadd &amp; Normで正規化を行っています。 そして、Multi-Head AttentionとFeed Forwardの箇所は、6回処理が繰り返し行われます。 TransformerのDecoderの構造まず、Embedding層で、入力文章をベクトルに圧縮します。その後、Positional Encoding層によって位置情報を加えています。このあたりは、Encoderと同じです。 そして、Masked Multi-Head Attention層というのが現れます。これもAttentionの一種です。ここでは、特定のKeyに対してAttention weightを0にする処理が行われます。これを行うことで入力した単語の先読みを、すなわち「カンニング」が行われてしまうことを防いでいるのです。この処理を行わないと、入力に基づいて学習が行われてしまい、未知のデータに対して正しく予測することができなくなってしまいます。 Masked Multi-Head Attentionの後、正規化を行い、Multi-Head Attention層に入ります。ここで、Encoderからの出力を受け付けています。Decoderからの流れと、Encoderからの流れがここで合流しています。 そして正規化を行い、次はPositionwise fully connected fedd-forward networkで処理されます。その後、再び正規化が行われています。 最後に、全結合層であるLinearがあり、Softmax関数で値の範囲を0から1の範囲に収めています。 まとめ Transformerとは、 ディープラーニングモデルの一つで、主に自然言語処理の分野で使される。 自然言語処理などの時系列データを処理するように設計されている。しかし、RNNで取り入れている再帰を用いていません。 構造としては、EncoderとDecoderの２つで構成されています。 参考文献 Attention is All You Need, Ashish. V. et al, (2017) 技術ブログ | アクセルユニバース株式会社 より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら","link":"/2020/12/20/what-is-transformer/"},{"title":"【自然言語処理】ファインチューニング(Fine-Tuning)とは何か","text":"✓目次 ファインチューニング(Fine-Tuning)とは ファインチューニングのメリット メリット1: データが不足した領域への適用を可能にする メリット2: 学習時間の短縮 メリット3: 既存の優れたモデルを利用できる まとめ ファインチューニング(Fine-Tuning)とはファインチューニングとは、訓練済のモデルを各タスクに合わせて調整するように訓練することです。 転移学習という言い方もします。大まかな例えでいうと、 - 工場Aには学習済のモデルがある - 工場Bにはモデルがない - 工場Bでも同じことができるようにしたい といった場合は、工場Aのモデルを転用することを考えます。 最初の時点で既存のモデルを適用し、そのモデルに対して訓練させたいデータ(例：自然言語処理であれば文章など)を与え、訓練をさせて、新たなモデルを作る処理がファインチューニングになります。 ファインチューニングにおいて、既存の学習済モデルは、「特徴抽出器」として用いられ、パラメータの更新はされません。 出力側に追加した層のパラメータが更新され、学習が行われる形式です。 すなわち、既存の学習済のモデルに、新しく層を追加して、その追加した層のパラメータを更新することで、ファインチューニングにおける学習が行われます。 ファインチューニングのメリットここからはファインチューニングのメリットについていくつかまとめていきます。 メリット1: データが不足した領域への適用を可能にする学習や訓練にはデータが必要になりますが、必ずしも十分なデータを用意できるとは限りません。また、実験回数を多く重ねることが難しい領域も多く存在します。 そんなときは、すでに多くのデータを用いて学習させたモデルを活用するのが有効かと思います。 ある領域で訓練したモデルというのは、実は別の領域に適用可能となるケースは多くあります。 複数のタスクにおいて共通的に捉えるべき特徴というのが存在し、少しだけ調整するだけで適用できたりします。 メリット2: 学習時間の短縮既存の学習モデルを特徴抽出することで学習時間を短縮させることができます。 先でも述べましたが、捉えるべき特徴については共通部分が存在し、それを使い回すことで学習時間を短縮することができます。 メリット3: 既存の優れたモデルを利用できる世の中には、膨大なデータを用いて、たくさんの試行錯誤により確立された既存モデルがアップロードされています。 それらを簡単にダウンロードして利用することができる仕組みになっています。 最初からモデルを構築していくのではなく、既存の学習済のモデルを活用して、自ら最適化されたモデルを構築していくという方法を取ることで、効率化が図れるのです。 まとめ ファインチューニングとは、 訓練済のモデルを各タスクに合わせて調整するように訓練すること ファインチューニングのメリットは、 データが不足した領域への適用を可能にする 学習時間の短縮 既存の優れたモデルを利用できる より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら Seq2seqを活用してAIチャットボットを学びたい方は必見です！ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/12/21/what-is-fine-tuning/"},{"title":"【自然言語処理】word2vecとは何か？CBOWとskip-gramも解説","text":"本記事では、word2vecというものについてまとめてみます。 ✓目次 word2vecは言葉をベクトル化するツール CBOW(Continuous bag-of-words)とは skip-gramとは CBOWとskip-gramの比較 参考にした記事等 word2vecは言葉をベクトル化するツールword2vecは、分散表現を作成することができるツールです。 word2vecを活用すると、言語をベクトル化することができます。 ベクトル化することにより、定量的に単語同士がどれだけ似ているかを算出したり、数値計算のように、言葉を合成させたり、言葉を削除したりする、みたいなのができるようになります。 word2vecでは、下記2つのいずれかのニューラルネットワークが用いられます CBOW(continuous bag-of-words) skip-gram そもそも、ニューラルネットワークとは何か、という方は、以下のUdemyのコースがおすすめです。※セールの時期は1000円前後で購入できます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWtt7KZ\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku-chainer/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356238_e149_4.jpg\"}}); 【キカガク流】現場で使えるChainerによるディープラーニング入門 CBOW(Continuous bag-of-words)とはCBOWとは、前後の単語から対象の単語を予想するニューラルネットワークです。 イメージレベルですが概略は以下のような具合です。 入力層、中間層、出力層があり、入力層と中間層の間と中間層と出力層の間に、重みが存在します。 図1において、青い長方形は、one-hot表現という単語を0と1からなるベクトルで表現されたものが当てはまります。 one-hot表現を「となりのととろ」という文章を例にあらわしてみると、以下のようになります。 「となり」、「の」、「ととろ」という風に単語ごとにIDが割り振られます。 one-hot表現は、該当する単語が位置している箇所を「1」と表して表現します。各単語に割り当てられたIDで表現されるのではなく、あくまでもテーブル表の列の位置で表されている点がポイントです。 そして、one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができるのです。 続いて図1において、黄色の長方形は分散表現というベクトルで表現されたものが当てはまります。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法です。 200個、のようにたくさんの値の個数で表現されていることを、高次元である、というので、分散表現をかっこよく説明したければ、「単語を高次元の実数ベクトルで表現する技術」と言えばよいです。 具体的なイメージは以下の通りです。 図3では、「男」、「東京」、「Ruby」という3つの単語があります。 これらは全く異なる単語なので、ベクトルは似ていません。もし、単語の類似度や関連性が高ければ、これらの単語同士の分散表現は、似たものになります。 この分散表現を活用すると、どのようなことができるかというと、例えば、 「王様」ー「男性」＋「女性」=「お姫様」 という風に、単語同士の足し算や引き算が可能になり、かつ、類似度の高い単語を見つけることができます。 次に、オレンジ色の長方形は重みを表す行列です。 重みを表す行列とは、例えば、「となりのととろ」の真ん中の単語の「の」を予測できるように学習させた後に生成される、各単語の分散表現が並んだ行列です。 以上のように、CBOWは前後の単語から対象の単語を予測するようにして分散表現を作成するものです。 skip-gramとはskip-gramとは、ある単語から前後の単語を予測するニューラルネットワークです。 CBOWとの違いは、入力が中央の単語で、出力がその前後の単語である点です。 そのため、CBOWとは逆に、中央の単語からその周囲の単語を予測するように学習が行われます。 skip-gramにおいても、CBOWと同様に学習によって、入力層と中間層の重みの行列は、分散表現のベクトルが並んだ行列になります。 CBOWとskip-gramの比較この辺は別記事で実際に比較評価をしてみようと思います。 一般論としては、CBOWよりもskip-gram方が、学習に時間がかかるが精度がよい、とされているようです。 この辺も後々、検証してみたいと思います。 参考にした記事等 分散表現(単語埋め込み) - 岩波データサイエンス [自然言語処理/NLP] Word2Vec触ったので備忘録としてざっくりまとめておく (理論編) | Developers.IO Word2Vecを理解する - Qiita 【まとめ】自然言語処理における単語分散表現（単語ベクトル）と文書分散表現（文書ベクトル） - Qiita 以下のUdemyのコースはとてもオススメa8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/04/18/word2vec-overview/"},{"title":"Dockerとは何か、メリット&#x2F;デメリットまとめ","text":"✓目次 この記事の対象者 仮想環境とは Dockerとは 従来の仮想化とコンテナ型仮想化の違い ホスト型仮想化 vs コンテナ型仮想化 その①：「仮想化のオーバーヘッド」 その②： 「アプリケーション実行の再現性」 その③： 「OSの自由度」 その④： 「分離レベル」 DockerイメージとDockerコンテナ Dockerイメージとは Dockerコンテナとは [参考]Docker Hubとは まとめ この記事の対象者 ・ 「仮想化」、「Docker」、聞いたことあってなんとなくわかるけど、ちゃんと理解していない気がする人向け ・ だけど細かい内容ではなく概要レベルで何なのか、何がうれしいのかを知りたい、という人向け 仮想環境とは シンプルに言ってしまえば、下図におけるゲストOSとアプリの部分を「仮想環境」と述べることが多いです。 ホストOSというのは、我々が普段使っているノートPCのOSを指します。 そのPCにOracle VirtualBoxとかVMWare Workstation Playerというソフトウェアをインストールし、その中にUbuntuとかCentOSと呼ばれるゲストOSを導入してアプリを動作させている、という構成の場合、ゲストOSからアプリのことを仮想環境といいます。 この辺りは、実際に環境構築して手を動かしてみるとよくわかると思います。 Dockerとは Docker社が提供しているコンテナ型アプリケーション実行環境を指します。 Docker自体はGoで作られており、Dockerには、Docker Community Edition(Docker CE)とDocker Enterprise Edition(Docker EE)が存在します。 Docker EEは有料版で、Docker CEは無償版になります。 有料版は、Docker社が認定したコンテナやプラグインが利用できたり、イメージのセキュリティスキャンが行われる等の恩恵が受けられます。基本的なDockerの機能は、無償版と有償版、共に利用できます。また、無償版は、さらに Stable版と、Edge版の2種類が存在します。 Stable版は4半期ごとにリリースされ、Edge版は1か月ごとにリリースされます。 最新版を使いたい場合は、Edge版を選択しましょう。 従来の仮想化とコンテナ型仮想化の違い 従来のホスト型仮想化とコンテナ型仮想化の違いは、コンテナ型仮想化は、ゲストOSを持たない、という点です。 ホスト型仮想化は、ハイパーバイザというミドルウェア上に各々のアプリを動作させるために、専有されたゲストOSを用意します。 一方、コンテナ型仮想化は、ゲストOSを必要とせず、ホストOSのカーネルを用いて(共有して)動作する仕組みを取ります。 ホスト型仮想化 vs コンテナ型仮想化 以下4つの観点で比較します。 ・ その①：「仮想化のオーバーヘッド」 ・ その②：「アプリケーション実行の再現性」 ・ その③：「OSの自由度」 ・ その④： 「分離レベル」 その①：「仮想化のオーバーヘッド」 ホスト型仮想化 リソース(CPUやメモリの使用率など)の面で、オーバーヘッドが多く、起動や停止に時間がかかる コンテナ型仮想化 コンテナは、アプリケーション実行に必要なものだけを含み、ホストOSのカーネルを使用するため、動作が速くリソースの使用率も少なくて済む。 その②： 「アプリケーション実行の再現性」 ホスト型仮想化 仮想マシンの環境の違いにより、アプリケーションが動作しなくなることが稀に発生する。 コンテナ型仮想化 特定のアプリケーションを動作させるために必要なものは、Dockerイメージにまとまっている。そのため、同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する。Dockerイメージについては後述します。 その③： 「OSの自由度」 ホスト型仮想化 仮想マシン上で任意のOSを動作させることができる。 コンテナ型仮想化 コンテナは、ホストOSのカーネルを使用して動作する。そのため、WindowsOS上で直接Linuxコンテナを動作させることはできない。その逆の、LinuxOS上で直接Windowsコンテナも動作させることもできない。 その④： 「分離レベル」 ホスト型仮想化 ハードウェアレベルで仮想化されており、ホストOSや仮想マシン間の分離レベルが高い。そのため、先ほどの図でいうVM1がVM2に影響を与える、といったことが起こりにくい。 コンテナ型仮想化 OSの機能を使用した仮想化は、ホスト型仮想化に比べて分離レベルが低い。そのため、要求されるセキュリティレベルが高いシステムを構築するには不向きと言われている。 外部から侵入されにくい設定や構成にし、不用意にパブリックなNWに公開しない点に注意する必要がある。また、不必要なパッケージをインストールしない、常にアップデートを心がけるなど、細かいケアが必要になる。 上記の記述を表でまとめると以下の通りです。 項目 ホスト型仮想化 コンテナ型仮想化 オーバーヘッド 多 少 アプリ実行の再現性 低 高 OSの自由度 高 低 分離レベル 高 低 DockerイメージとDockerコンテナ DockerイメージとDockerコンテナの違いを把握しておくことは、今後Dockerを実際に使ったり、kubernetesと言われるコンテナオーケストレーションツールを活用する際など、重要になってきます。 以降で簡単にまとめておきます。 Dockerイメージとは Dockerイメージとは、コンテナ実行に必要なファイルをまとめたファイルシステム Webサーバだったら、Apacheが既に含まれているもの。そのほかRubyの実行環境が入っていたりもする。要するに最初からパッケージ化されていて、実行環境を定義したもの。 aufsなどの特殊なファイルシステムが使用されている。aufs (AnotherUnionFS) は Linux のファイルシステムサービスであり、複数の異なるファイルシステム (ブランチと呼ばれる) のファイルやディレクトリ同士を透過的に重ねる (マージする) ことができる技術。 Dockerイメージを作成する方法は、基本的に、「ソースコードを作って、ビルドして、イメージを作る」という流れになります。 ソースコードというのは、Dockerfileというもので、必要なソフトウェアのインストールやアプリケーションの起動などのコマンド郡を記述したファイルです。 ソフトウェアのインストールやアプリケーションの起動というのは、例えば、pipコマンドでインストールしたり、所定のファイルをコピーしてコマンドを実行したり等です。 ビルドというのは、Docker社またはDockerコミュニティが提供しているOSのベースイメージ(CentOSやAlpine等のイメージ)に対して、Dockerfileでまとめた操作を実施することで機能を加えることを指します。そしてその結果として生成されるのが、自身で作成したDockerイメージになります。 Dockerコンテナとは Dockerコンテナとは、Dockerイメージを実行してできる実際の実行環境。 Dockerイメージが実行環境のテンプレートであり、Dockerコンテナは、このテンプレートを用いて構築された実際の環境、と理解しておけばよい。 [参考]Docker Hubとは Dockerイメージのレジストリサービス https://hub.docker.com Dockerイメージの公開、検索、ダウンロードができる。 自身のアカウントを作成することで、作成したイメージを公開することもできる。 具体的な使い方については、別記事で今後まとめられればと思います。 まとめ Dockerとは、Docker社が提供しているコンテナ型アプリケーション実行環境 従来のホスト型仮想環境との違いは、ゲストOSを持たない、という点 ホスト型仮想化ではなく、Dockerを活用するメリットは、「動作が速くリソースの使用率も少なくて済む」、「同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する」という点。 一方、ホスト型仮想化と比較した場合のデメリットとしては、「OSの自由度が低い」、「分離レベルが低く、セキュリティ面でケアが必要になる」という点 Dockerイメージはテンプレート。DockerコンテナはDockerイメージを実行してできる実際の実行環境。 Dockerを用いてRails開発環境構築方法もまとめているので参照ください 2020-12-29【Windows】DockerでRuby on Rails開発環境構築方法IT Dockerに特化した専門知識を身に着けたい方は以下がオススメ Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/03/14/Docker/"},{"title":"【ダイエットメニュー】プロテイン＋冷凍ブルーベリーが脂肪燃焼に最適だった","text":"脂肪燃焼したいなら、プロテインとブルーベリーが最適であることが分かったので記事にまとめていきます！ 在宅勤務でありながら、私はこの方法＋ハーフスクワットを朝にやったことで2ヶ月で5キロのダイエットに成功しました！ ✓目次 ブルーベリーで血管と脂質代謝の改善 [最強]早朝にプロテインと冷凍ブルーベリーのスムージーを飲んで筋トレする プロテイン＋冷凍ブルーベリースムージーの作り方 まとめ ブルーベリーで血管と脂質代謝の改善 本記事の内容は、アメリカの研究論文[1]による報告です。 ブルーベリーを1日当たり1カップ摂取すると、インスリン抵抗性の変化を伴わずに血管機能、脂質代謝の改善がもたらされることがわかりました。 また、その効果が持続することが示されました。 115名の男女の被験者を用意し、プラセボ郡を設けた上で6か月間の摂取により体に及ぼす影響を調査した研究になります。 プラセボ郡」というのは、被験薬に似せかつ薬効成分を含まない「偽薬」を摂取する人たちのこと。要するに「病は気から」っていうのをなるべく排除する取り組みですね。 ブルーベリーを一日あたり1カップ摂取した郡において、血管の拡張率が1.45%の改善、2.24%の動脈硬化指数の改善が見られたようです。 在宅勤務等で、体重の増加が心配な方は、ブルーベリーを積極的に摂取するのはいかがでしょうか。 報告論文 [1]Peter J Curtis, Vera van der Velpen, Lindsey Berends, Amy Jennings, Martin Feelisch, A Margot Umpleby, Mark Evans, Bernadette O Fernandez, Mia S Meiss, Magdalena Minnion, John Potter, Anne-Marie Minihane, Colin D Kay, Eric B Rimm, Aedin Cassidy. \"Blueberries improve biomarkers of cardiometabolic function in participants with metabolic syndrome—results from a 6-month, double-blind, randomized controlled trial\". The American Journal of Clinical Nutrition, Volume 109, Issue 6, June 2019, Pages 1535–1545, [最強]早朝にプロテインと冷凍ブルーベリーのスムージーを飲んで筋トレする なんで朝なんだろう？？ 朝は、体の中からすべての栄養素がなくなっている状態だからです。 これは、人間の体が活動するうえで必要とされるエネルギー源からひも解くと理解いただけると思います。 所説ありますが、人間の活動エネルギー源は主に以下3つにわけられ、1→2→3の順番で使われます。 1. 炭水化物（糖質） ↓ 2. 筋肉 ↓ 3. 体についた脂肪 これら1～3のエネルギーは、最初に「1.炭水化物」が使われます。 炭水化物からのエネルギーを使い切った後は、「2.筋肉」を分解して発生されるエネルギーを活用します。 「もうこれ以上筋肉の分解エネルギーは使えませんよ。」という信号が脳に届いたときに、やっと「3.体についた脂肪」をエネルギー源にするのです。 要するにおなかがペコペコで、筋肉を使った運動した状態でやっと体の脂肪がエネルギー源になるということか。これって結構しんどいなぁ。 そこで、朝食で炭水化物を取らずにプロテイン＋ブルーベリーのスムージーを飲むのが最適なのです。 加えてスクワットなどの筋トレをするとどうなるでしょうか。 寝起きは栄養枯渇状態なので炭水化物はないですよね。 そして、筋トレをして筋肉にダメージをあたえると、人間の脳では「筋肉を分解させてはいけない」という信号が送られます。 その結果、体についた脂肪で活動する状態になるのです。 なるほど！寝起きは栄養枯渇状態。そこに脂質分解を促進するブルーベリーと、筋肉分解を抑えるプロテインを摂取しつつ筋トレすれば、脂肪が効率的に燃やせるんだね！ プロテイン＋冷凍ブルーベリースムージーの作り方 以下の有名Youtuberのkatochan33さんの動画の3:10当たりで紹介されているように、ミキサーにプロテインと冷凍のブルーベリーを入れて混ぜるだけです。 甘さすっきりで、かつ冷凍のフルーツの冷たさで朝飲むと目覚めが良いです。 私は以下のアイリスオーヤマのジューサーを使用しています。Amazonで一番安いし使いやすい。 Amazonで最安！：アイリスオーヤマ ボトルブレンダー 600ml ホワイト IBB-600 プロテインは、正直好きなもので良いですが、ブルーべリーと相性がよく安価なプレーン味で良いのかなと思います。 国産のもので一番安い江崎グリコさんのプロテインを私は愛用しています。 プレーン味のプロテイン：グリコ パワープロダクション ホエイプロテイン高たんぱく低糖質 プレーン味 800g【使用目安 40食分】WPI たんぱく質含有率95%(無水物換算値)カルシウム 鉄 ビタミン マグネシウム Amazonで最安値のプレーンプロテインはこちらです。 Amazon最安！：リミテスト ホエイプロテイン 工場直販 国産 WPC PURE 1kg プロテイン LIMITEST (プレーン, 1kg) ブルーベリーは以下の国産の冷凍ブルーベリーが美味です！Amazonで国産の冷凍ブルーベリーは以下が最安です。 国産で最安！：南信州ここだに 長野県産 ブルーベリー 冷凍 国産 加工用 家庭用 (700g) まとめ 脂肪燃焼したいなら、朝起きて炭水化物を食べずにプロテインとブルーベリーのスムージを飲むが最適であることが分かりました！ よく読まれている記事 2020-01-11風邪予防はビタミンCとグルタミンのサプリメントが最強Health 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/2020/05/24/blueberries-improve/"},{"title":"【腰痛解消】人間工学に基づいた座椅子がリモートワークに最適過ぎた","text":"腰に優しい座椅子がほしいなぁ。 この記事では、 ・100%リモートワーク中の腰痛持ちITエンジニアによるオススメ座椅子を紹介します！ 記事の信頼性(自己紹介) omathin ・完全フルリモート勤務中のIT企業のアーキテクト|研究者. ・腰痛持ちだが本記事で紹介する座椅子を活用して腰痛解消！ 結論：産学連携 腰をいたわるヘッドリクライニング座椅子３ 以下の座椅子です。この椅子のおかげでリモートワークによる腰痛とおさらばできました！ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js\",\"msmaflink\"); msmaflink({\"n\":\"腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック\",\"b\":\"座椅子ヤマザキ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41uPBv7FFVL.jpg\",\"\\/41EvXO8MjfL.jpg\",\"\\/41lt8iYbQmL.jpg\",\"\\/41UFS55D9NL.jpg\",\"\\/31G3TSfbndL.jpg\",\"\\/31OgOTB38oL.jpg\",\"\\/41JOz8gi67L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016113HBU\",\"t\":\"amazon\",\"r_v\":\"\"},\"aid\":{\"amazon\":\"2391505\",\"rakuten\":\"2390941\",\"yahoo\":\"2391506\"},\"eid\":\"LQGK3\",\"s\":\"s\"}); リンク >>腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック この椅子が、なぜ腰痛とおさらばできるのかの理由を以下にまとめます。 ・人間の体の構造をデータ分析して作られている ・特許技術化された唯一無二の座椅子 ・製造会社の企業理念 腰痛にならない理由①：背骨のS字カーブをサポートする構造 理想の姿勢ってどんな姿勢なのかご存知ですか？？ 背骨がまっすぐの状態だと思いますよね。 実は違います。S字が理想なのです。 この椅子は、人間の理想の姿勢とされる背骨のS字カーブをサポートする構造になっています。 具体的には、腰が丸くならないようにお尻の後ろの隙間を埋め、背すじの自然なS字カープをサポートする構造になっています。 この正しいS字カーブの姿勢を座りながらにして実現させるために、「姿勢」と「座り心地」をデータで検証し、検証結果を踏まえて作られた椅子なのです。 腰痛にならない理由②：特許技術化された唯一無二の座椅子 この椅子の特徴であるS字カーブをサポートするの構造は、大学との共同研究によって開発されてます。 そしてこの構造は特許化されています。 つまりこの椅子と同じ構造の椅子は他に存在しないということです。 唯一無二の椅子なのです。 腰痛にならない理由③：製造会社の企業理念 この椅子は、株式会社ヤマザキという会社が製造しています。 歴史は長く、1963年創業の座椅子専門メーカーです。 会社概要｜国産 座椅子、フロアチェアーの専門メーカー株式会社ヤマザキ 社長あいさつでは以下のように述べられています。 株式会社ヤマザキは座椅子専門メーカーとして「腰の負担を軽減して楽に座るための座具」というコンセプトを第一に考え、①使う人の立場で考えた人間工学に基づく商品開発 ②産学共同研究による客観的な製品性能評価 ③自社工場での丁寧な品質管理この３つの方針を大切にして、楽に長く座れる「理想的な姿勢」を追求した座椅子の開発と生産に日々努力しています。 まさに、腰痛持ちの人のために作られた椅子といっても過言では有りません。 日本の歴史ある会社の努力によって生み出された椅子であることがおわかりになったかなと思います。 まとめ：腰痛持ちはこの椅子で決定 座り心地がとても良くてずっと座ってられます。 腰痛に苦しんでいると仕事も日常のクオリティオブライフが下がる一方です。 腰痛に悩んでおられる方はぜひこの座椅子を試していただければと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js\",\"msmaflink\"); msmaflink({\"n\":\"腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック\",\"b\":\"座椅子ヤマザキ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41uPBv7FFVL.jpg\",\"\\/41EvXO8MjfL.jpg\",\"\\/41lt8iYbQmL.jpg\",\"\\/41UFS55D9NL.jpg\",\"\\/31G3TSfbndL.jpg\",\"\\/31OgOTB38oL.jpg\",\"\\/41JOz8gi67L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016113HBU\",\"t\":\"amazon\",\"r_v\":\"\"},\"aid\":{\"amazon\":\"2391505\",\"rakuten\":\"2390941\",\"yahoo\":\"2391506\"},\"eid\":\"LQGK3\",\"s\":\"s\"}); リンク","link":"/2021/01/21/chair-remote/"},{"title":"[チートシート]minikube, dockerコマンドまとめ","text":"よく使うコマンドを一覧化しました。 ✓目次 Version確認 docker version確認 kubectl version確認 kubernetesクラスタを操作(minikube) minikube起動 minikube停止 状態確認 アドオン操作 アドオン追加 アドオン削除 アドオン一覧確認 リソース作成 リソース確認 リソース削除 Secretリソースのコマンド作成 Podに入ってコンテナ実行 Podとホスト間でファイル転送 ファイル転送(ホスト→Pod) ファイル転送(Pod→ホスト) Podの状態(概況)確認 Podのログ(詳細)を確認 Deploymentにおけるロールアウト履歴確認とロールバック ロールアウト履歴を表示 ロールバック dockerコマンド 指定されたイメージ取得 イメージ一覧 イメージ削除 コンテナ実行 コンテナ停止 コンテナ一覧 コンテナ削除(指定型) コンテナ削除(非指定型) コンテナ・イメージ削除 ビルド Dockerイメージの公開(DockerHub) Dockerイメージにタグ名追加 DockerHubへログイン DockerHubへ公開 Version確認docker version確認1$ docker version kubectl version確認1$ kubectl version kubernetesクラスタを操作(minikube)minikube起動1$ minikube start minikube停止1$ minikube stop 状態確認1$ minikube status ただし、実行環境がVirtualBoxではなくVMWare workstation等の場合は、--vm-driver=noneをコマンドの末尾に付与する必要がある。例えば、移動する場合は以下の通り 1$ minikube start --vm-driver=none アドオン操作 アドオンはminikubeに付属している機能で、様々なオプションを追加削除できる。 アドオン追加1$ minikube addons enable ADDON_NAME アドオン削除1$ minikube addons disable ADDON_NAME アドオン一覧確認1$ minikube addons list リソース作成 マニフェストファイルを作成したら、マニフェストファイルを指定してリソース作成/変更を行う オプション: -f &lt;filename&gt;: マニフェストファイルパス 例：kubectl apply -f hoge.yml 1$ kubectl apply -f &lt;filename&gt; リソース確認 作成したリソースを確認 オプション -f &lt;filename&gt;: マニフェストファイルパス TYPE: リソース種別(pod, replicasetなど) 例：kubectl get pod 1$ kubectl get [-f &lt;filename&gt; [TYPE]] リソース削除 指定したリソースを削除 オプション: -f &lt;filename&gt;: マニフェストファイルパス TYPE/NAME: リソース種別 or リソース名 参考（以下の-o wideオプションなどは、deleteコマンドにかかわらずgetコマンドでも使用可能。） -o [wide|yaml]: 出力形式を指定 wide: 追加情報の表示 yaml: YAML形式で表示 例：kubectl delete -f hoge.yml 例：kubectl get pod -o wide getコマンドに-o wideオプションを付与することでPodのIPアドレスが確認できる。 1$ kubectl delete [-f &lt;filename&gt;] [TYPE/NAME] [-o [wide | yaml]] Secretリソースのコマンド作成 Secretとは機微情報を扱うリソース。Secretのような秘密データは運用として手動登録になる。 引数: NAME: Secretリソース名 OPTION: --from-literal=KEY=VALUE: キーバリューペアを指定して登録 from-file=[KEY=]PATH: ファイルを指定して登録 1$ kubectl create secret generic NAME OPTION Podに入ってコンテナ実行 Podを作成後、作成したPodに入りシェル操作を行えるようにする。 引数: POD: 中に入りたいPod名 1$ kubectl exec -it POD sh Podとホスト間でファイル転送ファイル転送(ホスト→Pod) 指定されたファイルを指定された転送先に送る 引数: src: 転送元ファイル名/フォルダ名。ホスト側のカレントディレクトリからの相対パスでファイルを指定する。 pod-name: 転送先のPod名 dest: 転送先フォルダ名/ファイル名 例：kubectl cp ./hoge.txt debug:/var/tmp/hoge.txt 1$ kubectl cp &lt;src&gt; &lt;pod-name&gt;:&lt;dest&gt; ファイル転送(Pod→ホスト) 指定されたファイルを指定された転送先に送ります 引数: pod-name: 転送元のPod名 src: 転送元ファイル名/フォルダ名 dest: 転送先フォルダ名/ファイル名 例: kubectl cp debug:/root/hoge.txt ./hoge.txt 1$ kubectl cp &lt;pod-name&gt;:&lt;src&gt; &lt;dest&gt; Podの状態(概況)確認 Podがうまく動作しなかったときに必要となる。 引数: TYPE/NAME: リソース種別とリソース名を指定 例：kubectl describe pod/debug 1$ kubectl describe [TYPE/NAME] Podのログ(詳細)を確認 Podがうまく動作しなかったときに必要となる 引数: TYPE/NAME: リソース種別とリソース名を指定 —tail=n: 直近のnレコードだけ取得 例：kubectl logs pod/nginx 1$ kubectl logs [TYPE/NAME] [--tail=n] Deploymentにおけるロールアウト履歴確認とロールバックロールアウト履歴を表示 引数: TYPE: リソース種別 NAME: リソース名 1$ kubectl rollout history TYPE/NAME ロールバック ロールバックの実施 引数: TYPE: リソース種別 NAME: リソース名 —to-revision=N: 指定されたリビジョンに戻す。デフォルトは0(=直前の履歴) 1$ kubectl rollout undo TYPE/NAME --to-revision=N dockerコマンド指定されたイメージ取得 引数： NAME: Dockerイメージ名 TAG: タグ名。省略した場合はlatestになる。 例：docker image pull centos:7 1$ docker image pull NAME[:TAG] 省略コマンドは以下 1$ docker pull イメージ一覧 取得済みDockerイメージ一覧を表示 引数： なし 1$ docker image ls 省略コマンドは以下 1$ docker images イメージ削除 指定されたイメージを削除 引数： IMAGE: DockerイメージID [参考]Dockerイメージの削除にはdocker image pruneというコマンドもある。 これは、使われていないイメージを一括削除してくれるコマンド。 実際に作業するときは、このコマンドが使いやすい。 1$ docker image rm IMAGE 省略コマンドは以下 1$ docker rmi コンテナ実行 指定されたイメージを実行する 引数： OPTION -d:バックグラウンド実行 -it:shell実行する際に合わせて指定する 例：docker container run -it NAME sh -e KEY=VALUE: 環境変数を与える --name NAME: 実行時のコンテナ名を指定 -p CONTANER:HOST: コンテナポートをホストにマッピング COMMAND: 実行時に上書きしたいコマンド COMMANDは、Docker実行時にDockerコンテナに与えるコマンド。 例：docker container run -d nginx:1.17.2-alpine 1$ docker container run [OPTION] NAME[:TAG] [COMMAND] 省略コマンドは以下 1$ docker run コンテナ停止 指定したコンテナを停止する 引数: CONTAINER: コンテナID 1$ docker container stop CONTAINER 省略コマンドは以下 1$ docker stop コンテナ一覧 コンテナを一覧表示する 引数: OPTION -a: 停止中のコンテナも表示 オプション指定しない場合、起動中のコンテナのみが表示される。 1$ docker container ls [OPTION] 省略コマンドは以下 1$ docker ps コンテナ削除(指定型) 指定されたコンテナを削除する 引数: CONTAINER:Dockerコンテナ名 1$ docker container rm CONTAINER 省略コマンドは以下 1$ docker rm コンテナ削除(非指定型) 使用されていないコンテナを削除 引数: なし 1$ docker container prune コンテナ・イメージ削除 使用されていないデータを削除 引数: なし 1$ docker system prune ビルド 指定されたDockerfileを利用してDckerイメージを作詞絵 引数: OPTION: -t: イメージ名を指定する。「ユーザ名/イメージ名:バージョン名」で指定する形式が一般的 例：docker build -f hogehoge/test:v1.0.0 -f: Dockerfileの名前を指定する PATH: Dockerfileが保存されているパス 例:docker build -t test . 1$ docker build [OPTION] PATH Dockerイメージの公開(DockerHub)Dockerイメージにタグ名追加 引数: SRC_NAME: タグ付けしたいDockerイメージ名 TRG_NAME: 追加したいタグ名 1$ docker tag SRC_NAME[:TAG] TRG[:TAG] DockerHubへログイン 引数: -u USER: ユーザ名 -p PASSWORD: パスワード 1$ docker login [-u USER] [-p PASSWORD] DockerHubへ公開 引数: IMAGE_NAME: 公開したいDockerイメージ名 例：docker push hogehoge/test:v1.0.0 1$ docker push IMAGE_NAME[:TAG]","link":"/2020/03/22/commandsheat-docker-minikube/"},{"title":"【Python】Bubble Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Bubble Sortとは Pythonの基礎 [Python基礎]関数定義 [Python基礎]関数の引数と返り値の宣言 [Python基礎]関数アノテーション [Python基礎]__name__と__main__ [Python基礎]内包表記 Bubble Sortのコーディング まとめ Bubble Sortとはソートアルゴリズムの一種です。 要素の1番目と2番目を比較し、順番が逆であれば入れ換える。 次に2番目と3番目を比較して入れ換える。 これを最後まで行うと、最後の数だけが最小または最大の数として確定するので、確定していない部分について1つずつ減らしながら繰り返す。 詳しくは以下のWikipediaを参照ください。 バブルソート - Wikipedia 本記事では、プログラミングにおけるアルゴリズムの練習として、Bubble Sortアルゴリズムを実装したいと思います。 いきなり実装に入る前に、実装する上で必要なpythonの基礎もまとめていきたいと思います。 Pythonの基礎Bubble Sortをコーディングするために必要な、基本的なPythonの基礎をまずはまとめていきます。 [Python基礎]関数定義基本的な関数定義としては以下のようなコードがあります。注意点としては、def say_something()前にsay_something()と書いた場合、”関数定義がされてないよ”とエラーになります。pythonは、コードを上から読み込まれるためです。あと()をちゃんとつけましょう。 1234def say_something(): print('hi')say_something()# -&gt; hi ちなみに、print(type(say_something))とすると、say_somethingが何者なのかを確認することができます。 1234def say_something(): print('hi')type(say_something)# -&gt; function 返り値を返したい場合は、以下のようにreturnを用います。以下の例だと、sにhiが入り、返してくれます。 1234567def say_something(): s = 'hi' return sresult = say_something()print(result)# -&gt; hi 引数を用いれば、何度もif文を返さなくてOKになるので便利です。 12345678910111213141516def what_is_this(color): if color == 'red': return 'tomato' elif color == 'green': return 'green pepper' else: return \"I don't know\" result1 = what_is_this('green')print(result)result2 = what_is_this('red')print(result2)# -&gt; green pepper# -&gt; tomato [Python基礎]関数の引数と返り値の宣言関数は引数と返り値を明示的に宣言することができます。 123456def add_nums(a: int, b: int) -&gt; int: return a + br = add_nums(10, 20)print(r)# -&gt; 30 ここで、引数にあえてstringを入れてみます。 123456def add_nums(a: int, b: int) -&gt; int: return a + br = add_nums('a', 'b')print(r)# -&gt; ab 結果は、abという文字列を返します。 何を言いたいかというと、関数定義の際に、明示的にa, bにはintを宣言しているにも関わらず、aとbにstringを入れても、pythonはエラーを返してくれません。 この点は気をつけておきましょう。 [Python基礎]関数アノテーションPython3.0i以降では、関数アノテーションという仕組みが導入されました。 関数の引数や返り値にアノテーション（注釈）となる式を記述することができます。 1234567from typing import Union, Listdef func_u(x: List[Union[int, float]]) -&gt; float: return sum(x) ** 0.5print(func_u([0.5, 9.5, 90]))# 10.0 あくまでも注釈なので、コードが実行される際に型チェックは行われたりしません。 つまり、アノテーションで指定した型以外の引数を渡してもエラーになりません。 [Python基礎]__name__と__main__よく「おまじない」としてスルーされがちなコードですね。 pythonで関数を用いたコードを記述する際に、編集しているpythonファイルが他のコードからimportされて実行されないようにif __name__ = '__main__':を用いることが良しとされています。 作成しているコードが、プロジェクトの一部で使われることが想定される場合、関数を用いる場合は、以下のようにif __name__ = '__main__':を記述して関数を指定しましょう。 12345def main(): lesson_package.talk.animal.sing()if __name__ = '__main__': main() 詳しくは、Pythonのif name == “main“ とは何ですか？への回答 - Python学習チャンネル by PyQを参照ください。 [Python基礎]内包表記内包表記は、リストの要素を操作した上で、新しいリストを作成するための記法です。 通常、そのような処理はforやwhileによるループを使用しますが、内包表記を用いると、簡潔に記述することができます。内包表記は、以下の形式で記述します。 新たなリスト = [ 要素への処理 for 要素 in リスト] リスト内の要素を1つ1つ取り出して、要素への処理を実行した上で新しいリストを作成します。 123a = [1, 2, 3, 4, 5, 6]b = [c*3+1 for c in a] # aの要素を3倍して1を足し新たなリストを作るprint(b) Bubble Sortのコーディングまずは、数値のlistを扱いたいので、from typing import Listとしておきます。丁寧にアノテーションでlistを受け付けて、listを返す関数であるということを明示的に示しておきます。先述したとおり、指定した型に従った変数でなくてもエラーは返しません。 123from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: そして、数値のリストを作成し、bubble_sort()に引数として渡してあげます。 123456from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]:if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums) Bubble Sortの仕組みを考慮し、リストのindexの数を取り出したいので、lenメソッドを使い、indexの数を取り出し、それをprintします。 12345678910from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) print(len_numbers)if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums)# -&gt; 6 len_numbersを用いてループを回したいので、for文使います。 12345678910111213141516from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): print(i)if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums)# 0# 1# 2# 3# 4# 5 2つの数字を比較する回数は、今回でいうと6つの数字に対して、5回比較を行うため、len_numbers - 1回行えば良いことがわかります。 さらに、その回数は1回ずつ減っていくことから、len_numbers - 1 -iとすれば良いことがわかると思います。最初iには、0が入り、len_numbersには6が入るので、初期値は5になります。そしてループが回るごとに4, 3, 2, 1、となりますね。 123456789101112131415from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): for j in range(len_numbers - 1 - i): if numbers[j] &gt; numbers[j+1]: numbers[j], numbers[j+1] = numbers[j+1], numbers[j] return numbersif __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] print(bubble_sort(nums))# -&gt; [1, 2, 4, 5, 6, 8] もう少し大きな数字でもやってみます。内包表記を用いてlist内部で処理を記述します。 12345678910111213141516from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): for j in range(len_numbers - 1 - i): if numbers[j] &gt; numbers[j+1]: numbers[j], numbers[j+1] = numbers[j+1], numbers[j] return numbersif __name__ == '__main__': import random nums = [random.randint(0, 1000) for i in range(10)] print(bubble_sort(nums))# -&gt; [15, 218, 219, 230, 306, 308, 320, 390, 625, 876] まとめ本記事では、Bubble Sortというソートアルゴリズムを学びながら、以下のPythonの基礎を学びました。 関数定義 関数の引数と返り値の宣言 関数アノテーション __nameと__main__ 内包表記 アルゴリズムをより詳しく学びプログラミング力を高めたい方 以下の、Udemyのコースがおすすめです。セール時は、1200円で購入可能です。セール時でなくても、講師の方に、Twitterでクーポンコードの発行をお願いすれば、10$(1200円)で受講可能となります。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/2020/12/21/bubble-sort/"},{"title":"Djangoの開発環境をDockerで構築した後の初期設定","text":"Djangoでアプリを開発し始める際の初期設定をまとめていきます。 環境構築方法は、以下の記事を参照ください。 ✓目次 アプリの作成 settings.pyファイルに作成したアプリを記述する settings.pyファイルに.htmlファイルの配置場所を記述する プロジェクトのurls.pyにアプリのurls.pyファイルへのルーティングを記述する アプリにurls.pyファイルを作成する アプリのurls.pyにURLパスを設定 views.pyファイルに関数を定義 templatesに.htmlファイルを作成 localhost:8000/signupにアクセスする まとめ アプリの作成ここで言う「アプリ」というのは、一般的にいうスマホアプリとかWebアプリのことではありません。 Djangoが機能として備えているアプリです。 Djangoの構造は大きく分けて、プロジェクトとアプリという要素に分けられます。 ざっくりいうと、プロジェクトはそれぞれのアプリを統括する役割。 アプリは、個々の機能部という分担です。 環境構築の段階でプロジェクトは作成済なので、以下のコマンドでアプリを作成します。 terminal1docker-compose exec web python manage.py startapp hogehogeapp これでhogehogeappというフォルダと各種ファイルが生成されます。 プロジェクトとアプリに分けると機能を分割できるので、ごちゃごちゃにならなくて済むよ。複数人で開発する際も、データへのアクセスが分離されてカオスにならなくて済むね！ settings.pyファイルに作成したアプリを記述するsettings.pyファイルはプロジェクトフォルダ配下にあります。このファイルに、先程作成したhogehogeappというのを記述し、プロジェクトにアプリの存在を認識させます。 /examplepj/settings.py123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'hogehogeapp.apps.HogehogeappConfig'] 「INSTALLED_APPS」というのは、Djangoにおけるアプリケーションを意味しているんだね。adminと書かれているものは管理画面でauthは認証だよ。 settings.pyファイルに.htmlファイルの配置場所を記述するまずは、manage.pyファイルというファイルと同じ階層にtemplatesという空のフォルダを作成します。 次にsettings.pyファイルのTEMPLATESのDIRSにBASE_DIR / 'templates'と記述 /examplepj/settings.py123456789101112131415TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [BASE_DIR / 'templates'], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, },] プロジェクトのurls.pyにアプリのurls.pyファイルへのルーティングを記述するブラウザなどから送られるHTTPリクエストは、プロジェクトのurls.pyが受け取ります。 プロジェクトのurls.pyファイルは、受け取ったリクエストURLの文字列（リソースパス）を識別して、どのアプリのurls.pyファイルに送ればよいか振り分けます。 ここでは、いかなるURLリクエストにおいてもhogehogeappのurls.pyファイルの定義に従う記述にしておきます。 /examplepj/urls.py1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('', include('hogehogeapp.urls'))] アプリにurls.pyファイルを作成する作成したhogehogeappフォルダにはデフォルトでurls.pyが存在しません。 なので新規にurls.pyを作成します。コードはプロジェクトのurls.pyファイルのコードをコピペして以下のように編集します。 /examplepj/hogehogeapp/urls.py1234567from django.contrib import adminfrom django.urls import path, includefrom django.urls import pathurlpatterns = [ path('admin/', admin.site.urls),] アプリのurls.pyにURLパスを設定adminのpathは削除して、任意のURLパスを設定します。今回はsignup/というパスを作成します。 合わせて、これから作成するsignupfuncという関数も記述。 /examplepj/hogehogeapp/urls.py1234567from django.contrib import adminfrom django.urls import path, includefrom .views import signupfuncurlpatterns = [ path('signup/', signupfunc),] views.pyファイルに関数を定義signupfunc関数を記述します。 renderというのは、HTTPレスポンスオブジェクトをs買う制するモジュールです。 renderは引数と3つ必要とします。 request: リクエストそのもの '.html': templatesに作成したhtmlファイル '{ }': モデルのデータ or 任意に指定したデータ /examplepj/hogehogeapp/views.py123456from django.shortcuts import render# Create your views here.def signupfunc(request): return render(request, 'signup.html', {}) templatesに.htmlファイルを作成前に作成したtemplatesフォルダに、views.pyファイルに記述したsignup.htmoファイルを作成する。 適当に「hello world!」とでも書いておきましょう。 /examplepj/templates/signup.html1hello world! localhost:8000/signupにアクセスするブラウザでlocalhost:8000/signupにアクセスして、以下のような画面が出てくれがOKです。 まとめ本記事では、「Djangoの開発環境をDockerで構築した後の初期設定」というテーマでまとめました。 早速DjangoでWebアプリを開発していきましょう。 Djangoをより深く学びたい方へ(Udemyのオススメ講座) 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） こちらは大橋亮太先生のUdemy講座です。具体例をたくさん入れた解説が好評であり、「なぜ」の説明が丁寧です。 この講座を確認する","link":"/2021/01/23/django-startapp/"},{"title":"【特保＋楽痩せ食材】食べるだけで痩せる方法","text":"特保飲料と楽痩せ食材で簡単に痩せる方法を紹介。楽痩せこそが、リバウンドしない秘訣です。 この記事を見ている人は以下のような悩みがあるのではないでしょうか。 楽にやせたい 在宅期間中、なるべく運動せずに痩せたい。 バランスの良い食事が大事なのはわかるが、手間のかかる料理はしたくない or する余裕がない。 食べるだけで痩せる料理はどれも手間がかかる。怠け者の私でも実践できる良いものはないだろうか。 お金も時間もなるべくかけずに、食べるだけで痩せる食事を教えてほしい。 一つでも当てはまったら、この記事を読む価値はいくらかあると思いますので、お付き合いください。 かなりの怠け者でも継続して摂取できる食材、かつ、効果が示されているものを厳選してまとめております。 これから紹介する食材を摂取し、健康的な体を手に入れるだけでなく、リバウンドせずに体形をキープできるようになると思います。 ✓目次 本記事の対象者 本記事の信憑性 食材一覧 ✓焼き梅干し ✓ブロッコリースプラウト ✓特茶とからだすこやか茶 まとめ オススメ 本記事の対象者まずこの記事を読んでいる人の対象は以下とします。 医師からメタボリックシンドロームと診断された人 つまり、医学的に普通体系である人が、更に痩せて美しい体形を手に入れるための手法ではありませんので、ご注意ください。 とは言いつつも、実践すれば幾ばくか効果はあるかもしれないので、やってみる価値はあると思います。 本記事の信憑性現に私は、80kgから68kgまでこの方法で痩せました。 また私はビジネスサプリメントアドバイザーをはじめとした資格を持っており、栄養や食に関する知識があります。 そのため、これから紹介する食材がなぜ食べるだけで痩せるのかという理由も明確も示しながらまとめていきたいと思います。 食材一覧結論を言ってしまいます。以下が怠け者でも継続して摂取し続けられるお食事一覧です。 焼き梅干し ブロッコリースプラウト 特茶 からだすこやか茶W 以降は、作り方と効果が得られる理由をそれぞれまとめたいと思います。 ✓焼き梅干し焼き梅干しの作り方はとても簡単です。フライパンに少量の油をかけ、梅干しを投入し、少し焼き色がつくまで熱すればよいだけです。 「なんだよ、フライパンと加熱が必要だなんてめんどくさいじゃないか」 と言いたくなりましたよね？ なぜ焼き梅干しが怠け者向けなのかは、後々説明するとして、ひとまず、なぜ焼き梅干しが良いのかの理由を述べたいと思います。 梅干しには、「バニリン」という物資が含まれており、脂肪燃焼効果が備わっていることが分かっています。参考：脂肪燃焼作用 | 梅(梅干し)・バニリンの効能 | 紀州梅効能研究会 また梅干しには、バニリンによく似た「バニリングリコシド」という物質も多く含まれています。 このバニリングリコシドは、加熱することによって、バニリンに変化します。つまり、梅干しを加熱してから食べたほうが脂肪燃焼効果が高まるということです。 そしてさらに、ここが怠け者でも続けられるポイントなのですが、バニリングリコシドから変化したバニリンは、梅干しが冷めてもバニリングリコシドに戻らないということも明らかになっています。 つまり、、、 梅干しをまとめて加熱した後、冷蔵庫に入れても、バニリンが増えた状態を保つことができる ということです。 なので、梅干しを買ってきたら、全部の梅干しをフライパンで焼いてしまい、その後は冷蔵庫に入れ、隙間時間に食べればよいのです。 私は、朝起きたらとりあえず2粒。夜に小腹がすいたら1粒。みたいな形で食べています。 「塩分が気になる」という方は減塩の梅干しを用いる or 食べる量を控えめにするなどの工夫をしながら実施してみてはいかがでしょうか。 ✓ブロッコリースプラウトこちらは複数のメディアでも紹介されている食材ですね。 「スルフォラファン」という物質が、肝臓の働きを上げ、体質改善やダイエット効果があることが認められています。 怠け者でも続けられるポイントとしては、スルフォラファンを15g程食べた後、その効果が3日間継続する点です。 つまり 3日に1度、少し食べるだけで良い ということです。 また価格も安価でありお財布にも優しい点がGoodポイントだと思います。 サプリメントで手軽にスルフォラファンを取りたい、という方は以下がおすすめです。 ✓特茶とからだすこやか茶最後は、特保飲料の特茶とからだすこやか茶です。 「なぜ2種類なの？」と気になると思います。 理由は、特保飲料には、脂肪の燃焼を助けるタイプと脂肪の吸収を穏やかにするタイプの2種類が存在するということです。 特茶は、「脂肪の燃焼を助けるタイプ」であり、からだすこやか茶は「脂肪の吸収を穏やかにするタイプ」になります。 更に、からだすこやか茶Wは、脂肪だけでなく、糖質の吸収を穏やかにする効果もあるため、白米やラーメンが好きな方は特にこれを飲むことを推奨します。 そのため、私のお勧めは、以下のように飲み分けることです。 特茶→朝の通勤時に飲むからだすこやか茶→食事中 or 食後に飲む まとめ最後にまとめます。 怠け者向けの食べるだけで良いお食事は以下です。 焼き梅干し パックで買ったらまとめて焼いて、適宜食べる ブロッコリースプラウト 3日に1ど15g程度食べる。 特茶 朝にコンビニや自動販売機で買って飲む Amazonでまとめて買えば、ちょっとお得。 からだすこやか茶W コンビニなどで買って飲む Amazonでまとめてかえば、ちょっとお得。 その都度購入しても良いと思いますが、このような食品系は通販などでまとめて購入すると安く済みます。私は特茶やからだすこやか茶Wは、Amazonで購入しています。 ダイエットに成功すると、「もっと引き締まった体にしたい」という欲求が生まれてくると思います。そのような方向けの記事も、今後まとめていこうと思います。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです","link":"/2020/01/09/easy_diet/"},{"title":"マジメすぎると不幸になる話","text":"仕事はまじめに取り組まずにふざけたほうが成果も出るし評価も高くなる仕組みをご存じですか？ 研究結果に基づき、まじめにきっちり仕事をせずに遊び心を持って仕事をするほうが良いことが分かりました。 何のために仕事をしているのか？という疑問に対する答えが見つかるかもしれません。 目次 仕事は何のためにするのでしょうか？ 研究内容と結果 ユーモアは才能ではない まとめ 仕事は何のためにするのでしょうか？メンタリストDaiGoさんもYoutubeの中で以下のように述べています。 そもそも、仕事は何のためにしてますか？お金を稼ぐためですか？お金を稼ぐのは何のためですか？生きるためですか？生きるのって何のためですか？幸せになるためですよね。楽しく生きたいからみんな頑張っているわけですよね。不幸になるために頑張る人はいませんよね。でもこれってみんな見失うんです。私、講演会に呼ばれたりするときに、社長の人とかいっぱいいるんですが、よく聞く質問があるんですよ。「なんで起業したんですか？」って。するとですね、面白いことに、答えられない人が多いんですよ「お金が欲しいから」「成功したいから」って答える人がいるんですけど、「既にお金持ってるじゃないですか。成功してるじゃないですか。何が不満なんですか？」って聞きかえすんです。一見成功している人が幸せなのかというと必ずしもそうではなく漠然とした不安を抱えているんですね。 「何のために仕事をしているのか」という問いに対して、「生活のため」、とか、「仕事をするのは当たり前」というふうに、漠然と何気なく日常を過ごしている人は結構おおいのかな、と思います。 お金があって地位もある人が必ずしも幸せなのかというと、そうでもないな、と思う部分もありますしね。 結局、お金を稼ぐのも、仕事をするのも、幸せな状態でないと意味がないということだと改めて感じさせられます。 では、幸福になるためには何が必要なのでしょう、というのを調べてくれたのがチューリッヒ大学の研究なのです。 Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 研究内容と結果18歳～92最までのドイツ人4100名を対象にしたもので、全員にオンラインでアンケートを実施して、遊び心(Playfulness)が、幸福度に与える還元度を研究したものです。 要するに仕事でも人生でも遊び心を持って、悪い言い方するとふざけて生きている人と、まじめに生きている人とどっちの方が幸せなの？ という研究なんです。 遊び心の定義ですが、「ふざける」と述べましたがすべてを適当にやるというわけではないです。 例えば、自分が苦しい状況、まじめにやらなくちゃいけない状況、緊張している状況でも、周りに楽しさをふりまいたり、ユーモアを周りに与えたり、ということができるかどうか。目の前で起こっていることをいろんな視点で見て、面白さをもって、それを解釈することができるかどうか、ということです。 上手い突込みをいれたりとか、ちょっとぼけてみて周りから突っ込みが入る、みたいなユーモラスに会話ができる人っているじゃないですか。 一方で、上司の言うことを全部真に受けちゃったりとか、人に面白いことを言ったり冗談を言ったりすることをはばかるような人とか、仕事の時に冗談を絶対に言わない人、バカ話しないと決めちゃっている人とかいますよね。 それに対して遊び心がある人がどう影響を与えるかを調べたんですね。 結果として何が分かったかというと、遊び心をあらゆる場面で考えられる感覚は、すべての年齢に対してポジティブな体験を増やす、という効果が判明しました。 つまり、普段からユーモアをふりまいている人とか、ちょっと物事を嫌味にならない程度、反感を買わない程度でちゃかしたりとかができる人は、ポジティブな体験が増えたんですね。 つまり幸せになったということです。 ユーモアは才能ではないポイントは、ただユーモアを秘めている、だけではダメなんです。 少しでも良いから表に出す、というのが大事、とのことです。 笑いのセンスが必要というわけではなく、「茶目っ気があるなぁ」、とか、「遊び心があるなぁ」、というのを表現することが幸福感をあげる、ということなんです。 才能ではない、ということなんですね。 遊び心でを持って、ちょっとしたことを楽しむ、という姿勢が大事、という理解で良いと思います。 まとめ 「何のために仕事をするのか」の答えは、「幸せに生きるため」。今、自分は幸せだろうか。仕事で不幸になっていないだろうか、というのを自問自答してみるといいかもしれない。 仕事はまじめにやりすぎない。ちょっとしたことでもいいから遊び心を持つことが大事。 遊び心を持てることは才能ではない。ちょっとしたことを表現するだけでOK。 ユーモアのある人間に近づくためにオンライン学習をしませんか？ 遊び心を持てるようになれるには、自分のできることや引き出しを増やすことではないでしょうか。「本が苦手」、「毎日が忙しい」という方は、私も普段から取り組んでいるオンライン学習がおすすめです。プログラミングを例に、以下に記事をまとめているので、興味があれば読んでみてください。 エンジニアではなく、ビジネスや営業系の方は、以下の講座がおすすめです。私も受講しましたが、手書きで「誰に、どのような価値を、どのように提供すればよいのか」という思考法やフレームワークが学べます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWB6I0o\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/business_model/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1846780_8afd_2.jpg\"}}); ビジネスモデルを見える化しよう! その場で伝わる手書きの図解スケッチ 参考 Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 https://yuchrszk.blogspot.com/2016/08/blog-post_22.html https://www.youtube.com/watch?v=werZT4hc26A&amp;t=13s","link":"/2020/04/19/happy-method/"},{"title":"【Python】Insertion Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Insertion Sortとは Pythonの基礎について [Python基礎]while文 Insertion Sortのコーディング 別解 まとめ Insertion Sortとはソートアルゴリズムの一種です。 まず0番目と1番目の要素を比較し、順番が逆であれば入れ換える。次に、2番目の要素が1番目までの要素より小さい場合、正しい順に並ぶように「挿入」する（配列の場合、前の要素を後ろに一つずつずらす）。この操作で、2番目までのデータが整列済みとなる（ただし、さらにデータが挿入される可能性があるので確定ではない）。このあと、3番目以降の要素について、整列済みデータとの比較と適切な位置への挿入を繰り返す。 挿入ソート - Wikipedia Pythonの基礎についてInsertion Sortを実装するために必要なPythonの基礎知識は、以下の記事にもまとめていますので参照ください。 ここでは、上記の記事でまとめた基礎事項に加えて学んでおくべきPythonの基礎について整理します。 [Python基礎]while文whileはある条件が満たされる限り繰り返される処理を記述する際に使用します。 例えば以下のようなコードです。 123456789count = 0while count &lt; 5: print(count) count += 1# 0# 1# 2# 3# 4 注意すべきは、上記のコードでcount += 1の記述をせずに実行すると、無限ループが発生してしまう点です。 違う書き方としては、breakを用いた書き方があります。if判定に引っかかったら、breakされる、という内容です。 123456789101112count = 0while True: if count &gt;= 5: break print(count) count += 1# 0# 1# 2# 3# 4 また、continueを活用した方法もあります。continueは、一言でいうと、「次の文を飛ばして次のループに行ってください。」という命令になります。breakは完全に抜けるのに対して、continueは、continueの次の行をスキップしてコードを実行させるものになります。 123456789101112131415count = 0while True: if count &gt;= 5: break if count == 2: count += 1 continue print(count) count += 1# 0# 1# 3# 4 Insertion Sortのコーディングまずは関数を定義します。 123from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: 数字の配列を簡単に設定し、定義した関数に渡してあげます。 12345678from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums) 設定したlistの長さを取得したいので、lenメソッドを使って取得しrangeを用いてループ文を設定します。printでindexを表示してみます。 12345678910111213141516171819from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): print(i) if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums)# 0# 1# 2# 3# 4# 5# 6 Insertion Sortアルゴリズムがどのようなものかを改めて確認します。まず、[4, 3, 2, 5, 7, 6, 1]というリストがあった時に、まず最初に、4と3を比較します。そのとき、前のindexの数字（今でいうと4）が、次の数字（今でいうと3）よりも大きかったら3をtempに一旦保管し、そうでなかったらそのまま、という処理をします。 そしてtmpに保管した数値と、その数値よりも前のindexに格納されている数値の大小関係の比較処理を繰り返し、tmpよりも小さかったらOK、という処理を繰り返します。 もう少しわかりやすく説明すると、ある程度処理が進んでリストとして[2, 3, 4, 5, 6, 7, 1]という状態になったとします。 同様の流れで、7と1を比較し、7の方が大きいので、1をtmpに一旦保管し、次に6とtmp(tmpは1)を比較して6のほうが大きいので次の5と比較し、5のほうが大きいので次の4と比較して・・・・という処理を繰り返し、最終的に、[1, 2, 3, 4, 5, 6, 7]という状態にするのがInsersion Sortでした。 まずは、indexが0である4と、indexが1である3を比較することを見据え、forループのrangeを1からlen_numbersの範囲にします。 123456789101112131415161718from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): print(i) if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums)# 1# 2# 3# 4# 5# 6 tempは、初期値はindexが1の数値なので、temp = numbers[i]としておきます。 そして比較対象の数値は、i - 1のindexに含まれている数値なので、これをjという変数に代入しておきます。 123456789101112from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums) ここでwhile文を用いて、jが0以上である限りループを回すようにします。こうすることで、index番号を徐々に小さくする処理を組めることになります。 123456789101112131415161718192021222324from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0: print(j, end=' ') j -= 1 print() if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums))# 0 # 1 0 # 2 1 0 # 3 2 1 0 # 4 3 2 1 0 # 5 4 3 2 1 0 # None ここで、jを用いて、数値を入れ替えるという処理を含めます。 12345678910111213141516from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0: numbers[j+1] = numbers[j] j -= 1 print() if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums)) この入れ替え処理をいつまでやるかというと、numbers[j]がtempよりも大きい限り処理を続けさせるので、while j &gt;= 0 and numbers[j] &gt; temp:という風にします。 numbers[j]がtempよりも大きい限りはj + 1番目の数値と、j番目の数値を入れ替えるという処理を繰り返し、tempのほうが大きくなったら、while文を抜けます。 123456789101112131415from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: # numbers[j] &gt; tempを追記 numbers[j+1] = numbers[j] j -= 1 if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums)) while文を抜けた後どうするかを考えます。tempの数値を挿入する箇所は、j+1番目です。tempはj番目の数値と比較し、j番目の数値のほうが数が小さい場合、tempは、j + 1番目のindexに値を挿入されることが望ましいためです。 そして、numbersというリストをreturnで返却します。 コードを実行するとうまくソートされていることがわかります。 12345678910111213141516171819from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: numbers[j+1] = numbers[j] j -= 1 numbers[j + 1] = temp return numbers if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums))# [1, 2, 3, 4, 5, 6, 7] 固定したリストではなく、randomを活用して試してみます。 1234567891011121314151617181920from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: numbers[j+1] = numbers[j] j -= 1 numbers[j + 1] = temp return numbers if __name__ == '__main__': import random nums = [random.randint(0, 100) for _ in range(10)] print(insertion_sort(nums))# [2, 7, 14, 18, 39, 50, 68, 69, 80, 98] うまくいきました。 別解以下のようなコードでも問題なくソートできました。 1234567891011121314151617181920212223from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): count = i while count &gt;= 0: if count == len_numbers - 1: break elif numbers[i] &gt; numbers[i + 1]: numbers[i], numbers[i + 1] = numbers[i + 1], numbers[i] count -= 1 else: count -= 1 return numbers if __name__ == '__main__': nums = [1, 3, 2, 5, 7, 6, 9] print(insertion_sort(nums)) まとめ本記事では、Insertion Sortを学びながら、以下のPythonの基礎を学びました。 While文 アルゴリズムをより詳しく学びプログラミング力を高めたい方 以下の、Udemyのコースがおすすめです。セール時は、1200円で購入可能です。セール時でなくても、講師の方に、Twitterでクーポンコードの発行をお願い、10$(1200円)で受講可能となります。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/2020/12/23/insertion-sort/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで②[手術後～退院まで]","text":"別の記事で、前十字靭帯再建手術後までの記事をまとめました。 本記事ではその続きとして、手術後1週間後の退院までのリハビリ等について、経験をまとめたいと思います。 以下のような悩みや疑問があれば、読んで損はないと思います。 そもそもリハビリに対してどのような気持ちで臨めばよいのか？ 手術直後のリハビリって何が辛い？痛い？ 手術直後のリハビリで気を付けることは？ 注意点ですが、以降は、あくまで私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的に担当の理学療法士さんや医師とも相談しながらリハビリは進めていただければと思います。 ✓目次 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる 手術後から退院までの1週間のリハビリ概要 松葉杖は思っていたよりも難しい 膝の皿動かし 足の上げ下げ 超音波当て EMS リハビリ以外で大事なこと①：アイシング リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない リハビリ以外で大事なこと③：入浴はできない リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請 まとめ 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる「リハビリ」というと、辛い、しんどい、地味な動きの繰り返し、ストレスが溜まる等、マイナスのイメージを強く持たれると思いますが、私はそうは思いません。 私が思うケガの治療以外にリハビリを行うことによって得られるメリットは、以下だと思っています。 正しい体の使い方を身につけられケガする前よりも高いパフォーマンスを発揮できる。 体の痛みや変化、ケガの予防に注意を払う習慣が身に付き、結果的に健康にスポーツができる期間を長くさせることができる。 なお、これらのメリットは私だけが感じていることではありません。 元プロ野球選手の小久保裕紀選手は、2003年に「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という、私とは比べ物にならないくらいの大けがを負いました。 しかし、懸命のリハビリを乗り越え、復帰直後の2004年に、キャリアハイの打率.314, 41本塁打, OPS1.013という成績を残しました。 加えて小久保選手は、この大けがのおかげで体のことを学び、練習法から食事の面まで見直すことができ、結果的に現役選手生活を伸ばすことにつながった、と述べています。 私自身も別記事でまとめていますが、リハビリを通じて、食事や栄養、ケガの予防について学ぶ良いきっかけになったと思っており、健康寿命を延ばすことにつながっているのではないかと感じています。 なので、ケガしたこと、リハビリをしていることに対して悲観的になる必要は無いのではないかと思います。 「より良い体作り、パフォーマンスを発揮するための特別なトレーニングに取り組んでいるんだ」という前向きな気持ちで取り組められることを願っております。 手術後から退院までの1週間のリハビリ概要以下に取り組みを退院まで毎日やりました。基本的に退院までは膝を無理に動かすようなリハビリは少なかったと思います。 松葉づえで移動する練習 平地 階段の上り下り 膝の皿動かし 上下左右斜め8方向まんべんなく手で動かす 足の上げ下げ 仰向けで足上げ 横向きで足上げ 超音波を当てる 手術の傷跡周辺をまんべんなく EMS 手術した後の膝は炎症が強いため、いかにこの炎症を抑えるかが目的になります。 また超音波などを活用して皮膚や関節内部の回復を促進する治療が行われます。 基本的には、受診されている病院様の計画に沿って進めていく形になりますので、異なる点はあると思いますが、私が経験したことベースで、辛かったこと/驚いたこと/大事にすべきことを中心にまとめたいと思います。 松葉杖は思っていたよりも難しいこの辺りは理学療法士の方のご指導に忠実に従いましょう。 トイレに自分で行けたりするように、まずは理学療法士の方と共に松葉づえで平地の移動と階段の上り降りの練習行います。 手術後の足は、「ニーブレース」と呼ばれる厚手のサポーターでガチガチ固められおり、足自体の自由も効かないため、思っている以上に重量があります。 そのため、松葉づえでの移動は、思った以上にかなり大変です。 特に階段の上り降りは、最初のうちは難しいです。 その中でも階段の下り移動は難しく危険なので最初のうちは一人で階段を使っての移動は控えたほうが良いと思います。 基本的にエレベーターを使うのが無難だと思いました。 またこの際、出血がある為だと思うのですが、松葉づえで歩くときのように、手術した足を心臓よりも低い位置に下すと、血液が足先にじわじわ溜まっていく嫌な感覚があります。 この嫌な感覚は、大体2～3週間くらいはあったと思います。 松葉づえでの移動は、正直体力的にかなりしんどいです。体重が両脇・腕に重くのしかかるので、両腕の筋肉痛がありました。 膝の皿動かし無理のない範囲で自分の指で手術したほうの膝のお皿をまんべんなく動かします。 手術したばかりなので最初は恐る恐る膝を動かしてみる感じです。 細かいやり方は理学療法士の先生に指導いただきながら実施していただければと思います。 足の上げ下げ横向きで足を10回～20回。うつ伏せで足を10回～20回上げるトレーニングを行います。 ニーブレースをつけているので足全体が重く結構きついです。 超音波当てスポーツ界では有名な伊藤超短波株式会社様の超音波機を手術した膝の傷口周辺に当てていきます。 これが実は周波数にもよるが結構いたかったです 膝の中からジワジワ熱を持った痛みが沸き起こってくる感じでした。 もちろん痛い場合は、周波数を下げる or 休み休み超音波を当てる感じで対応していました。もちろん痛いときは理学療法士の方に言いましょう。 超音波の専門家ではないので詳しいことはわかりませんが、膝の手術をした膝周辺は癒着が起こる場合があります。 超音波は幹部の治療を促進させるとともに、癒着を防いで関節の可動化を確保することを目的としているようです。 私はこの癒着がそれなりにあったので、この超音波治療を積極的に行いました。周りを見ると私だけでなく多くの人が各々の目的で超音波治療を受けていましたので、大半の人はこの治療を経験する可能性が高いと思います。 治療を受けた実感としては、確かに超音波を当てた後は、膝周りが軽いというか健康な膝に近づいた感覚が得られました。 しかしながら、前述した通り、なんともいえない痛みがともなうため、私はあまり好きではありませんでした。。。 EMS通販でおなじみの電流を流して筋肉を動かすやつです。 膝のお皿の上部に張り付けて、電流で筋肉を収縮させ、筋力をつけることを目的にした治療だったと思います。 基本的に前十字靭帯再建手術を受けた後のリハビリは、太ももの筋肉をつけることが主軸になります。 筋トレは、鍛えている筋肉の箇所を意識することが大事なので、太ももの筋肉に意識を集中させるのが大事だと思います。 リハビリ以外で大事なこと①：アイシング手術直後は膝の炎症を抑えるためにアイシングが重要になります。 退院後も積極的なアイシングが必要になるので、氷嚢は購入しておいたほうが良いと思います。 リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない例えば足を組んだり、手術した足に負荷をかけるような姿勢や動作をしないように注意を受けます。 もちろん地面に足をつけることもNGでした。 リハビリ以外で大事なこと③：入浴はできない入浴は浴槽に入る際に転んだりする危険性があるので基本的にNGでした。 シャワーも不可でした。 ただし、洗面台で髪の毛を洗うのは可能です。 体は濡れたタオルで拭く形で対応します。 夏は熱くて汗をかくので結構しんどかったです。。。。 リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請高額医療費控除や保険関連の書類、現金の対応が必要になります。 この辺は病院のスタッフの方や勤務先の会社、保険会社に問い合わせて、書類を用意しましょう。 まとめ リハビリは体の使い方や体のケアを学ぶ有益な取り組み。復帰後、ケガする前以上に高いパフォーマンスを発揮できたり、結果的に現役でいられる時間を長くさせる結果につながります。私自身がそうだったように、前向きな気持ちで取りくめば、良い結果が付いてくると思います。 手術後はしばらく安静。膝の炎症を抑えることが最優先。リハビリは基本的に膝の状態を見ながら理学療法士の指示に従い忠実に取り組みましょう。 松葉づえの移動では、階段の下り移動に気を付けよう。（階段を使うのはなるべく避けましょう） 超音波治療は地味に痛いが効果を実感できるのでちゃんとやったほうが良い。 アイシングが大事。靭帯に負荷をかけないように注意が必要。 入浴はできないが、洗面台で頭を洗うことは可能。 以上です。次は、松葉づえを卒業し本格的なリハビリに入るところをまとめたいと思います。以下にまとめました。 この機会に体質改善をしたい方向け 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/01/26/knee-surgery-2/"},{"title":"【入門】OpenShiftを用いてビルドとデプロイメントを行う方法","text":"✓目次 1. Githubにソースコードをpushしておく 2. OpenShift Web Consoleでプロジェクト作成と設定を行う 3. 作成したプロジェクトを確認する まとめ OpenShiftを実機で動かすための環境構築方法は以下を参考にしてください。 Dockerって何？ビルドって何？という方は以下の記事を参照いただければと思います。 1. Githubにソースコードをpushしておく 今回は簡単なデモなので、python on Flaskの簡単なコードをご自身のGithubリポジトリにおいておきましょう。この記事で使用するのは、以下のapp.pyファイルと、requirement.txtファイルの2つです。 app.py1234567891011121314import osfrom flask import Flaskapp = Flask(__name__)@app.route(\"/\")def main(): return \"Welcome!\"@app.route('/how are you')def hello(): return 'I am good, how about you?'if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", port=8080) requirement.txt1Flask 2. OpenShift Web Consoleでプロジェクト作成と設定を行うOpenShiftのWebコンソールを開き、ログインします。 今回は、pythonのプログラムを動かすので、pythonというカタログを選択します。すると以下のような画面が現れるので、nextをクリックしましょう。 プロジェクト名等を入力しましょう。これらは任意の名称で問題ありません。そして、Git Repository欄に、GithubリポジトリのURLを入力し、Createをクリックしましょう。 以下のように表示されれば、プロジェクトの作成と設定は完了です。 3. 作成したプロジェクトを確認する以下のように、Webコンソール画面の右側に作成したプロジェクトが表示されます。本記事の場合ですと、Python testというプロジェクトが、それにあたります。My Projectというのは、デフォルトで存在するプロジェクトであり、今回は使用しません。 作成したプロジェクトをクリックし、左側のメニューの「Builds」→「Builds」とクリックすると、自動的に作成されたビルド設定があることが確認できます。 「View Logs」をクリックしてログを確認してみましょう。以下のようになっています。 1234567891011121314151617181920212223242526272829303132333435363738Cloning &quot;https://github.com/xxxxxxxxxx/openshift-sample-app.git &quot; ... Commit: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (update) Author: xxxx xxxx &lt;xxxxxx@xxxx.com&gt; Date: Thu Dec 10 12:45:37 2020 +0900Using 172.30.1.1:5000/openshift/python@sha256:ac50754646f0d37616515fb30467d8743fb12954260ec36c9ecb5a94499447e0 as the s2i builder image---&gt; Installing application source ...---&gt; Upgrading pip to version 19.3.1 ...Collecting pip==19.3.1Downloading https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl (1.4MB)Installing collected packages: pipFound existing installation: pip 9.0.1Uninstalling pip-9.0.1:Successfully uninstalled pip-9.0.1Successfully installed pip-19.3.1---&gt; Installing dependencies ...Collecting FlaskDownloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)Collecting itsdangerous&gt;=0.24Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl Collecting Jinja2&gt;=2.10.1Downloading https://files.pythonhosted.org/packages/30/9e/f663a2aa66a09d838042ae1a2c5659828bb9b41ea3a6efa20a20fd92b121/Jinja2-2.11.2-py2.py3-none-any.whl (125kB)Collecting click&gt;=5.1Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)Collecting Werkzeug&gt;=0.15Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)Collecting MarkupSafe&gt;=0.23Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl Installing collected packages: itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, FlaskSuccessfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0WARNING: You are using pip version 19.3.1; however, version 20.3.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command.Pushing image 172.30.1.1:5000/python-test/python-flask:latest ...Pushed 0/10 layers, 3% completePushed 1/10 layers, 16% completePushed 2/10 layers, 23% completePushed 3/10 layers, 38% completePushed 4/10 layers, 40% completePush successful ログからは以下が読み取れます。 最初にGithubリポジトリのクローンを実施。 アプリケーションのソースと依存関係をインストール ビルドが完了すると、172.30.1.1:5000にある内部のDockerレジストリにイメージをプッシュ プッシュが完了すると、自動的にkubernetesのリソースの一つであるDeploymentが作成され、アプリケーションイメージのインスタンスが生成されます。kubernetesのDeploymentとは、Podの集合であるReplicaSetの世代管理ができ、ロールバックやロールフォワードができるものです。余談ですが、Podの集合として、StatefulSetというリソースもあります。Deploymentとの違いは、StatefulSetはPodをスケールする際の名前が一定である点です。 Webコンソールの左側のメニューのOverviewをクリックし、作成されたアプリケーションメニューをみてみると、外部アクセス用に生成されたRouteがあります。 これをクリックすると、Flaskアプリケーションが確認できます。これが、エンドユーザに提供するリンクになるわけです。 まとめデモで見たように、OpenShiftは、Githubにあるソースコードをダウンロードし、Dockerイメージをビルドし、それをDockerレジストリにプッシュし、Deploymentを作成してアプリケーションをKubernetesクラスタにデプロイしてくれます。 Openshiftは、インフラ管理タスクを抽象化したツールを提供することで、開発者がKubernetesベースのインフラ上でアプリケーションを簡単にデプロイして管理できるようにしてくれる、ということが分かったと思います。 また、Openshiftは、Githubのようなソースコード管理ソフトウェアとの連携も可能であり、アプリ開発、ビルド、テスト、デプロイを一貫して担ってくれることも分かったと思います。 もっと詳しく学びたい方へ - 以下のUdemyの講座で、OpenShiftの基礎を学ぶことができます。ビルド、ビルドトリガー、イメージストリーム、デプロイメントの理解などをハンズオンで学ぶことができます。Udemyは30日間の返金保証が付いているため、「ちょっと違うな。」と思ったら返金も可能なので気軽に試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sii7ibQ\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/learn-openshift/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1685508_5cbe_3.jpg?_DOhkU4tHD4sMV2ocoxcydj3RISUqG6hmRkxzTsyxkEw8boc6Fkl0w-awjeYUCaesvaeTxw_LK4rSDiqulHny6bun1wQVKSPbq64Erphfc-ErhgZeHCereo1vY30wHb4\"}}); [セール時は1200円]Dockerに特化した専門知識を身に着けたい方は以下がオススメ Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/12/10/openshift-builds-and-deployments/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで④[長い長いリハビリ]","text":"前の記事で松葉杖の卒業までをまとめました。 この記事では7か月続いたリハビリの内容をまとめるよ！ 以下のようなことを意識してまとめたいと思います。 ・ 復帰までの大まかなリハビリの内容 ・ 復帰を早めるためにリハビリ期間中に工夫したことと効果 ・ リハビリ期間中、辛かったことと乗り越え方 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 復帰までに取り組んだリハビリメニュー(全体像) 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ リハビリでつらかったこと その①：関節拘縮 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 関節拘縮の克服その3：膝伸ばしのリハビリ リハビリでつらかったこと その②：モチベーションの維持 リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 まとめ 復帰までに取り組んだリハビリメニュー(全体像) 大きく分けて２つのリハビリを頑張りました！ 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ 1. 膝の回復状態にかかわらず実施したリハビリ 膝の伸び具合のチェック マッサージ 超音波 電気を当てる ※本記事トップの写真 EMS 2. 膝の回復状態別のリハビリ 歩く練習 両足スクワット 両足を開いて片足スクワット 踏み出してスクワット 片足のみでスクワット 中腰で左右に移動・方向転換 ジャンプして両足着地 ジャンプして方向転換して着地 ジャンプして片足着地 片足ジャンプ 片足ジャンプして方向転換して着地 30％ダッシュ 50%ダッシュ 100%ダッシュ ダッシュからの片足・・・・ リハビリ、、、というかトレーニングだね。。。 リハビリでつらかったこと その①：関節拘縮 私の膝は手術した内部の癒着がひどく、リハビリ初期の段階で膝が伸びない状態が予定よりも長く続いてしまいました。 手術後などに関節の動きが制限されてしまうことを関節拘縮と言い、この状態になってしまったのです。 膝関節の中は連続した空間であり、ここに癒着が生じると関節可動域が制限されるのです。 場合によっては、再度、関節鏡視下手術を行い、膝内部の癒着を剥がす処置をしなければなりません。 これは、癒着しやすい人と、そうでない人がいるらしく、私は不幸にも癒着を起こしやすい体質だったようです。 癒着の厄介なところは、仮に癒着をはがす手術をしたとしても、再度癒着してしまう可能性もある点です。 このような懸念もあり、「なんとか工夫をして手術せずに膝の可動域を確保せねば」と思ったのです。 結果として私はこれから紹介する方法で、癒着の剥離手術をせずに膝の可動域を確保することができました。 その方法をまとめていきます。もちろん理学療法士の先生とも相談しながら取り組んでください。 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 美顔ローラーで膝の癒着部分を皮膚を吸い上げるような具合でコロコロさせると良いです。 これはかなり効果がありました。 癒着をはがすために、指で皮膚をつまみ上げる作業を行うのですが、なかなかしんどいです。 美顔ローラで皮膚を吸い上げることで、効率的に癒着をはがせます。 美顔ローラはこちら この方法は、理学療法士の先生に教えてもらった方法です。まさか、美顔器が膝の癒着回避に役立つとは思いませんでした。 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 皮膚を柔らかくする効果があります。膝全体をマッサージするように軟膏を刷り込んで癒着を取る努力をしました。 軟膏自体は、お医者様の診察を受けてから、処方していただいたほうが良いと思います。 関節拘縮の克服その3：膝伸ばしのリハビリ 以下の記事で掲載している膝の力入れリハビリです。 何度も何度も自宅で集中して全力でやりました。 私と同じように、癒着がひどい方は参考になればと思います。 先生からは、「膝伸ばしを頑張れば頑張るほど良くなる」と言われました。 リハビリでつらかったこと その②：モチベーションの維持 リハビリ期間中はプレーしたい思いが先行して、焦りの気持ちや悲観的になることもあると思います。 しかし、リハビリを通じて正しい体の動かし方や、ケアの仕方を学ぶ良いきっかけだと思い込むようにしました。 野球選手であれば、小久保裕紀さんの本はとても勇気づけられると思いますのでお勧めです。 小久保さんは、以下の記事にある通り、「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という大けがをしました。 辛いリハビリを乗り越え復帰し、キャリアハイの成績を残した方です。 「けがをしたことは不幸なことだったが、結果として栄養や体のことを学び、選手としての寿命を延ばす結果につながった。」という言葉は、とても勇気づけられました。 なお私自身もリハビリを通じて体のバランスやキレが良くなり、ケガをする前以上のパフォーマンスを発揮できています。 今思えば、このリハビリが自分にとって大きな学びを与えてくれたと思っています。 是非、前向きな気持ちでリハビリに取り組んでください。結果は必ず付いてくるはずです。 リハビリを真面目に頑張ることで、怪我する前よりも良いプレーができるようなるはず！ リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 リハビリは、筋力の回復が重要視されます。 リハビリの後は、直ちにプロテインを取るのが有効です。 以下の論文によると、タンパク質+炭水化物を摂取したグループが最も筋肉の肥大につながっているとされております。 L. Holm, B. Esmarck, M. Mizuno, H. Hansen, C. Suetta, P. Ho¨lmich, M. Krogsgaard, M. Kjær(2006). “The Effect of Protein and Carbohydrate Supplementation onStrength Training Outcome of Rehabilitation in ACL Patients”. Journal of orthopaedic research, 2114-2123 プロテインは、基本的に吸収効率が良いとされるホエイプロテインが良いとされています。 牛乳等を飲むと、おなかが痛くなる方とかは、アミノ酸(BCAA)が良いでしょう。 筋肉が作られる仕組みは、すでに多くのサイトなどでまとめられていますので詳しくはまとめませんが、基本的に筋繊維が破壊された後、30分間がもっとも吸収効率が高いと言われています。 リハビリが終わったら、30分以内にプロテインを飲めば良いんだね！ 摂取したたんぱく質が筋肉になる流れは以下の通りです。 1. タンパク質が分解されアミノ酸になる 2. アミノ酸がされに分解され代謝性物質になる 3. 代謝性物質が血液で循環され、壊れた筋肉に運ばれる 4. 代謝性物質がアミノ酸に戻りタンパク質となり筋肉になる そして、タンパク質を分解するときに必要になるのが、ビタミンだといわれています。 ここで私は思いました。 プロテインとビタミンが両方含まれたサプリメントがほしいな。 プロテインについて調べてみると、1000円くらいで買えるものから、10000円を超えるものまでピンキリです。 よくよく成分表をみてみると、安いものは、純粋にタンパク質の粉末のみのものだったり、人工甘味料を使ってコストが抑えられているものでした。 一方、10000円を超える高級プロテインは、タンパク質だけでなく、多くのアミノ酸、ビタミン、抵抗力を上げるグルタミン、人工甘味料不使用、等々、筋肉をつけるために計算された配合になっていました。 つまりは安かろう悪かろう、という感じです。 私としては、そんなにお金かけて購入したくないな、という一方で、人工甘味料は体によくなさそうだし、可能であれば味がおいしいものがいいな、と思いました。 そしてビーレジェンドのプロテインを購入しました。 プロテインはこちら このプロテインの成分表は以下の通りです。 これでタンパク質とビタミンが同時に取れる！ まとめ 膝の回復とともにリハビリはハードになる。 手術後の癒着で膝関節の可動域を確保するのが大変でした。 美顔ローラー、軟膏、膝伸ばしリハビリが有効でした プロテインを活用しよう。 回復が早いという研究結果の論文があります。 おすすめは、ビーレジェンドのプロテイン 美顔ローラはこちら プロテインはこちら 他のおすすめ記事 ダルビッシュ選手も実践する風邪予防サプリメントが知りたい方はこちら↓ 特保飲料と食べるだけで痩せられる食材を使った楽痩せメソッドを知りたい方はこちら↓","link":"/2020/04/11/rehabilitation/"},{"title":"【入門】Swagger EditorでOpen APIを作る","text":"✓目次 この記事の対象者 Open APIとは Open APIの基本要素「ルートオブジェクト」 簡単なAPIをつくってみよう まとめ この記事の対象者 ・ REST APIをSwaggerで作成したいが、1歩を踏み出せない人 ・ REST APIについてなんとなく理解している(GET, POST等のメソッドやステータスコードの使い分け等)が、設計→仕様書作成に踏み込めていない人 REST APIを設計する際に気を付けるべき主なポイントを以下の記事にまとめています。 Open APIとは そもそもOpen APIとは何かを説明します。 Open APIとは、WSDLやXMLと比較されるようなフォーマットを意味します。 このフォーマットを使うと、「機械可能なREST API仕様」が記述できます。 Open APIはJSONまたはYAMLで記述可能ですが、YAMLで記述するケースが多い気がします。 そしてこのOpen APIを記述するエディタがSwagger Editorです。 Open APIの基本要素「ルートオブジェクト」 Open APIをSwagger Editorで記述する際、ルートオブジェクトをしっかり把握する必要があります。 ルートオブジェクトとは、平たく言えば、YAMLで記述する際に最も階層が浅い部分に記載する要素です。 Open APIの主なルートオブジェクトは7種類存在し、そのうち3種類が必須項目となっています。 以下の通りです。 openapi:: 必須。Open APIのバージョンを指定するオブジェクトです。 info:： 必須。APIのメタデータを定義します。 servers:： これから記載するAPI仕様書において、APIがどのような環境で提供されるのかを定義したもの。APIを提供するサーバを定義します。 tags:: APIを分類するタグを定義する。 paths:: 必須。APIとして利用可能なパスおよび操作を定義する。 security:: API全体にかけるセキュリティ要件。 components:: Open APIの中で利用する様々なオブジェクトをコンポーネント化して再利用可能にする。 要するに、必須のルートオブジェクトである、openapi:, info:, paths:のみ記述しておけば、APIが作れるのです。 簡単なAPIをつくってみよう 今回は簡単な例として、GETメソッドで/messageというURLをたたくと、「Hello World」が返ってくるAPIを作ってみたいと思います。 インターネット上のSwagger Editorを用いてもよいですが、ここではVisualStudioCodeにSwagger viewerを導入した環境で作成を進めてみたいと思います。 VisualStudioCodeにSwagger viewerを導入する方法は、以下の記事を参照ください。 VisualStudioCodeを起動し、新規ファイルを作成しましょう。 ファイル名は何でも良いですが、openapi.yamlという風に、yamlファイル形式のものを作成しましょう。 まずは、先ほど整理したルートオブジェクトのうち、必須のオブジェクトを書きましょう。必須のオブジェクトは、以下の通りでした。 openapi.yaml12345678openapi: \"3.0.3\"info: title: \"Sample API\" # 必須 version: \"1.0.0\" # 必須paths: {} なお、info:オブジェクトは、APIのタイトルを記述するtitle:と、APIドキュメントのバージョンを記述するversion:の記載が必須となっているので注意してください。 ここで、SHIFT + ALT + PでSwagger viewerを表示してみましょう。以下のようになっていればOKです。 続いて、URLを記述していきます。今回は/messageというURLをたたくと「Hello World」が返ってくるAPIなので、paths:に&quot;/message&quot;と記述し、メソッドとしてGETを指定しましょう。 openapi.yaml12345678910openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: 次にレスポンスを記述していきます。 レスポンスの記述も同様にpathsオブジェクトの配下に記述をしていきます。responses:として&quot;200&quot;を指定しましょう。※エラーが出てると思いますがひとまず気にしなくてOKです。 openapi.yaml1234567891011openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": 次に「Hello World」という文字列データを返してくれるように記述しましょう。 これは、content:というオブジェクトを用います。 content:は、レスポンスボディ部を記述する箇所であり、メディアタイプやデータの型を指定できます。 今回はメディアタイプはJsonとし、返却するデータは”Hello World”という文字列なので、データの型はstringにしたいと思います。そして、データの例として”Hello World”を指定しておきましょう。 openapi.yaml12345678910111213141516openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": content: application/json: schema: type: string example: \"Hello World !\" これで完成！ではありません。 こちらのコードをSwagger Editorに張り付けてみると以下のようなエラーが出力されます。 エラーの内容をよく見ると、「レスポンス 200の部分に”description”というプロパティが必要だよ。」と記載されています。 descriptionとは、APIが操作する内容等の説明を記述する要素です。 というわけで指示通りに記述します。 openapi.yaml123456789101112131415161718openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": description: \"Sample API operation\" content: application/json: schema: type: string example: \"Hello World !\" これで完成になります。 今回はとても簡単な例でしたが、以上がAPIを作成する流れになります。 なお、OpenAPIの記述ルールは、以下のgithubで確認できます。各ルートオブジェクトごとに定義できる項目として、何が用意されているのかが気になる方はこちらを参照いただければと思います。https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md まとめOpenAPIを作成する際の大まかな流れは以下の通りです。 作成するAPIを設計する。 設計する際の主なポイントはこちらを参照いただくか、本ページ下部にあるUdemyの講座で学ぶことをお勧めします。 ルートオブジェクトを記述する。 必須項目であるopenapi:, info:, paths:の3つを必ず記述。 設計に従い追記。 githubに掲載されているオブジェクトを確認しながら追記。 [必見]Swaggerを用いてAPIの設計をしたい方に REST APIの設計を重点的に学びつつ、Swaggerを用いてOpenAPIを作成したい方は以下のUdemy講座がおすすめです。質、ボリューム共に豊富で、不明点もWeb経由で質問し講師が直接回答してくれるため、挫折する心配もありません。Udemyは30日間の返金保証が付いているため、「ちょっと違うな。」と思ったら返金も可能なので気軽に試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-seZAKTG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rest-webapi-development/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2641334_7977_6.jpg?tQnHFB7pu2rjtgmRqdDrZqHnUNTMsGAspswDZd7agOUondO9kbLFpMNfi87HFWc4E1gpBZmlURm7aQ1JvEWRcrcF20SfqIUhFhf5IBU0kYKMsSCOb3M0GImDyz3qvkQ2\"}});","link":"/2020/11/01/openapi-helloworld/"},{"title":"【Python】Selection Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Selection Sortとは Pythonの基礎について [Python基礎]range関数 Selection Sortのコーディング まとめ Selection Sortとはソートアルゴリズムの一種です。 データ列中で一番小さい値を探し、1番目の要素と交換する。次に、2番目以降のデータ列から一番小さい値を探し、2番目の要素と交換する。これを、データ列の最後まで繰り返す（厳密には、データ列の最後より1つ手前までの繰り返しでよい。一つ前まで交換済みであれば、最後（残り）は必ず最大値になるからである）。 選択ソート - Wikipedia Pythonの基礎についてSelection Sortを実装するために必要な知識は以下の記事にもまとめていますので参照ください。Bubble Sortの学習もしていただくと良いと思います。 ここでは、追加で学んでおくべきPythonの基礎について整理します。 [Python基礎]range関数例えば、1から9までの数字を表示しなさい、と言われた時に、num_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]とリストを作って、これを表示するコードを書いてもいいですが、面倒ですよね。 こんな時に、pythonのrange関数が役に立ちます。 12345678910111213for i in range(10): print(i)# 0# 1# 2# 3# 4# 5# 6# 7# 8# 9 では、リストの3番目から表示してほしい、という場合はどうするでしょうか？その場合は、以下のような書き方をすればOKです。 12345678910for i in range(3, 10): print(i)# 3# 4# 5# 6# 7# 8# 9 では、2つ飛ばしで値を表示してほしい、という場合はどうでしょうか？これも簡単で、3つめの引数に2と入れるだけです。 1234567for i in range(3, 10, 2): print(i)# 3# 5# 7# 9 これを応用して、10回’hello’という文字列を出力する事もできます。ここではついでにindex番号も出力しています。 12345678910111213for i in range(10): print(i, \"hello!\")# 0 hello!# 1 hello!# 2 hello!# 3 hello!# 4 hello!# 5 hello!# 6 hello!# 7 hello!# 8 hello!# 9 hello! また、for i in range(10)としてforループで10回ループを回した後、「もうiは不要ですよ」というのを明示的に示すために、_を用いたりします。 forループの中でもiを使う必要もありません。index番号を使わない場合は、このような書き方をしてもOKです。 12345678910111213for _ in range(10): print(\"hello!\")# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello! Selection Sortのコーディング基本的な思考の流れは、Bubble Sortの時と同じです。 まずは、Bubble Sortと同様、関数宣言します。 123from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: 次に、リストの定義と定義した関数にリストを渡し、range関数とlenメソッドを用いて、リストのindexをprintしてみます。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): print(i) if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums)# 0# 1# 2# 3# 4# 5 Selection Sortは、先頭の数字を取り出し、前から順番に数字の大小を比較し、もし先頭の数字のほうが大きかったら入れ替える、という処理を繰り返します。 まず、最初の数字のindexを取り出すために、min_index = iを追記します。printは削除します。 123456789101112from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums) forループで、先頭のindex番号を一つ先のindex番号から最後のindex番号まで、先頭の数字とそれ以降の数字を比較する処理を記述します。 123456789101112from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums) もし、先頭のindex番号に含まれた数字のほうが大きかった場合は、数字を入れ替えるので、以下のように記載します。そして最後にreturnでリストを返却します。結果をprintするとうまくソートされていることがわかると思います。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: numbers[min_index], numbers[j] = numbers[j], numbers[min_index] return numbers if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] print(selection_sort(nums))# -&gt; [1, 2, 5, 6, 7, 7] 最後に、randomを用いて大きめの数字でも試してみるとうまくソートできていることが確認できると思います。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: numbers[min_index], numbers[j] = numbers[j], numbers[min_index] return numbersif __name__ == '__main__': import random nums = [random.randint(0, 1000) for _ in range(10)] print(selection_sort(nums))# -&gt; [66, 167, 205, 242, 294, 319, 339, 629, 913, 976] 別海としては、min_index = jと記述して、数値比較の際に小さい方の数のindex番号を入れ替える処理をすることを明示的に示すコードの書き方もあります。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: min_index = j numbers[i], numbers[min_index] = numbers[min_index], numbers[i] return numbers if __name__ == '__main__': import random nums = [random.randint(0, 1000) for _ in range(10)] print(selection_sort(nums))# -&gt; [8, 9, 51, 268, 322, 413, 599, 780, 858, 996] まとめ本記事では、Selection Sortとは何かを理解し、Pythonの基本を学びながらコードを作成してみました。 Pythonの基礎としては、Bubble Sortで学んだ内容に加えて、range関数について学びました。 より詳しく学びたい方 以下の、Udemyのコースがおすすめです。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。講師の方に、Twitterでクーポンコードの発行をお願いすれば、10$(1200円)で受講可能です。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/2020/12/22/selection-sort/"},{"title":"REST API設計時に気を付ける主なポイント","text":"✓目次 この記事の対象者 APIの設計 リクエスト URIの設計 ①誰もが読んで意味が理解できる ②サーバー側の構造が見えないようにする ③ルールが統一化されている HTTPメソッド クエリパラメータとパスパラメータの使い分け レスポンス HTTPメソッドとステータスコード データフォーマット この記事の対象者 ・ REST APIの設計方法の概要を知りたい人 ・ REST APIについてなんとなく理解している(GET, POST等のメソッドやステータスコードの使い分け等)が、設計→仕様書作成に踏み込めていない人 APIの設計 APIの設計は、大きく「リクエスト」と「レスポンス」に分けて考えられます。APIの設計は、○○が最も望ましい！というようなものは存在しません。企業だったり提供しているサービスによって考え方はまちまちなのかなと思います。その中でも、API設計時に、特に意識したほうが良い点をピックアップして整理したいと思います。以降は、「リクエスト」と「レスポンス」に分けて、要点を絞って、API設計時の考慮ポイントを整理します。 リクエストリクエストの設計時に考慮することは主に以下の3点があります。 ・ URIの設計 ・ HTTPメソッド ・ クエリパラメータとパスパラメータの使い分け URIの設計そもそもURIとは何を表すものなのかというと、「リソース」を表現するものです。 リソースとは、基本的には名前が付けられているものはすべてリソースになります。 例えば、サーバー側に保持されているデータもリソースです。そのほかにも、ドキュメント、サービス、商品、状態・・・これらすべて「リソース」です。よく見かけるものとしては、latestというのがあると思います。これは「latest(最新)」という「状態」を表すリソースです。 一方、リソースとしないものとして、これも所説ありますが、「動詞」は含まないことが多いです。 こういった前提を踏まえて、URI設計時に気を付ける主なポイントを以下にまとめます。 ・ ①誰もが読んで意味が理解できる ・ ②サーバー側の構造が見えないようにする ・ ③ルールが統一化されている ①誰もが読んで意味が理解できる例えば、 http://example.com/r/u みたいに、rとかuみたいな何らかの単語が省略されたようなURIになっているのは、あまりよくありません。 http://example.com/resources みたいに省略せずに記載し、誤認識を防ぐような書き方をすべきと考えます。 また http://example.com/リソース という風なのも基本的にはNGです。 理由は、「リソース」というような2バイト文字を用いると、エンコードが必要となり、URLとしては、 http://example.com/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9 となってしまい、意味が理解できなくなってしまうためです。 この点も気をつけましょう。 ②サーバー側の構造が見えないようにする例えば、 http://example.com/resources.php?id=abcde というURLとすると、サーバーサイドでPHPが用いられているのではないか、と予測できてしまいます。 これにより、悪意のある人間が脆弱性を狙い、情報漏洩等のインシデントにつながる可能性があります。 なるべくサーバーサイドの情報や仕組みをURLには反映しないように気をつけましょう。 ③ルールが統一化されている例えばあるAPIではクエリパラメータを使用し、他のAPIではパスパラメータを活用していたりすると、ルールが統一化されておらず、APIを利用する人にとってフレンドリーではなく間違いが発生します。 具体的には、顧客情報の取得として GET http://example.com/customers?id=1234567 という風にクエリパラメータを使用しているのに対し、顧客情報の登録では、 POST http://example.com/customers/1234123 という風にパスパラメータで指定しているケースです。 この場合は、例えば両方ともパスパラメータを活用するように、統一化するのが望ましいと思います。 HTTPメソッド以下の4つを最低限抑えておけば良いと思います。 GET → 通常のアクセス、ページ表示、情報などのリソース取得 POST → データ送信、新規登録、等リソースの新規登録 PATCH/PUT → データの更新等、リソースの更新 DELETE → データの削除等、リソースの削除 PATCHとPUTの違いは以下です。 PATCHは、データが既に存在しているものにたいして更新をかける処理 PUTは、データが存在しているかどうかわからないときに使い、データが存在しているときは更新をし、データが存在していないときは新規作成を行う処理になります。 設計したURLに対して、これらのメソッドを適用することで、そのリソース自体に対する操作を切り替えることができます。 クエリパラメータとパスパラメータの使い分けリソースを一意に表す必要がある場合：パスパラメータを使用例えばユーザIDとかがそれにあたります。 リソースを一意に表す必要がなく複数パタンが考えられる場合:クエリパラメータを使用例えば検索条件を指定する場合、検索条件は複数パタンが考えられるのでパスには含めずにクエリパラメータを使用します。 以下に記事に分かりやすくまとめられておりますので、気になる方は参照いただければと思います。 [RESTful API]パスパラメータ、クエリパラメータ、リクエストボディの違いと設計 - Qiita レスポンスリクエストの設計時に考慮することは主に以下の2点があります。 ・ HTTPメソッドとステータスコード ・ データフォーマット この他、データの内部構造や、エラー表現など細かい点で気を付けたほうが良いことはありますが、まずは大枠としてこの2点のみ整理したいと思います。 HTTPメソッドとステータスコードステータスコードは、HTTPリクエストを行った後、受け取るレスポンスの最初の行に記載されている3桁の数字です。これにより処理結果の概要を把握することができます。 100番台から500番台まで存在しますが、基本的には100番台はそこまで使用せず、200番台から500番台までを使います。 詳細な意味はその都度検索して把握すれば良いと思いますが、大まかな意味としては以下の通りとなります。 200番台：成功 300番台：リダイレクト 400番台：クライアントサイドに起因するエラー 500番台：サーバーサイドに起因するエラー ステータスコードとメソッドの対応関係は、基本的には、以下の表にまとめている通りとなります。 ステータスコード GET POST PUT DELETE 200 OK 〇 〇登録データあり 〇データあり 〇 201 Created 〇データなし 〇新規作成データなし 202 Accepted 〇 〇 〇 204 No Content 〇更新データなし 〇 304 Not Modified 〇キャッシュ 400 Bad Request 〇 〇 〇 〇 401 Unauthorized 〇 〇 〇 〇 403 Forbidden 〇 〇 〇 〇 404 Not Found 〇 〇 〇 409 Conflict 〇データ重複など 〇ロックなど 429 Too Many Requests 〇 〇 〇 〇 500 Internal Server Error 〇 〇 〇 〇 503 Service Unavailable 〇 〇 〇 〇 データフォーマット主要なレスポンスフォーマットは2種類で、XMLかJSONになります。しかし、XMLにくらべてデータ量を減らせるJSONが主流なのではと思います。XMLのタグは末尾にも同じ文字が必要なため冗長な記述であり、JSONと比較してデータ量が多くなってしまいます。 REST APIの設計を詳しく学びSwaggerを用いてAPI設計をしたい方は以下がおすすめ REST APIの設計を重点的に学びたい方は以下のUdemy講座がおすすめです。質、ボリューム共に豊富で、不明点もWeb経由で質問し講師が直接回答してくれるため、挫折する心配もありません a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-seZAKTG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rest-webapi-development/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2641334_7977_6.jpg?tQnHFB7pu2rjtgmRqdDrZqHnUNTMsGAspswDZd7agOUondO9kbLFpMNfi87HFWc4E1gpBZmlURm7aQ1JvEWRcrcF20SfqIUhFhf5IBU0kYKMsSCOb3M0GImDyz3qvkQ2\"}});","link":"/2020/10/31/swagger-editor-design-firststep/"},{"title":"【pipが使えない？】Cloud9でtweepyをインストールする方法","text":"TwitterのAPIを利用するライブラリであるTweepyのインストール方法です。Cloud9環境で実施しています。確認できたエラー、それに対する対応についてもまとめています。 ✓目次 Twitter API登録 Cloud9でTweepyのインストール Cloud9の環境をPython3環境にする Tweepyをインストール Twitter API登録以下の記事が大変参考になります。 Twitter API 登録 (アカウント申請方法) から承認されるまでの手順まとめ ※2019年8月時点の情報 - Qiita customer API keys(API keyとAPI secret key)とAccess token、Access token secretを取得しましょう。 Cloud9でTweepyのインストール以降はAWSが提供しているIDE環境であるCloud9環境での手順になります。 Cloud9の環境をPython3環境にするまずは、cloud9の環境をpython3の環境に変更します。 でなければpipのバージョンとpythonのバージョンがあわなくて、tweepyがインストールできません。以下の記事を参考に、環境設定を行いましょう。 【Python】Cloud9上でPython3系を使うとき絶対にやっておくべき環境設定【AWS】 | Utarog Cloud9のターミナルで、python -Vコマンドを実施し、以下の状態になったらOKです。 12345ec2-user:~\\environment $ python -VPython 3.6.8ec2-user:~\\environment $ pip -Vpip 9.0.3 from \\usr\\lib\\python3.6\\dist-packages (python 3.6)ec2-user:~\\environment $ Tweepyをインストールtweepyをpip install tweepyコマンドでインストールすると、下記エラーになります。 12345678910111213141516171819202122232425ec2-user:~\\environment $ pip install tweepyException:Traceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\basecommand.py\", line 215, in main status = self.run(options, args) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\commands\\install.py\", line 342, in run prefix=options.prefix_path, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_set.py\", line 784, in install **kwargs File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 1064, in move_wheel_files isolated=self.isolated, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 345, in move_wheel_files clobber(source, lib_dir, True) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 316, in clobber ensure_dir(destdir) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\utils\\__init__.py\", line 83, in ensure_dir os.makedirs(path) File \"\\usr\\lib64\\python3.6\\os.py\", line 220, in makedirs mkdir(name, mode)PermissionError: [Errno 13] Permission denied: '\\usr\\lib\\python3.6\\dist-packages\\urllib3'You are using pip version 9.0.3, however version 19.3.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command. pipをpip install --upgrade pipコマンドで、アップグレードしなさい、というメッセージなので、 以下のコマンドでpipをアップグレード 1ec2-user:~\\environment $ sudo pip install --upgrade pip pipコマンドを実行してみると、なぜかpipが使えなくなってしまいました。 12345678910111213141516171819202122232425262728ec2-user:~ $ pipTraceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 658, in _build_master ws.require(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 972, in require needed = self.resolve(parse_requirements(requirements)) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 863, in resolve raise VersionConflict(dist, req).with_context(dependent_req)pkg_resources.VersionConflict: (pip 19.3.1 (\\usr\\local\\lib\\python3.6\\site-packages), Requirement.parse('pip==9.0.3'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"\\usr\\bin\\pip\", line 6, in &lt;module&gt; from pkg_resources import load_entry_point File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3049, in &lt;module&gt; @_call_aside File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3033, in _call_aside f(*args, **kwargs) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3062, in _initialize_master_working_set working_set = WorkingSet._build_master() File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 660, in _build_master return cls._build_from_requirements(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 673, in _build_from_requirements dists = ws.resolve(reqs, Environment()) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 858, in resolve raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The 'pip==9.0.3' distribution was not found and is required by the application whichコマンドにallオプションをつけてpipの場所を探します。 123ec2-user:~ $ which -a pip\\usr\\local\\bin\\pip\\usr\\bin\\pip pipのインストールディレクトリがおかしかったようです。 この場合、python -m pipという風に-mオプションをつければOKです。 12ec2-user:~ $ python -m pip -Vpip 19.3.1 from \\usr\\local\\lib\\python3.6\\site-packages\\pip (python 3.6) 改めてtweepyをインストール。 --userをつけてね、とエラーが出たので以下のコマンドでTweepyをインストールします。 12345678910111213141516171819202122ec2-user:~ $ python -m pip install tweepy --userCollecting tweepy Using cached https:\\\\files.pythonhosted.org\\packages\\36\\1b\\2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec\\tweepy-3.8.0-py2.py3-none-any.whlRequirement already satisfied: six&gt;=1.10.0 in \\usr\\local\\lib\\python3.6\\site-packages (from tweepy) (1.13.0)Collecting requests&gt;=2.11.1 Using cached https:\\\\files.pythonhosted.org\\packages\\51\\bd\\23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb\\requests-2.22.0-py2.py3-none-any.whlCollecting PySocks&gt;=1.5.7 Using cached https:\\\\files.pythonhosted.org\\packages\\8d\\59\\b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9\\PySocks-1.7.1-py3-none-any.whlCollecting requests-oauthlib&gt;=0.7.0 Using cached https:\\\\files.pythonhosted.org\\packages\\a3\\12\\b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379\\requests_oauthlib-1.3.0-py2.py3-none-any.whlCollecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 Using cached https:\\\\files.pythonhosted.org\\packages\\b4\\40\\a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539\\urllib3-1.25.7-py2.py3-none-any.whlCollecting idna&lt;2.9,&gt;=2.5 Using cached https:\\\\files.pythonhosted.org\\packages\\14\\2c\\cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9\\idna-2.8-py2.py3-none-any.whlCollecting certifi&gt;=2017.4.17 Using cached https:\\\\files.pythonhosted.org\\packages\\b9\\63\\df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99\\certifi-2019.11.28-py2.py3-none-any.whlCollecting chardet&lt;3.1.0,&gt;=3.0.2 Using cached https:\\\\files.pythonhosted.org\\packages\\bc\\a9\\01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\\chardet-3.0.4-py2.py3-none-any.whlCollecting oauthlib&gt;=3.0.0 Using cached https:\\\\files.pythonhosted.org\\packages\\05\\57\\ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704\\oauthlib-3.1.0-py2.py3-none-any.whlInstalling collected packages: urllib3, idna, certifi, chardet, requests, PySocks, oauthlib, requests-oauthlib, tweepySuccessfully installed PySocks-1.7.1 certifi-2019.11.28 chardet-3.0.4 idna-2.8 oauthlib-3.1.0 requests-2.22.0 requests-oauthlib-1.3.0 tweepy-3.8.0 urllib3-1.25.7 ちゃんとインストールされているか確認します。 インタプリタモードで確認します。 12345ec2-user:~ $ pythonPython 3.6.8 (default, Oct 14 2019, 21:22:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import tweepy Tweepyのversionも確認してみます。 12ec2-user:~ $ python -m pip list | grep tweepytweepy 3.8.0 Tweepyがインストールできていることが確認できました。 APIを活用したアプリケーション講座 Rubyでビットコインを自動で売買するプログラムを作成できるようになります。bitFlyerのAPIドキュメントをマスターし、１人で開発ができるようになります。こちらの講座もCloud9を活用しているので、複雑な環境構築などは不要です。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXJ0Y7e\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム 絶対に躓かないオンラインプログラミング講座「SkillHacks」もおすすめです。LINE@による無制限質問サポートで挫折しない仕組みができており、合計94本のしっかりした動画があります。他のプログラミングスクールよりも安くて手頃です。 -Skill Hacks- 動画で学ぶWebアプリ開発講座","link":"/2020/05/01/twitter-api-tweepy-error/"},{"title":"風邪予防はビタミンCとグルタミンのサプリメントが最強","text":"風邪予防に効果的なサプリメントは、ビタミンとグルタミンが最強です。 この方法を実践してから、私は5年間風邪で寝込んでいません。 体の抵抗力を上げて、毎日健康ですこやかな毎日を過ごしましょう。 「子供から良く風邪をうつされる」、「疲れが取れにくくなった」、「肌荒れが気になる」、といった悩みがあれば、参考になると思います。 目次 結論:ビタミンCとグルタミン 体の土台を作る：マルチビタミン＆ミネラル 免疫細胞のエネルギー源：グルタミン まとめ 参考 結論:ビタミンCとグルタミン 以下、2つのサプリメントを摂取しましょう。 1. マルチビタミン＆ミネラル** 2. グルタミン これは、プロ野球選手のダルビッシュ有投手も実践しています。 体が資本の超一流プロ野球選手も実践しているんだね！2つだけでいいなら続けられそう！ 5年前から私もこれらのサプリメントを取っているのですが、1度も風邪で寝込んでいません。 以降は、私が実際に摂取している製品と合わせて、各々のサプリメントを摂取する意義や摂取するタイミングについても簡単にまとめたいと思います。（怠け者の私でも続けられている方法なのでおすすめです。） 体の土台を作る：マルチビタミン＆ミネラル これを朝と夜に1粒飲むようにしています。 ビタミンが体を作る土台であるということは既にご存じの方も多いと思います。 ミネラルも取るべきなの？と思うかもしれませんが、個人的には取ったほうが良位と思います。 ミネラルであるカルシウムやリン、マグネシウムなどは骨や歯をつくり、鉄やリン、硫黄はたんぱく質や脂質などと結びついて体やエネルギーの成分になるからです。 また筋肉や骨、髪の毛、肌、内臓など、体を作り上げる成分の元となるたんぱく質等は、いったん代謝性物質に変換される必要があるのですが、この代謝性物質に変えるためにビタミンB群が必要になるようです。 つまり、 体を作るためにはビタミンC以外のビタミンB、そしてミネラルも必要 ということなので私は全部まとめて摂ってしまおうと思い、マルチビタミン＆ミネラルを摂っています。 ビタミンCだけ取れば良い、ってものじゃないんだね。バランスが大事！ 「いやいや、ビタミンCだけで良いよ。」という方はこちらからどうぞ。 免疫細胞のエネルギー源：グルタミン 「あの旨味成分のやつ？」と思われる人が多いですが、旨味成分と思われるものはグルタミン\"酸\"であり、グルタミンとは全く別ものだよ！ グルタミンは、非必須アミノ酸とよばれる体の中で作ることができるアミノ酸であり、簡単に言うと、体の中に入ってくる菌やウィルスと戦ってくれる免疫細胞のエネルギー源です。 菌やウィルスと戦ってくれる免疫細胞が生き生きと活動してくれれば風邪になりにくくなるというのは直感的にも理解しやすいと思います。 グルタミンの摂取方法は各々の生活スタイルに合わせて摂取すれば良いですが、基本的には朝と寝る前にグルタミンをスプーン一杯分を摂取すればOKです。 これだけで高い抵抗力を維持することができ、風邪にかかりにくくなります。 また寝る前にグルタミンを経口摂取することで成長ホルモンの分泌が高まる、という報告があります[1]。 成長ホルモンが分泌されると以下のような効果が期待できます。 1. 体脂肪の燃焼を促す。 2. コラーゲンの合成を高める。 つまり、風邪の予防だけでなく、ダイエットや美肌効果につながる、というまさに一石二鳥のサプリメントです。 「サプリメントで取る必要はあるの？」「非必須アミノ酸ならわざわざ経口摂取しなくても良いのでは？」という疑問を持たれるかと思いますが、結論としてはグルタミンはサプリメントで取るべきだとおもいます。 理由は2つあります。 1. グルタミンは普段の生活のストレスや運動で消費され、慢性的に不足状態になっていることが多い。 2. グルタミンを含む食品は生の魚やアーモンドが主であり普段の食事から補うのは難しい。 についていえば、例えば、普段からランニングをはじめとした運動が好きな人に限ってよく風邪を引く人って周りにいませんか？ 「運動」というのは、健康的なイメージを持たれると思います。しかしその行為自体は、筋肉にダメージや負荷を与える行為であり、肉体的にはストレスをかけていることと同じなのです。 普段から運動をしている人がよく風邪にかかってしまうのは、このグルタミンが慢性的に不足している状態になっていることに他ならないのです。 またグルタミンは運動だけでなく普段の仕事のストレスを感じることでも消費されます。 大きいストレスがかかると体調を崩すのも、グルタミンが消費され抵抗力が下がってしまうことが一つの原因であると考えられます。 は文字通りで、普段からお刺身などを食べる生活は現実的ではないですよね。 グルタミンが多く含む食品一覧は、以下の記事が参考になります。 参考 [1] Increased plasma bicarbonate and growth hormone after an oral glutamine load.Am J Clin Nutr. 1995 May;61(5):1058-61 強力な免疫を確保せよ！～グルタミンの多彩な効果とは | サプリメント最前線 | DESIRE TO EVOLUTION | DNS ZONE まとめ 風邪予防には、マルチビタミン＆ミネラルとグルタミンがおすすめ プロ野球選手（ダルビッシュ有選手）も推奨 グルタミンは体脂肪の減少や美肌効果も期待できる。 ビタミン、ミネラル、グルタミンは、普段の食事から摂ることは難しいためサプリメントを活用するのが現実的 朝と夜に、マルチビタミン＆ミネラル1粒づつとグルタミンを小さいスプーン1杯分飲めば良いんだね！こりゃ楽だ！ Amazonでマルチビタミン&ミネラルを買う AmazonでビタミンCを買う Amazonでグルタミンを買う 参考 楽痩せダイエットメソッドが知りたい方は以下の記事も参照いただければと思います。運動不要。怠け者向け よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/2020/02/10/vitamins-and-glutamine/"},{"title":"【自然言語処理】Attentionとは何か","text":"✓目次 本記事の対象者 Attentionとは Self-Attention SourceTarget-Attention Multi-Head Attention Masked Multi-Head Attention まとめ 本記事の対象者 ・ ニューラルネットワークの基本的な仕組みを理解している方 ・ RNNやLSTM、Seq2Seqを活用した自然言語処理に関する知識（one-hot表現、分散処理など）を理解している人 ・ Transformerを理解していることが望ましいです。 RNNの基礎を学びたい方はこちら↓ Transformerの基礎を学びたい方はこちら↓ AttentionとはAttentionとは、一言でいうと文章中のどの単語に注目すればよいのかを表すスコアです。 Attentionは、Query, Key, Valueという３つの要素に分かれて計算されます。 Queryとは、Inputデータであり、入力データの中で検索したいものを表します。 Keyとは、検索すべき対象とQueryの近さを図るために使用します。どれだけ似ているかを図るために使用します。 Valueとは、Keyに基づいて適切なValueを出力する要素です。 少し複雑ですが、Attentionとは何かをより詳しく見てみます。以下の図に、Attentionの構造をまとめます。 黒線の四角はベクトルまたはテンソルを示し、青い四角は処理を表しています。 Inputというのは、入力である文章に相当します。 当然、自然言語で記述された文章ではなく、単語の分散表現で一定の次元に変換されたベクトルに変換されたものです。 これを埋め込みベクトルと言ったりします。 具体的には、「好き」、「な」、「アニメ」、「は」といった単語に分けられ、それぞれの単語にidが割り当てられています。 Memoryというのは、Inputデータに対する元データになります。具体的には、「ドラゴンボール」、「が」、「好き」といった具体のものです。これも、各単語はidで表されます。 まず、Inputが全結合層で処理を行い、各単語のQueryを作成します。 そして、Memoryを全結合層に入れてKeyを作成し、QueryとKeyで内積を取っています。 内積を取ることでQueryとKeyの類似度/関連度を計算するのです。結果として、InputとMemoryの各単語の関連度を計算することができます。 そしてこの関連度は、Softmax関数に入れられます。 Softmax関数は、Sigmoid関数を使用しており、主に確率を表現するために使われる関数です。 Softmax関数を適用すると、値の範囲を0から1に収めることができます。 そして、0から1の範囲に収められた関連度が、attention_weightになります。これは、Memoryのどの単語に注意を向けるかの重みをつけることになります。 QueryとKeyのベクトルが似ていれば、Attention_weightは大きくなりそうでなければ小さくなります。 このようにして、このニューラルネットワークは、学習していくことになります。 また、memoryから全結合層を介して、Valueが作られます。Valueは、Memoryの各単語を表す埋め込みベクトルです。 この埋め込みベクトルをAttention_weightとの間で内積を取っています。 具体的にこの例で述べると、「ドラゴンボール」というValueにアニメに対するAttention_weightである0.7を掛けた値と「が」というValueにアニメに対するAttention_weightである0.03を掛けた値と、「好き」というValueにアニメに対するAttention_weightである0.34を掛けた値を全部足し合わせた値になります。 こうすることで、もっとも関連度の高い「ドラゴンボール」という単語をそのものを出力するのではなく、他の単語との関係性も考慮することができるということになります。 そして全結合層に入れて、outputを得ることができます。 Attentionというのは奥が深く、実はここで説明したもの以外の他に様々なタイプのものが存在します。 以降は主に、Transformerに関わる以下の4つに着目して整理します。 Self-Attention SourceTarget-Attention Multi-Head Attention Masked Multi-Head Attention Self-Attention Self-Attentionは、InputとMemoryが同一のAttentionです。 Self-Attentionは、文法の構造だったり、単語同士の関係性を得るために使われます。 SourceTarget-Attention SourceTarget-Attentionは、InputとMemoryが異なるAttentionです。 Transformerにおいて、Encoderの出力とDecoder側の入力からの流れで合流する箇所があるのですが、そこでSourceTarget-Attentionが用いられています。 Multi-Head Attention Multi-Head Attentionは、Attentionを平行に並べたものです。図における「V」はValueで、「K」はKey, 「Q」はQuery, です。 Concatというのは、結合を意味します。 そして、Multi-Head Attentionにおいて、それぞれのAttentionはHeadと呼ばれています。 なぜこのようにAttentionを並列に並べるのかというと、性能が向上するからです。 機械学習では、アンサンブル学習という分野があります。これは複数の機械学習モデルを並列に並べて機能させることです。これにより、性能が向上することが知られています。 Masked Multi-Head Attention Masked Multi-Head Attentionは、特定のkeyに対して、Attention weightを0にする処理です。 Transformerでは、Decoderで、このMasked Multi-Head Attentionが用いられています。Transformerで、Masked Multi-Head Attentionが行われる理由は、入力した単語の先読みである「カンニング」を防ぐためです。 そのため、入力に予測すべき結果が入らないように、情報をMASKで遮断し、未知のデータに対して正しく予測することができなくなることを防いでいるのです。 まとめ Attentionとは何か Attentionとは、一言でいうと文章中のどの単語に注目すればよいのかを表すスコアです。 Query, Key, Valueという３つの要素に分かれて計算され Query: Queryとは、Inputデータ。入力データの中で検索したいものを表します。 Key: 検索すべき対象とQueryの近さを図るために使用します。 Value: Keyに基づいて適切なValueを出力する要素です。 Attentionには複数の種類があり用途も様々 Self-Attention: InputとMemoryが同一のAttention。文法の構造だったり、単語同士の関係性を得るために使われます。 SourceTarget-Attention: InputとMemoryが異なるAttention。Transformerにおいて、Encoderの出力とDecoder側の入力からの流れで合流点。 Multi-Head Attention: Attentionを平行に並べたものです。Attentionを並列に並べて性能を向上させる。 Masked Multi-Head Attention: 特定のkeyに対して、Attention weightを0にする処理。入力した単語の先読みである「カンニング」を防ぐ。 参考文献 - Attention is All You Need, Ashish. V. et al, (2017) - [技術ブログ \\| アクセルユニバース株式会社](https://www.acceluniverse.com/blog/developers/2019/08/attention.html) より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら","link":"/2020/12/20/what-is-attention-1/"},{"title":"オブジェクト指向のクラスをシンプルに理解する","text":"プログラミングを学習すると、高い確率で「オブジェクト指向」という言葉に誰しもが悩まされると思います。 本記事では、とてもシンプルにオブジェクト指向のClassの使い方をまとめます。 実際にご自身のプログラミング環境で手を動かしながら勉強してみてください。 ✓目次 この記事の対象者 プログラミングの環境を用意しよう。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態 クラス(設計書)を作成する。 クラス(設計書)の項目にパラメータを設定する。 クラス(設計書)をインスタンス化(実態化)する。 インスタンスに名前と国と年齢を聞いてみる。 クラス（設計書）の設計項目を変数にする。 【発展】インスタンスが挨拶する関数を作ってみる。 【発展】call関数の使い方 最後に この記事の対象者 プログラミングを勉強し始めたがオブジェクト指向、クラス、インスタンスというのが良くわからない人 回りくどい説明が嫌な人 シンプルなコードで、ざっくりと理解したい人 プログラミングの環境を用意しよう。Jupyter Notebookという環境で説明します。 以下、この記事を読まれている方の思考に応じて、2パターンのプログラミング環境の用意の仕方を紹介します。 その1:自分のPCにプログラミング環境を用意したい人 以下の記事を参考に、ご自身のPCに環境構築してみてください。 その2：環境構築とか面倒、という人 Google Colaboratoryがおすすめです。 Google Chromeとgoogleのアカウントを持っていれば、ブラウザ(Google Chrome)のみでプログラミング環境が用意できます。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態様々な本で同じような説明がされていると思います。 ここからは実際に簡単なソースコードを活用しながらクラスとはどのようなものなのかを理解していただければと思います。 クラス(設計書)を作成する。設計書には、最低限以下の2つを定義しなければいけません。 設計書の名前 設計項目 具体的な例として、人間(Person)という設計書を作っていきましょう。 今回は以下のような設計書を作ろうと思います。 設計書の名前: Person 設計項目 名前: name 国: nationality 年齢: age 早速、Personという設計書として名前, 国, 年齢という3つの設計項目を用意してみます。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"\" # 名前 self.nationality = \"\" # 国 self.age = \"\" # 年齢 このコードをJupyter Notebookのセルに記載して、実行してください。 SHIFTを押しながらEnterキーで実行できます。 これで、「人間」というクラス（設計書）ができました。 クラス(設計書)の項目にパラメータを設定する。次に、この設計書の各項目に値を設定します。 設定する値は、以下のようにしたいと思います 名前：鈴木 国：日本 年齢：10 早速、先ほどの設計書の設計項目に設定していきましょう。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"鈴木\" # 名前 self.nationality = \"日本\" # 国 self.age = \"10\" # 年齢 これでOKです。 クラス(設計書)をインスタンス化(実態化)する。ここまで作ってきた人間クラス（人間の設計書）を実体化します。 これも簡単です。 1suzuki = Person() これで、「suzuki」というインスタンス(実体)が作られました。 これまで作ってきたPersonという設計書からsuzukiという名前の人間を作ったのです。 もちろん、suzukiという名前のインスタンスではなく、satoという名前でインスタンス化しても問題ありません。 1sato = Person() ただし、Personという設計書には、”佐藤”ではなく”鈴木”という名前が設定されていました。 それにもかかわらずsatoという名前でインスタンス化してしまうと、外見は佐藤なのに、名前が鈴木という変な人間が作られてしまいます。 これを解決する方法についても後述しますので、読んでみてください。 インスタンスに名前と国と年齢を聞いてみる。suzukiという人間と、satoという人間が作られました。 まずはsuzukiさんに名前を聞いてみましょう。以下のコードで名前を聞くことができます。 1suzuki.name Jupyter notebook環境だと、以下のようになります。 名前と国と年齢をまとめて聞く場合は以下のようにすればOKです。 123print(suzuki.name)print(suzuki.nationality)print(suzuki.age) すると、以下のように出力されるはずです。 satoというインスタンスにも名前を聞いてみます。 想定通り、satoさんにもかかわらず”鈴木”と返ってきました。 でもこれ不便だと思いませんか？ クラス(設計書)の各設計項目に、鈴木、日本、10(歳)、という風に設定しまうと、suzukiというインスタンスしか作れなくなってしまいます。 できるなら、satoの中には、”佐藤”という名前を設定したいし、katoの中には”加藤”という名前を設定してほしくないですか？ これを解決する手段として、クラス(設計書)の設計項目を変数にするというのがあります。 クラス（設計書）の設計項目を変数にする。ここまで作成してきたPersonクラスの各設計項目(名前、国、年齢)には、”鈴木”、”日本”、10と設定していたいましたが、これをnamae, kuni, toshiという変数を設定します。※変数名は何でもOKです。 以下のようになります。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = namae # namaeという変数を設定 self.nationality = kuni # kuniという変数を設定 self.age = toshi # toshiという変数を設定 もう少し改造が必要です。 def __init__(self):の部分に、先ほど設定した3つの変数を追記して、def __init__(self, namae, kuni, toshi):とします。 1234567class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi インスタンス化してみます。 今回は、katoでインスタンス化してみたいと思います。 1kato = Person() すると、以下のようにエラーになると思います。※安心してください、想定通りです。 なぜエラーになったのかというと、インスタンス化する際に、クラス（設計書）の設計項目に設定した変数に代入する値を設定していなかったからです。 つまり、インスタンス化する時は、クラスで規定したnamae, kuni, toshiに代入する値を()に記載しなければいけないということです。 今回は、katoというインスタンスを作成するので、各設計項目に設定する値は以下とします。 名前(namae): 加藤 国(kuni): 日本 年齢(toshi): 30 以下のようにしてkatoというインスタンスを作成しましょう。 1kato = Person(\"加藤\", \"日本\", 30) ついでに、mikeというインスタンスも作成します。 1mike = Person(\"mike\", \"アメリカ\", 20) こうすることで、kato.nameと実行すれば”加藤”というのが出力されますし、mike.nameと実行すれば”mike”というのが出力されます。 【発展】インスタンスが挨拶する関数を作ってみる。発展と言っても難しくないのでご安心ください。 作成したインスタンスに、「こんにちは井上さん。私は鈴木です。」という風な感じで、挨拶をする関数を実装してみます。 以下の通り、9行目と10行目を追記してください。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self): print('こんにちは井上さん。私は鈴木です。') 早速インスタンス化しましょう。 まずはsuzukiさんというインスタンスを作成します。各変数に代入する値の設定を忘れずに！ 1suzuki = Person(&quot;鈴木&quot;, &quot;日本&quot;, 1) 早速、suzukiに挨拶をさせてみましょう。 1suzuki.say_hello() 以下のようにちゃんと挨拶ができました。 では次にbobさんというインスタンスを作成しましょう。この際も、各変数のに代入する値の設定を忘れずに! 1bob = Person(\"ボブ\", \"アメリカ\", 70) bobに挨拶をさせてみましょう。 1bob.say_hello() 以下のように出力されます。 ここまで来たらある程度予測できたのではないでしょうか。 そうです、ボブなのに、「私は鈴木です。」と言ってますね。 理想としては、ボブだったら、「私はボブです。」と挨拶できるようにしたいですよね？ あと、「こんにちは井上さん。」の”井上”の部分も、設定に応じて柔軟に変化できるようにしたいです。 順序が逆になってしまいますが、まずは、「こんにちは井上さん。」の”井上”の部分を柔軟に設定できるように変数化してみたいと思います。 これを解決する方法は、以下のように、say_hello(self, namae):という風に、namaeという変数を追加し、print('こんにちは{}さん。私は鈴木です。'.format(namae))という風に変更/追記すればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は鈴木です。'.format(namae)) 改めて、bobさんというインスタンスを作成し、近藤さんに挨拶をさせてみましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)bob.say_hello(\"近藤\") 以下の通り、「こんにちは近藤さん。私は鈴木です。」という風に、井上さんが近藤さんに代わりました。 最後に、bobというインスタンスの場合は、「私はbobです。」に変換し、tomというインスタンスの場合は「私はtomです。」という風に出力させるように改造します。 まず、”鈴木”の部分を{}に変更しします。 そして、この中括弧に当てはまる変数ですが、ここはインスタンス化する際に設定する名前なので、5行目のself.nameを指定すれば良いです。 selfは”自分自身の”と言い換えればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行したら、早速bobインスタンスとtomインスタンスを作成しましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)tom = Person(\"トム\", \"アメリカ\", 120) bobとtomに挨拶をさせてみます。 1bob.say_hello('近藤') 1tom.say_hello('山本') 以下の通り、ちゃんと期待通りに挨拶する相手を呼び、自分の名前を言えるようになりました。 【発展】call関数の使い方ここからはさらに発展になるので、「もう限界です。」という方は、ここまででも大丈夫です。 call関数というのは簡単に言うと、関数名を呼び出さずに処理を実行させることができる関数です。 言葉で説明するよりか、実際の動作を見たほうが分かるので、早速使い方を見ていきましょう。 以下のように、__call__という関数名で、say_hello()関数と同様の処理を定義してみます。 12345678910111213class Person: def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi # call関数でsay_hello()を定義 def __call__(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行し、yamadaというインスタンス作成します。 1yamada = Person(\"山田\", \"日本\", 200) そして、yamada.sayhello('大和田')というコードと、yamada.__call__('大和田')というコードを実行してみると、共に、「こんにちは大和田さん。私は山田です。」という出力が得られます。 では次に、yamada('大和田')という風に、関数名を宣言せずに実行してみてください。 すると、同様に、「こんにちは大和田さん。私は山田です。」と出力されます。 つまり、yamada.__call__('大和田')という風にわざわざ書かなくても、yamada('大和田')とするだけで、同様の処理が実行されるのです。 以下の通りです。 便利な関数なので、積極的に使ってみましょう。 最後に 本記事では、クラス、インスタンスの関係に加えて、関数の定義方法やcall関数についてもまとめました。 プログラミング学習については、以下の記事でおすすめの教材や勉強方法をまとめていますので、興味のある方は読んでみてください。","link":"/2020/05/05/class-practice/"},{"title":"【M1 Mac】Djangoの開発環境をdocker-composeで作成する","text":"M1 MacでもDockerでDjango開発環境作れるの？という疑問に答えていきます！ ✓目次 この記事の対象者 この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 requirement.txtの作成 docker-compose,ymlの作成 Djangoプロジェクトの作成 DBの設定 起動 [参考]startappコマンド [参考]makemigrationとmigrateコマンド Dockerの停止 この記事の対象者 ・ M1 MacでDjango開発環境をDockerで構築したい方(Django 3.1.2 / PostgreSQL) この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 requirements.txtの作成 docker-compose.ymlの作成 Djangoプロジェクトの作成 DB(postgresql)の設定 起動 Docker Desktop for Macのインストール 以下の記事にまとめられているインストール方法で問題なく導入できます。Macbook Pro M1(Apple Silicon) で Dockerを動かす - Qiita インストールが完了したらバージョンと動作確認。 terminal12345$ docker --versionDocker version 20.10.1, build 831ebeae96$ docker-compose --versiondocker-compose version 1.27.4, build 40524192 Dockerfileの作成 まずは任意の空のディレクトリを用意して、Dockerfileを用意していきます。 この記事では``django``という名前の空ディレクトリを作ります。 terminal123$ mkdir ~/django$ cd ~/django$ vim Dockerfile docker-composeを使う場合、docker-compose.ymlがおいてあるディレクトリ名が、コンテナ名やvolume名の接頭字として使用されます。 実際の開発においては、プロジェクトの名前など、意味のあるディレクトリ名にしておいたほうが望ましいです。 例えば、ToDoアプリを作るプロジェクトなら、Todoapppjという名前のフォルダを用意したほうが良いということだね。 また、作成したディレクトリをビルドコンテキストとするので、不要なファイルは含めないようにしましょう。 Dockerfileでは、pythonの実行環境のイメージを作成します。 Dockerfile1234567FROM python:3ENV PYTHONUNBUFFERED 1RUN mkdir /codeWORKDIR /codeCOPY requirements.txt /code/RUN pip install -r requirements.txtCOPY . /code/ Dockerfileの中身を以下にまとめます。 FROM python:3: イメージ名にpython3の実行環境のイメージを指定 ENV PYTHONUNBUFFERED 1: PYTHONUNBUFFERED`という環境変数に1という値を設定している。環境変数の意味は、pythonの標準出力、標準エラー出力をバッファーにため込まないための設定。1という数字自体に意味はないがこの環境変数に何らかの値を設定するとバッファーを無効化できます。 RUN mkdir /codeとWORKDIR /code: codeディレクトリを作成し、作業ディレクトリをcodeディレクトリに移動しています。 COPY requirements.txt /code/: ビルドコンテキスト上に存在するrequirements.txtをcodeディレクトリ内に置き、RUN pip install -r requirements.txtでpipインストールを実行しています。pipはpythonのパッケージ管理ツールで、pip installコマンドは、-rで指定した、requirements.txtに記載されているパッケージのインストールを実行します。rewuirements.txtは、この後ビルドコンテキスト内に作成しますが、このファイルにはDjangoとPosgreのドライバのパッケージ名を記載します。 COPY . /code/: ビルドコンテキストの内容をすべて/code内に置いています。 requirement.txtの作成 terminal1$ vim requirements.txt requirements.txtは、pipインストールコマンドで、インストールするパッケージを定義したもの。 本記事作成時点で最新バージョンの、Djangoパッケージ3.1.2を指定します。 psycopg2は、pythonでPostgreSQLに接続するためにドライバです。こちらについてはバージョンの指定はしません。 requirements.txt12Django==3.1.2psycopg この時点でフォルダの中には、Dockerfileとrequirements.txtの２つのみが存在しているかな？この２つ以外のファイルがあったら別の場所に移すか削除しようね！ docker-compose,ymlの作成 docker-compose.ymlで最後だから頑張ろう！ terminal1$ vim docker-compose.yml docker-compose.yml12345678910111213141516171819202122version: '3'services: db: image: postgres environment: POSTGRES_PASSWORD: password POSTGRES_USER: postgres volumes: - pgdatavol:/var/lib/postgresql/data # postgresqlのデータ領域である/var/lib/postgresql/dataのディレクトリにマウント web: build: . command: python3 manage.py runserver 0.0.0.0:8000 volumes: - .:/code ports: - &quot;8000:8000&quot; depends_on: - dbvolumes: pgdatavol: # データ永続化のため、pgdatavolというvolumeを作成 各コードの意味を以下にまとめます。 services:: dbとwebの2つが定義されている。2つのコンテナが起動する想定。dbにはpostgresQLを使用。 buildには.が`定義されているので、先ほど定義したdockerfileからイメージをビルドして使用する command:: コンテナ起動時に実行されるコマンドを意味している。ここでは、python3でmanage.pyを実行し、引数に開発用に軽量なサーバを立ち上げるrunサーバとlistenするIPアドレス、ポート番号を指定している。manage.pyはDjangoをインストールすると自動で生成されるファイル。ただし、ここに記載しているコマンドはコンテナ実行時にコマンドが渡された場合に上書きされる。そのため、引数にコマンドを渡さなかった場合にdocker-composeのコマンドが実行される volumes:: カレントディレクトリを/codeにbindマウントしている。 ports:: 8000番で公開して、コンテナの8000番に転送されるように設定している。転送先のポートは先ほどのrunserverのlistenポートで指定した8000番と合わせる必要がある。 depends_on:: dbが指定されている。これはWebサービスを起動する前にdbサービスが起動するように依存関係を定義している。これによってWebサービスを起動する際は自動的にdbサービスが先に起動するようになる。 これで、コンテナを立ち上げる設定ファイルの準備が完了しました。 Djangoプロジェクトの作成 ここまで作成した、Dockerfile, requirements.txt, docker-compose.ymlの３ファイルのみが配置されているフォルダで、以下のコマンドを実行しましょう。 ここでは、プロジェクト名をexamplepjとしていますが、任意のプロジェクト名でOKです。 1$ docker-compose run web django-admin.py startproject examplepj . このコマンドは、今いるディレクトリに配置されたdocker-compose.ymlファイルで定義している「web」というコンテナに対して、\"django-admin.py startproject examplepj .\"というコマンドを実施してね、という命令を出しているんだね。 すると、examplepjフォルダとmanage.pyファイルがカレントディレクトリに自動生成されます。この時点で以下のようなディレクトリ構成になっていると思います。 tree123456789101112131415161718.├── Dockerfile├── docker-compose.yml├── examplepj│ ├── __init__.py│ ├── __pycache__│ │ ├── __init__.cpython-39.pyc│ │ ├── settings.cpython-39.pyc│ │ ├── urls.cpython-39.pyc│ │ ├── views.cpython-39.pyc│ │ └── wsgi.cpython-39.pyc│ ├── asgi.py│ ├── settings.py│ ├── urls.py│ ├── views.py│ └── wsgi.py├── manage.py├── requirements.txt DBの設定 作成されたexamplepjのsettings.pyファイルに、DBの設定を記述していきます。 /examplepj/settings.py1234567891011121314# Database# https://docs.djangoproject.com/en/3.1/ref/settings/#databasesDATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'postgres', 'USER': 'postgres', 'PASSWORD': 'password', 'HOST': 'db', 'PORT': 5432 }} PASSWORDは簡単なものにしているけど、ちゃんとした開発のときは注意しようね！ 起動デタッチドモードで各サービスを起動します。 terminal1$ docker-compose up -d localhost:8000にブラウザでアクセスすると、以下のようにDjangoの画面が表示されます。 おめでとう！これで開発できるね！ Djangoでアプリ開発する際の以降の初期設定は以下の記事を参照してください。 [参考]startappコマンド terminal1$ docker-compose exec web python manage.py （アプリ名） 例1$ docker-compose exec web python manage.py sampleapp [参考]makemigrationとmigrateコマンド makemigrationは以下のコマンドで実行できます。 terminal1$ docker-compose exec web python manage.py makemigrations 0001_initial.pyというファイルが作成されていれば成功です。 migrateコマンドは以下で実行できます。 terminal1$ docker-compose exec web python manage.py migrate Dockerの停止Dockerコンテナを停止する際は以下のコマンドで停止できます。 terminal1$ docker-compose stop Dockerコンテナの停止とイメージの削除をしたい場合は以下のコマンドです。 terminal1$ docker-compose down コンテナイメージの停止やイメージの削除をしても、データベースの情報は消えないので安心してくださいね！ あわせて読みたい記事 2020-01-11【プログラミング学習】Progateの後はUdemyかSkillHacksがおすすめIT 2020-03-14Dockerとは何か、メリット/デメリットまとめIT 以下のUdemyコースで専門知識をつけよう【30日間返金保証付き】 Djangoを基礎から学びたい方は以下がおすすめ。ものすごく丁寧な解説でDjangoの構造を解説してくれてます。 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-slHH1qM\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/django-3app/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2290835_ef37_3.jpg?iwC9RW_9PjLKmknE8irPPhLDsDPidR5qIrmzzfZqYa2cHJ2KrGBH2xKXJMMq_gF4S6654Vd0NbW7jcYjgNxBxM2fCvSoJeJ9FbJheiHecen7tTDUvew9J0N4qgcuUA\"}}); Dockerに特化した学習は以下のUdemy講座がおすすめです。Dockerに関する基礎から応用まで、この講座１つで問題ありません！ ゼロからはじめる Dockerによるアプリケーション実行環境構築 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)のシステムをKubernetesで作るなど、実践的なスキルが身につきます。 Docker + Kubernetes で構築する Webアプリケーション 実践講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}});","link":"/2021/01/10/docker-compose-django/"},{"title":"【Windows】DockerでRuby on Rails開発環境構築方法","text":"✓目次 この記事の対象者 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Dockerfile GemfileとGemfile.lock docker-compose.yml Rails開発環境の構築 まとめ この記事の対象者 ・ Windows10のPC(Windows10 Pro 64bit)でDockerを用いてRuby on Railsの環境を作りたい人 ・ Rails version: 5.0.0.1, Ruby version: 2.4.5, MySQL 5.7系の環境構築方法を知りたい人 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Windows10のPCにDockerを導入し、Ruby on Rails環境を構築する大まかな流れは以下のとおりです。 Docker for Windowsのインストールと再起動→再起動後、Dockerが起動しているかタスクバーのアイコンを確認 PowerShellを起動しdocker run hello-worldを実行してDockerが正常に動作するかを確認 任意の場所にフォルダを作成し、以下のファイルを用意する Dockerfile Gemfile Gemfile.lock docker-compose.yml 上記4つのファイルを用いてコンテナ起動 以降は主に、3. と4. の工程を中心にまとめています。 Dockerfile 所定のフォルダに以下のようなDockerfileを用意します。 Dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app Dockerfileには、Railsを実行するためのファイルやパッケージを、イメージに含めるための定義が書かれています。 このDockerfileがビルドされることで、Docker Imageというコンテナ仮想環境の雛形が作成されるのです。 ruby:2.4.5のコロンの前の部分を、リポジトリと言い、コロンの後ろを、タグといいます。 この場合、2.4.5のタグを書いています。 リポジトリには様々なバージョンがあります。詳細は、以下のDocker Hubを参照してみてくださいhttps://hub.docker.com/_/ruby?tab=tags&amp;page=1&amp;ordering=last_updated COPY . /appはDockerファイルの置いてあるフォルダの内容をすべてコンテナ内の/appディレクトリにコピーをしています。これは、Railsのアプリケーション実行に必要なファイルを、全てコンテナの中に含めるために記載しています。そのため、余計なファイルを含めてしまうと、コンテナに含まれてしまうので関係ないファイルは置かないようにしましょう。 GemfileとGemfile.lock Gemfile12source 'https://rubygems.org'gem 'rails', '5.0.0.1' GemfileはインストールするGemを定義しておくためのファイルです。 sourceには、GemのダウンロードもとのURLを記載しておきます。 そしてインストールするGemにはRailsのバージョンである5.0.0.1を指定しています。 このファイルが配置されているディレクトリで、$ bundle installコマンドを実行することで、RailsのGemをダウンロードして、インストールが実行されます。 Gemfile.lockは、最初の時点では空のファイルとなります。これは、通常直接編集するものではなく、$ bundle installを行った場合に、実際にインストールしたGemのリストとバージョンが自動的にGemfile.lockに配置されます。 Gemfile.lock1(空のファイル) Gemfile.lockの用途は、サーバや他の開発者のPCなど、別の環境で同じRailsアプリを動かす場合に、同じGemをインストールするために仕様されます。 Gemのインストールの際にはインストールするGemを動かすために必要な別のGemも一緒にインストールされます。 こういったあるライブラリーが別のファイブラリを必要としていることを依存関係といいます。 Gemのインストール時には、この依存関係の解決が行われ、関係する様々なGemがまとめてインストールされます。 依存関係も含めて何がインストールされたのかが、すべてGemfile.lockに記載されます。 そして、このGemfile.lockを別のPCやサーバに持って行って、bundle installコマンドを実行すると、Gemfile.lockに記載された内容にしたがって、Gemのインストールが実行される、というわけです。 docker-compose.ymlDocker-compose.ymlは、Dockerで複数のコンテナを、設定に従ってまとめて起動するために使用します。 Docker-compose.ymlは、Dockerで複数のコンテナを、設定に従ってまとめて起動するために使用します。 Railsを実行するコンテナとMySQLサーバを実行するコンテナの二つを起動する定義を記載してあります。 以下のようなコードが書かれたファイルを用意します。 docker-compose.yml123456789101112131415161718192021version: '3' # docker-compose.ymlのフォーマットバージョンservices: web: # Railsのコンテナ設定 build: . # docker-compose.ymlと同じディレクトリにあるdockerファイルを元にイメージを作成して使用することを意味している。 command: bundle exec rails s -p 3000 -b '0.0.0.0' # コンテナを起動した時にデフォルトで実行されるコマンド。TailsのWebサーバを起動するコマンドを記載。 volumes: # PC上のディレクトリをコンテナの/appディレクトリにマウント - .:/app ports: - 3000:3000 # コンテナの外部に3000番ポートを公開。コロンの左側がコンテナ外に公開するポート番号で、コロンから右側が、コンテナ内で転送されるポート番号になります。 depends_on: - db # Railsが起動する前にdbサービス、すなわちMySQLサーバが先に起動するように設定 tty: true # Railsでplyを使用してデバッグする際に必要な為、設定しています stdin_open: true # Railsでplyを使用してデバッグする際に必要な為、設定しています db: # MySQLサーバのコンテナ設定 image: mysql:5. # MySQLの5.7を使用 volumes: - db-volume:/var/lib/mysql # db-volumeという名前でPC上に作成した領域をコンテナの/var/lib/mysqlディレクトリにマウント。これを設定しない場合、データベースのデータは、直にコンテナ上に保存されますが、コンテナが削除された場合には、データも一緒に消えてしまいます。 environment: # コンテナに設定する環境変数を定義しています。環境変数とはOS上で保持される変数のことで、ここで設定しているMYSQL_ROOT_PASSWORDは、MySQLのrootユーザのパスワードを設定するために使用しています。 MYSQL_ROOT_PASSWORD: passwordvolumes: db-volume: Rails開発環境の構築 ここまで解説した設定ファイルを使用して、Railsの開発環境を動かしてみます。 まずは、解説したファイルを配置したフォルダでターミナルを開きます。Windowsを使用している方は、PowerShellを使用しましょう。 terminal123456$ cd documents/rails$ ls -l-rw-r--r-- 1 omashi 197121 365 2月 13 2018 docker-compose.yml-rw-r--r-- 1 omashi 197121 205 8月 22 19:16 Dockerfile-rw-r--r-- 1 omashi 197121 1748 8月 22 19:17 Gemfile-rw-r--r-- 1 omashi 197121 4404 8月 22 19:17 Gemfile.lock 以下のコマンドを実行します。 terminal1$ docker-compose run web rails new . --force --database=mysql docker-compose run webの部分は、docker-composeファイルに定義したweb:のRailsコンテナ設定を指しており、Railsのコンテナ上で、後ろに続くコマンドを実行することを意味しています。 --forceは既存ファイルを上書きするオプション。--database=mysqlはMySQLを使用する設定を明示的に示すオプションです。 実行が完了すると、Railsのファイルが作成されます。 terminal12345678910111213141516171819$ ls -ltotal 33drwxr-xr-x 1 user 197121 0 8月 22 19:17 appdrwxr-xr-x 1 user 197121 0 8月 22 19:17 bindrwxr-xr-x 1 user 197121 0 8月 22 19:17 config-rw-r--r-- 1 user 197121 130 8月 22 19:17 config.rudrwxr-xr-x 1 user 197121 0 8月 22 19:17 db-rw-r--r-- 1 user 197121 365 2月 13 2018 docker-compose.yml-rw-r--r-- 1 user 197121 205 8月 22 19:16 Dockerfile-rw-r--r-- 1 user 197121 1748 8月 22 19:17 Gemfile-rw-r--r-- 1 user 197121 4404 8月 22 19:17 Gemfile.lockdrwxr-xr-x 1 user 197121 0 8月 22 19:17 libdrwxr-xr-x 1 user 197121 0 8月 22 19:17 logdrwxr-xr-x 1 user 197121 0 8月 22 19:17 public-rw-r--r-- 1 user 197121 227 8月 22 19:17 Rakefile-rw-r--r-- 1 user 197121 374 8月 22 19:17 README.mddrwxr-xr-x 1 user 197121 0 8月 22 19:17 testdrwxr-xr-x 1 user 197121 0 8月 22 19:17 tmpdrwxr-xr-x 1 user 197121 0 8月 22 19:17 vendor ここでGemファイルに追記されたGemのインストールや作成されたファイルをコンテナ内に取り込むために、以下のコマンドで、もう一度ビルドを実行します。 terminal1$ docker-compose build ビルドが完了したらRailsで使用するデータベースの設定ファイルを編集します。ファイルはConfigディレクトリ内にあるdatabase.ymlになります。default:の項目にある、パスワードとホストを変更します。 パスワードは、docker-compose.ymlに記載したMySQL_ROOT_PASSWORD環境変数のpasswordに合わせる必要があります。ホスト名もdocker-compose.ymlに記載したMySQLサーバのサービス名であるdbに合わせます。 /Config/database.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# MySQL. Versions 5.0 and up are supported.## Install the MySQL driver# gem install mysql2## Ensure the MySQL gem is defined in your Gemfile# gem 'mysql2'## And be sure to use new-style password hashing:# http://dev.mysql.com/doc/refman/5.7/en/old-client.html#default: &amp;default adapter: mysql2 encoding: utf8 pool: 5 username: root password: password # この部分を変更 host: db # この部分を変更development: &lt;&lt;: *default database: app_development# Warning: The database defined as \"test\" will be erased and# re-generated from your development database when you run \"rake\".# Do not set this db to the same as development or production.test: &lt;&lt;: *default database: app_test# As with config/secrets.yml, you never want to store sensitive information,# like your database password, in your source code. If your source code is# ever seen by anyone, they now have access to your database.## Instead, provide the password as a unix environment variable when you boot# the app. Read http://guides.rubyonrails.org/configuring.html#configuring-a-database# for a full rundown on how to provide these environment variables in a# production deployment.## On Heroku and other platform providers, you may have a full connection URL# available as an environment variable. For example:## DATABASE_URL=\"mysql2://myuser:mypass@localhost/somedatabase\"## You can use this database configuration with:## production:# url: &lt;%= ENV['DATABASE_URL'] %&gt;#production: &lt;&lt;: *default database: app_production username: app password: &lt;%= ENV['APP_DATABASE_PASSWORD'] %&gt; 設定が完了したら、以下のコマンドを実行。のコマンドにより、RailsサーバーのコンテナとMySQLサーバのコンテナが起動します。 terminal1$ docker-compose up -d コンテナが起動しているか確認します。 terminal123456$ docker-compose ps指定されたパスが見つかりません。 Name Command State Ports--------------------------------------------------------------------------------rails_db_1 docker-entrypoint.sh mysqld Up 3306/tcp, 33060/tcprails_web_1 bundle exec rails s -p 300 ... Up 0.0.0.0:3000-&gt;3000/tcp 起動はしましたが、まだ開発環境用のデータベースが作成されていない状態なので、次のコマンドでデータベースを作成します。 terminal123456$ docker-compose run web bundle exec rake db:createStarting rails_db_1 ... done/usr/local/bundle/gems/activesupport-5.0.0.1/lib/active_support/xml_mini.rb:51: warning: constant ::Fixnum is deprecated/usr/local/bundle/gems/activesupport-5.0.0.1/lib/active_support/xml_mini.rb:52: warning: constant ::Bignum is deprecatedCreated database 'app_development'Created database 'app_test' これも先ほどと同様に、bundle exec以降がRailsのコンテナ内で実行されるコマンドです。 bundle exec rakeはRails環境にインストールされているrakeコマンドの実行を表しており、後ろにはdb:createと書いてあります。 rakeコマンドは、Railsで様々なタスクを実行する際に使用されるもので、rake db:createとした場合は、dbがまだ存在しない場合に新規に作成してくれます。 つまり、bundle exec rakeの部分は、Rails環境にインストールされているrakeコマンドを実行し、rake db:createでRailsで使用するデータベースをMySQLサーバ上に作成してくれます。 これで、Railsサーバにアクセス可能な状態になっているはずですので、ブラウザのURL欄にlocalhost:3000と打って開いてみましょう。 まとめ 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Dockerfile: Gemfile: Gemfile.lock docker-compose.yml 以下のコマンド、設定ファイルを編集して環境構築 $ docker-compose run web rails new . --force --database=mysql $ docker-compose build /Config/database.ymlを編集 $ docker-compose up -d $ docker-compose run web bundle exec rake db:create localhost:3000にブラウザでアクセス。 RailsとDockerの専門知識を身に着けたい方は以下がオススメ Ruby on Rails 5を使用した即戦力レベルのアプリケーション作成のスキルを身に着けることができます。Ruby言語の基礎から始め、Ruby on Rails5を使用したWebアプリケーションの開発方法について学びます。Railsの動作環境をDockerで構築する方法についても学びます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-skxv9Up\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rails-kj/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1497262_1c92.jpg?GWx9DbWnjp0BqiV4QmWg058nKfwbletKUaSEPdHrjzwwc2r7H-wOc7ywgZwkAf2FmIJuWFItn9Rb4VVChGfNro77USCLiDp0eI_Fb2Yp9nnVMFiXPKlsdKdOxnk\"}}); フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 Dockerに特化した専門知識を身に着けたい方は以下がオススメ Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/12/29/docker-ruby-on-rails/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで①[ケガ→手術→リハビリ開始まで]","text":"右膝前十字靭帯を断裂し、再建手術を受け、復帰に向けたリハビリに入る前までの体験談をまとめました。 以下のような関心事や分からないことがあれば読んでみても損はないと思います。 ・手術を決意した後、どのような流れで手術を迎えるのか、実体験を基にした具体的な流れが知りたい。 ・麻酔って、どんな感じなの？痛いの？ ・手術中や手術が終わった後って、どんな感じ？ ・細かいレベルで辛かったこと、痛かったことを知りたい。 私自身も、前十字靭帯の再建手術を受けました。 野球に復帰するまでは10か月くらいかかり、リハビリを卒業するまでは約1年3か月くらいかかりました。 ざっくりとした復帰までの流れは以下のとおりです。 ・2017年5月: 野球の守備で前十字靭帯を損傷 ・2017年5月～7月: リハビリ ・2017年7月: 再建手術・入院 ・2018年3月: 復帰※リハビリは続く ・2018年8月: リハビリ卒業 順調に回復し現在はケガする前よりも高いパフォーマンスが発揮できるくらいになりました。 復帰に向けたリハビリの際に自分なりに工夫したことなども、今後別記事にまとめたいと思います。 目次 手術を決意するまで 手術当日を迎えるまで 手術当日 翌朝 まとめ 手術を決意するまで ケガをしたときは「捻挫かな？」という感じでした。 それなりに歩けましたし、ケガした当日は車も運転しました。 しかし翌日になると、みるみる膝が腫れてきたため、急遽職場近くの病院に行きました。 医者にケガしたときの細かい動作や、ケガをしたときに感覚を伝えると、 前十字靭帯を切ってるかもね。 とのことでした。 「膝の関節に注射するから横になって」とすぐに言われたときは、心拍数はMAX。 注射の針は3cmくらいの長い針で、本当にビビりました。 注射自体はひどい痛みではありませんでした。口でゆっくり呼吸すると痛みが和らぐらしいです。 膝の中にたまった液体は、真っ赤な血液でした。 水ではなくて血だから、何らかの組織が損傷してるということだね。。。 注射1本分の血液量(たしか50ccくらい)だったと思います。 この時は絶望でした。 血液を抜いたあと、「痛み止めも膝に入れておくね。」と言われ、別の注射器で透明な液体を入れられました。痛み止めを入れてくれたはずなのに、気分が落ち込んだせいか、痛みが増した気がした。 ケガした膝をMRIで撮影し確認したところ、本来ならあるはずの靭帯がありませんでした。orz ”手術しない”という選択肢はあるのでしょうか。。。？ 私の問いに対して医師は、 前十字靭帯は、自然に治ることはほぼ無いんだよ。手術せずに運動したら変形関節症になって人工関節にしないといけなくなったり、歩けなくなるかもしれないよ？ ・・・・・わかりました、手術受けます（泣） 手術当日を迎えるまで すぐに手術なのかと思ったら、そうではありませんでした。 ケガによって委縮してしまった筋肉を、なるべくケガする前の状態に戻す必要があるためです。 なぜ手術前にリハビリが必要なのかは、病院のHPや専門の方がまとめている記事を参照いただければと思います。 私の場合、1か月後の7月に手術をするスケジュールで週に1回、3時間ほどのリハビリをしました。 内容は膝のマッサージ、スクワット(両足・片足)、ゴムチューブを使ったレッグカール(前と後ろ)が中心でした。 手術を受ける1週間前になると、手術の説明を受けます。 全身麻酔での手術になります。入院は1週間でその後は自宅で1ヶ月間、絶対安静でお願いしますね。手術の同意書とかその他の注意点は書類で渡すのでよく読んでおいてくださいね。 あと今日は、採血と麻酔のアレルギーのチェックしますね！ 採血と麻酔アレルギー検査のために、別室に連れていかれました。 麻酔アレルギーの検査は、ちょっと痛いので我慢してくださいね！ （え！？痛いの！？）わ、、、わかりました。 麻酔アレルギーの検査は、腕の皮膚と筋肉の間に少量の麻酔を打ち、アレルギー反応が起こるかどうかを確認するのです。 この麻酔注射は、採血よりも全然痛かったです。 思わず「いててててて！」と声に出してしまいました。。。 特にアレルギーはでなかったので、そのまま帰宅しました。 その後は、保険関連で用意したほうが良い書類とかを確認し、当日を迎えることになります。 手術当日 手術当時の朝は、飲み物を含む食事は禁止でした。（というか気分が落ち込みすぎて食欲なかった汗） 病院に向かう道中は、本当に憂鬱です。 麻酔は痛くないだろうか。全身麻酔から冷めなかったらどうしよう。術後の痛みどうなんだろう。 などなど。 このような気持ちになるのは正直仕方ないかと思います。 病院に到着すると、まずは入院する部屋に案内されます。 そこで、血圧を図ったり、体重を図ったり、膝の状態の確認をされます。マジックでケガしたほうの足に色々書かれます。 そして、麻酔を体に入れるための点滴針も入れられます。これはそんなに痛くなかったです。 体重計に乗って体重を図ったり、膝はどのくらい曲がるのか、等のチェックもその際に行います。 しばらく待機。 すると、 痛み止めの座薬を入れましょうね。私が入れましょうか？自分で入れます？ （ざ、、、座薬。。）じ、、、自分で入れます。。。 人差し指の第一関節くらいまで押し込んでくださいね！ 手袋とカプセル型の座薬を渡され、自分でその場でいれました。 （なんとも言えない微妙な空気。。。） そしていよいよ手術室に案内されます。手術室には、自分の足で歩いて手術台に横たわります。 〇〇さーん、気分はどうですかー。リラックスしてくださいね〜。 左腕にバンド巻きますね〜。 とか色々言われながら処置が進み、 じゃあ、麻酔入れますね〜。ちょっとグラグラしますよ〜。 と言われた瞬間に、天井がぐにゃぐにゃになりました(笑)※みんな同じ感覚なのかな。 そして気が付いた時には手術が終わってました。 ！？手術終わったの！？ 手術の時間も含めて、5時間くらい寝ていたと思います。 本当に時間の感覚無く、どれだけ時間がたったのかも分からないくらいの一瞬の出来事で少し恐ろしかったです。 麻酔がまだ少し効いてるので、意識は朦朧してるとおもいます。時間がたてば意識がはっきりしてくるので安心してくださいねー。何かあったらナースコールしてください。あと、手術したほうの足の足首は、頻繁に動かしてくださいね。 手術後の右足は出血状態が続いており、頻繁に足首を動かして血を循環させたほうが良いそうです。 間もなく先生からも半月板の状態はどうだったか、とか、いろいろ説明があります。 そしてそこで初めて手術後の自分の体がどのような状態になっているのかが分かるのです。 私の場合、体には計5本の管が入っていました。 ・左腕に点滴の管 ・右側股関節に痛み止めの管 ・右ひざのお皿の近くに血抜きの管（その1） ・右ひざのお皿の近くに血抜きの管（その2） ・尿道に管 ← **これが最悪** 全体を振り返ると一番つらかった/痛かったのは、この5.尿道の管だったように思います。 常に残尿感がある状態のような感覚でとにかく気持ち悪いし、少し体を動かすだけでチクチク痛いのです。 (尿道の管、いつか抜くと思うんだけど、絶対に痛い！） 恐怖したのを今でも覚えています。 なお、膝は手術後の血が足にたまらないように少し高くされており、氷嚢でアイシングされた状態になっています。 この状態のときは全く身動きが取れないので、とにかく寝ることに徹したほうが良いです。（しかしながら、ときおり看護師さんが点滴の入れ替えや、尿の出具合を確認しに来るので、あまり眠れない。。。） ちなみに手術後の痛みは、股関節に入れられている管から入れられている痛み止めが効いているおかげでほとんどありませんでした。 翌朝 朝10:00くらいになると、医師と看護師が管を抜きに来ます。 まずは、膝の管。 人によっては痛いようですが、私の場合は痛み止めが効いていたからかわかりませんが、痛みはありませんでした。 次に、股関節の管。この辺も大丈夫。 点滴もこの時に抜かれた気がします。 そして最後の尿道の管。 てきぱきと抜こうとするのでおもわず、 ちょ、、、ちょっと待ってください。これ(尿道の管)絶対に痛いですよね？汗 と言いました(笑) 看護師さんが、 あー、男性の方は尿道が長いので痛いみたいですねぇ。口呼吸すると、幾分か痛みが和らぐみたいですよ？自分で管抜きますか？ い、、、いや、、、自分では絶対ムリなのでお願いします泣 というので思いっきり口呼吸しました。。。 でもやはり、、、、 いてててててててて！！！！！！ って感じです。 しかし、すべての管がなくなると、本当に身軽になります。 以降は普通に食事もできます。 少ししんどいですが、自ら松葉杖を使ってトイレに行くこともできます。 この経験をすると、”自分でトイレを済ませることができる”ということのありがたみが分かります。介護される側の立場からすると、トイレのお世話をしてもらうのが精神的につらいものがあるのではと思いました。 この経験を忘れないように、自らの健康管理を徹底したいと思っています。 まとめ 手術を決意した後、しばらくリハビリ期間があります。 手術の数週間前に麻酔のアレルギー検査があります。少し痛い。 全身麻酔は怖くない。ただし、手術後が辛い。 特に尿道の管は辛い ”自分でトイレを済ませることができる”というのは素晴らしいことです。 以上です。続きは以下の記事にまとめています。 オススメの記事 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです プログラミング学習に興味のある方はこちら","link":"/2020/01/16/knee-surgery/"},{"title":"【M1 Mac】Railsの開発環境をdocker-composeで作成する","text":"M1 MacでもDockerでRails開発環境作れるの？という疑問に答えていきます！ ✓目次 この記事の対象者 この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 Gemfileの作成 Gemfile.lockの作成 docker-compose ymlの作成 MySQLの設定ファイルの作成 Rails開発環境の構築 この記事の対象者 ・ M1 MacでRails開発環境をDockerで構築したい方(Rails 6.0.3.4 / mySQL 8.0.22系) この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 Gemfileの作成 Gemfile.lockの作成 docker-compose.ymlの作成 MySQLの設定ファイルの作成の設定 Rails開発環境の構築 Docker Desktop for Macのインストール 以下の記事にまとめられているインストール方法で問題なく導入できます。Macbook Pro M1(Apple Silicon) で Dockerを動かす - Qiita インストールが完了したらバージョンと動作確認。 terminal12345$ docker --versionDocker version 20.10.1, build 831ebeae96$ docker-compose --versiondocker-compose version 1.27.4, build 40524192 Dockerfileの作成 まずは任意の空のディレクトリを用意して、Dockerfileを用意していきます。 この記事では``railsapp``という名前の空ディレクトリを作ります。 terminal123$ mkdir ~/railsapp$ cd ~/railsapp$ vim Dockerfile docker-composeを使う場合、docker-compose.ymlがおいてあるディレクトリ名が、コンテナ名やvolume名の接頭字として使用されます。 実際の開発においては、プロジェクトの名前など、意味のあるディレクトリ名にしておいたほうが望ましいです。 また、作成したディレクトリをビルドコンテキストとするので、不要なファイルは含めないようにしましょう。 railsapp/Dockerfile12345678910111213FROM ruby:3.0.0RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /appRUN curl https://deb.nodesource.com/setup_12.x | bashRUN curl https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -RUN echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | tee /etc/apt/sources.list.d/yarn.listRUN apt-get update &amp;&amp; apt-get install -y nodejs yarn postgresql-client Dockerfileは、Railsを実行するためのファイルサーバやパッケージをイメージに含めるための定義が書かれています。ポイントだけ説明します。 FROM ruby:3.0.0: 現時点で最新バージョンであるruby 3.0.0を指定しています。 COPY . /appはDockerファイルの置いてあるフォルダの内容をすべてコンテナ内の/appディレクトリにコピーしています。これはrailsのアプリケーション実行に必要なファイルをすべてコンテナの中に含めるために記載している。そのため余計なファイルを含めてしまうと、コンテナに含まれてしまうので、本記事で述べるファイル以外の関係のないファイルはおかないように注意しましょう。 10行目〜13行目は、yarnというjsのパッケージ管理ツールをDockerコンテナ内部にインストールするためのコードです。後々、Webpackを導入するために必要となります。 Gemfileの作成 GemfileはインストールするGemを定義しておくためのファイルです。 railsapp/Gemfile12source 'https://rubygems.org'gem 'rails', '6.0.3.4' sourceには、Gemのダウンロード元のURLを記載しています。 インストールするGemには現時点で最新バージョンであるRailsの6.0.3.4を指定しています。 このGemfileが配置されたディレクトリで、「bundle install」コマンドを実行すると、インストールが実行されるよ！ Gemfile.lockの作成 terminal1$ vim Gemfile.lock Gemfile.lockでは空のファイルになります。通常Gemfile.lockは、直接編集するものではありません。Gemfile.lockはbundle installを行った際に、実際にインストールしたGemのリストとバージョンが自動的に記載されるファイルです。 つまり、1. Gemfileでinstallしたいgemを定義2. bundle installコマンドを実行3. gemがインストールされる4. installしたgemがGemfile.lockに記載されるということだね！ Gemfile.lockの用途は、別のサーバーや他の開発者のPCといった別環境で同じRailsアプリを動かす際、同じGemをインストールするために使用されます。 Gemをインストールする際は、インストールするGemを動かすために必要な別のGemも一緒にインストールしてくれます。 あるライブラリが別のライブラリを必要とすることを「依存関係」っていうんだ！ 依存関係も含めて何がインストールされたのかが、全てGemfile.lockに記載されます。 このGemfile.lockを別の環境に持っていき、そこでbundle installコマンドを実行すると、Gemfile.lockに記載された内容に従って、Gemのインストールが実行される、というわけです。 docker-compose ymlの作成 docker-compose.ymlは、Dockerで複数のコンテナを設定に従ってまとめて起動するためのファイルです。ここでは、Railsを実行するコンテナとMySQLを実行するコンテナを起動する定義を記載します。 railsapp/docker-compose.yml12345678910111213141516171819202122version: '3'services: web: build: . command: bundle exec rails s -p 3000 -b '0.0.0.0' volumes: - .:/app ports: - 3000:3000 depends_on: - db tty: true stdin_open: true db: image: mysql@sha256:dce31fcdd15aaedb5591aa89f19ec37cb79981af46511781fa41287d88ed0abd volumes: - db-volume:/var/lib/mysql - ./mysql-confd:/etc/mysql/conf.d environment: MYSQL_ROOT_PASSWORD: passwordvolumes: db-volume: 注目する点は、MySQLのimages指定です。2021年1月時点ではタグではなくDIGESTの欄のIDを指定しないとエラーが出ます。 そして./mysql-confd:/etc/mysql/conf.dは、MySQLのデフォルトの認証形式であるcaching_sha2_passwordからmysql_native_passwordに変更するファイルになります。 この設定ファイルは次のセクションで作成します。 MySQLの設定ファイルの作成 MySQLのデフォルトの認証形式をデフォルトのcaching_sha2_passwordからmysql_native_passwordに変更するファイルは以下のとおりです。 railsapp/mysql-confd/default_authentication.cnf12[db]default_authentication_plugin= mysql_native_password [db]と書かれている部分は、docker-compose.ymlファイルに記載されたデータベースのservice名に対応しています。 Rails開発環境の構築 ここまで作成した設定ファイルを使用して、Railsの開発環境を動かしていきます。 フォルダとファイルは以下のとおりです。 tree123456789.├── Dockerfile├── Gemfile├── Gemfile.lock├── docker-compose.yml└── mysql-confd └── default_authentication.cnf1 directory, 5 files 以下のコマンドを実行します。 terminal1$ docker-compose run web rails new . --force --database=mysql 処理が完了するとRailsプロジェクトのファイルが自動生成されます。 terminal123456/railsapp $ lsDockerfile Rakefile config lib package.json testGemfile app config.ru log postcss.config.js tmpGemfile.lock babel.config.js db mysql-confd public vendorREADME.md bin docker-compose.yml node_modules storage yarn.lockshingo_omata ~/docker-space/RoR/railsapp ここでGemfileに追記されたGemのインストールや作成されたファイルをコンテナ内に取り込むために、もう一度ビルドを実行します。 terminal1$ docker-compose build ビルドが完了したら、Railsで使用するデータベースの設定ファイルを編集します。ファイルはconfigディレクトリ内にあるdatabase.ymlです。 変更箇所は17行目と18行目です。 database.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# MySQL. Versions 5.5.8 and up are supported.## Install the MySQL driver# gem install mysql2## Ensure the MySQL gem is defined in your Gemfile# gem 'mysql2'## And be sure to use new-style password hashing:# https://dev.mysql.com/doc/refman/5.7/en/password-hashing.html#default: &amp;default adapter: mysql2 encoding: utf8mb4 pool: &lt;%= ENV.fetch(&quot;RAILS_MAX_THREADS&quot;) { 5 } %&gt; username: root password: password # 変更 host: db # 変更development: &lt;&lt;: *default database: app_development# Warning: The database defined as &quot;test&quot; will be erased and# re-generated from your development database when you run &quot;rake&quot;.# Do not set this db to the same as development or production.test: &lt;&lt;: *default database: app_test# As with config/credentials.yml, you never want to store sensitive information,# like your database password, in your source code. If your source code is# ever seen by anyone, they now have access to your database.## Instead, provide the password as a unix environment variable when you boot# the app. Read https://guides.rubyonrails.org/configuring.html#configuring-a-database# for a full rundown on how to provide these environment variables in a# production deployment.## On Heroku and other platform providers, you may have a full connection URL# available as an environment variable. For example:## DATABASE_URL=&quot;mysql2://myuser:mypass@localhost/somedatabase&quot;## You can use this database configuration with:## production:# url: &lt;%= ENV['DATABASE_URL'] %&gt;#production: &lt;&lt;: *default database: app_production username: app password: &lt;%= ENV['APP_DATABASE_PASSWORD'] %&gt; ファイルを保存して、以下のコマンドを実行します。 terminal1$ docker-compose up -d webとdbの２つのコンテナが起動状態になっていることを確認します。両方ともStateがUPになっていればOKです。 terminal12345$ docker-compose ps Name Command State Ports --------------------------------------------------------------------------------railsapp_db_1 docker-entrypoint.sh mysqld Up 3306/tcp, 33060/tcp railsapp_web_1 bundle exec rails s -p 300 ... Up 0.0.0.0:3000-&gt;3000/tcp 起動は完了しましたが、まだ開発環境用のデータベースが作成されていない状態なので、次のコマンドでデータベースを作成します。 terminal1$ docker-compose run web bundle exec rake db:create これでうまく行けば良いですが、まれに以下のようなエラーが出てくるかと思います。 エラー1Mysql2::Error::ConnectionError: Plugin caching_sha2_password could not be loaded: /usr/lib/aarch64-linux-gnu/mariadb19/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory これは、MySQL 8.0系の認証形式がcaching_sha2_passwordのままになっているためです。 本来ならdefault_authentication.cnfが変えてくれるはずなんですけどね。。。 以下のように、MySQLにログインして2つのrootの認証方式をmysql_native_passwordに変更します。 terminal12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152$ docker exec -it ror_db_1 bashroot@a503c7951a1f:/# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10Server version: 8.0.22 MySQL Community Server - GPLCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; SELECT User, Host, Plugin FROM mysql.user; +------------------+-----------+-----------------------+| User | Host | Plugin |+------------------+-----------+-----------------------+| root | % | caching_sha2_password || mysql.infoschema | localhost | caching_sha2_password || mysql.session | localhost | caching_sha2_password || mysql.sys | localhost | caching_sha2_password || root | localhost | caching_sha2_password |+------------------+-----------+-----------------------+5 rows in set (0.04 sec)mysql&gt; select @@version;+-----------+| @@version |+-----------+| 8.0.22 |+-----------+1 row in set (0.02 sec)mysql&gt; alter user 'root'@'%' identified WITH mysql_native_password by 'password';Query OK, 0 rows affected (0.22 sec)mysql&gt; alter user 'root'@'localhost' identified WITH mysql_native_password by 'password';Query OK, 0 rows affected (0.13 sec)mysql&gt; SELECT User, Host, Plugin FROM mysql.user;+------------------+-----------+-----------------------+| User | Host | Plugin |+------------------+-----------+-----------------------+| root | % | mysql_native_password || mysql.infoschema | localhost | caching_sha2_password || mysql.session | localhost | caching_sha2_password || mysql.sys | localhost | caching_sha2_password || root | localhost | mysql_native_password |+------------------+-----------+-----------------------+5 rows in set (0.01 sec) これで再び以下のコマンドを実行してください。 terminal1234$ docker-compose run web bundle exec rake db:createCreating ror_web_run ... doneCreated database 'app_development'Created database 'app_test' localhost:3000にブラウザでアクセスするとRailsの画面が現れます。 よし！これでM1 MacでRailsの開発ができるぞ！ Railsの即戦力エンジニアになりたい方へ 100以上のUdemy講座を受講した筆者がRails／Docker関連の講座を紹介します。1200円で無制限で見放題！30日間返金保証！講師への質問も自由！ Udemyを詳しく見る 即戦力レベルのアプリケーション作成のスキルを身に着けることができます。Ruby言語の基礎から始め、Railsを使用したWebアプリケーションの開発方法について学びます。Railsの動作環境をDockerで構築する方法についても学びます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-skxv9Up\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rails-kj/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1497262_1c92.jpg?GWx9DbWnjp0BqiV4QmWg058nKfwbletKUaSEPdHrjzwwc2r7H-wOc7ywgZwkAf2FmIJuWFItn9Rb4VVChGfNro77USCLiDp0eI_Fb2Yp9nnVMFiXPKlsdKdOxnk\"}}); フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 Dockerについては以下の講座１つでもう大丈夫！というくらい質、ボリュームともに文句なしです。これが1200円で受講できるなんていい時代になりました。。。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 インフラの知識を増やしたかったら、Kubernetesを学びましょう。Kubernetesを用いて、Web3層構造(MongoDB, Node.js, Nginx)環境をDockerで構築することで、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座 参考記事 Rails6 Webpackerでエラーが出た - Qiita yarnをインストールする - Qiita docker for macでrails × yarn × webpackerのfront環境を整える - Qiita dockerイメージ内にyarnをインストールする - Qiita MySQLの認証プラグインを変更する方法(caching_sha2_password) - Qiita Docker Compose と Rails(+MySQL) で開発環境作成したときに気になったポイント - Qiita Docker で MySQL 8.0.4 を使う - Qiita MySQL8.0におけるデフォルトの認証プラグインの変更 – variable.jp [データベース,パフォーマンス,運用]","link":"/2021/01/16/m1-mac-dockercompose-rails/"},{"title":"【Keras基礎】ニューラルネットワークを作成してsin関数を学習して予測させてみた。","text":"ニューラルネットワークとはどのようなものかをkerasという機械学習を簡単に使うためのライブラリを使ってまとめました。高校の数学でならったsin(サイン)関数をつかって、学習→予測をしてみたいと思います。 ✓目次 本記事の対象者 環境 学習データの準備 入力データxの作成 正解データ（sin関数）の作成とグラフ描画 ニューラルネットワークの構築、学習、予測 ニューラルネットワークの設定 ニューラルネットワークの構築 1セット目(入力層と中間層)の追加 2セット目(中間層と出力層)の追加 コンパイル ニューラルネットワークを用いて学習 学習の推移をグラフで確認 学習済ニューラルネットワークを使用して予測 本記事の対象者 ニューラルネットワーク、というものがなんとなくわかっているが、細かい言葉の定義とかを忘れてしまった人。（順伝播、逆伝播とかを知っている。） 高校の数学（特に三角関数）を理解している。 pythonのプログラミングを、それなりに理解している。（progate等でpythonの使い方を雰囲気程度で理解している） これから本格的に、ニューラルネットワークを学ぶために基本的なことを復習したい人。 環境以下の記事で紹介しているように、Anaconda NavigatorでJupyter notebookの環境を整えてください。 もしくは、Google Colaboratoryという、Google chromeというブラウザのみでプログラミングができる環境を使ってもいいと思います。 https://colab.research.google.com/?hl=ja 学習データの準備本記事では、データの例としてサイン関数を用意したいと思います。 入力データをx, 正解データをtとします。 入力データxの作成まずは入力データとなるxを作成します。 ソースコードは以下の通り。 123456import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1)print(x) numpyとmatplotlibというライブラリをインポート。 入力xとしてnp.linspace(-np.pi, np.pi).reshape(-1, 1)と記載していますが、これは、-πからπまでの値を50行、1列の行列データを作成しています。 linspace()というのは、値の範囲を指定するメソッドです。ここで、-np.pi, np.piとすることで、-π(-3.1415・・・)からπ(3.1415・・・)までの範囲の値を扱うことを宣言しています。 reshape()は、行数と列数を指定して、行列の形を指定したり変更したりするメソッドです。 このコードでは、reshape(-1, 1)、すなわち行数を-1, 列数を1としています。行数が-1ってどのような意味なのかというと、-1を指定することで、「良い具合に自動で列数決めてくださいね。」というメッセージを送っていることになります。 良い具合に、というのは、reshapeの大本であるlinspaceにおけるデフォルト設定のことを指しており、具体的な数値でいうと50が設定されます。 すなわち、-πからπまでの値を50等分した配列データを作成しています。 作成したxをプリントすると以下のようになります。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[[-3.14159265] [-3.01336438] [-2.88513611] [-2.75690784] [-2.62867957] [-2.5004513 ] [-2.37222302] [-2.24399475] [-2.11576648] [-1.98753821] [-1.85930994] [-1.73108167] [-1.60285339] [-1.47462512] [-1.34639685] [-1.21816858] [-1.08994031] [-0.96171204] [-0.83348377] [-0.70525549] [-0.57702722] [-0.44879895] [-0.32057068] [-0.19234241] [-0.06411414] [ 0.06411414] [ 0.19234241] [ 0.32057068] [ 0.44879895] [ 0.57702722] [ 0.70525549] [ 0.83348377] [ 0.96171204] [ 1.08994031] [ 1.21816858] [ 1.34639685] [ 1.47462512] [ 1.60285339] [ 1.73108167] [ 1.85930994] [ 1.98753821] [ 2.11576648] [ 2.24399475] [ 2.37222302] [ 2.5004513 ] [ 2.62867957] [ 2.75690784] [ 2.88513611] [ 3.01336438] [ 3.14159265]] これで入力データは完成です。 正解データ（sin関数）の作成とグラフ描画続いて、正解データであるtを用意します。 ソースコードは以下です。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1) print(x)t = np.sin(x) # sin関数plt.plot(x, t)plt.show() 1行目の、%matplotlib inlineですが、実はこれが記載されていないとJupyter Notebook環境でグラフが表示されません。おまじないのように記載しておきましょう。 3行目から7行目は、先ほどの入力データxで説明した箇所なので、説明は省きます。 9行目のt = np.sin(x)で、先ほどの入力データxをサイン関数にいれて、これを正解データtとしています。 そして、plt.plot(x, t)で、横軸をx、縦軸をtとし、plt.show()とすることで、描画したグラフを出力させます。※plt.show()の記述が無くてもグラフが描画されたりしますが、そこは気にしない。 コードを実行すると以下のようにサイン関数のグラフが出力されます。 ニューラルネットワークの構築、学習、予測ここから、Kerasを使ってニューラルネットワークの構築し、sin関数を学習し、入力データを用いて予測を行います。 ここで構築するのは、入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1の3層のニューラルネットワークです。 ニューラルネットワークの設定ソースコードは以下の通りです。 12345678910111213141516from keras.models import Sequentialfrom keras.layers import Dense# ニューラルネットワークの設定n_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数batch_size = 8 # バッチサイズ# 入力層、中間層、出力層の３層のニューラルネットワークを構築model = Sequential()model.add(Dense(n_mid, input_shape=(n_in,), activation=\"sigmoid\")) # 活性化関数にシグモイド関数model.add(Dense(n_out, activation=\"linear\")) # 活性化関数に恒等関数model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 損失関数に二乗誤差、最適化アルゴリズムにSGDを使用してコンパイルprint(model.summary()) 少し複雑に思うかもしれませんが、一つ一つ説明していきます。 入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1、なのでニューラルネットワークの設定として、 入力層のニューロン数をn_in = 1 中間層のニューロン数をn_mid = 20 出力層のニューロン数をn_out = 1 という風に記載します。 続いて、バッチサイズを8と設定しています。 バッチサイズとは、膨大なデータを細かく分割する単位の数です。 例えば、100万個のサンプルがあったとします。 これに対してバッチサイズを100と設定した場合、100万のサンプルを100個ずつ細かく分割し、1万個の小さい100個入りの箱に分けるということです。 この箱の一つ一つをミニバッチといい、ミニバッチに分けて計算することをミニバッチ学習と言います。 ミニバッチ学習をすると何が嬉しいのでしょうか。 100万個のサンプルの計算というのは基本的に多くの時間がかかり、1回の更新を終えるだけで膨大な時間を要します。 しかし、ミニバッチ学習を採用することで、誤差を修正する更新を終える頻度を増やすことができます。 そのため、どのように値が更新されたのかを観察しやすく、かつ、更新頻度を増やすことで、サンプル全体として最適な値を導くことができ、局所解を防ぐことができます。 なお、100万個のサンプル全体の計算を終えて、パラメータの更新が1回終わることを、1epoc(エポック)と言います。 そして、ミニバッチのパラメータを更新することを1 iteration(イテレーション)と言います。 今回の例でいうと、100万サンプルを100ずつ細かく分割し1万の小さい箱に分けているので、1epoch = 1万iterationとなります。 これで、「バッチサイズ」、「ミニバッチ」、「ミニバッチ学習」、「エポック」、「イテレーション」というものの概要が理解できたかと思います。 ニューラルネットワークの構築続いて、入力層、中間層、出力層の３層のニューラルネットワークを構築していきます。 3層のニューラルネットワークを構築する前に、ニューラルネットワークを構築する際の考え方として大事なのは、2層を1セットで考えるということです。 つまり、下図に示すように「入力層と中間層」で1セット、「中間層と出力層」で1セット、合計2セットとして扱うということです。 それぞれの1セットは、Dence()を用いて追加します。 1セット目(入力層と中間層)の追加Denseは、Sequential()を用いてmodelを作成し、addメソッドによって活用されます。 コードでいうと、1セット目(入力層と中間層)の部分はmodel.add(Dense(n_mid, input_shape=(n_in,), activation=&quot;sigmoid&quot;))という風にして追加しています。 Dense({中間層のニューロン数}, {入力の形状}, {活性化関数})という記述になっています。 活性化関数というのは、中間層の各ノード(ニューロン)内で適用されるアルゴリズムで、下図における\\( u \\)から\\( z \\)を求める関数です。 活性化関数は、様々あり、自然言語処理の世界では、シグモイド関数、tanh(ハイパボリックタンジェント)、恒等関数が主となるようです。 今回は、シグモイド関数を使っていますが、他の活性化関数を適用して実験してみてもいいと思います。 また、こちらの\\( u \\)から\\( z \\)への変換を、非線形変換といったります。 線形でない曲線的な関数である、非線形の関数を用いて\\( u \\)から\\( z \\)を変換しているので、非線形変換といいます。 なぜ非線形なのでしょうか。線形変換でもよいのでは？と思うかもしれません。 理由は、ものすごく簡単に言ってしまうと、実際のビジネスでは、非線形なデータの方が多く、非線形変換を行わなければ、実際のビジネスの現場では使えないためです。 2セット目(中間層と出力層)の追加続いて2セット目の層を追加します。 こちらもDenseを用います。 出力層のニューロン数と活性化関数を指定すればOKです。 コードとしては、model.add(Dense(n_out, activation=&quot;linear&quot;))となります。 コンパイルコンパイルというのは、人間が分かる言葉で書いたプログラムのコードを、コンピュータが分かる言葉に変換/翻訳することです。コンピュータが分かる言葉というのは、いわゆる0と1の列です。 コンパイルの際は、損失関数と、最適化アルゴリズム、というのを指定します。コードでいうと、model.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;sgd&quot;)と記載しているところです。 損失関数とは、ニューラルネットワークが予想した値が静価値にどれだけ近いかを評価する関数のことです。 別名、評価関数とも呼びます。 損失関数は２つに分類されます。 回帰(数値を予測) → 二乗誤差 分類(カテゴリを予測) → クロスエントロピー（交差エントロピー） 今回は、数値を予測するので、二乗誤差を指定しています。 最適化アルゴリズムとは、重み\\( w \\)をどのようなルールで変換して正解値に近づけるかを数式化(モデル化)したものです。 SGDとは、確率的勾配降下法というもので、数式としては、以下のようなものになります。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}}以下のページに詳しい説明がまとめられているので、興味のある方は参考にしてください。https://mathwords.net/sgd 先ほどのコードを実行して、構築したモデルのsummary()を表示すると以下の通りとなります。 12345678910111213Model: \"sequential_1\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================dense_1 (Dense) (None, 20) 40 _________________________________________________________________dense_2 (Dense) (None, 1) 21 =================================================================Total params: 61Trainable params: 61Non-trainable params: 0_________________________________________________________________None Output Shapeというのは、各Denseの出力側の形状を示しています。 1セット目(入力層から中間層の部分)のOutput Shapeは、(None, 20)となっているため、中間層のニューロン数が20であることを意味しています。 2セット目(中間層から出力層の部分)のOutput Shapeは、(None, 1)となっているため、出力層のニューロン数が1であることを示しています。 Paramというのは、各層のパラメータ数を示しています。 1セット目のパラメータ数が40(重みの数が20, バイアスの数が20の合計40)で、2セット目のパラメータ数が21(重みの数が20, バイアスの数が1の合計21)であることを示しています。 ニューラルネットワークを用いて学習ここから、構築したニューラルネットワークを用いて学習を行います。 学習は、fit()メソッドを使います。 1history = model.fit(x, t, batch_size=batch_size, epochs=2000, validation_split=0.1) # 10%のデータを検証用に使う modelのfitメソッドに、先ほどの入力xと正解t、バッチサイズ、エポック数、バリデーションスプリットを設定しています。 バリデーションスプリットとは、全データの何%を検証用のデータとして扱うかを指定することができます。今回は10%のデータを検証用に使うので、0.1を設定しています。 こちらのコードを実行すると以下のような出力が得られます。 1234567891011121314151617Train on 45 samples, validate on 5 samplesEpoch 1/200045/45 [==============================] - 0s 5ms/step - loss: 0.5445 - val_loss: 0.0813Epoch 2/200045/45 [==============================] - 0s 295us/step - loss: 0.3997 - val_loss: 0.0355Epoch 3/200045/45 [==============================] - 0s 502us/step - loss: 0.3446 - val_loss: 0.0444Epoch 4/2000(略)45/45 [==============================] - 0s 301us/step - loss: 0.0093 - val_loss: 0.1108Epoch 1999/200045/45 [==============================] - 0s 265us/step - loss: 0.0093 - val_loss: 0.1142Epoch 2000/200045/45 [==============================] - 0s 323us/step - loss: 0.0095 - val_loss: 0.1142 loss: となっている部分は、訓練用データの誤差になります。 10%の検証用データを用いた結果の誤差が、val_loss:として出力されています。 学習の推移をグラフで確認matplotlibを用いて、先ほどのlossとval_lossをグラフとして描画してみます。 123456loss = history.history['loss'] # 訓練用データの誤差vloss = history.history['val_loss'] # 検証用データの誤差plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 以下のようなグラフが表示されます。 検証用のデータは青いラインで、訓練用のデータがオレンジのラインです。 両者ともに、エポック数を重ねると順調に下がっています。 学習済ニューラルネットワークを使用して予測predict()メソッドを用いることで、学習済みのニューラルネットワークを使用して予測を行うことができます。 123plt.plot(x, model.predict(x)) # 予測を行うplt.plot(x, t)plt.show() 最初に、入力xと入力xをpredictメソッドに入れた結果をプロットします。 predictメソッドに入力値を渡すだけで、予測データの出力を得ることができます。 比較のために、入力xと正解値tをプロットしたものを同時に出力したいと思います。 コードを実行すると以下のようなグラフが描画されます。 正解値はオレンジのラインで、学習済みのモデルに入力値を入れて予測したデータが青いラインになります。 正解のオレンジのラインをまねるように、青いラインが描かれていることから、ニューラルネットワークがサイン関数を学習していることが分かります。 参考にしたページや文献など 確率的勾配降下法の大雑把な意味 - 具体例で学ぶ数学 Optimizer : 深層学習における勾配法について - Qiita ニューラルネットワークをちゃんと学びたい！という方は以下のUdemyの講座がおすすめ。Stay Home期間中にオンライン講座でスキルを身に着けるのはいかがでしょうか？ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXZlto6\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku_blackbox_1/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356190_9cbb_6.jpg\"}}); 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - ニューラルネットワークの発展形であるRNNやLSTMを構築して自然言語処理を学びたい方は、以下がおすすめです。本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 プログラミングを0から学びたい、、、という方は絶対に躓かないオンラインプログラミング講座「SkillHacks」もおすすめです。LINE@による無制限質問サポートで挫折しない仕組みができており、合計94本のしっかりした動画があります。他のプログラミングスクールよりも安くて手頃です。 -Skill Hacks- 動画で学ぶWebアプリ開発講座","link":"/2020/05/03/keras-nn-basic/"},{"title":"【プログラミング】SkillHacks受講後にオススメのUdemy講座","text":"SkillHacksを受講した後の学習スケジュールは決まってますか？ SkillHacks同様、オンラインで学習を進めたいという方は、Udemyがおすすめです。 Udemy 不定期に開催されるセール時は、1000円台で講座を購入できるのでお財布にも優しいです。 SkillHacksを受講し終わった方を対象に、数あるUdemyの講座の中で、おすすめの講座をまとめました。 ✓目次 本記事の信頼性について オススメの講座一覧(タイプ別) 1.Ruby/Ruby on Railsの知識を深めたい方 1.1. Rubyで作る! ビットコイン自動売買システム 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 3. インフラの知識を深めたい方 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 3.2. Amazon Web Service マスターコース EC2編 4. 他の言語等を学び知識の幅を広げたい方 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） 4.2. 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 4.3. 【JavaScript】：実例でわかる JavaScript 初心者講座 まとめ 本記事の信頼性について こちらで紹介している講座は、筆者が実際に受講した講座の中から選定しております。※筆者が受講済の講座数は、2020年5月時点で、約30講座です。 網羅性という観点で心配されるかと思いますが、Udemyは30日間の返金保証があります。 「受講してみたけど、やっぱり違うな」と感じたら、お金は返ってきますのでご安心ください。 オススメの講座一覧(タイプ別) これから学習したい方向性や考え方別にまとめたいと思います。 SkillHackの講師が「学んだほうが良い」と述べているもの ＋ 今のIT業界の流行という観点で分類しました。 Ruby/Ruby on Railsの知識を深めたい方 現場で絶対に使うGit/Githubの知識を深めたい方 インフラの知識を深めたい方 他の言語等を学び知識の幅を広げたい方 早速、以下にまとめたいと思います。 1.Ruby/Ruby on Railsの知識を深めたい方 SkillHacksで、Ruby/Ruby on Railsを学ばれたかと思いますが、Ruby/Ruby on Railsには、まだまだ深い技術が存在します。 SkillHacksでは扱わなかった技術を補完する or 深めるということにフォーカスして、２つの講座を紹介します。 1.1. Rubyで作る! ビットコイン自動売買システム a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYnOIbA\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム SkillHacksの講師である迫さんが講師を務める講座です。 開発環境がSkillHacksと同じAmazonCloud9であり、かつ、講師が同じなのでスムーズに講義に入れると思います。 講義の中身ですが、SkillHacksでは扱っていないRubyのライブラリやREST APIを用いたアプリケーション開発手法が学べます。 Railsの講義はありませんが、Webアプリケーションを作成する際、外部のAPIを活用して作成する機会は多いです。 API keyの扱い方やJsonの知識もRubyと合わせて学んでおくべきだと思います。 講座の概要欄に「現在，bitFlyerにて新規アカウントの作成が停止されています。」と記載がありますが、2019年7月3日から、bitflyerの新規アカウントの受付が再開されているのでご安心ください。 あわよくば仮想通貨で一攫千金が狙えるかも？ 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoetKL\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rails-kj/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1497262_1c92.jpg\"}}); フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 即戦力のRailsエンジニアになることを目的とした講座です。 基本的なRubyの基礎から応用まで網羅的にまとめられているので復習もかねて学習が進められると思います。 ”即戦力”というだけあり、コードを綺麗に書く際の考え方に加え、Dockerというコンテナ型仮想化技術や、プログラムが想定した動作をすることをテストするためのプログラムであるテストコード(RSpec)のレクチャもあります。 またSkillHacksでは扱っていない、ログイン、ログアウト機能の実装についても、本講義で扱っています。 かなりのボリュームなので、全部をマスターするには時間がかかると思いますが、この講座の内容を習熟できれば十分即戦力のRuby/Ruby on Railsのエンジニアになれると思います。 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 Web関連の開発現場では、ソースコード管理ツールGitは必須の知識となります。 開発メンバーにいち早く加わるためにも、GitとGitHubを学びましょう。 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYolLK2\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 正直この講座だけでGit/GitHubは問題ありません。 Gitとはなにか、GitHubとはなにか、等、綺麗な図で説明されており、ハンズオンで手を動かしながら学ぶことができます。 GitHub Flowと呼ばれるチーム開発でコードの管理をするための概念を理解したうえで、Gitを扱えるようになっておけば、開発現場のメンバーとしてすぐに加われると思います。 また、自分が作成したアプリのコードをGithubにアップロードしておいて技術をアピールしてもいいかもしれません。 余談ですが、このブログはGithubの機能の一つであるGitHub PagesとHexoという静的ブログジェネレータを用いて作成されています。 3. インフラの知識を深めたい方 インフラ技術は多岐にわたりますが、その中でもAWSを扱う企業が多い印象を受けます。 ここではSkillHacksを学んだRuby on Railsと関わり高いAWS関連の講座を中心にまとめました。 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYozwYi\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/aws-and-infra/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2361020_edcc.jpg\"}}); AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 Linuxのコマンドの少々不安がある方は、こちらの講座で基礎から学ぶのが良いと思います。 先ほど紹介した「Git： もう怖くないGit！チーム開発で必要なGitを完全マスター」と同じ講師の方になります。 分かりやすさの観点では断トツに良いです。 AWSの基本的な機能であるEC2, Route53, RDS, S3周辺は、この講座で問題ないかと思います 3.2. Amazon Web Service マスターコース EC2編 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYouKOH\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/amazon-web-service-ec2/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1949062_f23f_2.jpg\"}}); Amazon Web Service マスターコース EC2編 Webサーバの構築やそれなりにAWSを知っている方は、こちらの講座が良いと思います。 EC2を中心にしっかりと学ぶ、という意味では、おそらくこの講座が筆頭であり、詳細な領域まで学ぶことができます。 「フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座」と同じ講師の方の講座になります。 EC2編となっておりますが、VPC編もありますので、余力があればそちらも受講すると良いかと思います。 4. 他の言語等を学び知識の幅を広げたい方 Ruby/Ruby on Rails以外の言語も学びたいという方向けにオススメの講座をまとめました。 特に人気の高いPython, JavaScriptに分けて記載しています。 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoFMhf\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/django-beginner/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1213286_dfba_2.jpg\"}}); 【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） ”3日でできる”とタイトルにありますが、たぶん3日で終わらないくらい充実した講座です。 Djangoとは、Ruby on Railsによく似たPythonのWebフレームワークです。 UdemyのプラットフォームもPythonとDjangoで開発されています、 昨今のAIブームから、ニューラルネットワーク用のライブラリが豊富なPythonベースであるDjangoを使う企業も多くなると想定します。 この講座ではブログサービスを構築しており、SkillHacksでも学んだ内容がそのまま活かせる内容になっていておすすめです。 AWSへの公開方法もレクチャーの中で学べます。 SkillHacksで作成した掲示板を、Python on Djangoで作成するとより理解が深まります。※私もやりました。 4.2. 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 数あるUdemyの講座の中でも、「【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論」はオススメです。 理由は、以下です。※ほぼSkill Hacksと同じですが、、、 ・ コードを書く前の設計方法をレクチャーしてくれる ・ コードを書く際の思考の流れもレクチャーしてくれる。 最初に述べたSkill Hacksと同様、プログラミングを書く際の思考が学べる講座だからです。 この講座を実際に受講して、私個人が「いいな」と思ったのは、いきなりコードを書かずに日本語の文章でどのような処理をどうすればよいのかという考え方から入る点です。 これは、実際に仕事でプログラミングをする際にも行うことなのですが、この工程をせずにいきなりコードを書き始める講座がホントに多いんですよね。。。。 「どのような設計や構造にすれば、目的のシステムが作れるのか」というのを、頭に思い浮かべながらコードを書くことができる人はごく少数です。 大抵は、まず日本語のテキストや絵をつかって、どのようなアルゴリズムで組み立てればよいのかを整理する「設計」から入るのです。 また、この講座の中でも講師の方が何度も言うのですが、「最初から完璧で美しいコードを作ろうとせず、まず動かすことを目指しましょう」という考え方が、とてもGoodだと思いました。 本当にそのとおりで、最初は汚いコードでも動けばOKで、動いてから綺麗なものに成形(リファクタリング)すればよいと思います。 正直、コードの書き方自体は、様々なオンライン講座で学んだ知見＋Google検索を駆使すれば問題ありません。 4.3. 【JavaScript】：実例でわかる JavaScript 初心者講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoLbht\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/javascript-kouza/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/654658_4489_3.jpg\"}}); 実例でわかる JavaScript 初心者講座 2019年の人気プログラミング言語ランキング1位のJavaScriptを基本的な文法を学びつつ実際に動くアプリを作成して理解を深められる講座です。 作成するアプリは多岐にわたります。その数なんと15個！ 税込み計算アプリ（入力欄から数値を得て計算結果を表示） アウトライン メモ（アウトライン エディタ風に、ネストしたリストを追加） 三択問題アプリ（ユーザーの解答に応じて、結果表示を分岐） 字典アプリ（マウスオーバーで、説明表示を切り替え） テーブル ソート（テーブルを、名前順や数値順で、自在にソート） 連続計算アプリ（複数行入力欄の数式を、行ごとに計算して結果表示） メモ アプリ（Webブラウザに情報を記録したり、取り出したり） HTML自動リンク アプリ（文字列からURLを探し出して、自動でタグを付加） 角丸四角画像生成アプリ（角丸四角のパスを作り、画像を動的に生成） 画像切り抜きアプリ（画像を丸く切り抜いたPNG画像を生成） セピア調アプリ（画像の画素を処理して、セピア調に変換） 音声再生アプリ（音声を読み込み、再生） 動画再生アプリ（動画を読み込み、再生） ストップウォッチ（経過時間を取得して、定期的に表示を更新） 人気Webページ表示（Web APIを利用して情報を得て、リンクボタンを自動生成 どのアプリも普段から使えそうなものばかりですよね。 私は画像の切り抜きアプリは資料作成の際に使ってます。 まとめSkillHacks終了後の学習計画の参考になればと思いUdemyのおすすめ講座をまとめました。 私自身、Udemyで現在進学習中ですので、「これは良い！」と思ったものは積極的に紹介していきたいと思います。 UdemyにはATやIoT、ブロックチェーン、動画編集、ビジネスモデル等を学べる領域は多岐にわたります。 様々な学習を通じて、興味の幅や適応領域を広げ、人生を豊かにしていきましょう。 あわせて読みたい記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/2020/05/08/skill-hacks-next-step-udemy/"},{"title":"【初心者レベル別】Web系エンジニアを目指すためのUdemyオススメ講座","text":"Udemyが1/21(木)までセール中！￥1,500から購入できるチャンスです！ ・Web系エンジニアにオススメのUdemy講座が知りたい。 ・なるべく低コストで即戦力スキルを身に着けたい。 ・エンジニアになってリモートワークしたい。 ・そもそも何の言語から学習すべきか分からない。 こんな疑問に対して回答していきます。 この記事を読めば、 ・パソコン初心者でも即戦力のWeb系エンジニアになる学習ルートが分かる。 ・実践すればWeb系エンジニアへの転職、またはフリーランスで案件獲得も十分可能なレベルになる。※実際に知人がこの方法でWeb系エンジニアに転職した。 ✓目次 本記事の対象者:初心者レベルの確認 学ぶべきWeb系言語 【Web言語別】オススメUdemy講座 PHP/LaravelのオススメUdemy講座 Ruby/RailsのオススメUdemy講座 Python/DjangoのオススメUdemy講座 まとめ：学習計画を踏まえUdemyを活用しよう！ 本記事の対象者:初心者レベルの確認 Udemyは、普段PCを触ってなかったり、プログラミングに全く触れたことがない人にとっては少々難しいと思います。そんな方は、以下の記事を参照ください。 本記事で述べる”初心者”の定義は以下です。 ・PCの操作に慣れている。(ブラウザのダウンロード、キーボード操作で\"~\"とか入力できる) ・Windows10またはMacbookなど、それなりのパソコンを持っている。 ・Progateでプログラミングを少し学んだ。 ・Linuxのコマンドが少し分かる。(cd, ls, mkdir, など) 以降は学ぶべきプログラミング言語を決めるための参考情報も踏まえつつ、オススメのUdemy講座を紹介します。 学ぶべきWeb系言語 コロナウィルスの影響でリモートワークが主流になりつつあります。 IT業界には常駐での仕事とリモートワーク可能な業務があります。どうせなら、リモートワークで働きたいですよね？ リモートワーク可能な業界は大半がWeb系業界になります。 Web系業界で活用されるプログラミング言語は主に以下になります。なおWeb系エンジニアとしては、Laravel, Raisl, Djangoといったフレームワークの知識はほぼ必須です。プログラミング言語とフレームワークをセットでまとめていきます。 ・ PHP/Laravel ・ Ruby/Rails ・ Python/Django 求人サイトで各言語の求人数を調べてみました。※2021年1月17日時点 プログラミング言語 Midworks Indeed PHP 214件 16648件 Ruby 116件 5065件 Python 82件 7555件 国内のWeb系エンジニアの求人は、PHPが頭一つ抜けていることがわかりました。Rubyも多いですね。 ただし、今後この構図は大きく変わる可能性が高いです。 理由は、IT技術の最先端であるシリコンバレーではPythonとGoが主流だからです。PythonはAIやFintechそして自動化関連のライブラリが豊富に用意されていることが主な要因です。GoはPythonに比べて処理速度が早く、バックエンドの言語として主流になりつつあります。中国の人気Webサイトは、（人口が多いので）Goでつくられています。 海外で主流となっている技術や流行は、5年後に日本の流行となる傾向があります。 そのため学ぶべき言語は、数年後を見据えた学習なのか、直近のジョブチェンジを見据えた学習なのか等で変わってくると思います。 つまり、、、・3〜5年後を見据えた学習→Python・直近のニーズに適した学習→PHP or Rubyということだね！ ただし、PHPやRubyを学んでおけば、Pythonへの学習も楽になるので決して無駄にはなりません。 以上を踏まえ、自分が何の言語を学ぶべきかを決めた上で、Udemyで学んでいきましょう。以降はWeb系プログラミング言語別のUdemy講座を紹介します。 【Web言語別】オススメUdemy講座 以降は私がおすすめする各言語別のオススメ講座を紹介します。 その前に、オススメする根拠として評価観点を整理します。 コスパの良し悪し 「作って終わり」ではなく外部に公開するためのレクチャーも含まれるかどうか 初心者ファーストに開発環境のインストールも丁寧に説明しているかどうか 評価観点 1. 講義のボリューム2. 外部公開レクチャーの有無3. 環境構築レクチャーの有無 繰り返しになりますが、全くのプログラミング初心者の場合、Udemyは難しいと感じる可能性が高いです 全くの初心者の方は以下の記事を参照してください。 PHP/LaravelのオススメUdemy講座 PHPからLaravelまで サーバーサイドをとことんやってみよう【初心者から脱初心者へ】【わかりやすさ最重視】 講義のボリューム 12.5時間 レクチャ数：132 外部公開レクチャーの有無 ○ Xサーバーへのアップロード 環境構築レクチャーの有無 ○ Win・Mac両方有り 講義内容 ・ PHP基礎 ・ お問合せフォーム ・ データベース接続 ・ セッションや高度な関数 ・ オブジェクト指向やモダンPHP ・ Laravel入門 ・ 簡易Webアプリ（CRUGFD/RESTful） ・ Webアプリを開発するために ・ 補足(XAMPPインストール, MAMPインストール, Visual Studio Codeインストール, コマンドプロンプトの使い方, composerのインストール, Laravelのインストール, Node.jsのインストール) PHPの基礎、フォームの作成、DB接続、Laravelと内容が盛りだくさんです。講師の方は、わかりやすさをモットーに講義を作成しておられることもあり、レビューの評価も高くUdemyベストセラーの講座となっています。 作成したアプリケーションをサーバーへアップロードする方法もレクチャーに含まれているので、この講義をベースに自分なりのアプリケーションを作成し外部公開/アピールが可能となります。 受講の際ですが講師の方から以下のようなお知らせが記載されています。 わかりやすさをモットーに解説しておりますが、まったくのプログラミング初心者の場合は少し内容が難しいかもしれません。全くの初心者の場合はプロゲートやドットインストールなどでプログラミングってこんなもの、と体験いただいてからご受講いただいた方がいいかもしれません。 Ruby/RailsのオススメUdemy講座はじめてのRuby on Rails入門-RubyとRailsを基礎から学びWebアプリケーションをネットに公開しよう 講義のボリューム 9時間 レクチャ数：166 外部公開レクチャーの有無 ○ Herokuへのアップロード 環境構築レクチャーの有無 ○ AWS Cloud9を使用 講義内容 ・ 開発環境構築 ・ はじめてのRuby入門 ・ 初めてのRuby on Rails入門 ・ ミニQ&Aサービスの開発 ・ インターネットにWebサービスを公開する Rubyの基礎からHerokuというPaaS環境にアプリを公開するレクチャーまで一気通貫で学べる構成になっています。 Herokuは、無料で自分のWebアプリケーションを外部公開できるクラウドサービスであり、私も重宝しているサービスです。 本講座の特徴は、AWS Cloud9というクラウド環境の開発環境を使用している点です。Cloud9を利用する場合はメールアドレス、クレジットカード、電話番号が必要です。 クレジットカードなど用意できないという方は、本ブログでDockerというコンテナ型仮想環境を使った開発環境構築方法を整理しているので参照いただければと思います。 受講の際の注意点など、講師の方から以下のようなお知らせが記載されています。Progateなどで要件を満たしてからの受講が望ましいと思います。 受講者対象プログラミング入門サイトを1周したくらいのWeb開発初心者プログラミングの基礎は学習したが、Webサービスの実際の作り方と公開の仕方がわからないポートフォリオサイトを作ってWeb系の企業に転職したい要件HTMLの基礎知識CSSの基礎知識JavaScriptの基礎知識データベース・SQLの基礎知識Linuxコマンドによるファイル操作の基礎知識（cd, ls, mv, sudoが使えるレベル） Python/DjangoのオススメUdemy講座【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） 講義のボリューム 19時間 (Django2/3両方のため実質9.5時間) レクチャ数：165 (Django2/3両方のため実質82) 外部公開レクチャーの有無 ○ VPSへのアップロード 環境構築レクチャーの有無 ○ Win/Mac両方対応 講義内容 ・ はじめに ・ フレームワークとは ・ 開発環境の構築 ・ Hello Worldアプリ ・ Todoアプリ ・ 社内SNSアプリ ・ 作成したアプリの公開 Djangoは2019年12月にバージョン3が公開されました。 Django3に対応したUdemyの日本語講座は3つほどしか存在しません。 その中でもこの講座は、Django単体では本講座が最もわかりやすく丁寧に解説されています。 ただし、HTML、CSS、Pythonの基礎は本講座では触れてないので、Progateで学んでおく方が理解は早いと思います。 受講の際の注意点など、講師の方から以下のようなお知らせが記載されています。Progateなどで要件を満たしてからの受講が望ましいと思います。 受講者対象フレームワークについてこれから学ぼうと考えている方Djangoの基礎的な内容を学びたい方要件Pythonの基礎的な文法を学んでいると、より理解を深めることができます。フレームワークやDjangoの知識は必要ありません。使われるマシンにもよりますが、Linuxの基本的なコマンド（ls、mkdir、touch、cd）を理解しているとスムーズに進めることができるかと思います。 まとめ：学習計画を踏まえUdemyを活用しよう！ 今回は、「パソコン初心者がエンジニアになるためのオススメUdemy講座」というテーマでお話しました。 まず大事なのは、Udemyは全くのプログラミング初心者には少し難しいということです。 そんな方向けの記事もまとめているので参考になればと思います。私自身は以下の記事で紹介している流れで学習を進めて土台を作り、Udemyで新たな知識を吸収しています。 最後に、Web系エンジニアに必要なスキルは、まだまだ多くことが必要になります。例えばGit/Gtihubやデータベースの知識も必要になります。でも大丈夫です。ここまで頑張ったなら、自らGoogle検索やドキュメンなどを調べて自ら学ぶための自走力はついているはずです。 なお、Udemyには無料でGit/Githubを学べるレクチャがあります。Udemyがどんなものなのかを試しに見てみる程度でも良いので、ご確認いただければと思います。 無料でGitを学ぶ！ 以上です！ Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。","link":"/2021/01/18/road-to-web-engineer/"},{"title":"【未経験OK】プログラミング学習はProgate→SkillHacks→Udemyがおすすめ","text":"学生時代は情報系ではなく化学だった私は、社会人になってからプログラミングを学び始めました。 最初は本当に大変だった。。。 その経験を踏まえ、プログラミング学習方法をまとめたいと思います。 ✓目次 [高額なプログラミングスクール不要]オンライン学習がオススメ！ 本記事が述べる良い講座の定義 -設計や思考まで解説しているかどうか- まずはパソコンを用意しよう。 最初はProgateでプログラミングの全体像をつかもう 国内のWeb系エンジニアを目指すならRubyがオススメ Progateの後はSkill Hacksがオススメ SkillHacksの次はUdemyがオススメ オンライン学習の勉強方法：ちゃんとノートを取って復習する オンライン学習の効率化のために(Git, Github) まとめ [高額なプログラミングスクール不要]オンライン学習がオススメ！ 昨今のコロナウィルスのこともあり、プログラミングスクールに行くのは少し抵抗ありませんか？ そもそもプログラミング学習は、オンラインでの動画学習が最適です。 ・ スクールに向かう移動時間を学習時間にあてられる。 ・ お金を払えば、期限なしに動画見放題 ・ 好きな時間に好きなだけ勉強できる ・ 質問も、追加料金なしで、質問し放題 ・ 教材がアップデートされる ・ 単純に安い また、プログラミング学習においては書籍で勉強は正直お勧めしません。 プログラミング言語は、時期とともにバージョンアップが図られ、文法が変わったりします。 そのため、少し古い本だとコードの仕様が変わっていたりしてエラーで動かないなんてことが頻発して、高い確率で挫折します。 本だと質問できる人がいないから、挫折しちゃうんだよね。。。 一方、オンライン学習は、書籍とは違い、その時々に応じてコードや内容等がアップデートされるし、何よりも講師の人に質問ができるので、挫折しない仕組みが整っています。 好きな時間、自分の都合の良いタイミングで、好きなだけ学習できるので最高です。 本記事が述べる良い講座の定義 -設計や思考まで解説しているかどうか- プログラミングを始めた頃に、私含めて周りのプログラミング初心者の人が勘違いしていたことは、プログラマーは何らかのサービスを作る際、完成品に向けていきなりコードを書き始めているものだと思っている点です。 当然これはNoです。 何らかのサービスを作る際に重要なのは、「設計」です。 例えば掲示板のようなアプリであれば、 記事のタイトル一覧を表示する 記事を新規に作成する 記事を削除する 記事を編集する ・・・といった機能が考えられます。 これらの機能をどのようにプログラミングに落とし込めばよいのか、というのが大切です。 本記事では、プログラミングを行う際のサービス設計や思考を丁寧に解説している教材に限定して整理したいと思います。 まずはパソコンを用意しよう。 オンボロPCしかないのですが・・・・・ インターネットに繋がってYoutubeが見れるくらいのパソコンであれば基本問題ないと思います。 Windowsであれば最低限Windows7以上、Macであれば3世代くらい前のもので十分です。 まずは気楽に身近にあるパソコンでやり始めましょう。 最初はProgateでプログラミングの全体像をつかもう まったくの初心者の方は、まずは、Progate[プロゲート]でプログラミングというのがどんなもんなのか、感覚をつかむといいと思います。 無料プランでもいいので、まずはプログラミングがどんな感じのものなのか体感しましょう。 完璧にすべてのコードを覚えようとせず、穴埋め問題的にどんどんLessonを進めてしまってOKです。まずは、プログラミングを続けていけそうかどうか（嫌いじゃないかどうか）を判断するくらいで良いと思います。 最初は誰でも初心者！プログラミングをやってみて、「難しそうだけど頑張ればできそうだな。」という感じであれば、問題ないと思うよ。 国内のWeb系エンジニアを目指すならRubyがオススメ プログラミング言語は、「国内でエンジニアとして活躍したい！」、「エンジニアとして転職したい！」というのであれば、Rubyが良いと思います。 その理由は、日本国内のWeb系エンジニアの求人として、Ruby, Ruby on Railsの求人が多いからです。※2021年1月時点 米国シリコンバレーやAIブームもあり、Pythonの人気が高くなっていますが、フリーランスエンジニアのための求人・案件サイトである、Midworksで確認いただくと、Ruby, Ruby on Railsの求人はPythonよりも多く、比較的単価も高い案件が多くなっています。 特にこだわりがなく、エンジニアとしてスタートを切りたいのであれば、Ruby, Ruby on Railsを学ぶのが良いと思います。 Progateの後はSkill Hacksがオススメ Progateは、プログラミングの感覚をつかむのは良いですが、穴埋め問題的な形で学習が進むため、たぶん、学習を終えても満足にコードが書けるようになってないのではないかと思います。 「設計」を勉強してないからしょうがない。。。 Progateでプログラミングがどんなものかを体感したら、オンライン動画でプログラミング(Ruby, Ruby on Rails)が学べる、SkillHacksの受講をおすすめします。 私のおすすめ：Skill Hacks おすすめの理由を簡単にまとめます。 ✔受講生の評価もかなりよく，絶対に挫折させない仕組みがあること ✔プログラミングスクールの現役講師が作った講座だということ ✔著者はUdemyベストセラー動画の著者・書籍執筆経験があるということ ✔エンジニア経験がある人が作っているということ ✔LINE@による無制限質問サポートで挫折しない仕組みがあるということ ✔94本のしっかりした動画があるということ ✔他のプログラミングスクールよりも安くて手頃ということ ✔動画は無期限で見放題 ✔コードを書く前のサービス設計まで丁寧に解説していること 挫折させない仕組み、って何？？ まずプログラミングをするための環境がクラウド環境であるという点です。どういうことかというと、インターネットに接続可能なパソコンがあれば誰でも始められる、ということです。 また、LINE@による無制限質問サポートが非常に良いです。 エラーが出てもすぐに講師の方に質問して解決できるので「途中で学習が進められなくなった。」みたいなことはありません。 現在SkillHacksは、以下のコンテンツが用意されています。 第00章 事前準備をしよう (2本) 第01章 HTMLのサイト作成講座 (6本) 第02章 CSSでのWebデザイン基礎講座 (6本) 第03章 HTML/CSSワークショップ -自己紹介サイトを作ろう- (6本) 第04章 Bootstrap活用デザイン講座 (7本) 第05章 Rubyプログラミング学習講座 (12本) 第06章 Rubyワークショップ -メモアプリ開発- (7本) 第07章 Ruby on Rails コントローラ・ビュー編 (14本) 第08章 Rails基礎講座 モデル・データベース編 (10本) 第09章 Rails実践編 メモアプリ開発・デプロイ (11本) 第10章 Rails実践編 メモアプリに削除編集カテゴリを追加 (13本) 本記事の冒頭でも述べているように、SkillHacksは単純にアプリを作る方法をレクチャーするのではなく、アプリを作る際の設計についても丁寧に解説されています。 そのため、1つのアプリを作る知識が単純につくのではなく、自分の作りたいアプリを自分の力で形にする思考力も身につけることができます。これが私が最もおすすめする理由です。 Skill Hacksを詳しく見る 多くの教材は、この「設計」の考え方がなく、完成品がいきなり提示され、その完成品の作成に向けてプログラミングのレクチャが始まります。 しかしSkill Hacksは、そのようなスタイルではなく、「設計の考え方まで含まれている点が良いのです。」 また、設計後にコードを書く際も、単純にコードの書き方をレクチャーするのではなく、コードを書くに至るまでの思考も細かくレクチャーしてくれるので、一流のプログラマがどのように考えながらコードを書いているのかを理解することができます。 そして何よりも、エラーで躓いた際のサポートが的確で早い点です。 しかも無制限。聞き放題です。 とはいっても、私自身は2～3回くらいしか質問しなかったです。 それだけ講座の内容が分かりやすく、躓かないように工夫がなされている証拠だと思います。 では、肝心の価格ですが、69,800円（税込）です。※2021年1月時点 少々値は張ると思いますが、この値段で、94本の動画と無制限質問サポートつき。追加料金なしの買い切り価格です。 なので、教材としては一生ものになります。 ただし、価格は予告なく上がる可能性があるようです。 近年の、コロナウィルスの影響で、リモートワークが一気に普及しました。 そのため、リモートワークがしやすい、IT企業への就職または転職を目指す人が増えてくるでしょう。 そうなれば、おのずと本講座の受講生は増えるだろうし、それに伴い、受講料も上がる可能性が高いと思います。 7万という価格で一生もののスキルを身に着けられますし、7万なんて正直すぐに回収できる価格なので、個人にとってみればほぼ無料(むしろ得でしかない)価格に等しいと思います。 Skill Hacksを詳しく見る SkillHacksの次はUdemyがオススメ Udemyとは、世界最大級のオンライン学習プラットフォームです。 Udemyは米国Udemy,Inc.が運営するプラットフォームで日本では、しまじろうでおなじみの、ベネッセが事業パートナーとして協業をしています。 講師は、現役のシリコンバレーエンジニアなど、超一流の方々ばかりです。 価格は、通常価格は2万円くらいですが、不定期で開催されるセール中は最安値で1200円で購入することができます。 すべての講座には、30日間の返還保証もついているため、「ちょっとこの講座ちがうな。」と思ったら返金してくれます。 ちなみに、私はいつも不定期に開催されるセールの時期に、興味のある講座をまとめて購入しています。 Udemyをはじめる Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。 オンライン学習の勉強方法：ちゃんとノートを取って復習する skill hacksに限らず、オンラインの動画でプログラミングなどを勉強する際は、単純に動画の通りに手を動かして進めてもあまり定着しまぜん。 理由は単純に忘れてしまうからです。。。汗 忘れないためにどうすればよいでしょうか。 動画を何度も見返せばよいでしょうか。 それでは少し非効率なのではと考えています。 私の考えとしては、 どのような思考で1つ1つのコードを書いたのかを、何度も振り返られるようにノートを取る というのが、良いと思っています。 ノートの取り方は各々の環境に合わせてやりやすい方法で良いと思いますが、 私の場合は、Boostnoteというツールを使っています。(無料です) Boostnoteに、コードを書く際の思考の流れと、実際のソースコードを記述し、Githubというコードやテキストファイルなどを保存/管理するプラットフォームに置いて、隙間時間にスマホ等で復習を行うとよいでしょう。 GitHubの使い方は、別途学習が必要なので、最初はBoostnoteに講義内容を書き留めればOKです。 Boostnoteでノートを取る際は、マークダウンという記法を活用すると、コードを色付けしてくれたりして、読みやすくなるのでお勧めです。 最低限まずは、「見出し」と「コードブロック」の書き方を覚えておけば良いでしょう。 Googleで「マークダウン 書き方」と検索すれば、記述方法がまとまった記事が出てくるので、参照してみてください。 オンライン学習の効率化のために(Git, Github) 先ほど少し述べたGIt, GitHubも学習しましょう。 Web系の会社に勤めるとなると間違いなく必要です。 自分が作成したアプリを外部に公開する際も必要になります。 Gitというのは、ドキュメントやソースコードなどの記録を変更履歴とともに管理するシステムで、GitHubは、このGitの仕組みを利用して、プログラムコードやデザインデータなどを保存できるウェブサービスです。 skill hacksで学んだ内容をGitHubに記録すれば、通勤中、奥様のお買い物の付き添い中、（環境にもよりますが）職場でも自分の勉強した内容を復習することができます。 勉強は何よりも復習が大事です。 また、GitとGitHubはエンジニアを目指すのであれば必須の知識です。 学んでおいて全く損はない（むしろ得することばかり）なので、プログラミングの学習と並行して、GitとGitHubも勉強しましょう。 なお、GitHubは、プライベートモードにしておけば、他の人に閲覧されることはないのでご安心ください。 まずは以下の無料のGithubのUdemy講座を受講しましょう。個人で使うレベルであれば、こちらのUdemyの無料講座で十分です。 無料でGitを学ぶ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sm2sCFi\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/intro_git/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/480x270/1081802_50f8_2.jpg?XV3MCps2tn22sb2zV5oDjnZGHjMMH__93M51-yhuKYWR7DxRtAuPdFt4nfjaPVHp8LglgLp1M5V9KBywz9TUWSAJt336gv1OjAmNjNVt9hQ8OLFmZ4T5linwaxMVIw\"}}); 中級レベルのGit, Githubを学ぶ必要があれば以下がおすすめです。上記の無料講座を受講いただければ、以下の講座は割引クーポンで1500円程度で安く購入できます。 Git中級編を学ぶ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rNlhfWh\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://i.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); まとめ プログラミング学習はオンライン動画がオススメ。IT技術の進化は早く、書籍での勉強は、コード仕様の変更でエラーになるなど挫折必須。 最初はProgateでプログラミングの感覚をつかむ。終わったら、Skill Hacksを受講して、エンジニアとして自走力をつけよう！ Skill Hacksが終わったらUdemyがオススメ！セール時は1200円で動画は無期限で見放題。30日間の返金保証付き！ 動画を見ながら手を動かすだけではなく、講師が口頭で述べている考え方もちゃんとノートを取ろう。 ノートはBoostnoteがおすすめ。 余力があればGit, GitHubの使い方も勉強し、作成したノートをいつでもどこでもスマホで復習できるようにしよう。 まずは無料のGit：はじめてのGitとGitHub 上記の無料講座が終わったら、Git： もう怖くないGit！チーム開発で必要なGitを完全マスターを学ぼう。 Skill Hacksを詳しく見る Udemyを詳しく見る 無料でGitを学ぶ Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。","link":"/2020/01/11/programing-study-next-of-progate/"},{"title":"【RNN基礎】RNNとはなにか？Pythonで実装しながらちゃんと理解してみる。","text":"✓目次 本記事の対象者 RNNとはなにか RNNは勾配爆発と勾配消失を起こしやすい RNNを実装してみる 訓練用データを作成する。 ①ノイズ付きサイン関数の作成 ②入力データと正解データの作成 ③入力データと正解データの形状をKerasのRNN仕様に変更する。 RNNの構築 バッチサイズとモデルの設定 モデルを作成し層を追加 構築したRNNのモデルを用いて学習 学習の推移を確認する。 学習済モデルを使ってサイン関数を予測 まとめ 参考にした文献等 本記事の対象者 ニューラルネットワークとは何かを理解している人。 pythonの基本を理解している人。 Kerasでニューラルネットワークを作ったことがある人 以下の記事で、Kerasを使ってニューラルネットワークとはどのようなものかをまとめているので、参考にしてみてください。 RNNとはなにかRNNは「リカレントニューラルネットワーク」の略です。 RNNとは、過去のデータを基に、これからどのような処理をするのかを判断することが得意なニューラルネットワークです。 時系列データを扱うのが得意なニューラルネットワークとも言われ、具体的には以下のような時系列データをあつかったりします。 株価 音声データ 音楽 文書 気象 RNNではこの時系列データを入力および正解として扱います。 RNNの特徴は、以下の図に示すように、中間層がループする構造を取る点です。 中間層がループする構造とは、中間層の出力が入力層からの次の入力とセットで、中間層への入力になるということです。 このように、自ら出力したデータを再び入力データとしてループすることを再帰といいます。 そのためRNNは、「再帰型ニューラルネットワーク」と言い換えられたりもします。 このような特徴から、RNNは過去のデータを保持することになるため、過去のデータを用いて判断を行うことができるのです。 時間\\( t\\)の経過に沿った動作を図で表すと以下のようになります。 時間が経過すればするほど、中間層が何層にもつながり、ある意味深いニューラルネットワークになることが分かります。 順伝播で入力データに対する予測が行われ、逆伝播の際に学習が行われます。 重みの更新は、通常のニューラルネットワークと同様、以下の式で表される勾配に基づいて行われます。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}}RNNと通常のニューラルネットワークとの違いは、重みやバイアスのパラメータ更新に、過去のデータからさかのぼってきた情報を利用する点にあります。 つまり、全時刻を通じて誤差をさかのぼり、重みとバイアスを更新するということになります。 RNNは勾配爆発と勾配消失を起こしやすいRNNは時系列データを用いて深いニューラルネットワークになっています。 このような構造を取った場合、何層にもわたって誤差を伝搬させることにより、勾配が大きくなりすぎるという問題が発生します。 勾配が大きくなりすぎてしまうことを勾配爆発と一般的に言い、これが起きてしまうとコンピュータ側で処理できなくなってします。 また、その逆で勾配が小さくなりすぎてしまう、勾配消失（勾配が0になる）というのも起こることがあり、学習できなくなってしまいます。 RNNは、前の時刻からデータを引継ぎ、繰り返し同じ重みを掛け合わせるため、通常のニューラルネットワークと比べて、これらの問題が起こりやすいと考えられています。 勾配爆発の対策としては、勾配クリッピングが有効です。勾配クリッピングとは、勾配の大きさに制限をかけることにより、勾配爆発を抑制することです。 勾配消失の対策としては、活性化関数を変更するか、LSTMというRNNの発展形であるニューラルネットワークを用いるのが良いそうです。 RNNを実装してみるJupyter NotebookでRNNの実装を行います。 ここでは、ノイズを含めたサイン関数を用意し、RNNを構築し、学習させたあと、学習済みモデルを使用して予測を行ってみたいと思います。 訓練用データを作成する。まずは、RNNで用いる訓練用のデータを作成します。 ①ノイズ付きサイン関数の作成サイン関数に代入する値として、\\( -2π\\)から\\( 2π\\)までの値を用意します。 123456%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまで値を50個 x_dataは以下のようになっています。 12345678910array([-6.28318531, -6.02672876, -5.77027222, -5.51381568, -5.25735913, -5.00090259, -4.74444605, -4.48798951, -4.23153296, -3.97507642, -3.71861988, -3.46216333, -3.20570679, -2.94925025, -2.6927937 , -2.43633716, -2.17988062, -1.92342407, -1.66696753, -1.41051099, -1.15405444, -0.8975979 , -0.64114136, -0.38468481, -0.12822827, 0.12822827, 0.38468481, 0.64114136, 0.8975979 , 1.15405444, 1.41051099, 1.66696753, 1.92342407, 2.17988062, 2.43633716, 2.6927937 , 2.94925025, 3.20570679, 3.46216333, 3.71861988, 3.97507642, 4.23153296, 4.48798951, 4.74444605, 5.00090259, 5.25735913, 5.51381568, 5.77027222, 6.02672876, 6.28318531]) このx_dataをサイン関数に代入し、np.random.randnにより、乱数でノイズを加えてsin_dataとします。 グラフとして描画も実施します。 1234sin_data = np.sin(x_data) + 0.3*np.random.randn(len(x_data)) # sin関数に乱数でノイズを加えるplt.plot(x_data, sin_data)plt.show() サイン関数にノイズが付いたプロットが表示されました。 ②入力データと正解データの作成続いて入力データと正解データを作りたいと思います。 1234n_rnn = 15 # 時系列の数n_sample = len(x_data)-n_rnn # サンプル数i_data = np.zeros((n_sample, n_rnn)) # 入力c_data = np.zeros((n_sample, n_rnn)) # 正解 まず、時系列の数を設定します。 時系列の数というのは、要するに中間層がループする回数です。 今回は15回中間層がループする設定にします。 サンプル数は、len(x_data)-n_rnnとなり、今回の例でいうと、50 - 15 = 35となります。 これは、入力データと正解データを1セットで1サンプルとしてカウントするためです。 具体的に説明します。 x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、これを入力データとします。 そして、入力データから値を予想するモデルを作るために必要な正解データとして、入力データを1つずらした15個分のデータ1ブロックを正解データとします。 そして1サンプルというのは、先に述べた入力データおよび正解データの2つを1セットにしたものを指します。 図で表すと以下のようなイメージです。 入力データであるi_dataは、numpyのzerosメソッドで、すべて0とし初期化しておきます。 i_dataの行数は、サンプル数であるn_sampleとし、列数は時系列の数であるn_rnnにします。 正解データに関しても同様の配列にします。 i_data.shapeを実行すると(35, 15)、つまり、35行、15列になっていることが分かります。 もちろん配列データの中身は[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]となっています。 次に初期化したi_dataとc_dataに、sin関数にノイズを加えたsin_dataを設定していきます。 123for i in range(0, n_sample): i_data[i] = sin_data[i:i+n_rnn] c_data[i] = sin_data[i+1:i+n_rnn+1] # 時系列を入力よりも一つ後にずらす 入力データi_dataは、iからi+n_rnnまでを1ブロックとして加えたものになります。 正解データc_dataは時系列を入力データよりも1つ後にずらしたものになります。 未来のデータであればsin_data[i+n_rnn+1]の一つだけでも良さそうですが、これではエラーになります。 RNNには2つのタイプがあり、最後の時刻のみの出力を使うタイプと、全ての時刻の出力を使うタイプです。 前者に必要な正解は1つですが、後者は出力の数だけ正解が必要になります。 今回は後者にあたります。 上記のコードを実行し、i_dataの中身を見てみると、以下のようになっています。 12345678array([[-0.03454036, 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603], [ 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603, -0.52893013], (略) ③入力データと正解データの形状をKerasのRNN仕様に変更する。入力と正解データを作成しましたが、Kerasでは、データの形状を(入力のサンプル数, 時系列の数, 入力層のニューロン数)にする必要があります。 現時点でのi_dataの形状は、(35, 15)になっているので、reshapeを用いて、形状を変更させます。 12i_data = i_data.reshape(n_sample, n_rnn, 1) # KerasにおけるRNNでは、入力を（サンプル数、時系列の数、入力層のニューロン数）にするc_data = c_data.reshape(n_sample, n_rnn, 1) # 今回は入力と同じ形状 i_dataの中身を見てみると以下のようになっており、形状は(35, 15, 1)となります。 それぞれサンプル数、時系列の数、入力層のニューロン数を表しています。 12345678910111213141516171819202122232425262728293031323334array([[[-0.03454036], [ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603]], [[ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603], [-0.52893013]], (略) これで、訓練用のデータを作成することができました。 RNNの構築Kerasを使ってRNNを構築します。 Kerasで活用できるRNNは主に以下があります。 SimpleRNN: RNN。全結合の中間層が再帰的になる。 LSTM: RNNの発展版であるLSTMを活用できる。複雑な時系列データを扱えるが学習に時間がかかる。 GRU: LSTMの簡易版のようなもの。LSTMに比べパラメータが少ないので、LSTMに比べて学習に時間がかからない。 お好みに合わせて、何れかのニューラルネットワークを活用すればよいと思います。 バッチサイズとモデルの設定本記事では、Kerasで活用できるRNNの中で一番シンプルな、SimpleRNN層を使います。 バッチサイズ、入力層のニューロン数、中間層のニューロン数、出力層のニューロン数を設定します。 1234567from keras.models import Sequentialfrom keras.layers import Dense, SimpleRNNbatch_size = 5 # バッチサイズn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数 これでOKです。 モデルを作成し層を追加Sequential()でモデルを作成し、層を追加していきます。 1234567model = Sequential()# SimpleRNN層の追加。return_sequenceをTrueにすると、時系列の全てのRNN層が出力を返す。# return_sequenceをTrueをFalseにすると、最後のRNN層のみが出力を返す。model.add(SimpleRNN(n_mid, input_shape=(n_rnn, n_in), return_sequences=True))model.add(Dense(n_out, activation=\"linear\"))model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 誤差は二乗誤差、最適化アルゴリズムはSGDprint(model.summary()) まずはSimpleRNNの層を追加します。 SimpleRNN追加の際は、中間層のニューロン数を設定して、入力の形状を設定します。 RNNの場合、入力の形状は、(時系列の数(15), 入力層のニューロン数(1))となります。 return_sequencesはTrueに設定します。Trueにすることで、時系列のすべてのRNN層が出力を返すことになります。これをFalseに設定すると、最後のRNN層のみが、出力を返すことになります。なお、デフォルトでは、この値はFalseになっています。 SimpleRNNの後は、Denceを追加します。 Denceは通常のニューラルネットワークにおける、全結合層になります。 Denceには、出力層のニューロン数を設定し、活性化関数を、linearに設定します。linearは、恒等関数です。 SimpleRNNでは、活性化関数を設定していませんが、SimpleRNNの標準としてtanh(ハイパボリックタンジェント)が設定されます。 最後に、compileを行います。 損失関数は、回帰の場合は二乗誤差を適用し、分類の場合はクロスエントロピーを適用するのが一般的です。今回は、回帰になるので二乗誤差を設定します。 最適化アルゴリズムには、SDGを使用します。 こちらのコードを実行すると、model.summary()によって、以下のような出力を得ることが来ます。 1234567891011121314Model: \"sequential_2\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================simple_rnn_2 (SimpleRNN) (None, 15, 20) 440 _________________________________________________________________dense_2 (Dense) (None, 15, 1) 21 =================================================================Total params: 461Trainable params: 461Non-trainable params: 0_________________________________________________________________None SimpleRNNのOutput Shapeは(None, 15, 20)となっています。15は時系列の数、20は中間層のニューロン数を意味しています。 パラメータの数は、合計で461であることが分かります。 SimpleRNNのパラメータ数は440であることが分かります。440の内訳は以下の通りです。 入力に対しての重み入力の次元数ｘ隠れ状態の次元数 → 1*20 隠れ状態に対しての重み隠れ状態の次元数 x 隠れ状態の次元数→ 20*20 バイアス隠れ状態の次元数→ 20 その他のパタンのパラメータ数の数え方については、以下の記事で分かりやすくまとめられてます。 https://qiita.com/Phoeboooo/items/6c3ea770047c820046f4 DenseのOutput Shapeは(None, 15, 1)となっています。15は時系列の数、1は出力層のニューロン数を意味しています。 参考ですが、重みやバイアスを調べる方法を以下にまとめます。 123456789print(len(model.layers[0].get_weights()))# 3i_weight, h_weight, bias = model.layers[0].get_weights() # lenが3なので、3変数に代入print(i_weight.size)# 20print(h_weight.size)# 400print(bias.size)# 20 構築したRNNのモデルを用いて学習学習は、fitメソッドを用いて行う。 入力データ(i_data)、正解データ(c_data)のほかにエポック数を指定する。 またバッチサイズとバリデーションスプリットも指定を行う。 1history = model.fit(i_data, c_data, epochs=100, batch_size=batch_size, validation_split=0.1) すると以下のように学習が走ります。 12345678910111213141516Train on 31 samples, validate on 4 samplesEpoch 1/10031/31 [==============================] - 0s 5ms/step - loss: 0.3232 - val_loss: 0.2373Epoch 2/10031/31 [==============================] - 0s 631us/step - loss: 0.2265 - val_loss: 0.2034Epoch 3/10031/31 [==============================] - 0s 551us/step - loss: 0.2003 - val_loss: 0.1930(略)Epoch 98/10031/31 [==============================] - 0s 500us/step - loss: 0.1233 - val_loss: 0.1471Epoch 99/10031/31 [==============================] - 0s 505us/step - loss: 0.1233 - val_loss: 0.1467Epoch 100/10031/31 [==============================] - 0s 490us/step - loss: 0.1230 - val_loss: 0.1468 学習の推移を確認する。lossとval_lossを確認していきましょう。 123456loss = history.history['loss']vloss = history.history['val_loss']plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 訓練用のデータ、検証用のデータ、共に収束していることが分かります。 学習済モデルを使ってサイン関数を予測入力データを用います。 入力データ(i_data)とは何なのかをおさらいすると、、x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、このブロックが合計で35個あるデータでした。 i_data.shapeを実行すると(35, 15, 1)と出力されることからも理解ができると思います。 入力データから最初の行列取り出し、reshape(-1)で1次元のベクトルにし、predictedという変数に格納します。 12predicted = i_data[0].reshape(-1) # 入力データの最初の行列データを取り出し、reshape(-1)で一次元のベクトルにする。predicted これを実行すると、以下のように出力されます。 123array([-0.29245656, 0.33761251, 0.73473534, 0.88417973, 0.8520399 , 0.91658402, 1.33572366, 0.84339794, 1.00440569, 0.45843943, 0.56022552, 0.23427566, 0.10704196, -0.65186734, -0.73755624]) 次に、この入力データ(predicted)を学習済みのモデルに入力し、値の予測をさせてみたいと思います。 以下のfor文になります。 123for i in range(0, n_sample): y = model.predict(predicted[-n_rnn:].reshape(1, n_rnn, 1)) # 直近のデータを使って予測を行う predicted = np.append(predicted, y[0][n_rnn-1][0]) # 出力の最後の結果をpredictedに追加する 最初のforループでは、predicted[0:]となるので、predictedに代入されているすべての15データを使って予測をしています。 その後、予測値yの末尾をpredictedに追加しています。 2回目以降のループでは、前回の予測値yの末尾を含んだ直近のデータ15個で予測をしています。 そのため、2回目のループでは、「predictの先頭のデータを除いた14個のデータ」 ＋ 「末尾に加えられた予測値yのデータ」の合計、15個のデータで予測を行っています。 そのため、ループの16回目からは、もともとのpredictのデータは全く使われず、すべて予測値yのデータで、追加予測をしていることになります。 予測結果を確認してみます。比較のために、sin_dataも同時にプロットします。 1234plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")plt.plot(np.arange(len(predicted)), predicted, label=\"Predicted\")plt.legend()plt.show() 青いラインが訓練用のデータで、オレンジのラインが学習済みのRNNのモデルで予測した結果です。 このように、直近の時系列データを使って、次の値を予測できるようになりました。 直近のデータを加えながら予測を行っているため、グラフが右に進めば進むほど、誤差の影響が積み重なるように受けてしまうため、訓練用データとのずれが大きくなっていることが確認できます。 まとめ今回は、sin関数の予測を行いました。 cos関数の予測に挑戦してみたり、各設定値を変えたり、実際の時系列データ（株価等）に適用してみたりすれば、より理解を深められるかもしれません。 参考にした文献等 ニューラルネットワークをちゃんと学びたい！という方は以下のUdemyの講座がおすすめ。Stay Home期間中にオンライン講座でスキルを身に着けるのはいかがでしょうか？ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXZlto6\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku_blackbox_1/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356190_9cbb_6.jpg\"}}); 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - ニューラルネットワークの発展形であるRNNやLSTMを構築して自然言語処理を学びたい方は、以下がおすすめです。本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 https://note.nkmk.me/python-tensorflow-keras-count-params/ https://note.nkmk.me/python-tensorflow-keras-get-weights-kernel-bias/ https://qiita.com/Phoeboooo/items/6c3ea770047c820046f4 https://nzw0301.github.io/2016/05/comparison-rnn","link":"/2020/05/06/rnn-basic/"},{"title":"【翻訳技術】seq2seqを実装しながら理解してみた","text":"✓目次 本記事の対象者 seq2seqとはなにか 訓練用のデータを作成する。 seq2seqの構築 1. 学習用モデル構築（ライブラリのインポートとモデルの設定） 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 コサイン関数をサイン関数に翻訳 本記事の対象者 ・ RNNとLSTMを理解している人 ・ pythonの基本を理解している人。 ・ Kerasでニューラルネットワークを作ったことがある人 RNNの基礎については以下の記事でまとめているので参照してください。 RNNの基礎を学びたい方はこちら↓ また、実行環境としてはJupyter Notebookになります。以下の記事に従って環境構築していただければと思います。 環境構築はこちら↓ 今回は、Kerasを使ってseq2seqを構築し、コサイン関数をサイン関数に変換（翻訳）してみたいと思います。 seq2seqとはなにかseq2seqは、シーケンスを受け取り別のシーケンスに変換するモデルのことで、文章などの入力を圧縮するencoderと、出力を展開するdecoderからなります。 「私はペンを持っている」という文章を、「I have a pen」という英文に翻訳することが可能となります。 encoderとdecoderに、それぞれRNNの層が構築され、encoderとdecoderが接続させることによってseq2seqが作られます。 seq2seqの仕組みについては以下の記事が大変分かりやすいので、参考にしてください。こちらでまとめられている絵を見ながら、以降の記事を読んでいただくと、それぞれのコードがどの領域の実装なのかがイメージしやすくなると思います。https://sinyblog.com/deaplearning/seq2seq-001/#i 少々複雑に聞こえるかもしれませんが、今回は簡単な例としてcos関数をsin関数に翻訳する形で、その構造を理解したいと思います。 訓練用のデータを作成する。cos関数の値をencoderへの入力、sin関数の値をdecoderへの入力とします。 なお、正解は、sin関数になります。 decoderへの入力というのは正解から1つ後の時刻にずらした値になります。これは、ある時刻におけるdecoderの出力が、次の時刻における入力に近づくように学習をさせるためです。 このように、ある時刻における正解が次の時刻の入力となる手法を教師強制と言います。 まずは、cos関数とsin関数を作成してプロットしてみます。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_ax = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまでの50つの値cos_data = np.cos(x_ax)sin_data = np.sin(x_ax)plt.plot(x_ax, cos_data)plt.plot(x_ax, sin_data)plt.show() 次に、encoderへの入力、decoderへの入力、decoderの正解を作成します。 今回、時系列の数は10に設定しておきます。 zerosメソッドでエンコーダー、デコーダー、正解の形状を作成します。 今回はすべて同じ形状にする。 1234567891011n_rnn = 10 # 時系列の数n_sample = len(x_ax) - n_rnn # サンプル数x_encoder = np.zeros((n_sample, n_rnn)) # encoderの入力x_decoder = np.zeros((n_sample, n_rnn)) # decoderの入力t_decoder = np.zeros((n_sample, n_rnn)) # decoderの正解print(x_encoder.shape)print(x_decoder.shape)print(t_decoder.shape)# 全部(40, 10) x_encoderには、コサイン関数の値を入れていき、x_decoderにはサイン関数の値を入れていきます。 この時、x_decoderに入れるサイン関数は、1つ後の時刻にずらす必要があります。時系列で1以降の値に代入するので最初の値は0のままということになります。 123456789101112131415161718for i in range(0, n_sample): x_encoder[i] = cos_data[i:i+n_rnn] x_decoder[i, 1:] = sin_data[i:i+n_rnn-1]x_decoder# array([[ 0.00000000e+00, 2.44929360e-16, 2.53654584e-01,# 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01],# [ 0.00000000e+00, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 0.00000000e+00, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01], 続いて正解データであるt_decoderを作成します。 t_decoderには、サイン関数の値をそのまま入れます。 1234567891011121314151617for j in range(0, n_sample): t_decoder[j] = sin_data[j:j+n_rnn]t_decoder# array([[ 2.44929360e-16, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 2.53654584e-01, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01],# [ 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01, 7.40277997e-01, 5.45534901e-01,# 3.15108218e-01], KerasにおけるRNNの入力の形状にするために、x_encoder, x_decoder, t_decoderの形状を、サンプル数、時系列の数、入力層のニューロン数という形状に変更しておきます。 123x_encoder = x_encoder.reshape(n_sample, n_rnn, 1) # （サンプル数、時系列の数、入力層のニューロン数）x_decoder = x_decoder.reshape(n_sample, n_rnn, 1)t_decoder = t_decoder.reshape(n_sample, n_rnn, 1) これで、データの準備はOKです。 seq2seqの構築Kerasを使ってseq2seqを構築していきます。 seq2seqの特徴は、学習用のモデル構築と予測用のモデル構築の2つのモデル構築を別々で行う点にあります。 学習用のモデルと予測用のモデルの中に、それぞれencoderとdecoderが存在します。 この特徴を踏まえ、以下のような流れで作成を進めていきます。 1. 学習用モデル構築(ライブラリのインポートとモデルの設定) 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 それでは一つ一つ順を追ってseq2seqを構築していきたいと思います。 1. 学習用モデル構築（ライブラリのインポートとモデルの設定）これまで、RNNやLSTMを構築した際は、Sequentialクラスを使用してましたが、今回は、Modelクラスを使います。 Modelクラスを用いることで、複数の経路の入力を持つニューラルネットワークを構築することが可能だからです。 また状態を渡すことでRNN同士を接続することもできます。 今回のseq2seqのRNN部分にはLSTMを使おうと思います。 各種ライブラリをインポートしていますが、今回はInputというのも導入します。 Inputは、入力層を表すライブラリです。 モデルの設定をしていきます。入力層のニューロン数は1、中間層のニューロン数は20、出力層のニューロン数は入力層のニューロン数と同じにします。 123456from keras.models import Modelfrom keras.layers import Dense, LSTM, Inputn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = n_in # 出力層のニューロン数 こちらのコードで各種ライブラリのインポートと、モデルの設定は完了です。 2. 学習用モデル構築(encoderの構築)最初にInputを使ってencoderの入力層を設定します。 Inputを使用する際は、入力の形状を設定する必要があります。時系列数, 入力層のニューロン数を指定しますので、n_rnn, n_inとします。 1encoder_input = Input(shape=(n_rnn, n_in)) 続いてencoderにLSTMを設定します。中間層のニューロン数を設定し、return_stateをTrueに設定します。 return_stateをTrueに設定すると、その時刻における出力と共に状態を得ることができます。 LSTMにおける出力\\(h_{t}\\)と状態であるメモリセルを得ることができるということです。 1encoder_lstm = LSTM(n_mid, return_state=True) そして、このencoderのLSTMに、先ほどのencorderの入力を渡します。その結果得られるのは、encoderの出力とencoderの状態\\(h\\)とencoderの状態\\(c\\)になります。 LSTMの内部に\\(h\\)と\\(c\\)という2つの状態を持っている点については、以下の記事で詳しくまとめらていますので、詳細が知りたい方は参考にしてください。https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca 1encoder_output, encoder_state_h, encoder_state_c = encoder_lstm(encoder_input) この2つの状態\\(t\\)と\\(c\\)は、リストでまとめておき、encoder_stateとしておきます。 1encoder_state = [encoder_state_h, encoder_state_c] これでencoderは完成です。 3. 学習用モデル構築(decoderの構築)まずInputを用いて、decoderの入力層を作ります。 1decoder_input = Input(shape=(n_rnn, n_in)) encoderの時と同様、LSTMの層を作ります。こちらも先ほど同様に、return_stateをTrueにしておきますが、return_sequencesもTrueにしておきます。 このようにすることで、すべての時系列の出力を出力として得ることができます。 1decoder_lstm = LSTM(n_mid, return_sequences=True, return_state=True) decoderのLSTMには、先ほど作成したdecoder_inputを入れます。その際に初期状態であるinitial_stateに先ほどのencoder_stateに設定します。 その結果返ってくるのが、decoderの出力と2つの状態です。 この段階で、decoderから出力された状態は使わないので、とりあえず_をいれておきます。 1decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_state ) LSTM層の次に、全結合層であるDenseを入れます。 Denseには出力層のニューロン数を設定します。活性化関数は、ひとまずlinearとしておきます。linearは恒等関数を意味します。 1decoder_dense = Dense(n_out, activation='linear') そして、このdecoder_denseにdecoder_outputを入れることでdecoderの出力を得ることができます。 1decoder_output = decoder_dense(decoder_output) decoderの構築はこれで完了です。 4. 学習用モデル構築(モデルのコンパイル)まずはseq2seqにおける学習用のモデルを構築していきます。 Modelクラスを用いてモデル構築を行います。 Modelクラスは、全体の入力と出力のみ設定すればOK、という優れものです。 入力が複数存在する場合は、リストを使って設定すればOKです。 入力は、encoder_inputとdecoder_inputの2つになります。 そして全体の出力は、decoder_outputになるので、コードとしては以下となります。 1model = Model([encoder_input, decoder_input], decoder_output) 次にモデルのコンパイルを実施します。 コンパイルの際は、損失関数とと最適化アルゴリズムを指定する必要があります。 損失関数は回帰の場合は、二乗誤差で、分類の場合はクロスエントロピーが提供されるのが一般的です。 今回は、encoderの入力から、学習した結果に基づいて翻訳結果を予測するので、二乗誤差を適用します。 最適化アルゴリズムは、収束しやすいadamでもいいですが、sgdを適用してみたいと思います これでモデル構築は完了なので、print(model.summary())で、構築したモデルの概要を確認したいと思います。 1234567891011121314151617181920212223model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")print(model.summary())# Model: \"model_11\"# __________________________________________________________________________________________________# Layer (type) Output Shape Param # Connected to # ==================================================================================================# input_18 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# input_19 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# lstm_9 (LSTM) [(None, 20), (None, 1760 input_18[0][0] # __________________________________________________________________________________________________# lstm_10 (LSTM) [(None, 10, 20), (No 1760 input_19[0][0] # lstm_9[0][1] # lstm_9[0][2] # __________________________________________________________________________________________________# dense_5 (Dense) (None, 10, 1) 21 lstm_10[0][0] # ==================================================================================================# Total params: 3,541# Trainable params: 3,541# Non-trainable params: 0# __________________________________________________________________________________________________# None encoderの入力とdecoderの入力があります。 また、encoderのLSTMとdecoderのLSTMがあります。decoderの方は、全結合層であるDenseを1つ所持していることが確認できます。 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施)RNNの時と同様にfitメソッドを使用して学習を行います。 入力は、x_encoderとx_decoderとし、正解は、t_decoderを指定します。 バッチサイズを10とし、エポック数を30に設定します。 123history = model.fit([x_encoder, x_decoder], t_decoder, batch_size=8, epochs=30) 6. 学習用モデル構築(学習の推移を確認する。)以下のコードでグラフで誤差の収束具合を確認します。 123loss = history.history['loss']plt.plot(np.arange(len(loss)), loss)plt.show() んー、収束しきってない気がします。 7. 予測用モデル構築(encoderのモデルを構築)seq2seqでは、訓練用のモデルと、予測用のモデルを別々に構築する必要があります。 予測用モデルは、学習済みのオブジェクトから、encoder, decoderのモデルを構築します。 encoderは入力を受け取り状態を返し、decoderは入力と状態を受け取って出力と状態を返すようにします。 まずはModelクラスを用いてencoderのモデルを構築します。 入力としてencoder_input、出力としてencoder_stateを設定します。 encoder_inputとencoder_stateの間には、encoder_lstmが存在する構造をとっています。このencoder_lstmは先ほどの学習済みのLSTMになります。 これだけで、予測用モデルにおけるencoderは完成します。 1encoder_model = Model(encoder_input, encoder_state) 8. 予測用モデルの構築(decoderのモデルを構築)続いて予測用モデルのdecoderを構築します。 入力層は、新規にInputを使って作成します。形状は、時系列の長さ、入力層のニューロン数を設定します。 今回は、時系列の長さは1で入力層のニューロン数はn_inで設定しているので、以下のようになります。なお、時系列の長さが可変である場合は、Noneを設定します。 1decoder_input = Input(shape=(1, n_in)) LSTMには内部に2つの状態を持つので、状態の入力を2つ作ります。 この2つの状態は、decoder_state_in_hとdecoder_state_in_cとします。 それぞれの状態の数は、中間層のニューロンの数と同じになります。 これらは、1つのリストにまとめて、decoder_state_inとしておきます。 123decoder_state_in_h = Input(shape=(n_mid,))decoder_state_in_c = Input(shape=(n_mid,))decoder_state_in = [decoder_state_in_h, decoder_state_in_c] 次に先ほどのdecoder_lstmにdecoder_inputとdecoder_state_inを設定します。decoder_state_inは、初期状態として設定するので、initial_stateとしておきます。 decoder_lstmも同様、既存の学習済みのLSTMになります。 1decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_input, initial_state=decoder_state_in) 得られたdecoder_state_hとdecoder_state_cは、以下のようにリストにし、そのうえで、decoder_denseにdecoder_outputを入れて、decoderの出力を得ることができます。こちらも、すでに学習済みのDenseになります。 12decoder_state = [decoder_state_h, decoder_state_c]decoder_output = decoder_dense(decoder_output) いよいよ、decoderのモデルを構築します。 モデル化の際に、入力として渡すのは、decoder_inputとdecoder_state_inです。 出力は、decoder_outputとdecoder_stateになります。 それぞれ、リストとして値を保持しており、入力として渡す際は、各リストを結合して渡すので、+でリストを結合しています。 1decoder_model = Model([decoder_input] + decoder_state_in, [decoder_output] + decoder_state) 9. 翻訳用の関数を定義コサイン関数を翻訳して、サイン関数に変換するための関数を定義します。 encoderへの入力値であるinput_dataを渡し、予測用モデルに適用した翻訳結果を返す処理を定義します。 12345678910111213def translate(input_data): translated = [] state_value = encoder_model.predict(input_data) # 予測モデルのencoderにinput_dataをわたし、学習済みのLSTMで予測。出力は、内部状態h, cの2つが出力される y_decoder = np.zeros((1, 1, 1)) for i in range(0, n_rnn): y, h, c = decoder_model.predict([y_decoder] + state_value) # 1つ前の時刻の出力(最初は空)と、状態（内部状態hとc）をdecoder_modelの学習済みLSTMとDenceで予測、 y = y[0][0][0] # 出力yから翻訳された結果を抽出 translated.append(y) y_decoder[0][0][0] = y # 次の時刻に渡す値 state_value = [h, c] # 次の時刻に渡す状態 return translated コサイン関数をサイン関数に翻訳123456789idices = range(0, 40)for indice in idices: x = x_encoder[indice:indice+1] # 入力を一部取り出す y = translate(x) plt.plot(x_ax[indice:indice+n_rnn], x.reshape(-1), color=\"b\") # 翻訳前を青い線 plt.plot(x_ax[indice:indice+n_rnn], y, color=\"r\") # 翻訳後は赤い線 plt.show() 翻訳の結果としては少々いまいちでした。 epoc数を30ではなく50に増やして再度翻訳してみます。 まだ微妙ですね。思い切ってepoc数を100に増やして再度実施してみます。 収束しきっているようなしていないような微妙な感じです。翻訳までさせてみると以下のような感じです。 どうやらこの三次元的なコサインカーブはどうにもならないみたいですね。 こんな時は、最適化アルゴリズムをsgdではなく別のものを適用すると改善される可能性が高いです。もしくは、通常のニューラルネットワークとかですと、中間層のニューロン数を増やしたり、層を増やしたりするのもある程度完全が見込めるかもしれません。最終手段としてはデータの中心化（バッチノーマリゼーション）と言われる処理をするとよくなるパタンが多いそうです。 今回は、KerasのDocumentationにて記載のある最適化アルゴリズムの中で、Adagradという最適化アルゴリズムを適用してみたいと思います。 以下のように、Adagradという風にするだけです。エポック数は100のままにしています。 1model.compile(loss=\"mean_squared_error\", optimizer=\"Adagrad\") 誤差の収束具合は以下の通りです。（さっきと全然違う） 肝心の翻訳結果は以下の通りです。すごい、ちゃんとコサインカーブになりました。 以上です。 以下のUdemyのコースを参考にさせていただきました。基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。こちらでまとめたSeq2seqを応用して、文豪の小説文を学習し、入力データに対して、それらしい応答をしてくれるチャットボットの構築をするなど、とても面白い内容になっています！ Seq2seqを活用してAIチャットボットを学びたい方は必見です！ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 本格的にAIを学びたい人へ 以下の何れかに該当する方は、キカガクさんのオンラインスクールがおすすめです。まずは無料のカウンセリングに参加し、自分が目指すキャリアや身に着けたいスキルが学べるか、等確認してみてください ・プログラミング初学者（Pythonで機械学習を学びたい方）・機械学習を学び、キャリアに活かしたい方・何かAIサービスを企画、開発したい方・技術を身に着けて転職したい方・E資格を取得したい方 無料カウンセリング予約はこちら","link":"/2020/05/17/seq2seq-study/"},{"title":"【85講座受講】技術者が推奨するUdemyのPython講座オススメ集","text":"Udemyが1/21(木)までセール中！￥1,500から購入できるチャンスです！ 本記事では、オンライン学習マニアである筆者がオススメする、オンライン学習プラットフォーム「Udemy」のPythonプログラミング講座を紹介します。 記事の信頼性(自己紹介) omathin ・IT企業のアーキテクト|研究者. ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得 分かりにくくて恐縮ですが、Udemyは85コースほど受講しており、Pythonの講座も海外含めて複数受講しております。 そんな私がUdemyでオススメのPython講座をまとめていきます。 目次 Udemyがオススメの理由 Udemyが提供するPythonのジャンル一覧 Pythonの基礎文法/アルゴリズム 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 Webアプリ開発 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！ データサイエンス 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 AI/機械学習/深層学習 みんなのAI講座 ゼロからPythonで学ぶ人工知能と機械学習 【2020年最新版】 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - ディープラーニング特化講座(自然言語処理) 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 まとめ：迷わずUdemyで学び始めよう！ Udemyがオススメの理由 Udemy 各社プログラミング教室 価格 1200円〜※セール時30日以内であれば返金可能 20万以上＋交通費 拘束時間 特になし。好きな時に好きなだけ受講可 教室利用時間が限られる サポート Udemy講師が直接回答 メンターサポート制度 講師 全国の一流エンジニア現役シリコンバレーエンジニア等 国内の専任講師 なんと言ってもこの価格の低さです。しかも好きな時に好きなだけ受講できるのです。 また、プログラミングは、書籍での学習はおすすめしません プログラミング言語は日々仕様が代わるため、本がちょっとでも古いとエラーで動かないなんてことが頻発します。 一方Udemyは、講師の方が教材をアップデートしてくれるので安心です。 Udemyの教材が他と比較してコスパが良いかおわかりいただけたかと思います。 Udemyが提供するPythonのジャンル一覧 Pythonの分野 1. Python基礎文法/アルゴリズム2. Webアプリ開発3. データサイエンス4. AI/機械学習/ディープラーニング5. ディープラーニング特化講座（自然言語処理） 以降は、これらのジャンル別および受講レビュー含めて紹介します。 Pythonの基礎文法/アルゴリズム Pythonの基本的な文法およびプログラミング力を向上させるアルゴリズム論に関するオススメ講座をまとめます。 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル こちらはシリコンバレーのエンジニアである酒井潤さんの講座です。シリコンバレーはIT技術の最先端企業が集まる都市です。そんな、IT最先端としで現役エンジニアとして活躍されている方が、「美しいコードの書き方」含めてPythonの基礎をレクチャーしてくれる講座です。1200円で超一流エンジニアの講義が受けられるなんで、素晴らしいと思いませんか？ 講義のボリューム 28時間36分レクチャ数：290 レベル 初級 講義内容 ・ Python環境の設定 ・ Pythonの基本 ・ データ構造 ・ 制御フローとコード構造 ・ モジュールとパッケージ ・ オブジェクトとクラス ・ ファイル操作とシステム ・ 入門編の終了 応用編に行く前に簡単なアプリケーションの演習 ・ コードスタイル ・ コンフィグとロギング ・ データベース ・ Webとネットワーク ・ テスト ・ 並列化 ・ 暗号化 ・ インフラ構築自動化 ・ Pythonの便利なライブラリやツールや豆知識 ・ グラフィックス ・ データ解析 ・ キューイングシステム ・ 非同期処理 asynico ・ 最後に 筆者の所感 ご覧の通りすごいボリュームです！用途としてはPythonに関する辞書みたいな形で活用するべきだと思います。空き時間にスマホとかで眺めたり、実際にコードを書いて動作を確認するという使い方なのかなと思います。応用編の内容は高度であり、正直初心者にはかなり辛いかと思います。「こんな使い方もあるのか」という認識でまずは全体を眺め、気になる部分は注意してみる学び方で良いと思います。 この講座を確認する 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編）【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） こちらは株式会社キカガクさんが提供するPythonプログラミング力向上のための講座です。 キカガクさんは、AI人財の教育事業を中心とする企業です。UdemyではAI系の講座を中心にベストセラーとなっている講座を数多く提供しています。 講義のボリューム 3時間31分レクチャ数：17 レベル 初級 講義内容 ・ コース紹介 ・ イントロダクション(Pythonの基礎) ・ 演習課題1: 素数を見つけるアルゴリズム ・ アルゴリズム徹底練習 ・ 演習課題2: 圧縮のアルゴリズム ・ ボーナスレクチャー: AI人材としてプロフェッショナルになるための教育とは？ 筆者の所感 プログラミング初心者であればキカガク流シリーズは間違いないかと思います。プログラミング初学者がつまづくポイントをちゃんと抑えた講義内容になっています。プログラミングに自信がない or 経験が浅い方は、このコースの受講を推奨します！ この講座を確認する 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 こちらはシリコンバレーのエンジニアである酒井潤さんの講座です。最先端のIT企業に就職する際はコーディングテストというものが存在します。様々なアルゴリズムを簡潔で誰でも読みやすい形式でかけるかどうかが試される試験対策の講義になります。 講義のボリューム 12時間47分レクチャ数：64 レベル 初級 講義内容 ・ はじめに ・ アルゴリズムと計算量 ・ ソート ・ サーチ ・ リンクリスト ・ ハッシュテーブル ・ スタックとキュー ・ ツリー ・ ハッシュルのクイズ ・ カウントのクイズ 筆者の所感 とっつきにくいアルゴリズムを１つ１つ丁寧に紹介されています。コードの中身が詳しく解説されている素晴らしい講座です。ただ、Udemyでは初級と表記されているものの、個人的にはPythonの基礎をほぼ習熟している中級者向けなのではというのが正直なところです。この講座でわからないことが出てきたら、酒井先生のPython基礎講座に戻って確認するというやり方が良い勉強法だと思います。 この講座を確認する Webアプリ開発 PythonでWebアプリケーション開発をする際に必須となるフレームワークに焦点を当てたオススメ講座を紹介します。 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） こちらは大橋亮太先生の講座です。具体例をたくさん入れた解説が好評であり、「なぜ」の説明が丁寧です。初学者の方々に挫折してもらいたくないという気持ちが見て取れます。 講義のボリューム 19時間 レクチャ数：165(Django2/3両方公開中のため実質9.5時間82レクチャ) レベル 初級 講義内容 ・ はじめに ・ フレームワークとは ・ 開発環境の構築 ・ Hello Worldアプリ ・ Todoアプリ ・ 社内SNSアプリ ・ 作成したアプリの公開 筆者の所感 Djangoのチュートリアルレベルを理解し使えるレベルにするならこの講座一択だと思います。Python初心者でもついていけるように丁寧な解説が印象的でした。質問に対する回答も非常に丁寧なので、「初心者だけどPythonで何か作りたい」という方にとっては最適な講座だと思います。よくある失敗するコードと解決までの流れも紹介してくれるため、自力でDjangoを使用したWebアプリを作る力をつけられます。本講座で完成したWebアプリをカスタマイズして自分だけのアプリを開発してみましょう！ この講座を確認する データサイエンス データサイエンスとは、簡単に言えば抽出したいデータをWebから収集/解析し、欲しい情報や解析結果を得る手法になります。例えば、Twitterから何らかのキーワードに関連する情報を抽出し、その中でもバズっているツイートのみを抽出する、とかができます。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 こちらは大橋亮太先生の講座です。数学や確率理論から、プログラミング、実装まで幅広い講義ですが無駄がありません。総講義時間も非長いですが、よく構成が練られているため、全く長さを感じさせない作りになっています。 講義のボリューム 26時間24分 レクチャ数：439 レベル 初級 講義内容 ・ はじめに ・ データサイエンスの領域 ・ 確率（ベイズ理論、分布等） ・ 統計 ・ Python ・ 線形回帰、ロジスティック回帰、クラスター分析等 ・ ・・・(多すぎて書ききれません笑) 筆者の所感 データ分析に必要な要素がすべて盛り込まれています。今後、データサイエンティストとして実業務を進める上でも、リファレンスとして何度も振り返る価値のある教材だと思います。Pythonに引っ張られず、データサイエンスの全体像から説明されているので、非技術者の方にもおすすめです。 この講座を確認する AI/機械学習/深層学習 文字認識や株価予測等をPythonでコード化する学習領域です。 みんなのAI講座 ゼロからPythonで学ぶ人工知能と機械学習 【2020年最新版】みんなのAI講座 ゼロからPythonで学ぶ人工知能と機械学習 【2020年最新版】 こちらは我妻幸長先生の講座です。我妻先生は、UdemyだけでなくYoutubeでもAIに関する講義を発信しています。複数の有名企業でAI研修を担当されており、数多くの書籍も発行されているAIのプロフェッショナルな方です。 講義のボリューム 13時間4分 レクチャ数：136 レベル 初級 講義内容 ・ 人工知能の概要と開発環境 ・ Pythonの基礎 ・ 必要な数学の学習 ・ ニューラルネットワーク ・ 機械学習 ・ 機械学習ライブラリの活用 ・ さらに学ぶために(機械学習ライブラリの活用、発展技術の解説等) 筆者の所感 Google ColaboratoryというChromeブラウザ上でPythonコードが使える環境を用いて講義が進みます。そのため環境構築に困ることなく学習をすすめることができます。全くの初学者向け、というよりかはある程度Pythonを学んでいる方向けだと思います。 この講座を確認する 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 -【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - こちらは株式会社キカガクさんが提供する人工知能・機械学習の講座です。 講義のボリューム 4時間17分 レクチャ数：25 レベル 初級 講義内容 ・ コースの紹介 ・ 微分 ・ 単回帰分析 ・ Python速習 ・ 単回帰分析の実装 筆者の所感 キカガクさんの講座は、完全な初心者の方には最適です。機械学習の仕組み理解に必要な数学を紙に手書きで数式を書きながらすすめる講義は、驚くほどわかりやすいと思います。数学に自信がない方も、この講座から始めると良いのかなと思います。 この講座を確認する ディープラーニング特化講座(自然言語処理) 深層学習(ディープラーニング)をより深く学ぶための講座として、自然言語処理に特化したオススメ講座を紹介します。 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 こちらは我妻幸長先生の講座です。日本語で提供されている自然言語処理のUdemy講座は、我妻先生の講座しかないかな、という印象です。 講義のボリューム 6時間2分 レクチャ数：47 レベル 初級 講義内容 ・ Pythonの基礎 ・ 必要な数学 ・ ニューラルネットワークとバックプロパゲーション ・ 自然言語処理の準備 ・ word2vec ・ リカレントニューラルネットワーク(RNN) ・ LSTM ・ 文章の生成(seq2seq) 筆者の所感 ディープラーニングのさらなる理解を、自然言語処理技術に触れながら深めるには最適の講座だと思います。私は、こちらで学んだ内容を元にサンドウィッチマンの漫才を訓練させて自動生成するアプリを作ったりしました。完全初心者の方だと少し理解が難しい部分が多いと思いますが、純粋に深層学習でどんなことができるのかを具体的に理解する目的で受講しても良いかと思います。 まとめ：迷わずUdemyで学び始めよう！ 本記事では、「【85講座受講】技術者が推奨するUdemyのPython講座オススメ集」というテーマでお話しました。 数あるUdemyの講座を受講した経験を元に特に素晴らしいPythonの講座を厳選したつもりです。 Udemyにはこの記事で紹介しきれないくらい豊富な講座があります。 求めている講座が必ずあるはずなので、まずは会員登録だけ行い、どんな講座があるのか確認だけでもしてみるのはいかがでしょうか？「ちょっと、違うかな。」と思ったら30日以内であれば返金可能です！ 迷っている時間がもったいないです。今すぐはじめましょう！ Udemyを詳しく見る よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/2021/01/20/udemy-python/"},{"title":"【AI】LSTMでサンドウィッチマンの漫才を学習して予測させてみた","text":"本記事では、LSTM(Long short-term memory)というRNNの拡張モデルを活用して、サンドウィッチマンさんの漫才ネタを学習させて、もっともらしい単語の予測をさせてみました。 ツイートした内容としては以下になります。それなりにリアクションあり。 目次 LSTMとは 入力データの準備 データの読み込み 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定 各文字のベクトル化 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 時系列データと予測する文字の抽出 入力と正解をone-hot表現で表す LSTMモデルの構築 文書を生成するための関数を記述し学習 まとめ LSTMとは以下の記事で詳細にまとめられています。 https://qiita.com/t_Signull/items/21b82be280b46f467d1b LSTM(Long short-term memory)は、RNN(Recurrent Neural Network)の拡張として1995年に登場した、時系列データ(sequential data)に対するモデル、あるいは構造(architecture)の1種です。その名は、Long term memory(長期記憶)とShort term memory(短期記憶)という神経科学における用語から取られています。LSTMはRNNの中間層のユニットをLSTM blockと呼ばれるメモリと3つのゲートを持つブロックに置き換えることで実現されています。 要するにRNNの中間層がLSTM層に置き換わったものであるということです。 LSTM層の内部には、記憶セル、入力ゲート、出力ゲート、忘却ゲートという内部要素を保持しており、複雑に絡み合っております。 しかしながらPythonのKerasを用いることでシンプルに実装することができます。 なお、RNNについては以下の記事でまとめているので参考にしてください 入力データの準備今回は、サンドイッチマンさんの漫才ネタをテキストデータとして用意したものを使います。 その中でも私個人的に好きな、ハンバーガー屋のネタ、弔事のネタ、旅行代理店のネタの3つを、テキストで書いたものです。 以下のような感じです・ sand_manzai.txt12345あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。(略)婚活パーティーか、お前。金取れ、女からも。バカたれ！さっ！というわけでねっ。そろそろお時間となってしまいました。何でラジオの終わりみたいになってんの。おかしい。DJみたいになってんじゃん、急に。ホントにねっ。まろやかに眠ってもらいたいです。いやいや。やすらかにだよ、やすらかに。まろやかにってお前、クリープかお前。それではまた、来週のこの時間まで！さようならぁ～！来週もやんのかよ。どういうことだよ、これお前。こんな感じでどうかな？全部書き直せ。もういいぜ。 ハンバーガー屋のネタから弔事のネタまでを、ただ単にテキストで書き連ねただけのデータです。 データの読み込みまずは、このテキストデータをJupyter Notebook環境に読み込みます。 読み込むテキストデータは、実行している.ipynbファイルと同じフォルダに配置しましょう。 12345678import rewith open(\"sand_manzai.txt\", mode=\"r\", encoding=\"utf-8\") as f: sand_original = f.read()sand = re.sub(\"[\\n]\", \"\", sand_original) # 改行の削除 print(sand) これで、テキストデータが表示されればOKです。 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定この辺りの値は、実験を繰り返しながら最適な値を設定しました。 以下は、何回か実験を繰り返した結果の最終的な値です。 1234n_rnn = 10 # 時系列の数batch_size = 128 # バッチサイズepochs = 60 # エポック数n_mid = 256 # 中間層のニューロン数の数 入力データに対する時系列の数やバッチサイズって、どのように設定するのがベストプラクティスなのかは、勉強中です。。。 以下の記事によると、少しばかりヒントがありました。https://www.st-hakky-blog.com/entry/2017/11/16/161805 よく論文で見るBatch sizeDeep Learningの論文を読んでいるとどうやって学習をさせたかみたいな話はほぼ乗っているので、そういうのを見ていてよく見かけるのは以下あたりではないかと思います(すみません、私の観測範囲ですが)。 1 32 128 256 512だいたい、1だと完全に確率的勾配降下法になりますし、512だと学習速度をあげたかったのかなという気持ちが見えます。このあたりについてどれにするべきかというところを考察してみたいと思います。 各文字のベクトル化各文字をone-hot表現にします。one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができます。 各文字をone-hot表現にするには、以下のように処理を行います。 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 入力と正解をone-hot表現に変更する 文字の重複を省きlist化まずは、setを使って文字の重複を省き、listにして、sortしたものをcharに格納したいと思います。 1234567import numpy as npchars = sorted(list(set(sand)))print(chars)print(\"文字数(重複なし)\", len(chars))# ['(', ')', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'D', 'J', 'M', 'h', 'i', 'k', 'o', 's', 'y', '…', '※', '♪', '、', '。', '々', '「', '」', 'ぁ', 'あ', 'ぃ', 'い', 'う', 'ぇ', 'え', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'っ', 'つ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ね', 'の', 'は', 'ば', 'ひ', 'び', 'ふ', 'ぶ', 'へ', 'べ', 'ほ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'を', 'ん', 'ァ', 'ア', 'ィ', 'イ', 'ウ', 'ェ', 'エ', 'オ', 'カ', 'ガ', 'キ', 'ク', 'グ', 'ケ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ソ', 'タ', 'ダ', 'チ', 'ッ', 'ツ', 'テ', 'ト', 'ド', 'ナ', 'ニ', 'ハ', 'バ', 'パ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ペ', 'ホ', 'ボ', 'ポ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ュ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ヴ', '・', 'ー', '一', '万', '丈', '三', '上', '下', '不', '世', '両', '中', '予', '事', '二', '京', '人', '今', '仕', '他', '付', '仙', '代', '以', '伊', '休', '会', '何', '作', '使', '修', '俺', '個', '健', '偽', '僕', '優', '兄', '入', '全', '内', '円', '冬', '出', '分', '刺', '削', '前', '加', '助', '勝', '化', '北', '千', '印', '原', '厨', '参', '取', '受', '古', '叩', '召', '台', '各', '合', '同', '名', '向', '周', '品', '員', '商', '喋', '回', '因', '図', '国', '土', '地', '場', '壁', '士', '売', '変', '夏', '外', '多', '夜', '大', '太', '夫', '奇', '奮', '女', '奴', '好', '婚', '季', '安', '定', '客', '宴', '密', '富', '小', '少', '尿', '居', '屋', '山', '岡', '川', '差', '帰', '幌', '年', '康', '式', '弔', '当', '彷', '待', '徨', '念', '怖', '思', '急', '性', '感', '態', '慌', '懐', '房', '手', '払', '投', '担', '拶', '持', '指', '挨', '振', '故', '文', '料', '断', '新', '方', '旅', '日', '早', '昨', '時', '普', '暮', '曲', '書', '最', '月', '期', '本', '札', '来', '東', '根', '桶', '棺', '業', '極', '楽', '構', '様', '樹', '次', '欲', '正', '歩', '歴', '死', '残', '気', '永', '求', '江', '決', '泊', '注', '活', '流', '海', '淳', '渕', '渡', '湯', '澤', '無', '然', '物', '状', '球', '理', '生', '田', '由', '申', '男', '界', '発', '皆', '盛', '目', '直', '相', '真', '眠', '知', '砂', '確', '神', '福', '秘', '稲', '笑', '第', '等', '答', '算', '箸', '米', '粧', '糖', '紀', '約', '終', '結', '続', '綿', '総', '緒', '繰', '置', '考', '者', '耳', '聞', '膳', '自', '興', '若', '草', '菅', '葬', '行', '要', '見', '覚', '触', '言', '診', '詰', '話', '読', '誰', '談', '象', '買', '跡', '踏', '輪', '辞', '近', '返', '通', '造', '週', '過', '達', '遠', '適', '選', '還', '郎', '部', '金', '間', '閣', '阪', '集', '静', '面', '音', '頃', '願', '飛', '食', '飲', '高', '鳩', '鶏', '麗', '麻', '黙', '鼻', '！', '（', '）', '０', '１', '２', '５', '７', '？', 'Ａ', 'Ｌ', 'Ｍ', 'Ｓ', '～']# 文字列(重複なし) 477 文字がキーでインデックスが値の辞書を作成次にchar_indicesという空の辞書を作成し、そこにループでインデックスi, 各文字をcharに格納。 char_indicesのキーとしてcharを指定してiを格納することで、文字がキーでインデックスが値の辞書が完成します。これは後程使います 1234567891011121314151617181920212223242526char_indices = {}for i, char in enumerate(chars): char_indices[char] = ichar_indices# {'(': 0,# ')': 1,# '-': 2,# '0': 3,# '1': 4,# '2': 5,# '3': 6,# '4': 7,# '5': 8,# '6': 9,# '7': 10,# '8': 11,# '9': 12,# 'D': 13,# 'J': 14,# 'M': 15,# 'h': 16,# 'i': 17,# 'k': 18,# 'o': 19,# 's': 20,# 以降は省略 インデックスがキーで文字が値の辞書を作成次に、indices_charというインデックスがキーで文字が値の辞書を作成します。こちらも後程使います。 12345678910111213141516171819202122232425indices_char = {}for i, char in enumerate(chars): indices_char[i] = charindices_char# {0: '(',# 1: ')',# 2: '-',# 3: '0',# 4: '1',# 5: '2',# 6: '3',# 7: '4',# 8: '5',# 9: '6',# 10: '7',# 11: '8',# 12: '9',# 13: 'D',# 14: 'J',# 15: 'M',# 16: 'h',# 17: 'i',# 18: 'k',# 19: 'o',# 以降は省略 時系列データと予測する文字の抽出時系列データはtime_chars、予測する文字はnext_charsに格納します。 テキストの長さから時系列の長さをを引いた分だけループを実施。 time_charsにはテキストのi～i+n_rnn分の長さだけの文字を加えてあります。これで時系列の数の回数分だけ再帰処理する時系列データを用意できます。 next_charsにはtime_charsから予測すべき文字なので、i + n_rnn番目の文字をリストに格納しています。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849time_chars = []next_chars = []for i in range(0, len(sand) - n_rnn): time_chars.append(sand[i: i + n_rnn]) next_chars.append(sand[i + n_rnn]) time_chars# ['あら。昨日の夜まで何',# 'ら。昨日の夜まで何も',# '。昨日の夜まで何もな',# '昨日の夜まで何もなか',# '日の夜まで何もなかっ',# 'の夜まで何もなかった',# '夜まで何もなかったの',# 'まで何もなかったのに',# 'で何もなかったのに、',# '何もなかったのに、急',# 'もなかったのに、急に',# 'なかったのに、急にハ',# 'かったのに、急にハン',# 'ったのに、急にハンバ',# 'たのに、急にハンバー',# 'のに、急にハンバーガ',# 'に、急にハンバーガー',# '、急にハンバーガー屋',# 以降は省略next_chars# ['も',# 'な',# 'か',# 'っ',# 'た',# 'の',# 'に',# '、',# '急',# 'に',# 'ハ',# 'ン',# 'バ',# 'ー',# 'ガ',# 'ー',# '屋',# '出',# '来'# 以下省略 入力と正解をone-hot表現で表すここで、入力\\(x\\)と正解\\(t\\)を作っています。最初はzerosすべての要素を0にします。 入力\\(x\\)の形状は、[time_charsの長さ、時系列データの長さ(n_rnn)、文字数]、となります。今回は、要素は0か1の二通りしかありませんので、データのタイプはbool型にしておきます。 また、正解\\(t\\)ですが、こちらは、[time_charsの長さ、文字数]、の形状にします。こちらも同様にデータのタイプはbool型にしておきます。 time_charsの数だけまずループを行います。 まず、正解に対して値を設定。 indexがiで各要素がt_csになるわけですが、正解な文字が入っているnext_charsから文字を取り出し、char_indicesによりindexに変換します。そして、その要素を1に設定します。 これにより、この要素のみ1で、あとは0になるone-hot表現に変換されることになります。 また、入力の方は、さらにループの入れ子構造を使って設定します。 t_csを使ってループを行っており、この際のインデックスはj, 要素はcharとします。 \\(x\\)のiとjを設定して、そのうえでchar_indicesを使って文字をインデックスに変換します。 この要素を1にします。 こうすることで、入力も同様にone-hot表現で表すことが可能です。 試しに、xを出力してみます。 1234567891011121314151617181920212223242526x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)for i, t_cs in enumerate(time_chars): t[i, char_indices[next_chars[i]]] = 1 # 正解をone-hot表現で表す for j, char in enumerate(t_cs): x[i, j, char_indices[char]] = 1 # 入力をone-hot表現で表す x# array([[[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]],t# Out[9]:# array([[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]]) xとtの形状も確認してみます。 1234print(\"xの形状\", x.shape)print(\"tの形状\", t.shape)# xの形状 (5408, 10, 477)# tの形状 (5408, 477) これでone-hot表現化は完了です。 LSTMモデルの構築Kerasを使ってLSTMを構築していきます。 SimpleRNN層と同じ方法で構築できます。 損失関数は、複数の分類に適したcategorical_crossentropyを指定し、最適化アルゴリズムは収束しやすいadamを指定したいと思います。 1234567891011121314151617181920212223242526272829303132333435from keras.models import Sequentialfrom keras.layers import Dense, LSTMmodel_lstm = Sequential()model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))model_lstm.add(Dense(len(chars), activation=\"softmax\"))model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")print(model_lstm.summary())# Model: \"sequential_1\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# simple_rnn_1 (SimpleRNN) (None, 20) 440 # _________________________________________________________________# dense_1 (Dense) (None, 1) 21 # =================================================================# Total params: 461# Trainable params: 461# Non-trainable params: 0# _________________________________________________________________# None# Model: \"sequential_2\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# lstm_1 (LSTM) (None, 20) 1760 # _________________________________________________________________# dense_2 (Dense) (None, 1) 21 # =================================================================# Total params: 1,781# Trainable params: 1,781# Non-trainable params: 0# _________________________________________________________________# None 文書を生成するための関数を記述し学習各エポックが終了した際に、文章を生成するための関数を作成します。 12345678910111213141516171819202122232425262728293031323334353637from keras.callbacks import LambdaCallback def on_epoch_end(epoch, logs): print(\"エポック: \", epoch) beta = 5 # 確率分布を調整する定数 prev_text = sand[0:n_rnn] # 入力に使う文字。「'あら。昨日の夜まで何'」という文字列 created_text = prev_text # 生成されるテキスト print(\"シード: \", created_text) for i in range(400): # 入力をone-hot表現に x_pred = np.zeros((1, n_rnn, len(chars))) for j, char in enumerate(prev_text): x_pred[0, j, char_indices[char]] = 1 # 予測を行い、次の文字を得る y = model.predict(x_pred) # (1, 479)のarray。array([[0.00203636, 0.0020888 , ・・・・・ p_power = y[0] ** beta # 確率分布の調整。y[0]は(479,)のarray。array([0.00203636, 0.0020888 , 0.00209593, ・・・・ next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) # next_indexには、len(p_power)の数値である0～479間のintがランダムで代入される。 next_char = indices_char[next_index] # 'あ'とか'～'とか文字列を得る。 created_text += next_char prev_text = prev_text[1:] + next_char print(created_text) print()# エポック終了後に実行される関数を設定epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)model = model_lstmhistory_lstm = model_lstm.fit(x, t, batch_size=batch_size, epochs=epochs, callbacks=[epock_end_callback]) LambdaCallbackは、エポック終了時等のタイミングで、特定の処理を行うための関数として使用します。 betaという定数が設定されています。これは確率分布を調整する定数です。 確率分布を使用する意図は、最も確率が高い文字だけではなく、それ以外の文字からも確率に従いサンプリングをするためです。結果的に、高い確率の文字が選ばれる頻度が高くなります。これは、入力データに対して、次の文字として最も確率の高い文字を予測する代わりに、確率分布を推定する、ということになります。 prev_textには、テキストの最初から時系列分だけを取り出したサンドウィッチマンのネタの文字列が入ります。これが、モデルに入力される文字列になり、常に直近の時系列データが入るようにします。 created_textは、生成されるテキストです。文章は必ず、prev_textから始まるようにするので、prev_textを入れておきます。そして、created_textがシードになります。これがベースとなって次々と次の文字を予測していくことになります。 今回は400文字の文章を生成する。 入力をone-hot表現に変換するために、入力x_predには、まずnp.zerosで初期化したものを含める。サンプル数が1, 時系列データ, charsの数の形状をしています。 次に予測を行っていきます。model.predictに、x_predを入れて出力のyを得ることができます。 y[0]で各文字に対応する確率分布のリストが得られる。これにbetaを累乗。betaの値は、1より大きいと高い確率がより高くなるように確率分布が調整されます。 次の文字として、next_indexに、特定の確率分布の中からサンプリングされた値(文字のインデックス)が代入される。確率分布pは、p_powerに対して、P_powerを足し合わせたもので割っている。これは、確率分布pが、すべて足しあわされて1にならなければならないためです。確率分布については、以下のchainerチュートリアルのドキュメントが分かりやすいと思います。 https://tutorials.chainer.org/ja/06_Basics_of_Probability_Statistics.html そして、next_indexをキーとして、indices_charに入れることで、次の文字を取り出すことができる。 prev_textは、最初の文字を取り除き、next_charを加えることで、直近の時系列に更新される。 このようにして訓練済みのLSTMのモデルを使って、文章を自動生成することができる。 学習の推移を確認していくと徐々にサンドイッチマンのネタに近づいていきます。途中ずっと「いらっしゃいませこんにちは！」しか言わなったりしますが、、、 123456789101112131415161718192021222324252627282930313233343536373839Epoch 1/605408/5408 [==============================] - 14s 3ms/step - loss: 5.3819エポック: 0シード: あら。昨日の夜まで何あら。昨日の夜まで何ないかんんーんーんんいい。い。ないいいんい、ん、っいんかいんいなかいおいんっん。いかていい、っい、たんな、、いいだのいいいんんいてお、ない、いんーいーいいーーい、いんい。っい、で、ー、いいーー、いいな、。ん、いいなんんいー、ーーいいいんていっおんいいっなんんいーーあ、、ん。だーんんいんん、、んおんい、っない、ー、いっいい、いいいい、ら、んかんん。っないかいいー、。っん、いおおいて、っいっ、いいいー、かんおおーいていん、、んんいいいいすん、おーーー、いい、いい、いんっー、っっいいーーいってんいいいーんいい、ーんいのし、なんんい、、んっいすっんーてーんてーいっなのいーい、、いっ、い、、いんっー。、のなー、いんー、っ、いっ。んいておいいーよいん、んー、ーなー、い、、っんい、いんないんだっ、か、いーなん、、っっいんーてーんいおいんうでいで、んーの。い、、のんんい。ーおしっ、いんんんいんいーいいん。Epoch 10/605408/5408 [==============================] - 11s 2ms/step - loss: 4.1347エポック: 9シード: あら。昨日の夜まで何あら。昨日の夜まで何たたいたいんだよ。。あ、、ののののに・・のにいににいっててん。。。んのく、のののののにののすののですかか？。か？か、、。ちののにののしのの、、いすに。ののののーー、だ、よ。。、れののの方にののにしにいってん。。。ちちののののの、いのののにしにいてんだよ。。あちれしっての。。。あ、、ののにののの方になのたっててん。。。の、のののののの・・・・・で・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・、・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・Epoch 20/605408/5408 [==============================] - 12s 2ms/step - loss: 2.5751エポック: 19シード: あら。昨日の夜まで何あら。昨日の夜まで何ですかかもにりだよ。おっていいます。何や、ロオーー。そー、知れ。これ、お前。あー、ううらううう。あれ、あうです。やうやでしうから、お前。ないまですか？やや、だオー。ララララ見にてってるてよかな。でんですか？いいんだよ。お前、ちゃんだよ。いいいです。何やからだー、お前。何ですか？？いわ、、なん。持持ちてよ、お前。えってんでよ。どうううってんだよ。あン、これになんだよ。お前、あ、、お前。きやきうららいます。あ、ですも。ううーうう！！！れンンううううう！！ンンンンンンンン！ンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンEpoch 44/605408/5408 [==============================] - 12s 2ms/step - loss: 0.2862エポック: 43シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってよねうか。お前、あットババナナェイェイで…いやサイでです。こいなににこんらくくちゃいていのお前。なー、じゃあの、こンにに北おおかしなあ。バー。繰イ人人、お前。あ、で婚の人お前っなんか。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言Epoch 49/605408/5408 [==============================] - 12s 2ms/step - loss: 0.1811エポック: 48シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちEpoch 60/605408/5408 [==============================] - 12s 2ms/step - loss: 0.0870エポック: 59シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。上に置いとかな全然見えなかったわ、お前。あー、どうしようかな。じゃあ、ビッグバーガーセットはいかがですか？太るわ。普通なんかサイドメニューみたいな。サイドメニュー？ご一緒に(※ポテトの発音で)ホタテになります。(※ポテトの発音で)ホタテに！あ、いらっしゃちいま。あとち言ーにますらか。な一ににつらっていませま。。あもですぎ。１ぇの！ういいや！１１回！（※でも１をを指両両両のををンン指指を指を 誤差の収束具合をグラフで確認します。 12345678%matplotlib inlineimport matplotlib.pyplot as pltloss_lstm = history_lstm.history['loss']plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")plt.legend()plt.show() ちゃんと誤差が収束に向かっているのが分かります。 まとめLSTMの理解を深めるために、サンドウィッチマンのネタを学習し予測させてみました。 様々なデータに活用し、実験してみていただけると幸いです。 RNNやLSTMを構築して自然言語処理を学びたい方は、以下のUdemy講座がおすすめです。 本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/05/11/lstm-sandwich/"},{"title":"HTTPメソッド9種類 | PATCHとPUTの違いも解説","text":"HTTPメソッド全8種類をまとめていくよ！ HTTPメソッドは全部で9種類 下表にまとめる9種類が主なHTTPメソッドになります。 メソッド 意味 CRUD分類 OPTION サーバー側が提供する機能の確認 GET リソースの取得 HEAD リソースのヘッダー(メタ情報)取得 POST 従属リソースの作成 PUT/PATCH 新規リソースの作成、リソースの更新 DELETE リソースの削除 TRACE 通信経路の確認 CONNECT プロキシのトンネル接続 patchとputの違いpatchとputはともにデータを更新するメソッドですが少しニュアンスが異なります。 patchは、データがすでに存在しているものに対して更新をかける処理です。 putはデータが存在しているかどうかわからないときに使用します。データが存在しているときは更新をし、データが存在しない場合は新規作成を行うという処理です。 REST APIの設計を詳しく学びたい方へ Udemyが提供しているREST WebAPI サービス 設計という講義が参考になります。Swaggerで本格的なAPI設計のベストプラクティスを学びましょう。 以上です。","link":"/2021/01/24/http-method/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"ブログ","slug":"ブログ","link":"/tags/%E3%83%96%E3%83%AD%E3%82%B0/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"自然言語処理","slug":"自然言語処理","link":"/tags/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86/"},{"name":"ダイエット","slug":"ダイエット","link":"/tags/%E3%83%80%E3%82%A4%E3%82%A8%E3%83%83%E3%83%88/"},{"name":"サプリメント","slug":"サプリメント","link":"/tags/%E3%82%B5%E3%83%97%E3%83%AA%E3%83%A1%E3%83%B3%E3%83%88/"},{"name":"エラー","slug":"エラー","link":"/tags/%E3%82%A8%E3%83%A9%E3%83%BC/"},{"name":"doc2vec","slug":"doc2vec","link":"/tags/doc2vec/"},{"name":"ニューラルネットワーク","slug":"ニューラルネットワーク","link":"/tags/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"landscape","slug":"landscape","link":"/tags/landscape/"},{"name":"instagram","slug":"instagram","link":"/tags/instagram/"},{"name":"BULMA","slug":"BULMA","link":"/tags/BULMA/"},{"name":"OpenShift","slug":"OpenShift","link":"/tags/OpenShift/"},{"name":"EPA","slug":"EPA","link":"/tags/EPA/"},{"name":"葉酸","slug":"葉酸","link":"/tags/%E8%91%89%E9%85%B8/"},{"name":"前十字靭帯","slug":"前十字靭帯","link":"/tags/%E5%89%8D%E5%8D%81%E5%AD%97%E9%9D%AD%E5%B8%AF/"},{"name":"リハビリ","slug":"リハビリ","link":"/tags/%E3%83%AA%E3%83%8F%E3%83%93%E3%83%AA/"},{"name":"育児","slug":"育児","link":"/tags/%E8%82%B2%E5%85%90/"},{"name":"子育て","slug":"子育て","link":"/tags/%E5%AD%90%E8%82%B2%E3%81%A6/"},{"name":"勉強","slug":"勉強","link":"/tags/%E5%8B%89%E5%BC%B7/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"コンテナ","slug":"コンテナ","link":"/tags/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"VisualStudioCode","slug":"VisualStudioCode","link":"/tags/VisualStudioCode/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"git bash","slug":"git-bash","link":"/tags/git-bash/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"word2vec","slug":"word2vec","link":"/tags/word2vec/"},{"name":"ブルーベリー","slug":"ブルーベリー","link":"/tags/%E3%83%96%E3%83%AB%E3%83%BC%E3%83%99%E3%83%AA%E3%83%BC/"},{"name":"chair","slug":"chair","link":"/tags/chair/"},{"name":"remotework","slug":"remotework","link":"/tags/remotework/"},{"name":"minikube","slug":"minikube","link":"/tags/minikube/"},{"name":"コマンド","slug":"コマンド","link":"/tags/%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/"},{"name":"プログラミング","slug":"プログラミング","link":"/tags/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"在宅","slug":"在宅","link":"/tags/%E5%9C%A8%E5%AE%85/"},{"name":"楽痩せ","slug":"楽痩せ","link":"/tags/%E6%A5%BD%E7%97%A9%E3%81%9B/"},{"name":"仕事","slug":"仕事","link":"/tags/%E4%BB%95%E4%BA%8B/"},{"name":"手術","slug":"手術","link":"/tags/%E6%89%8B%E8%A1%93/"},{"name":"トレーニング","slug":"トレーニング","link":"/tags/%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/"},{"name":"twitter","slug":"twitter","link":"/tags/twitter/"},{"name":"風邪予防","slug":"風邪予防","link":"/tags/%E9%A2%A8%E9%82%AA%E4%BA%88%E9%98%B2/"},{"name":"オブジェクト指向","slug":"オブジェクト指向","link":"/tags/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/"},{"name":"クラス","slug":"クラス","link":"/tags/%E3%82%AF%E3%83%A9%E3%82%B9/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Rails","slug":"Rails","link":"/tags/Rails/"},{"name":"Ruby","slug":"Ruby","link":"/tags/Ruby/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"keras","slug":"keras","link":"/tags/keras/"},{"name":"Udemy","slug":"Udemy","link":"/tags/Udemy/"},{"name":"SkillHacks","slug":"SkillHacks","link":"/tags/SkillHacks/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"seq2seq","slug":"seq2seq","link":"/tags/seq2seq/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"},{"name":"http","slug":"http","link":"/tags/http/"}],"categories":[{"name":"IT","slug":"IT","link":"/categories/IT/"},{"name":"Health","slug":"Health","link":"/categories/Health/"},{"name":"Method","slug":"Method","link":"/categories/Method/"},{"name":"Goods","slug":"Goods","link":"/categories/Goods/"}]}