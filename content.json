{"pages":[{"title":"","text":"Sorry…現在、構築中です。。。","link":"/404.html"}],"posts":[{"title":"【解説】ダミー変数化 | データサイエンス100本ノック【問58 回答】","text":"目次 この記事の対象者 第58問目: ダミー変数化 まとめ: ダミー変数化の方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonでダミー変数化の方法を知りたい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第58問目: ダミー変数化 P-058: 顧客データフレーム（df_customer）の性別コード（gender_cd）をダミー変数化し、顧客ID（customer_id）とともに抽出せよ。結果は10件表示させれば良い。 ダミー変数ってなんだろう？ ダミー変数とは、0か1の値を取る変数のことを言います。 Pythonではget_dummies関数を用いることで、ダミー変数化できます。 実際にPythonのコードで具体的な使い方を見ていきましょう。 ダミー変数化の例12345import pandas as pdsr = pd.Series(['male', 'female', 'female', 'male', 'female'])pd.get_dummies(sr) 出力123456 female male0 0 11 1 02 1 03 0 14 1 0 このように各項目においてmaleなのかfemaleなのかを、0と1で表現させることができます。 なお、male, femaleではなく、apple, banana, orangeのように２種類以上のデータにもダミー関数は適用できます。 2種類以上のデータにもダミー関数は適用できる12345import pandas as pdsr = pd.Series(['apple', 'banana', 'orange', 'apple', 'orange', 'banana'])pd.get_dummies(sr) 出力1234567 apple banana orange0 1 0 01 0 1 02 0 0 13 1 0 04 0 0 15 0 1 0 これで前提知識はOK。早速問題に取り掛かります。 今回のダミー変数化の対象は、顧客データフレームの性別コード(gender_cd)ですね。 get_dummies関数は、引数columnsにダミー化したい列の列名をリストで指定すると、指定した列のデータを対象にダミー関数化してくれます。 本問を解きながら、その使い方を学びましょう。 以下のように書けばOKです。 1pd.get_dummies(df_customer[['customer_id', 'gender_cd']], columns=['gender_cd']).head(10) 出力1234567891011customer_id gender_cd_0 gender_cd_1 gender_cd_90 CS021313000114 0 1 01 CS037613000071 0 0 12 CS031415000172 0 1 03 CS028811000001 0 1 04 CS001215000145 0 1 05 CS020401000016 1 0 06 CS015414000103 0 1 07 CS029403000008 1 0 08 CS015804000004 1 0 09 CS033513000180 0 1 0 これで完了です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"文系のための データサイエンスがわかる本\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51pFg1ZaJHL._SL500_.jpg\",\"\\/41SUCa0-1+L._SL500_.jpg\",\"\\/41tFUtTo5rL._SL500_.jpg\",\"\\/41zx+gmqJNL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"Q5cG7\",\"s\":\"s\"}); リンク まとめ: ダミー変数化の方法を学びました。本記事は、「【Python】ダミー変数化 | データサイエンス100本ノック【問58 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 &gt;&gt; [続き]第59〜60問の回答・解説を確認する","link":"/100knock-58/"},{"title":"【解説】データサイエンス100本ノック【問77〜78 回答】","text":"目次 第77問目: 外れ値・異常値（外れ値除外） 第78問目: 外れ値・異常値(四分位点範囲を利用した外れ値判定) まとめ: データサイエンス100本ノック【問77〜78 回答】で外れ値・異常値判定を学びました データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第77問目: 外れ値・異常値（外れ値除外）外れ値とは、他の値から大きく外れた値のことです。 外れ値を検出する手順は以下の2stepです 標準化する 平均値からある閾値以上離れたデータを抽出する 本問を解きながら具体的な流れを確認しましょう。 まずは、df_receiptの売上金額(amount)を顧客ID(customer_id)ごとに合計したデータを代入します。 文字の前方一致（カラム名.str.startswith）について確認する groupbyメソッドを確認する 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales_amount.head(10) 出力1234567891011customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 33375 CS001211000025 4566 CS001212000027 4487 CS001212000031 2968 CS001212000046 2289 CS001212000070 456 標準化を行います。 標準化はStandardScalerクラスを使用して行います。 1234scaler = preprocessing.StandardScaler()scaler.fit(df_sales_amount[['amount']])df_sales_amount['amount_ss'] = scaler.transform(df_sales_amount[['amount']])df_sales_amount 12345678910111213 customer_id amount amount_ss0 CS001113000004 1298 -0.4593781 CS001114000005 626 -0.7063902 CS001115000010 3044 0.1824133 CS001205000004 1988 -0.2057494 CS001205000006 3337 0.290114... ... ... ...8301 CS051212000001 336 -0.8129888302 CS051513000004 551 -0.7339598303 CS051515000002 265 -0.8390868304 CS052212000002 192 -0.8659198305 CS052514000001 178 -0.8710658306 rows × 3 columns 問題の指定通り、平均から3σ以上離れたものを10件抽出します。 1df_sales_amount.query('abs(amount_ss) &gt;= 3').head(10) 出力1234567891011 customer_id amount amount_ss332 CS001605000009 18925 6.0199211755 CS006415000147 12723 3.7402021817 CS006515000023 18372 5.8166511833 CS006515000125 12575 3.6858001841 CS006515000209 11373 3.2439721870 CS007115000006 11528 3.3009461941 CS007514000056 13293 3.9497211943 CS007514000094 15735 4.8473471951 CS007515000107 11188 3.1759701997 CS007615000026 11959 3.459372 これで完了です。 第78問目: 外れ値・異常値(四分位点範囲を利用した外れ値判定) P-078: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客単位に合計し、合計した売上金額の外れ値を抽出せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。なお、ここでは外れ値を第一四分位と第三四分位の差であるIQRを用いて、「第一四分位数-1.5×IQR」よりも下回るもの、または「第三四分位数+1.5×IQR」を超えるものとする。結果は10件表示させれば良い。 四分位点とは、データを4分の1に分割する分位点のことです。 四分位数については、以下の記事で詳しく説明しています。 &gt;&gt; 【解説】四分位点を学ぶ | データサイエンス100本ノック【問55 回答】 - omathin blog 外れ値を判定する際に、IQR（四分位範囲）を利用する方法があります。 IQRとは、第一四分位Q1と第三四分位Q3の差を取ったものです。 I Q R=Q 3-Q 1一般的に、このIQRを使用して「第一四分位数-1.5×IQR」より下回るものと「第三四分位数＋1.5×IQR」を超えるものを外れ値として考えます。 実際に本問を解きながら外れ値の算出をしてみたいと思います。 まずは、df_receiptの売上金額(amount)を顧客ID(customer_id)ごとに合計したデータをsf_sales_amountに代入します。 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales_amount.head(10) 出力1234567891011 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 33375 CS001211000025 4566 CS001212000027 4487 CS001212000031 2968 CS001212000046 2289 CS001212000070 456 第一四分位数と第三四分位数を求めます。 1234pct75 = np.percentile(df_sales_amount['amount'], q=75)pct25 = np.percentile(df_sales_amount['amount'], q=25)print(&quot;第三四分位数:&quot; , pct75)print(&quot;第一四分位数:&quot; , pct25) 出力1234567891011 customer_id amount98 CS001414000048 8584332 CS001605000009 18925549 CS002415000594 95681180 CS004414000181 95841558 CS005415000137 87341733 CS006414000001 91561736 CS006414000029 91791752 CS006415000105 100421755 CS006415000147 127231757 CS006415000157 10648 これで完成です。 まとめ: データサイエンス100本ノック【問77〜78 回答】で外れ値・異常値判定を学びました本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-77-78/"},{"title":"【31.5インチ】M1 Macに4Kモニター（ASUS-VA32U）を接続！購入時の注意点も解説！","text":"ASUSのVA32Uのレビュー記事です。結論を言うと、目の疲れ激減します！そしてデカイ！ただし、モニター導入時に気をつけるポイントがあります。本記事を参考に最高の4Kモニターライフを楽しんでほしいと思います。 目次 4Kモニター到着！ [注意！]画面がON/OFFを繰り返すブラックアウト現象 ブラックアウトの解決策→ケーブルを変える！ [推奨]イヤホンケーブルも購入しよう。 まとめ 他社の31.5インチ 4Kモニターの比較記事はこちら 4Kモニター到着！ 改めてみると、デカイですね。 HDMIケーブルが付属されているのも嬉しいです。 早速開封してデスクに設置してみます。 4Kの動画を映している様子ですが、「きれいだなぁ」と思わず声に出してしまうほどです。 しかし、使用しているといくつかおかしな動作をしたり、不便だと思う点がみつかりました。 対処策と合わせてまとめていきます。 [注意！]画面がON/OFFを繰り返すブラックアウト現象M1 Macにtype-CとHDMI変換アダプタを接続し、HDMIケーブルで4Kモニターに接続したところ、スリープモードから復帰するたびに、ディスプレイがON/OFFを繰り返す現象が発生しました。 つまり、ディスプレイが点いたり消えたりを繰り返すのです。 これは、ブラックアウトという現象です。 ブラックアウトの厄介なところは、一時的な症状なのか、PCに問題があるのか判断がつきにくい点です。 別の記事でまとめられている対処策を試したところ、とあるケーブルに変えたら症状が解消されました。 以降、ケーブルの紹介含めてまとめていきます。 ブラックアウトの解決策→ケーブルを変える！ M1 MacをASUS-VA32Uに接続する際は、以下のケーブルを使いましょう。 このケーブルに変えたおかげで、ブラックアウト現象が起こらなくなりました！ 以下のような感じです。 超快適になりました。 なお、この画像に写っているM1 Macを載せているPCリフトは、BoYataのPCリフトです。 安定性抜群で最高です。 [推奨]イヤホンケーブルも購入しよう。ASUS-VA32Uのイヤホンジャックは、ディスプレイの裏面にあり、少し差し込むのが面倒です。 以下の画像に示す位置に、イヤホンジャックがあります。 これを解消するために、以下の延長ケーブルを導入しました。 以下の画像のように、ディスプレイの背面を覗き込んでイヤホンを接続する必要がなくなりました。 まとめ本記事では、M1 MacにASUSの4Kモニターを接続レビューをまとめました。 4Kモニター接続時は、アダプターやケーブルが原因で、ディスプレイがON/OFFを繰り返すブラックアウトと言う現象が発生します。以下のケーブルを導入することで解決しましたので、同様の現象でお困りの方は、購入を検討してみてください。 &gt;&gt;Amazonでケーブルを確認","link":"/4k-monitor-asus/"},{"title":"【Hexo】Icarusテーマで作成される記事のタイトル、h2、h3のデザインを変更","text":"Hexoで作成した記事を読みやすいデザインにしませんか？ 本ブログはIcarus(v3.0)というテーマを採用しておりますが、h2タグやh3タグにborder-leftをつけて記事の可読性を上げたいな、とおもっていました。 本記事では、それらのカスタマイズ方法をまとめました。 ✓目次 この記事の対象者 読みやすい記事とは h2タグ、h3タグのデザイン変更 記事タイトルをsemi-boldに変更 この記事の対象者 HexoにIcarusテーマを適用している方。Icarusはv 3.0.0。 基本的なHTML, CSSを理解している方 読みやすい記事とはそもそも読みやすい記事って、どんな記事なのか。 やはりブログで多くのお金を稼いでいる方のデザインなのかなと思います。 Icarusテーマの配色に近いデザインを用いている有名ブロガーさんとして、manablogさんのデザインを参考（というかほぼ丸パクリ）にしてデザインを当ててみたいと思います。 h2タグ、h3タグのデザイン変更編集するファイルは、\\themes\\icarus\\include\\style\\article.stylです。 以下のように設定すればOKです。 \\themes\\icarus\\include\\style\\article.styl1234567891011121314151617181920212223242526h2 font-size: 25px background: #f7f7f7; padding: 20px 15px 18px border-left: 9px solid #4865b2; line-height: 40px; margin-top: 60pxh3 font-size: 20px letter-spacing: 1.6px; padding: 10px 15px 10px; border-left: 9px solid #4865b2; font-weight: 600 margin-top: 60px;h4 font-size: 16px letter-spacing: 1.6px; padding: 5px 15px 5px; border-left: 9px solid #4865b2; font-weight: 400 margin-top: 60px; ファイルの編集が終わったら、ファイルを保存し、hexo cleanコマンドでキャッシュなどを削除。 hexo generateコマンドを実施し、hexo serverでlocalhost:4000にアクセスしてみましょう。 ちゃんとh2タグ、h3タグにデザインが当てられていればOKです。 記事タイトルをsemi-boldに変更記事のタイトルは\\themes\\icarus\\layout\\common\\article.jsxファイルを変更します。 titleクラスにhas-text-weight-semiboldを追記します。 \\themes\\icarus\\layout\\common\\article.jsx1234{/* Title */}&lt;h1 class=\"title is-3 is-size-4-mobile has-text-weight-semibold\"&gt; {index ? &lt;a class=\"link-muted\" href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title}&lt;/h1&gt; IcarusはBulmaというCSSフレームワークを使っています。 以下に、fontに関連するhelperのリンクを張っておきますので、semibold以外のフォントにしたい場合は、こちらを参照してください。 Typography helpers | Bulma: Free, open source, and modern CSS framework based on Flexbox その他、Icarusのデザイン変更に関する記事","link":"/Icarus-h2h3title-change/"},{"title":"本ブログについて","text":"本ページをご覧いただきありがとうございます。 著者について 本ブログが提供する主な価値 Ruby, Python, Reactを始めとする環境構築手順 データサイエンス100本ノックの全回答・解説を掲載 データサイエンス関連のpythonコードを瞬時に検索・参照できる 著者について 自己紹介 omathin ・IT企業のアーキテクト|研究者. ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得・毎日オンライン英会話で英会話力瀑上げ中！Twitterで学習成果を発信中！ 本ブログが提供する主な価値本ブログは、これからプログラミングを始めようとする方を対象に、環境構築手順やPythonによるデータの加工・操作方法などをまとめたブログです。 Ruby, Python, Reactを始めとする環境構築手順プログラミングをこれから学ぼうとする人のモチベーションを下げる主な要因は、環境構築です。 「環境構築に苦戦しプログラミング学習のモチベーションを下げてほしく無い！」という思いから、本ブログでは主にRuby on Rails, Python on Django, Reactといったモダンなプログラミング言語の環境構築方法をまとめています。 【Windows】DockerでRuby on Rails開発環境構築方法 - omathin blog 【M1 Mac】Railsの開発環境をdocker-composeで作成する - omathin blog 【M1 Mac】AnacondaとPycharmでDjangoの開発環境を構築する方法 - omathin blog 【M1 Mac】Djangoの開発環境をdocker-composeで作成する - omathin blog 【M1 Mac】React開発環境の構築 - omathin blog また、これらの手順でうまく行かなかった場合は、各記事のコメント欄にてお知らせください。 また、これからプログラミングを学習される方にも展開をしていただけると幸いです。 データサイエンス100本ノックの全回答・解説を掲載本ブログでは一般社団法人データサイエンティスト協会がGithubに公開している「データサイエンス100本ノック」の始め方と全解答解説を公開しています。 これからPythonを学び始める人、データサイエンティストの学習をしたい人は、本記事の内容を元にデータサイエンスの学習を進めていただきたいなと思ってます。 無料で始められるので、是非トライしてみてください。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 全100本の問題と解説は以下のリンクから確認できます。 データサイエンス100本ノック 全問回答解説記事集 | omathin blog データサイエンス関連のpythonコードを瞬時に検索・参照できる本ブログの右上の検索機能にPythonのコードや実施したいデータ処理名を入力すると、瞬時にサンプルコードが掲載された記事一覧を出力させることができます。 まず右上の虫眼鏡マークを押してください。 検索文字を入力欄に任意の文字列を入力ください。例として「結合」と入力すると、Pythonで表を結合する際のPythonコードのサンプルを確認できる記事が一覧として出力されます。 ノウハウとしては先述したデータサイエンス100本ノックの100問分のノウハウが参照できます。 データサイエンス業務のお供として、本ブログをブックマークいただき、「あれ、Pythonのコードどうやって書けば良いんだっけ？」という時に活用していただけると幸いです。","link":"/about-this-blog/"},{"title":"【比較】糖質制限 vs 脂質制限","text":"糖質制限ダイエットと脂質制限ダイエットについてまとめてみました。 ✓目次 結論 論文の内容を簡単にまとめる 結論低炭水化物ダイエットの効果は低脂肪ダイエットと同じ 低脂肪ダイエットと低炭水化物ダイエットの減量効果と参加者の遺伝子パターンやインスリン分泌との関係を調べた結果、減量効果に有意差はなく、遺伝子やインスリンとの関連もみられなかった、という米国スタンフォード大学からの研究報告がありました。 『米国医学会誌(JAMA)』https://jamanetwork.com/ https://www.wsj.com/articles/SB10001424052748703862704575099742545274032 論文の内容を簡単にまとめる18-50才の糖尿病ではなく、BMIが28-40の609名を対象に、2013年1月から2015年4月にかけて介入試験を実施し、その後2016年5月まで追跡調査した結果がまとめられています。 参加者はランダムに、健康的な低脂肪食（HLF）群と健康的な低炭水化物食（HLC）群に振り分けられ12か月間モニタリングを行ったようです。 (色々難しいことは省いて、、、) 介入の結果、12月で、HLF群で平均-5.3kg、HLC群で平均-6.0kgの体重変化が観察されたが、両群間には有意差が見られなかった。また、食事と遺伝子パターン、または食事とインスリン分泌能と、12か月間の体重変化の間にも有意な関連は認められなかったという。 筆頭研究者のクリストファー・ガードナー教授によれば、本研究結果の最大の収穫は、減量においては低脂肪食も低炭水化物食でも、その基本的な戦略が類似していた点であるという。 砂糖を減らし、精製穀類を減らし、野菜を可能な限りたくさん食べる。加工度の低い食品（Whole foods）を主に食べるようにする。 どちらのダイエットでも、最も体重を減らした人々が語っていたのは、様々な食べ物に対する知識、そしてそれらをどのように食べるかについてもっとよく考えるようになったことが大事ということだと筆者(Christopher Gardner氏)は述べています。 ボディメイクのプロの人は、最初に油を断ち切って体重を減らし、それでも目標値まで落ちなかった場合は糖質を制限するというのが一般的であると述べていました。 ダイエット効果が同じなら、油を制限する方を選びますが、結局はバランスよく、加工度の低い食品を自分で選んで食べるのが一番であるということですね。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/cbnoildiet/"},{"title":"本ブログの免責事項","text":"https://omathin.com/（以下、「当サイト」とします。）における免責事項は、下記の通りです。 コメントについて次の各号に掲げる内容を含むコメントは、当サイト管理人の裁量によって承認せず、削除する事があります。 特定の自然人または法人を誹謗し、中傷するもの 極度にわいせつな内容を含むもの 禁制品の取引に関するものや、他者を害する行為の依頼など、法律によって禁止されている物品、行為の依頼や斡旋などに関するもの その他、公序良俗に反し、または管理人によって承認すべきでないと認められるもの 当サイトの情報の正確性について当サイトのコンテンツや情報において、可能な限り正確な情報を掲載するよう努めています。しかし、誤情報が入り込んだり、情報が古くなったりすることもあります。必ずしも正確性を保証するものではありません。また合法性や安全性なども保証しません。 損害等の責任について当サイトに掲載された内容によって生じた損害等の一切の責任を負いかねますので、ご了承ください。また当サイトからリンクやバナーなどによって他のサイトに移動された場合、移動先サイトで提供される情報、サービス等について一切の責任も負いません。当サイトの保守、火災、停電、その他の自然災害、ウィルスや第三者の妨害等行為による不可抗力によって、当サイトによるサービスが停止したことに起因して利用者に生じた損害についても、何ら責任を負うものではありません。当サイトを利用する場合は、自己責任で行う必要があります。 当サイトで掲載している画像の著作権や肖像権等について当サイトで掲載している画像の著作権や肖像権等は、各権利所有者に帰属します。万が一問題がある場合は、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 無断転載の禁止について当サイトに存在する、文章や画像、動画等の著作物の情報を無断転載することを禁止します。引用の範囲を超えるものについては、法的処置を行います。転載する際には、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 Amazonアソシエイトについて当サイトは、amazon.co.jpを宣伝しリンクすることによってサイトが紹介料を獲得できる手段を提供することを目的に設定されたアフィリエイト宣伝プログラムである、 Amazonアソシエイト・プログラムの参加者です 2020年1月6日 策定2020年4月24日 改訂","link":"/disclaimer/"},{"title":"【M1 Mac】AnacondaとPycharmでDjangoの開発環境を構築する方法","text":"✓目次 この記事の対象者 ツールのインストール 仮想環境の構築 プロジェクト作成 この記事の対象者 ・ M1 MacでDjangoの開発環境を構築したい人 ・ Anaconda NavigatorとPycharmを活用した開発環境の構築方法、設定方法を知りたい人 ・ M1 MacでDjango REST Frameworkを使ってオリジナルのAPIを作りたい人 ツールのインストール まずは、Anaconda NavigaterとPycharmをインストールします。 Anaconda NavigaterはGoogleなどで「Anaconda Navigater Distribution」と検索してトップに出てくるものを選択し、ページの一番下にAnaconda Installersというのがあるので使用しているOSに対応したインストーラを選択すればOKです。 https://www.anaconda.com/products/individual そして開発環境で使っていくのがPycharmというエディタです。 こちらもオープンソース版のコミュニティというのをダウンロードしましょう。 仮想環境の構築 Anaconda Navigatorを使って仮想環境を作っていきます。 Anaconda Navigatorを立ち上げる。 Enviromentsのタブを選択し、Create。好きな仮想環境の名前を入力。例えばDjango REST Frameworkなどの名前にしておきます。 Pythonの3.7が選択されていることを確認して作成。 環境が作成できたら▶をクリックし、Open termilalをクリック pip install DjangoコマンドでDjangoをインストール terminal1234567891011121314(DRF_API) pip install DjangoCollecting Django Downloading Django-3.1.6-py3-none-any.whl (7.8 MB) |████████████████████████████████| 7.8 MB 8.8 MB/s Collecting asgiref&lt;4,&gt;=3.2.10 Using cached asgiref-3.3.1-py3-none-any.whl (19 kB)Collecting sqlparse&gt;=0.2.2 Using cached sqlparse-0.4.1-py3-none-any.whl (42 kB)Collecting pytz Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB) |████████████████████████████████| 510 kB 7.6 MB/s Installing collected packages: sqlparse, pytz, asgiref, DjangoSuccessfully installed Django-3.1.6 asgiref-3.3.1 pytz-2021.1 sqlparse-0.4.1(DRF_API) 続いてpip install djangorestframeworkコマンドを実行 terminal1234567891011(DRF_API) pip install djangorestframeworkCollecting djangorestframework Downloading djangorestframework-3.12.2-py3-none-any.whl (957 kB) |████████████████████████████████| 957 kB 374 kB/s Requirement already satisfied: django&gt;=2.2 in ./opt/anaconda3/envs/DRF_API/lib/python3.7/site-packages (from djangorestframework) (3.1.6)Requirement already satisfied: asgiref&lt;4,&gt;=3.2.10 in ./opt/anaconda3/envs/DRF_API/lib/python3.7/site-packages (from django&gt;=2.2-&gt;djangorestframework) (3.3.1)Requirement already satisfied: sqlparse&gt;=0.2.2 in ./opt/anaconda3/envs/DRF_API/lib/python3.7/site-packages (from django&gt;=2.2-&gt;djangorestframework) (0.4.1)Requirement already satisfied: pytz in ./opt/anaconda3/envs/DRF_API/lib/python3.7/site-packages (from django&gt;=2.2-&gt;djangorestframework) (2021.1)Installing collected packages: djangorestframeworkSuccessfully installed djangorestframework-3.12.2(DRF_API) これでインストール完了。 次はPycharmの方のプロジェクトのフォルダを作っていきます。通常のterminalを立ち上げる。 プロジェクトフォルダのディレクトリは好きな名前でOKです。 terminal12$ cd drf-api $ ~/drf-api 次にPycharmを立ち上げます。 Openを選択。 先程作成したフォルダを選択。 これから、Pycharmのプロジェクトに、Anaconda Navigatorで作成した仮想環境を紐付けていきます。 Pycharm→Preferencesを選択。Project→Python Interpreterを選択 右上の歯車をクリックし「Add..」をクリック 「Existing Environment」を選択 「…」をクリック。Users/optフォルダを選択するとanaconda3のフォルダが確認できる さらに「envs」というフォルダがあるのでこれを選択。 Anaconda Navigatorで作成した仮想環境フォルダを選択。今回は「DRF_API」を選択 その中の、「bin」というフォルダを選択。 「python」というファイルを選択してOKをクリック 更にOKをクリック。 するとPreferemceウィンドウの上部のPython Interpreter;の欄にAnaconda Navigatorで作成した仮想環境が設定されていることが確認できる。 Pycharmのterminalもデフォルトで仮想環境のターミナルになっていることがわかる。 プロジェクト作成 terminalでdjango-admin startproject drfapi .コマンドを実行。 次にアプリケーションを作成していきます。 django-admin startapp apiコマンドを実行。 すると、drfapiというフォルダと、apiというフォルダが自動生成されています。 この状態でローカルサーバーを動かしてみましょう。manage,pyというファイルを実行する。 manage,pyを右クリックしてRun 右上の「manage」となっているところを選択すると、「manage configration」というのが選択できるようになっているのでこれを選択します。 「parameters」という項目にrunserverと記述。OKをクリック。 Pycharmの右上の▶ボタンをクリック http://127.0.0.1:8000/にアクセスするとDjangoの初期画面が表示される これ以降は、pycharmの右上の▶ボタンと■ボタンで起動と停止を切り替えることができます。これで完了です！ Django REST Framework APIを学びたい方へ &gt;&gt;ゼロイチビズカレッジでDjango REST Framework APIを学ぶ","link":"/django-rest-framework-api/"},{"title":"【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説","text":"本記事では、doc2vecというものについてまとめてみます。 ✓目次 doc2vecとは、word2vecを拡張したもの dmpv DBOW dmpvとDBOWの比較 Doc2Vecの実装 参考にした記事など doc2vecとは、word2vecを拡張したものdoc2vecとは、word2vecを単語レベルではなく、文または文章でも扱えるように拡張したものです。 word2vecって何？何ができるの？という方は、以下の記事を参照いただければと思います。 doc2vecを用いることで何ができるのかというと、文や文章をベクトル化することができます。word2vecを学んだ人向けに言い換えれば、文や文章に対して、分散表現を獲得することができる、ということです。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法でしたね。 word2vecでは、CBOWとskip-gramという、2つのニューラルネットワークを用いますが、doc2vecでは、下記2つのいずれかのニューラルネットワークが用いられます。 dmpv(distributed memory) DBOW(distributed bag-of-words) 以降、dmpv, DBOWについてまとめたいと思います。 dmpvdmpvは、入力層、中間層、出力層があり、入力層と中間層の間と、中間層と出力層の間に重みを表す行列が存在します。 word2vecのCBOWに似ているように見えますが、違いは、入力に各単語とは別に、緑色の四角の文書IDがあることです。 文書IDというのは、この図でいうと、「となりのトトロ」という文章に付与されているID(“012”)というものをone-hot表現で表したものを指しています。※ちょっとややこしい。 文書IDを入力層に加えることで、文書自体をベクトルとして表すことが可能となり、文脈を加味した学習が可能となったのです。 簡単な例で述べましたが、これはあくまでイメージとしてとらえていただければと思います。実際は大量の文章と、文書IDを用いて学習され、dmpvをはじめとする学習モデルが作成されることで、文章のベクトル化がされます。 DBOWDBOWは、word2vecのskip-gramに似ており、入力は文書IDのone-hot表現のみであるのが特徴です。 該当文章内に含まれる単語を予測するように学習が行われ、dmpvと同様に、文書自体を分散表現で表すことができる。 dmpvとDBOWの比較DBOWの方が、シンプルなモデルでメモリをあまり使わないため、高速に計算することが可能と報告されています。しかし、dmpvの方が精度の面で優れているとされています。 [1507.07998] Document Embedding with Paragraph Vectors Doc2Vecの実装Doc2Vecの実装方法を以下の記事にまとめました。 こちらの記事も参照して、理解を深めていただければと思います。 参考にした記事など Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル - DeepAge gensimでDoc2Vec - 機械学習・自然言語処理の勉強メモ 自然言語処理の学習に役立つ教材 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 本格的にAIを学びたい人へ 以下の何れかに該当する方は、キカガクさんのオンラインスクールがおすすめです。まずは無料のカウンセリングに参加し、自分が目指すキャリアや身に着けたいスキルが学べるか、等確認してみてください。無料カウンセリング予約はこちら ・プログラミング初学者（Pythonで機械学習を学びたい方）・機械学習を学び、キャリアに活かしたい方・何かAIサービスを企画、開発したい方・技術を身に着けて転職したい方・E資格を取得したい方 Aidemyのプレミアムプランもオススメ AIを学ぶならアイデミープレミアムプラン","link":"/doc2vec-overview/"},{"title":"docker-compose run web rails dbconsoleができない問題の対処","text":"タイトルに記載したコマンドを実行したらうまくいかなかったので備忘録的にまとめます。 ✓目次 環境 問題（エラー内容） エラーの原因 対処 参考記事 環境Windows10 proRuby 2.4.5MySQLの5.7 問題（エラー内容） 以下のようなエラーが発生 terminal1234$ docker-compose run web rails dbconsoleStarting b74e972d_db_1 ... doneCouldn't find database client: mysql, mysql5. Check your $PATH and try again. エラーの原因 ローカルにMySQLアカウントがないからと想定 対処エラーが発生する場合のdockerfileは以下の通り dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 以下のように修正 dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev postgresql-client nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app buildを実施 terminal1$ docker-compose build 同じエラーが発生。dockerfileを以下の通り、修正する。 Dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs mysql-clientRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 再度buildを実施 terminal1$ docker-compose build 成功したので、dbconsoleを実行 terminal1$ docker-compose run web rails dbconsole パスワードを聞かれた場合は、dokcer-compose.ymlに記載されている、MYSQL_ROOT_PASSWORD: に記述されているパスワードを入力。 これで成功するはず。 参考記事 docker-compose で Rails の開発環境を作る - Qiita docker-composeで、rails dbconsoleが使えなくてハマった話。 - Qiita Dockerを専門に学ぶためのオンライン学習講座 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/docker-compose-run-web-rails-dbconsole-error/"},{"title":"【5分で分かる】Docker Composeとは何か【メリットも解説】","text":"✓目次 この記事の対象者 Docker Composeとは Docker Composeの実行手順 Docker Composeを使うメリット Docker Composeを実際に使ってみよう この記事の対象者 ・ Docker Composeとは何かをざっくり知りたい人 ・ Docker Composeを使うメリットを知りたい人 Docker ComposeとはDocker Composeとは、複数のDockerコンテナを定義し実行管理するためのツールです。 このツールを使用することで、コンテナの起動時設定を、YAMLファイルと呼ばれるデータ記述形式で定義することが可能になります。 コンテナの起動時設定とは、例えばWebサーバを構築する際に開放するポートや、コンテナ内部で実行されるコマンドや各コンテナの起動手順などを指します。 よく使用される用途としては、開発環境や自動テストの実行環境を立ち上げるときに使われます。 Docker Composeの実行手順Docker Composeを使用するための順序は以下の3ステップで完了します。 1. Dockerfileを用意するか、使用するイメージをDocker Hubなどに用意する 2. docker-compose.ymlで各コンテナの設定を記載する 3. docker-compose upコマンドを実行し、各コンテナを起動する Docker Composeを使うメリットDocker Composeのメリットは、設定ファイルさえ記載しておけば、たった１つのコマンドを実行するだけでシステムを起動させることが可能になります。 例えば、Railsの開発環境や、Djangoの開発環境の設定をdocker-compose.ymlに定義しておけば、docker-compose upコマンドを実行するだけで構築することができるのです。 またDocker Compose を使用することで、以下のことができるようになります。 サービスの開始、停止と再構築を簡単に行える 各コンテナの起動順序を指定することが可能 各コンテナ間ネットワークの設定を簡単に行うことができる Docker Composeを実際に使ってみよう実際にDocker Composeを使ってみましょう。 以下にRailsとDjangoの開発環境をDocker Composeを用いて構築する手順をまとめています。 ぜひこちらの記事を参考に、Docker Composeの利便性を体感いただければと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"仕組みと使い方がわかる Docker\\u0026Kubernetesのきほんのきほん\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/514Mfb930CL._SL500_.jpg\",\"\\/41G+4LdNGmL._SL500_.jpg\",\"\\/41qh0svED1L._SL500_.jpg\",\"\\/410ZyjijKAL._SL500_.jpg\",\"\\/41fqGahRYuL._SL500_.jpg\",\"\\/51gxCtm4+CL._SL500_.jpg\",\"\\/51p9d5zTG6L._SL500_.jpg\",\"\\/41XJMfFWbdL._SL500_.jpg\",\"\\/51LTmIBg6zL._SL500_.jpg\",\"\\/415FAIN8ZQL._SL500_.jpg\",\"\\/41a4CLuAaUL._SL500_.jpg\",\"\\/51NI2avawnL._SL500_.jpg\",\"\\/41mnn0PzgaL._SL500_.jpg\",\"\\/51pDI1xjJ8L._SL500_.jpg\",\"\\/41e4PVfuW8L._SL500_.jpg\",\"\\/41grpORVbvL._SL500_.jpg\",\"\\/51GtMeleLTL._SL500_.jpg\",\"\\/41KhfdrFPxL._SL500_.jpg\",\"\\/41wj6X11seL._SL500_.jpg\",\"\\/41LiVIb+p6L._SL500_.jpg\",\"\\/51NSFx-477L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839972745\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839972745\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E4%BB%95%E7%B5%84%E3%81%BF%E3%81%A8%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%20Docker%26Kubernetes%E3%81%AE%E3%81%8D%E3%81%BB%E3%82%93%E3%81%AE%E3%81%8D%E3%81%BB%E3%82%93\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"1dJ2M\",\"s\":\"s\"}); リンク","link":"/docker-compose/"},{"title":"【入門】OpenShiftの環境設定方法","text":"✓目次 前提とする環境 設定手順 1. Minishiftユーティリティのダウンロード 2. フォルダをCドライブ直下に移動させコマンド実行 3. OpenShiftのWebコンソールにアクセス 前提とする環境 Windows10 64ビット VirtualBoxをセットアップ済 VirtualBoxをセットアップしてない場合は、VirtualBoxのダウンロードページに移動し、使用しているオペレーティングシステム用のバージョンをダウンロードしてください。ウィザードに従ってインストールを完了させておきましょう。 設定手順 以下、設定方法を順番にまとめていきます。とても簡単です。 1. Minishiftユーティリティのダウンロード 以下のURLにアクセスします。https://www.okd.io/minishift/ Webサイトの下部にGet Startedという欄があります。”Minishift releases”という箇所をクリック。 Githubのページに遷移するので、使用しているプラットフォームに適したバージョンをダウンロードし、フォルダに展開します。 Windows10 64ビットの場合は、minishift-1.34.3-windows-amd64.zipになります。zipファイルを解凍しましょう。 2. フォルダをCドライブ直下に移動させコマンド実行 解凍したフォルダを、cドライブの直下に移動させます。 コマンドプロンプトを開きます。フォルダをエクスプローラで開き、パスの部分に”cmd”と入力すれば、そのフォルダに移動された状態でコマンドプロンプトを開くことができます。 Windowsの場合、MinishiftはデフォルトでHyper-Vを使用してMinishift仮想マシンをデプロイします。そのため--vm-driver virtualboxオプションを指定し、VirtualBoxを使用するように指示する必要があります。 以下のようにminishift.exe start --vm-driver virtualboxコマンドを実行します。 1C:\\minishift-1.34.3-windows-amd64&gt;minishift.exe start --vm-driver virtualbox このコマンドを実行すると、Minishiftはインターネット上に存在するISOイメージを取り出し、VirtualBox上に仮想マシンを作成します。 各種ダウンロードなどが完了し、コマンドプロンプト上に以下のような表示がされたら完了です。 123456789101112131415OpenShift server started.The server is accessible via web console at: https://192.168.99.100:8443/consoleYou are logged in as: User: developer Password: &lt;any value&gt;To login as administrator: oc login -u system:admin-- Exporting of OpenShift images is occuring in background process with pid 27020. VirtualBoxのコンソール画面を確認すると、minishiftという名前の新しいVMが自動的に作成されている状態になります。 3. OpenShiftのWebコンソールにアクセス OpenShiftのWebコンソールにアクセスしてみましょう。 google chrome等のブラウザを用いて、上記で示されているhttps://192.168.99.100:8443/consoleにアクセスしてみましょう。 このログイン画面で、任意のユーザー名、パスワードを使用してログインします。 この認証モードは、開発者がポータルに簡単にログインできるようにするためにMinishiftの為だけに設定されていることを覚えておきましょう。本番環境では使えません。 ユーザー名とパスワードを入力しLog inをクリックすると以下のような画面が表示されます。 これでOpenShiftクラスタを活用することができるようになりました。 OpenShiftをもっと学びたい方 以下のUdemyの講座で、OpenShiftの基礎を学ぶことができます。ビルド、ビルドトリガー、イメージストリーム、デプロイメントの理解などをハンズオンで学ぶことができます。 OpenShift for the Absolute Beginners - Hands-on Udemyは30日間の返金保証が付いているため、「ちょっと違うな。」と思ったら返金も可能なので気軽に試してみてください。","link":"/get-start-openshift/"},{"title":"【Hexo】Icarusテーマで画像を中心に寄せる方法","text":"Icarus(v3.0)テーマを適用して記事を作成すると、デフォルトの設定で画像を掲載すると、以下のように画像が左に寄ってしまってます。 これを中心に位置付けるための方法をまとめます。 Icarusテーマで画像を中心に寄せる\\themes\\icarus\\include\\style\\article.stylファイルを編集します。 123456789101112131415161718 h4 font-size: 16px letter-spacing: 1.6px; padding: 5px 15px 5px; border-left: 9px solid #4865b2; font-weight: 400 margin-top: 60px; h5 font-size: 1em+ img + margin: auto;+ display: block; pre font-size: .85em 以下のようになります。 画像を中心にする方法は複数ありますが、Icarusの場合は、img要素をブロック要素にして、margin: autoにすると画像が中央に寄ります。 その他、画像を中心に寄せる方法は、以下の記事が参考になりますので、参照いただければと思います。 https://webkcampus.com/201501/949/ おしまい。 Icarusテーマのカスタマイズにご興味がある方は以下も参考になると思います。","link":"/hexo-image-center/"},{"title":"【Hexo】ブログカード内のファビコンが表示されない問題の対処","text":"Hexo(Icarusテーマ)で、はてなブログカードを使用した際に、faviconがうまく表示されなかったので、解消法を備忘録的にまとめます。 ✓目次 エラーの事象 使用しているプラグイン 原因 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨 対処その②：適用しているIcarus(v3.0)テーマの修正 検証 エラーの事象以下のように、faviconが出てきません。 使用しているプラグインshundroidさんが提供してくれているプラグインを使用させていただきました。 以下のコマンドでインストール可能です。 terminal1npm install shundroid/hexo-embed-hatena-blog-card --save 記事を作成する際に実施するhexo new &quot;{記事名}&quot;コマンドで生成されるマークダウンファイルに｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝という風に、｛% hatenablogcard (記事のURL) %｝と記述していました。 しかしながら、本記事の冒頭の通り、faviconだけが表示されませんでした。 原因画像のパスがhttps://となっていると、faviconが表示されない場合があるようです。※セキュリティ的によろしくない。 Icarus v3.0においてOpen Graph Protocolが正常に適用できない状態になっていたようです。 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨自身のブログ記事をChromeで表示し、F12で正常に表示されていないFaviconの箇所を確認すると、以下の通りとなっていました。 html12&lt;img src=\"https://cdn-ak.favicon.st-hatena.com?url=https%3A%2F%2Fomathin.com%2F2020%2F02%2F01%2Fmatsuba%2F\" alt=\"omathin.com\" title=\"omathin.com\" class=\"favicon\"&gt; Chromeのデベロッパーツール上で、試しに、?url= httpsとなっている部分を、?url=httpという形に変更すると、Faviconが表示されました。 よって、ブログ記事を作成するマークダウンファイル上で、｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝と記載していた箇所を、｛% hatenablogcard http://omathin.com/2020/01/16/knee-surgery/ %}という風に、https:形式からhttp:に変更すれば、ブログカード内にFaviconが表示されるようです。 しかしながら、これはセキュリティ的にあまりよろしくないですよね。 他に対策はないのか、とOpen Graph Protocolなどを調査してみると、なんと私が現在使用しているIcarus(v3.0)では、Open Graph Protocolが正常に適用できない状態になっているバグがあったようです。 対処その②：適用しているIcarus(v3.0)テーマの修正私が適用していたIcarusのバージョン3.0では、Open Graph Protocolが正常に適用できない状態になっていたそうです。 修正するコードはgithubを参照し、以下のように修正すればOKです。 layout/common/head.jsx123456789 author={open_graph.author || config.author} description={open_graph.description || page.description || page.excerpt || page.content || config.description} keywords={page.keywords || (page.tags &amp;&amp; page.tags.length ? page.tags : undefined) || config.keywords}- url={open_graph.url || url}+ url={open_graph.url || page.permalink || url} images={openGraphImages} siteName={open_graph.site_name || config.title} language={language} package.json12345678 \"bulma-stylus\": \"0.8.0\", \"deepmerge\": \"^4.2.2\", \"hexo\": \"^4.2.0\",- \"hexo-component-inferno\": \"^0.2.3\",+ \"hexo-component-inferno\": \"^0.2.4\", \"hexo-log\": \"^1.0.0\", \"hexo-pagination\": \"^1.0.0\", \"hexo-renderer-inferno\": \"^0.1.3\", 検証本ブログの別記事のブログカードを以下に張り付けてみると問題なく画像が表示されました。","link":"/hatenablocard-favicon-error/"},{"title":"【Hexo】Icarusテーマに吹き出しを加える方法","text":"✓目次 本記事の対象者 本記事による効果 作成方法(コピペでOK！) 本記事の対象者 ・ Hexo+Github Pagesで無料ブログをやっている方 ・ ブログのデザインをもっと良くしてブログで収益を得たい方 ・ キャラクター付きコメントを加えて、読者にメッセージを訴えかけたい方 本記事による効果 こんな感じで、吹き出しコメントを加えられるようになるよ！ 作成方法(コピペでOK！) IcarulテーマのCSSファイルに以下のコードを貼り付けましょう。 themes/icarus/include/style/article.styl12345678910111213141516171819202122232425262728293031323334353637383940414243444546.balloon5 { width: 100%; margin: 1.5em 0; overflow: hidden;}.balloon5 .faceicon { float: left; margin-right: -90px; width: 80px;}.balloon5 .faceicon img{ width: 100%; height: auto; border: solid 3px #d7ebfe; border-radius: 50%;}.balloon5 .chatting { width: 100%;}.says { display: inline-block; position: relative; margin: 5px 0 0 105px; padding: 17px 13px; border-radius: 12px; background: #d7ebfe;}.says:after { content: &quot;&quot;; display: inline-block; position: absolute; top: 18px; left: -24px; border: 12px solid transparent; border-right: 12px solid #d7ebfe;}.says p { margin: 0; padding: 0;} そして記事作成ファイルに以下のコードを貼り付ければ、完了です。 source/_posts/article.md12345678910&lt;div class=&quot;balloon5&quot;&gt; &lt;div class=&quot;faceicon&quot;&gt; &lt;img src=&quot;/images/xxxx.png&quot;&gt; &lt;/div&gt; &lt;div class=&quot;chatting&quot;&gt; &lt;div class=&quot;says&quot;&gt; &lt;p&gt;ここにセリフを記載&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 以下のサルワカさんのページを参考にさせていただきました。サルワカさんのページには他にも様々なサンプルがありますので、自分好みのデザインを作ってみましょう。CSSで作る！吹き出しデザインのサンプル19選 よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/hexo-icarus-speech-bubble/"},{"title":"【Hexo】Icarusテーマに更新日を表示させる方法","text":"Icarus(v3.0)テーマを適用して記事を作成すると、デフォルト設定では以下のようになってると思います。 御覧の通り、作成日として”3日前”という表記があるだけで、更新日がありません。 これを変更したいと思います。 \\themes\\icarus\\layout\\common\\article.jsxを変更すればOKです。 \\themes\\icarus\\layout\\common\\article.jsx12345 {/* Date */}+ &lt;i class=\"fas fa-clock\"&gt;作成日:&lt;/i&gt; &lt;time class=\"level-item\" dateTime={date_xml(page.date)} title={date_xml(page.date)}&gt;{date(page.date)}&lt;/time&gt;+ &lt;i class=\"fas fa-wrench\"&gt;更新日:&lt;/i&gt;+ &lt;time class=\"level-item\" dateTime={date_xml(page.updated)} title={date_xml(page.updated)}&gt;{date(page.updated)}&lt;/time&gt; こちらのコードを反映すると、以下の通りとなります。 アイコンは、Font Awesomeの参照して、&lt;i class=&quot;fas fa-clock&quot;&gt;&lt;/i&gt;等を使えばアイコンを表示させることができます。 https://fontawesome.com/icons?d=gallery 以上です。","link":"/hexo-icarus-updated/"},{"title":"[Hexo landscape]スマホで閲覧した際にInstagramの幅がはみ出る","text":"Hexo landscape themeで、Instagramの投稿を埋め込んだ記事を、スマートフォンで閲覧すると、幅があってない時の対処方法を記載します。 結論としては、/theme/landscape/source/css/_partial/配下のmobile.stylファイルを修正すればOKです。 12$ cd /thema/landscape/source/css/_partial/$ vim mobile.styl 以下のコードを一番下に追記。 mobile.styl12345678910@media screen and (max-width: 728px){ .instagram-media{ width:414px !important; max-width: 100% !important; min-width: initial !important; }} 完了したらhexo d -gでデプロイすればOKです。","link":"/hexo-landscape-instagram-modify/"},{"title":"Hexo＋github pagesで構築したブログをBoostnoteを用いて更新する方法","text":"備忘的記事です。 Boostnoteのバージョンは、Boostnote 0.11.13です。 _config.ymlの記述 post_asset_folder: falseの状態にしておく。 123456789101112131415161718192021222324(省略)# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: enable: true # Open external links in new tab field: site # Apply to the whole site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: false(省略) [ステップ1]ページの作成 以下のコマンドでページを作成する。ここではimageというページを作成する例。 12$ hexo new &quot;image&quot;INFO Created: ~\\usr\\source\\_posts\\image.md [ステップ2]boostnoteで記事を作成する。 画像を張り付けるなど、boostnoteのお作法で好きなように記事を作成する [ステップ3]記事を出力 File→export→MarkDownを選択 この際、先ほど作成したimage.mdを上書きする形でexportと保存を実行 上述の_config.ymlの44行目のようにpost_asset_folder: falseとなっている場合、以下のようなフォルダ構成になるようにする。 作業としては、sourceフォルダの配下にimagesフォルダを新規作成する。 [ステップ4]画像が出力されるようにファイル編集 上書きする形でexportしたimage.mdを下記のように編集する。適当なエディタを使ってください。 attachements/xxxxx.pngとなっているのを/images/xxxx.pngに変更 attachementsフォルダに配置されているxxxx.pngを/source/images/配下にコピーする。 [ステップ5]記事の確認 hexo serverコマンドで起動し、localhost:4000で確認。 1$ hexo server [ステップ6]記事のアップロード 問題なければ以下のコマンドでgithubにpushする 1$ hexo d -g これで画像が表示されているはずです。 備考githubにpushした際、ページが表示されなくなる場合ブログのドメイン名を記載したCNAMEファイルが、githubのリポジトリから消えている為です。 githubにpushする前に、hexo cleanコマンドでキャッシュの削除をすると、publicフォルダが丸々削除されてしまい、publicフォルダにCNAMEファイルが削除されてしまったことが原因だと思われる。 CNAMEファイルを作成し、publicフォルダに配置し、再度hexo d -gコマンドでgithubにpushしましょう。 またads.txtファイルもpublicフォルダから削除されているので、こちらもpublicフォルダに配置してgithubにpushしましょう。 参考ページNode.js製の静的サイトジェネレータ「Hexo」で無料ブログ開発 vol.1 | dotstudio HEXOを使ってブログを構築しました。 その1 | ant magazine","link":"/hexo_post/"},{"title":"【Hexo】Icarusテーマで強調メッセージブロックを使う方法","text":"Hexo(Icarus)+Github pagesで無料ブログを作成した際、記事の中でページの一部を強調するために色付きのメッセージブロックを使いたくなる時があります。IcarusはBULMAというCSSフレームワークが適用されているので簡単に導入できます。 本記事の対象者 ・ Hexo + Github pagesでテーマはIcarusの人 ・ Icarusのv3.0.0以上の人 以下のコードをコピペすればOKです。hexo new &quot;hogehoge&quot;(hogehogeはファイル名)でジェネレートしたマークダウンファイル内部に、以下のコードをコピペして、&lt;div class=&quot;message-body&quot;&gt;と&lt;/div&gt;の間に文章などを記述すればOKです。 12345678&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Info&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. &lt;strong&gt;Pellentesque risus mi&lt;/strong&gt;, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum &lt;a&gt;felis venenatis&lt;/a&gt; efficitur. Aenean ac &lt;em&gt;eleifend lacus&lt;/em&gt;, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. &lt;/div&gt;&lt;/article&gt; 上記のコードを使うと以下のような形になります。 Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque risus mi, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum felis venenatis efficitur. Aenean ac eleifend lacus, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. 文章だけでなく、はてなブログカードを埋め込んだり、アフィリエイトリンクを埋め込むことも可能です。 例えば、以下のようなコードでマークダウンファイルに記述した場合、、、 1234567891011&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt;{% hatenablogcard https://omathin.com/2020/05/05/Icarus-h2h3title-change/ %} &lt;/div&gt;&lt;/article&gt; 以下のようになります。 Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓ いくらか見栄えがいい感じになりますね。 ちなみに、はてなブログカードのプラグインは、以下のnpmコマンドで導入が可能です。 1npm install shundroid/hexo-embed-hatena-blog-card --save 他の色を使いたい場合はBULMAのドキュメントを参照してくださいメッセージブロックについては、以下のページに記述されているコードを参照しコピペしながら使いましょう。 こちらも参考になるかもしれません。 積極的にBULMAを活用して、視認性の高い記事を作っていきましょう！ おしまい","link":"/icarus-bulma/"},{"title":"HTTPメソッド9種類 | PATCHとPUTの違いも解説","text":"HTTPメソッド全9種類をまとめていくよ！ HTTPメソッドは全部で9種類 下表にまとめる9種類が主なHTTPメソッドになります。 メソッド 意味 CRUD分類 OPTION サーバー側が提供する機能の確認 READ GET リソースの取得 READ HEAD リソースのヘッダー(メタ情報)取得 READ POST 従属リソースの作成 CREATE PUT/PATCH 新規リソースの作成、リソースの更新 UPDATE DELETE リソースの削除 DELETE TRACE 通信経路の確認 READ CONNECT プロキシのトンネル接続 READ patchとputの違いpatchとputはともにデータを更新するメソッドですが少しニュアンスが異なります。 patchは、データがすでに存在しているものに対して更新をかける処理です。 putはデータが存在しているかどうかわからないときに使用します。データが存在しているときは更新をし、データが存在しない場合は新規作成を行うという処理です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"RESTful Webサービス\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51Su2Ger2sL._SL500_.jpg\",\"\\/41J5X9LP1CL._SL500_.jpg\",\"\\/31zXLORJyoL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873113539\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873113539\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/RESTful%20Web%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=RESTful%20Web%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"gH5Du\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Web API: The Good Parts\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51GHwTNJgSL._SL500_.jpg\",\"\\/51mbCCcY9bL._SL500_.jpg\",\"\\/51vvyuOOt5L._SL500_.jpg\",\"\\/51PYEUExTuL._SL500_.jpg\",\"\\/41VQnYQ1efL._SL500_.jpg\",\"\\/51++aIO9xlL._SL500_.jpg\",\"\\/41qmncE46cL._SL500_.jpg\",\"\\/515WK7ntpML._SL500_.jpg\",\"\\/51DHLuByFiL._SL500_.jpg\",\"\\/5152K8Arh5L._SL500_.jpg\",\"\\/51HG2exJpUL._SL500_.jpg\",\"\\/51op2gZZUOL._SL500_.jpg\",\"\\/51VJUmW2m1L._SL500_.jpg\",\"\\/410utF8MFHL._SL500_.jpg\",\"\\/51f7B2cUx5L._SL500_.jpg\",\"\\/519zkljUGrL._SL500_.jpg\",\"\\/51MI-VafIhL._SL500_.jpg\",\"\\/513+biosBXL._SL500_.jpg\",\"\\/51SCRpCqGlL._SL500_.jpg\",\"\\/51OZREZnkUL._SL500_.jpg\",\"\\/51Myy6DtThL._SL500_.jpg\",\"\\/51I0cnlpwNL._SL500_.jpg\",\"\\/51ykHHoGXNL._SL500_.jpg\",\"\\/513VeymYtBL._SL500_.jpg\",\"\\/51sLGBndSVL._SL500_.jpg\",\"\\/51gDF+OJLGL._SL500_.jpg\",\"\\/513A1L-2HuL._SL500_.jpg\",\"\\/51ydehSTr4L._SL500_.jpg\",\"\\/51dI6EZdT6L._SL500_.jpg\",\"\\/51TPCOoMCkL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873116864\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873116864\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Web%20API%3A%20The%20Good%20Parts\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Web%20API%3A%20The%20Good%20Parts\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"lWGQ7\",\"s\":\"s\"}); リンク REST APIの設計を詳しく学びたい方へ Udemyが提供しているREST WebAPI サービス 設計という講義が参考になります。Swaggerで本格的なAPI設計のベストプラクティスを学びましょう。 以上です。","link":"/http-method/"},{"title":"Hexoのicarusテーマのフォントの変え方","text":"Icarusのテーマを早速適用してみると、中国語っぽいフォントになっているので変更したいな、と思いました。 例えば、「所」だと下図の左側のような表記になっており、日本人からすると「読めなくはないけど変だな」という文字になっています。◆中国語の漢字「簡体字」について（その３） ｜ Chinese－Lab ～中文研究網～ 基本的にChromeのF12キーで編集したい箇所を指定して、どのようなCSSが割り当てられているのかを調べる。 想定通りfont-familyにMicrosoft YaHeiが含まれているのが大きな原因のようでした。 icarusフォルダ内の、どのファイルを変更すればよいかを、icarusのgithubページのリポジトリで検索。ひとまず、”Microsoft YaHei”と入力して検索してみる。 このようにbase.stylファイルか、cyberpunk.stylが該当することが分かる。 パラメータを変更しながら、どちらのファイルを変更すればよいのかを探り、正解はbase.stylであることが分かる。他の人気ブロガーの方のフォントを参考にfamily-sans = Noto, Hiragino Sans, Helvetica, Arial, sans-serifという風に、Microsoft Yaheiがない形式に変更したら、中国語の漢字で表示されなくなりました。 \\themes\\icarus\\include\\style\\base.styl123456789101112131415161718/* --------------------------------- * Override Bulma CSS Framework * --------------------------------- */$body-size ?= 14px$body-background-color ?= #f7f7f7$family-sans-serif ?= Noto, Hiragino Sans, Helvetica, Arial, sans-serif # ←このように変更すればOK$family-code ?= 'Source Code Pro', monospace, 'Microsoft YaHei'$primary ?= $blue$custom-colors ?= { grey-lightest: { '1': $grey-lightest '2': $grey-darker }}","link":"/icarus-theme-change/"},{"title":"【Hexo】Icarusテーマのサムネイル位置やサイズを変更する方法","text":"サムネイルの位置を変更する方法をまとめました。 デフォルトの設定では、以下のようにタイトルの上部にサムネイル画像が配置されます。 このサムネイルの位置をタイトルの下に配置されるように変更したので、その方法をまとめました。 ✓目次 サムネイルの設定方法 サムネイル位置の変更方法 サムネイルのサイズ変更 サムネイルの設定方法まずサムネイルは、記事を作成するマークダウンファイルの上部にthumbnail: {画像ファイルのパス}を記載することで設定されます。 例えば、以下のような記載になります。 1234567891011121314---title: &quot;【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説&quot;date: 2020-04-29 10:48:30update: categories:- AItags:- 自然言語処理- doc2vec- ニューラルネットワークdescription: &quot;doc2vecとは何か。dmpv, DBOWというdoc2vecの理解に必要な技術をわかりやすくまとめてみました。&quot;thumbnail: images/hogehoge.webp--- Hexoのテーマの一つであるIcarus(v 3.0.0)だと、タイトルの上にサムネイル画像が設置されますが、これをタイトル下に設置するように変更します。 サムネイル位置の変更方法hexo-theme-icarus/layout/common/article.jsxファイルを編集することで、サムネイルの位置を変更することができます。 まず、タイトル上部に表示されるサムネイル画像を非表示にするには、以下のコードの{/* Thumbnail */}というコードブロックを削除すればOKです。 1234567891011121314 return &lt;Fragment&gt; {/* Main content */} &lt;div class=\"card\"&gt;- {/* Thumbnail */}- {has_thumbnail(page) ? &lt;div class=\"card-image\"&gt;- {index ? &lt;a href={url_for(page.link || page.path)} class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/a&gt; : &lt;span class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/span&gt;}- &lt;/div&gt; : null} {/* Metadata */} &lt;article class={`card-content article${'direction' in page ? ' ' + page.direction : ''}`} role=\"article\"&gt; {page.layout !== 'page' ? &lt;div class=\"article-meta size-small is-uppercase level is-mobile\"&gt; 次に、記事タイトルの下にサムネイルを表示されるには、hexo-theme-icarus/layout/common/article.jsxファイルの{/* Title */}というコードブロックの下に、{/* Thumbnail */}コードブロックを追記すればOKです。 123456789101112 {/* Title */} &lt;h1 class=&quot;title is-3 is-size-4-mobile&quot;&gt; {index ? &lt;a class=&quot;link-muted&quot; href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title} &lt;/h1&gt;+ {/* Thumbnail */}+ {has_thumbnail(page) ? &lt;div class=&quot;card-image&quot;&gt;+ {index ? &lt;a href={url_for(page.link || page.path)} class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/a&gt; : &lt;span class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/span&gt;}+ &lt;/div&gt; : null} 以下のように、タイトルの下にサムネイルが表示されるようになりました。 サムネイルのサイズ変更サムネイルの配置を変えましたが、サムネイルの画像サイズによっては、以下のように上下がカットされてしまったり、記事タイトルの文章が見えている状態になっています。 これをうまい具合に変更したい場合は、include/style/article.stylファイルを変更します。 以下のように変更します。 12345.thumbnail object-fit: contain width: 100% !important height: 100% !important background-color: #fff 変更後、以下のようになります。 オススメ Webの仕事に関わる人なら誰でも必要な、「HTML/CSS」とプログラミング言語「JavaScript」の知識をこれ一本で。基礎の基礎から、jQuery/Vue.jsまで学ぶことができます。Hexoブログを自分が思うがままにカスタマイズしたい方は、受講したほうが良い講座だと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXxoT1x\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/html-css-js/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1334522_9c8b_3.jpg\"}}); [HTML/CSS/JavaScript] フロントエンドエンジニアになりたい人の Webプログラミング入門","link":"/icarus-thumbnail-custom/"},{"title":"【Hexo】Google検索結果に記事公開日ではなく最終更新日を表示させる方法","text":"目次 本記事の対象者 課題: Google検索の結果の日付を最新化したい URLに年月日を含めないようにpermalinkを変更 既に記事を作成している人: リダイレクト設定をする まとめ: URLに年月日を含めない設定にしよう！ 本記事の対象者 ・Hexoを用いてブログを運営している人 ・HexoブログでSEO対策をしたい人 ・Google検索結果に表示される自分のブログの日付が最終更新日になっていない人 課題: Google検索の結果の日付を最新化したい例えば本ブログのDockerとは何か、メリット/デメリットまとめという記事は、公開日は2020年3月14日ですが更新日は2021年5月29日になっています。 Google検索の結果として表示されている日付は、更新日である2021年5月29日と表示されていることが望ましいです。 しかしながら、Google検索の結果を見てみると、、、、 このように公開日である2020/03/13となっております。 記事をUpdateしたのにGoogle側に認識されていないのはSEO的にも問題です。 そこでHexoブログにおいて記事の最終更新日を表示させる方法を検討したので紹介します。 URLに年月日を含めないようにpermalinkを変更Hexoブログのデフォルト設定で記事を作成した場合、記事のURLは以下のようになっているはずです。 https://omathin.com/2021/05/22/datamodel/ このように/2021/05/22/という文字列がURLに含まれている場合、いくらリライトをしてもGoogle側はURLの情報を優先し古い記事とみなしてしまうようです。 これを解消するためにはHexoの設定を変える必要があります。 hexoのconfig.ymlにおけるpermalinkの箇所がデフォルトでは、:year/:month/:day/:title/となっているかと思います。 これをpermalink: :title/とすればOKです。 _config.yml123456789# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://omathin.comroot: /permalink: :title/ # :year/:month/:day/:title/から変更permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks 設定が完了したらterminalでhexo serverコマンドでlocalhostで起動してみましょう。 記事のURLに日付が含まれない形式になっているはずです。 既に記事を作成している人: リダイレクト設定をする もう既にいくつか記事を書いてしまっているのですが、それでもURLを変更しても大丈夫なのでしょうか？ 結論を言うと、旧記事から新記事にリダイレクトを行えば問題ありません。 Hexoの場合、hexo-generator-aliasというプラグインを用いることで対処できます。 まずはターミナルでプラグインをインストールしましょう。 hexo-generator-aliasをインストール1npm install hexo-generator-alias --save 完了したら各記事の設定欄(各記事の最上部)にalias: 旧URLを設定すればリダイレクト設定してくれます。 例としては以下のような記述です。 「Dockerとは何か、メリット/デメリットまとめ」の記事設定12345678910111213---title: &quot;Dockerとは何か、メリット/デメリットまとめ&quot;date: 2020-03-14updated: 2021-05-29categories:- ITtags: - docker- コンテナdescription: &quot;「仮想化」、「Docker」、聞いたことあってなんとなくわかるけど、何ができるのか、何がうれしいのか、従来のホスト型仮想化と比較した場合のメリットデメリットは何なのかを知りたくないですか？「仮想環境とは」から始まり、Dockerのメリットデメリットまでまとめています。従来のホスト型仮想環境とDockerの違いは、ゲストOSの有無です。そこからひも解いてメリット、デメリットをまとめています。&quot;thumbnail: https://omathin.com/images/docker.PNGalias: /2020/03/14/Docker/--- もしかして、この設定全部の記事にしないといけないの？ あまり賢くない方法ですが、私は全部手作業でやりました。100記事くらいだとチェック含めて大体1時間位の作業になるかな。 まとめ: URLに年月日を含めない設定にしよう！本記事は、「【Hexo】Google検索結果に記事公開日ではなく最終更新日を表示させる方法」というテーマでまとめました。 Hexoでブログを始める際は、permalinkの設定を変更しましょう 記事を書き積んだ後にURLの変更をするのはとても大変な作業を伴います。 これからHexoを用いてブログを始める方はぜひ注意してください。 &gt;&gt; [参考]Hexoの公式ドキュメント&gt;&gt; [参考][Hexo] 記事のURLを変更&gt;&gt; [参考]【2020年版】Google検索結果の日付を更新する方法&gt;&gt;[ 参考][Hexo] URLのリダイレクト (hexo-generator-alias/hexo-generator-redirect])","link":"/hexo-updateday/"},{"title":"【5分で分かる】結合演算とは | 内部結合と外部結合の違いを理解する","text":"✓目次 本記事の対象者 結合演算とは 内部結合: 項目が一致するデータだけを結合する 外部結合: 項目が一致しないデータも結合する まとめ: 内部結合と外部結合を学びました 本記事の対象者 ・ データベースに関する業務に携わる初心者の方 ・ データサイエンティストを目指している方 ・ テーブルの内部結合と外部結合の概要を知りたい方 結合演算とは 結合演算とは、複数の表を1つの票にまとめる演算のことです。 表形式で整理されたデータを１つの表に結合する上で、どのように結合するのか大きく２つの方法に分けられます。 それが、「内部結合」と「外部結合」です。 以降、それぞれについて整理したいと思います。 内部結合: 項目が一致するデータだけを結合する内部結合とは、複数のテーブルを結合する際に結合した項目が一致するものだけを結合する方式です。 具体的には、以下の図に示すようなイメージです。 内部結合のポイントは、一致している列(カラム)を把握することです。 ここで示している「テーブルA」と「テーブルB」で一致しているカラムは、「商品コード」という名前のカラムです。 両テーブルの「商品コード」というカラムにおいて、共通するコードは、「00001」と「00002」になります。 内部結合の場合、「00001」と「00002」という商品コードのみが抽出され、1つの結合テーブルとして生成されます。 つまり、「00003」と「00004」は結合されず、結合テーブルには反映されません。 以上が内部結合になります。 外部結合: 項目が一致しないデータも結合する 外部結合とは、複数の表を1つの表に結合する際に、一致しないデータも含めて結合する方式です。 具体的には、以下の図に示すようなイメージです。 外部結合を行う場合、結合項目が一致しないデータについては、「NULL」として反映されます。 まとめ: 内部結合と外部結合を学びました 本記事では、「【5分で分かる】結合演算とは | 内部結合と外部結合」というテーマでまとめました。 以下に概要をまとめます。 内部結合: 項目が一致するデータだけを結合する 外部結合: 項目が一致しないデータも結合する データサイエンス業務やSQLでデータを抽出する際の参考になればと思います。 なおPythonを用いて内部結合を行う方法を以下の記事でまとめていますので、合わせて読んでいいただければと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク","link":"/join-operation/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで③[自宅安静～抜糸～松葉づえ卒業まで]","text":"前の記事で前十字靭帯再建手術後、退院までの1週間をまとめました。 本記事では、その続きとして松葉づえが取れるまでの手術後約1か月をまとめたいと思います。 前の記事は、こちらを参照ください。 以下のようなことが知りたければ参考になると思います。 実体験に基づいた松葉づえが取れるまでの生活を具体的に知りたい 抜糸は痛いのかどうか？？ 自宅での生活は？？ 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 退院直後の生活(退院～抜糸まで) 抜糸後の生活 リハビリで重視されたのは「膝の力入れ」 膝の状態、感覚 松葉づえの卒業 まとめ 退院直後の生活(退院～抜糸まで)基本的に自宅で膝のアイシング、痛み止めを飲みながら、膝を心臓よりも高くして安静です。 自宅では、時間を見つけては膝のお皿を上下左右斜めに動かしたりします。 抜糸は、手術してから2週間後くらいだったと思います。 抜糸自体は少しチクチクするくらいで、そんなに痛くありません。※手術前の麻酔のアレルギーチェックや尿道の管を抜くときのほうが全然痛いです。 尿道の管の苦しさを乗り越えたのなら、全く問題ないと思います。 抜糸したあとも、基本的には傷口にテーピングをして置きます。このとき、傷口に対して垂直にテープを張ると傷跡が残りにくくなるそうです。 抜糸後の生活松葉づえが取れるまでは、手術から40日くらいがたった頃だったと思います。足はものすごい勢いで細くなります。 リハビリは、1週間に2回 or 3回のペースで通院しましたが、自宅でも積極的にリハビリをすることが大事です。膝のお皿動かしや、膝の力入れを積極的にしました。 病院までの通院は、電車やバスなどは使わずになるべく車で送り迎えをしてもらいましょう。電車やバスの場合、急な揺れや人との接触による危険があるため、車で送り迎えしてもらうのが良いと思います。 1回のリハビリは約1時間～1.5時間ほどで、理学療法士によるマッサージ、足上げによる筋トレ、EMS、超音波、患部側の足に体重を徐々にかける練習、歩く練習、あたりがメインでした。 ちなみに、手術後に手術した方の足に体重を乗せるのは緊張するものです。 松葉づえを卒業するためには、最終的に手術したほうの足に全体重が乗っても大丈夫な状態にならなければなりません。 いきなり全体重をかけるのではなく、最初は自分の体重の1/4, 1/2, , 全体重、という風に段階を踏んで徐々に進めていきます。 リハビリで重視されたのは「膝の力入れ」基本的に炎症を抑えることについて変わらないのです。膝を曲げる角度も時期に応じて制限があるので理学療法士の人の指導に従うべきだと思います。 とはいうものの、リハビリのなかでも、膝の力入れは、結構徹底されました。 膝の裏に丸めたタオルを入れて、太ももの前の筋肉を意識して、そのタオルを押しつぶすように力を入れる動作です。ちょっと言い過ぎなのでは？とも思いましたが、「100回でも200回でもいいからいくらでもやりましょう」というぐらいの勢いです。 (実はこの膝の力入れを本気でやることの重要性を、後々知るのでした。このあたりは、続きの記事でまとめようと思います) 注意事項など、参考になる良い動画がYoutubeにあったので、ここに載せておきます。 膝の状態、感覚退院直後は膝からの出血もあるため、松葉づえでトイレに行くときに血液が足先にたまっていく嫌な感覚がありますが、代替術後2週間くらいになるとで嫌な感覚がなくなります。 ※本記事冒頭のように、ふくらはぎ周辺に出血の跡を意味する黄色いシミみたいなのができてきます。 松葉づえの卒業手術してから約1ヵ月後くらいに、手術した方の足に、全体重が乗せられるようになり、かつ、ある程度松葉づえなしで歩けるようになれば、松葉づえ1本の卒業が認められました。 松葉づえなしで歩けるといっても、長い距離を歩いたり、走ったりは全くできないので、1本は持っておいた方が良いだろうという判断でした。 特に下り坂は膝に負担がかかるらしく、結構きつい。。。。そのため、手術から1ヵ月後に会社に復帰する際は、念のため松葉づえをもって出社しました。電車やバスで急な揺れにも備えたほうが良いという判断を理学療法士の方としました。 朝の満員電車はなかなか席を譲ってくれないパタンも多いので、松葉づえを持っていきましょう。 まとめ 松葉づえ期間も基本的には安静。 リハビリは膝の皿動かし、膝の力入れ、EMS、超音波、など。皿動かし、膝の力入れは積極的に自宅でも行いました。 松葉づえの卒業は1ヵ月以上かかる。リハビリや通勤はなるべく車で送迎してもらえると良い。 抜糸は痛くない。 以上です。次は、復帰を早めるためにリハビリ中に工夫したこと、辛かったことなどをまとめようと思います。以下に、7か月のリハビリについてまとめました。 体質改善したいひとにオススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/matsuba/"},{"title":"【Hexo】Icarusのページ読み込みスピードを改善させてみた","text":"このブログの読み込みスピードを上げるために試したことをまとめます。 ✓目次 設定前の読み込みスピード レンダリングブロッキングCSS hexo-img-optimizationの適用 まとめ 参考にした記事 Speeding hexo (or any page) for PageSpeed insights · dizzy.zone 設定前の読み込みスピード GoogleのPageSpeed Insightsで読み込みスピードを計測したところ、以下のような結果でした。 スコア モバイル 29% デスクトップ 75% 以降の修正を加えてどの程度改善するのか見ていくよ！ レンダリングブロッキングCSS CSSが非同期に読み込まれるようにします。参考記事と同様にheadタグで外部CSSを読み込んでいる部分に適用してみました。※これで良いのかよくわかりませんが。。。 themes/icarus/layout/common/head.jsx123{hlTheme ? &lt;link rel=&quot;stylesheet&quot; href={cdn('highlight.js', '9.12.0', 'styles/' + hlTheme + '.css')} as=&quot;style&quot; onload=&quot;this.onload=null,this.rel=&quot;stylesheet&quot;&quot;/&gt; : null}&lt;link rel=&quot;stylesheet&quot; href={url_for('/css/' + variant + '.css')} as=&quot;style&quot; onload=&quot;this.onload=null,this.rel=&quot;stylesheet&quot;&quot;/&gt; この状態で測定してみたところ下記のとおりでした。 スコア モバイル 32% デスクトップ 81% ちょっと良くなったのかな？という感じです。。。 hexo-img-optimizationの適用 hexoのシンプルな画像最適化ライブラリを適用します。 hexoブログフォルダで、以下のコマンドを実行します。 インストール1npm i --save hexo-img-optimization インストールが完了したら、以下のコマンドを実行します。 最適化1hexo generate &amp;&amp; hexo img すると、imagesフォルダに配置している画像ファイルに対して、最適化処理が走ります。 実行後、再度計測すると以下の通りでした。 スコア モバイル 39% デスクトップ 83% うーん。。。大きな改善とまでは言えませんが多少はましになったでしょうか。 まとめ HexoのIcarusテーマにおけるページ読み込みの改善についてまとめてみました。 とはいっても、まだまだ読み込みが遅いので、改めて改善柵を検討してみたいと思います。 この記事が役に立った、という方はTwitterのフォローよろしくおねがいします。 その他、Icarusのデザイン変更に関する記事","link":"/page-speed-up-test/"},{"title":"【React】fetchメソッドでREST APIを叩く方法","text":"Reactでfetchメソッドを用いて外部のREST APIを叩き、取得した情報をブラウザ上に出力する方法をまとめました。 実行環境 使用端末: M1 MacbookPro 以下の通りM1 MacでHomebrewをインストール済であることを前提としています。 ・ M1 Macbookpro ・ Homebrewはインストール済 利用するAPIは「Json Placeholder」を使用します。JSONPlaceholder - Free Fake REST API 目次 ReactでAPIにアクセスする方法は2つある Reactの開発環境作成 コンポーネントの作成 アクセスするAPIの確認 ApiFetch.jsファイルを編集 App.jsファイルの編集 Reactを起動して確認 ReactでAPIにアクセスする方法は2つある ReactでAPIにアクセスする方法は以下の2通りがあります。 ・axiosという3rd Partyのアプリを使用する方法 ・JavaScriptのfetchメソッドを使う方法 本記事では、fetchメソッドを方法をまとめます。 axiosを使う方法は以下の記事を参照ください。 Reactの開発環境作成まずは、Reactの開発環境を作成していきましょう。 Node.jsのインストール含め、Reactの開発環境整備については以下の記事に詳細をまとたのでこちらを参照ください。以下の記事でまとめた開発環境構築が完了している前提で以降まとめていきます。 まずは以下のコマンドでReactでAPIにアクセスするアプリの雛形を作成します。 terminal1npx create-react-app react-fetch 作成したreact-fetchフォルダに移動して、npm startコマンドで、Reactを起動させてみましょう。 コンポーネントの作成まずはsrcフォルダ配下にcomponentsという名前のフォルダを作成します。 terminal1mkdir src/components componentsフォルダ配下にApiFetch.jsというファイルを作成し、以下のようなコードを記載します。 src/components/ApiFetch.js1234567891011import React from 'react'const ApiFetch = () =&gt; { return ( &lt;div&gt; &lt;/div&gt; )}export default ApiFetch ちなみにこちらのコードはVisal Studio Codeの拡張機能であるes7 reactをインストールしておくと、rafceと入力するだけでコードを生成してくれます。 アクセスするAPIの確認今回はJSON Placeholderの/postsを呼び出します。 https://jsonplaceholder.typicode.com/posts このAPIには、1〜100までのidが割り当てられた投稿が含まれています。 このAPIを叩くことでJSONオブジェクトが取得できます。 ApiFetch.jsファイルを編集以下のようなコードになります。 123456789101112131415161718192021222324252627import React, {useState, useEffect} from 'react'const ApiFetch = () =&gt; { const [posts, setPosts] = useState([]) useEffect(() =&gt; { fetch('https://jsonplaceholder.typicode.com/posts', {method: 'GET'}) .then(res =&gt; res.json()) .then(data =&gt; { setPosts(data) }) },[]) return ( &lt;div&gt; &lt;ul&gt; { posts.map(post =&gt; &lt;li key={post.id}&gt;{post.title}&lt;/li&gt;) } &lt;/ul&gt; &lt;/div&gt; )}export default ApiFetch コードの解説をします。 まず、ApiFetch.jsファイルでuseStateとuseEffectをimportします。 今回は、JSON Placeholderの/postsのデータを格納するpostsというStateを定義し、postsを更新するsetPostsというメソッドを定義します。初期値は空のリストにしておきます。 useEffectでブラウザ起動時にAPIが1度だけ叩くようにしたいので、13行目のように第荷引数に空のリストを記述します。 fetch('')の文字列の部分に、叩きたいREST APIのURLを記述します。 fetchメソッドを使う場合、メソッドの指定は{}を使います。 今回はGETメソッドなので{method: 'GET'}としておきます。 .thenでレスポンスを取得します。 fetchメソッドの場合は、HTML形式でレスポンスが返ってきます。 そのため、HTML形式をJSON形式に変換する必要があります。 JSON形式に変換するためにはjsonというメソッドを使えばOKです。 JSONに変換したレスポンスはdataという変数に代入し、それを引数にsetPostを用いてpostsというステートに結果を代入しています。 App.jsファイルの編集先程作成したApiFetchコンポーネントをApp.jsファイルに登録します。 ApiFetchをimportし、10行目に&lt;ApiFetch /&gt;を追記しています。 123456789101112131415161718192021222324252627import logo from './logo.svg';import './App.css';import ApiFetch from './components/ApiFetch';function App() { return ( &lt;div className=&quot;App&quot;&gt; &lt;header className=&quot;App-header&quot;&gt; &lt;img src={logo} className=&quot;App-logo&quot; alt=&quot;logo&quot; /&gt; &lt;ApiFetch /&gt; &lt;p&gt; Edit &lt;code&gt;src/App.js&lt;/code&gt; and save to reload. &lt;/p&gt; &lt;a className=&quot;App-link&quot; href=&quot;https://reactjs.org&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; &gt; Learn React &lt;/a&gt; &lt;/header&gt; &lt;/div&gt; );}export default App; Reactを起動して確認npm startコマンドを実行してReactを起動しましょう。 以下の通り、APIを叩いてレスポンスをブラウザ上に表示できたことが確認できるはずです。 以上がfetchメソッドを用いたAPIアクセス方法になります。 この記事が役に立った！という方はTwitterのフォローや記事の共有など、よろしくおねがいします。 もっと詳しくReactを学びたい方 Udemyの[基礎編]React Hooks + Django REST Framework API でフルスタックWeb開発で学ぶのがおすすめです。","link":"/react-api-2/"},{"title":"【M1 Mac】React開発環境の構築","text":"React開発環境の構築方法をまとめます。 実行環境 以下の通りM1 MacでHomebrewをインストール済であることを前提としています。 ・ M1 Macbookpro ・ Homebrewはインストール済 大まかな流れ nodebrewのインストール node.jsのインストールと有効化 環境パスの設定 react開発環境の作成 nodebrewのインストール まずはHomebrewを使用してnodebrewをインストールします。 terminal1brew install nodebrew インストールが完了したらnodebrewのバージョンを確認しましょう。 terinal1nodebrew -v 以下のような出力が確認できたらOKです。 terminal1234567891011121314151617181920212223242526nodebrew 1.0.1Usage: nodebrew help Show this message nodebrew install &lt;version&gt; Download and install &lt;version&gt; (from binary) nodebrew compile &lt;version&gt; Download and install &lt;version&gt; (from source) nodebrew install-binary &lt;version&gt; Alias of `install` (For backword compatibility) nodebrew uninstall &lt;version&gt; Uninstall &lt;version&gt; nodebrew use &lt;version&gt; Use &lt;version&gt; nodebrew list List installed versions nodebrew ls Alias for `list` nodebrew ls-remote List remote versions nodebrew ls-all List remote and installed versions nodebrew alias &lt;key&gt; &lt;value&gt; Set alias nodebrew unalias &lt;key&gt; Remove alias nodebrew clean &lt;version&gt; | all Remove source file nodebrew selfupdate Update nodebrew nodebrew migrate-package &lt;version&gt; Install global NPM packages contained in &lt;version&gt; to current version nodebrew exec &lt;version&gt; -- &lt;command&gt; Execute &lt;command&gt; using specified &lt;version&gt;Example: # install nodebrew install v8.9.4 # use a specific version number nodebrew use v8.9.4 node.jsのインストールと有効化 node.jsをインストールする際は、LTSの推奨版（安定版）をインストールします。 terminal1nodebrew install-binary stable インストールされたnode.jsのバージョンを確認しましょう terminal1nodebrew ls 以下のようにcurrent: noneとなっている場合は、使用するバージョンを有効化します。 出力結果123v14.15.4current: none 指定したバージョンのnode.jsを有効化する際は以下のコマンドで有効化が可能です。ここでは、2021年1月時点で最新の安定バージョンであるv14.15.4を有効化します。 terminal1nodebrew use v14.15.4 有効化が完了しているか確認をします。 terminal1234nodebrew lsv14.15.4current: v14.15.4 これで完了です。 環境パスの設定 M1 Macのデフォルトターミナルであるzshでnodeコマンドが使えるように環境パスを設定します。 terminal1vim ~/.zprofile zprofileには以下を追記します。 ~/.zprofile1export PATH=$HOME/.nodebrew/current/bin:$PATH 完了したら以下のコマンドを実行して環境パスを読み込みます terminal1source ~/.zprofile nodeが使用できるか確認しましょう。 terminal1node -v 出力結果1v14.15.4 上記のようにv14.15.4と表示されればOKです。 react開発環境の作成 まずは任意の場所にフォルダを作成します。ここではUserの配下にreact-pjというフォルダを作成します。その後、作成したreact-pdフォルダに移動します。 terminal12mkdir react-pjcd react-pj react-pfフォルダに移動したら、以下のコマンドを実行し、react開発環境を実行します。react-appの箇所は任意の名前でOKです。 terminal1npx create-react-app react-app すると、react-appというフォルダが作成されます。このフォルダに移動し、npm startコマンドを実行します。 terminal12cd react-appnpm start すると以下の出力が現れます。 terminal1234567You can now view react-basic in the browser. Local: http://localhost:3000 On Your Network: http://192.168.158.15:3000Note that the development build is not optimized.To create a production build, use npm run build. 場合によっては、chromeにアクセスしてもよいかのポップアップが現れるので、OKを選択しましょう。 chromeなどのブラウザで、localhost:3000にアクセスすると、reactの最初の画面が現れるかと思います。 ReactとDjango REST Framework APIを学ぶ バックエンドエンジニアとしてフロントエンドの知識を学びつつ、Django REST Framework APIを学びたい方は、Udemyの[基礎編]React Hooks + Django REST Framework API でフルスタックWeb開発で学ぶのがおすすめです。 こちらの記事もあわせて読みましょう","link":"/react-getstart/"},{"title":"「子供を勉強させるにはどうすればいいの？」","text":"「うちの子供、全然勉強しないんだけど、どうすればいいかな？」 保育園や子供の習い事の送り迎えの立ち話で、こんなワードが出てきます。 そんな時は 親である貴方が勉強してないからじゃないの？というと大体納得する親が多い気がしました。 次に出てくるワードも大体見えていて、 「何を勉強すれば良いかな？」 or 「忙しくて勉強する暇がない」 なんですよね。 まず「何を勉強すれば良いかな？」という問いに対しては、 「好きな事というよりかは嫌いじゃない事が何かを整理して、続けられそうなトピックを勉強すれば良いのでは？」と答えます。 たぶん、勉強したいこと、やりたいこと、好きなこと、とかって、基本的になんとなく生活を送っていると、なかなかないものだと思います。 やりたいこと、とか、好きなこと、というのは、「自分ができること」の延長線上にあることが多い例えば、 野球ができる→野球の勉強したい、野球をもっとやりたい 料理ができる→栄養の勉強がしたい、サプリの勉強がしたい 運転ができる→レーサーになりたい、タクシーの運転手になりたい プログラミングができる→ITの仕事をしたい、プログラミングの勉強がしたい 気象予報士の資格を持っている→気象予報士になりたい 介護の資格を持っている→リハビリの勉強をしたい、介護の仕事をしたい という感じで、なんとなく始めた習い事とか学校で取った資格や学んだ知識の延長線上で、やりたいこととかを考えるのが一般的なのだと思います。 あの、東進ハイスクールの林先生も同様のことを言っています。※youtubeで検索すると出てくるかも。 なので、特にやりたいこととか好きなことが無い場合は、まずは、この「できる」という項目をとにかく増やす、という目的で、嫌いじゃないトピックを勉強すれば良いと思います。 私自身も、大学では化学を専門にしていましたが、就職先は、希望の化学系の部署に行けずにIT・通信関連の部署に配属になりました。 最初は何も分からなく挫折の毎日でしたが、プログラミングとかサーバの設定とかは、嫌いではなかったので地道に勉強していきました。 結果、「IT系の仕事で良かったな」と思っています。 言いたいこととしては、特にやりたいことがない、という人は、なんでも良いので嫌いじゃない領域を見つけて、勉強を始めてみるのが良いと思います。 「忙しくて勉強する暇がない」という人もいらっしゃると思います。 でもよくよく考えてみてください。 YoutubeやUdemy等、インターネットとスマホがあれば、いつでもどこでも好きなだけ学べる時代になった今、「忙しくて勉強する暇がない」といわれると、申し訳ないのですが「本当に？」と思ってしまうのです。 私自身も、子供の保育園の送り迎え等をしていますが、Udemyで数十個の講座を受講し、できることの幅を広げられています。学ぶことで、やりたいことが見つけられる、ということを信じて今すぐ勉強を始めてみるのはいかがでしょうか？ 世界最大級のオンライン学習サイトUdemy それでも「これ！」ってものがない場合のおすすめですが、私としては、これからは5Gの時代もやってくることも考えると、やはり動画の編集能力とか、需要が高くなる可能性が高いと思っています。 私もこれから、Udemyのキャンペーンのタイミングで以下の講座を受講して、動画の編集スキルを身に着けたいなとおもっているところです。 業界最先端の動画制作テクニックを制覇！Adobe Premiere Pro オンライン講座 少し値は張るかもしれませんが、以下のMovieHacksも良いと思います。Skill Hacksがとても良かったので、信頼度高めです。 -Movie Hacks- YouTubeに特化した動画編集講座 おしまい","link":"/study-for-child/"},{"title":"Swagger EditorをDockerで動かす方法","text":"✓目次 この記事の対象者 Swaggerとは 1. Swagger Editor 2. Swagger Codegen 3. Swagger UI Dockerを使って起動してみよう Docker Playgroundで環境構築 この記事の対象者 ・ Swaggerとは何なのかを知りたい人 ・ Swagger Editorを使う環境をDockerを用いて構築したい人 Swaggerとは SwaggerはOpen APIを作成、表示、利用するツール郡です。Open APIとは、WSDLやXMLと比較されるようなフォーマットを意味します。Open APIのフォーマットは、JSONまたはYAML形式になります。 Swaggerは”ツール郡”という通り、様々な機能を有しております。主に以下の3つの機能です。 1. Swagger Editor 2. Swagger Codegen 3. Swagger UI 1. Swagger EditorEditorという名前の通り、Open APIを記述するエディタです。YAMLやJSONで記述します。 2. Swagger CodegenSwagger Editorで作成されたOpen APIを読み取ってスタブであったり、クライアントのソースコードを生成してくれるツールです。 スタブというのは、REST APIのリクエストに対するレスポンスが期待通りの値を返してくれるかをテストするためのモジュールを指します。 3. Swagger UISwagger UIはOpen APIの仕様書を読み取って、綺麗なWebページとして見える化してくれるツールです。 Dockerを使って起動してみよう Swaggerというのがなんとなくわかったところで早速動かしてみましょう。 まずはDockerをインストールしておきましょう。もしDocker環境が無ければ、Docker Playgroundでも試すことができます。以降は、Docker Playgroundを使った方法を紹介します。 Docker Playgroundで環境構築 ブラウザを立ち上げる 「Docker Playground」と検索 DockerHubのアカウントが必要になります。DockerHubのIDとパスワードを持っていなければ発行してログインしてください。 「Add new Instans」という項目をクリック。以下のように、Dockerが使える環境が整います。 コマンドを入力してSwagger Editorを導入しましょう。 コマンドは、docker run -d -p 80:8080 --name editor [コンテナ名:タグ名]という感じです。 コンテナ名は、DockerHubで確認をします。「swagger editor docker hub」と検索しましょう。Swagger Editorのdockerコンテナ名が以下のように把握することができます。この場合だと、swaggerapi/swagger-editorがコンテナ名になります。 次に、タグ名を調べます。DockerHubのTagsをクリック。 以下の通り、v3.11.7であることが分かります。 以上より、以下のコマンドを入力すれば良いことが分かります docker run -d -p 80:8080 --name editor swaggerapi/swagger-editor 注意：80番ポート以外だと、Swagger Codegenが動作しません このコマンドをDocker Playgroundに張り付けて実行します。 Docker Playgroundの場合、ポートを公開すると画面の上部のOpen Portのところに解放されたポート番号が表示されます。これをクリックします。 これでSwagger Editorが起動します。 そもそもDockerって何？という方 以下の記事で、Dockerとは何かをメリット/デメリットを共に解説してますので、こちらを参照ください。","link":"/swagger-get-start/"},{"title":"Gitリポジトリを用いてSwaggerを起動する方法","text":"✓目次 この記事の対象者 導入手順 この記事の対象者 ・ ローカル環境でSwagger Editorを起動させたい人 Visual Studio CodeにSwagger viewerを導入したい人はこちらの記事を参照ください。 Dockerを用いてSwaggerを導入したい人はこちらの記事を参照ください。 導入手順 まずブラウザを立ち上げ、Google検索で「github swagger editor」と検索しましょう。 検索結果の一番上に表示されるリンク「GitHub - swagger-api/swagger-editor: Swagger Editor」をクリック。 以下の「Releases」をクリック タグが付与されたSwagger Editorのリリース情報一覧が表示されます。最新バージョンのSwagger EditorのSource code(zip)をダウンロード ダウンロードしたzipファイルを解凍し、フォルダを開く。 index.htmlファイルが存在するので、これをブラウザにドラック&amp;ドロップ Gitに使い慣れている人は、任意のフォルダでgit cloneコマンドを入力して直接落とすことも可能です。 git clone https://github.com/swagger-api/swagger-editor.git","link":"/swagger-git/"},{"title":"Visual Studio CodeでSwagger viewerを導入する方法","text":"✓目次 この記事の対象者 導入手順 この記事の対象者 ・ Visual Studio Codeを使っている人 ・ Swagger EditorをVisual Studio Codeで使いたい人 導入手順 まずはVisual Studio Codeをインストールしましょう。インストール方法は以下の記事を参照ください。 Visual Studio Codeを起動し、左側の拡張機能をクリックし、”Swagger viewer”と検索窓に入力して検索しましょう。 Swagger viewerが表れるので、インストールを実施。 インストールが完了したら、Visual Studio Codeを再起動しましょう。これでインストール完了です。 Openapi specのサンプルをVisual Studio Codeに記述しましょう。Visual Studio Code上で新しいファイルを作成します。openapi.yaml等任意のファイル名でOKです。 新規作成したyamlファイルに、以下の、Open API Spec v3.0のPetStore.yamlをコピペしてください。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111openapi: \"3.0.0\"info: version: 1.0.0 title: Swagger Petstore license: name: MITservers: - url: http://petstore.swagger.io/v1paths: /pets: get: summary: List all pets operationId: listPets tags: - pets parameters: - name: limit in: query description: How many items to return at one time (max 100) required: false schema: type: integer format: int32 responses: '200': description: A paged array of pets headers: x-next: description: A link to the next page of responses schema: type: string content: application/json: schema: $ref: \"#/components/schemas/Pets\" default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\" post: summary: Create a pet operationId: createPets tags: - pets responses: '201': description: Null response default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\" /pets/{petId}: get: summary: Info for a specific pet operationId: showPetById tags: - pets parameters: - name: petId in: path required: true description: The id of the pet to retrieve schema: type: string responses: '200': description: Expected response to a valid request content: application/json: schema: $ref: \"#/components/schemas/Pet\" default: description: unexpected error content: application/json: schema: $ref: \"#/components/schemas/Error\"components: schemas: Pet: type: object required: - id - name properties: id: type: integer format: int64 name: type: string tag: type: string Pets: type: array items: $ref: \"#/components/schemas/Pet\" Error: type: object required: - code - message properties: code: type: integer format: int32 message: type: string 次にSwagger Viewerを起動します。Shift + Alt + Pの3つのキーを押下してください。するとVisual Studio Codeの右側に、Swagger UIが表示されます。 Swaggerを使ったREST APIの設計方法について Swaggerを用いてREST APIの設計書を作成する方法は、以下のUdemy講座を確認ください。30日以内であれば、無料（返金保証付き）です。 【視聴期限無し】UdemyでSwaggerを学ぶ【30日間返金保証付き】 関連書籍 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Web APIの設計\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/61GK-dw0hDL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08CK2H12H\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08CK2H12H\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Web%20API%E3%81%AE%E8%A8%AD%E8%A8%88\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"PqRZq\",\"s\":\"s\"}); リンク 関連記事 Dockerを用いてSwagger Editorを動作させる方法もまとめています。 REST APIを設計する際に気を付けるべき主なポイントを以下の記事にまとめています。","link":"/visualstudiocode-swagge-viewer/"},{"title":"Visual Studio Codeをインストールし、ターミナルをGit bashに変更する手順","text":"✓目次 Visual Studio Codeのインストール Visual Studio Codeの表記を日本語にする フォントサイズやデザインを変えたいとき Git for windows VScodeのターミナルをGit for Windowsのbashにする 参考 Visual Studio Codeのインストール マイクロソフトが開発したエディタ。Googleで検索してダウンロード。 ダウンロードされたファイルをダブルクリック。Visual Studio Codeセットアップウィザードが開く。 「次へ」を押下 ライセンスを確認して「同意」を押下 インストール先はそのままでOK。「次へ」を押下。 追加タスクの選択のパートで以下の項目に✓をいれて「次へ」を押下。これらにチェックを入れておくと便利。 「エクスプローラーのファイルコンテキストメニューに[Codeで開く]アクションを追加する」 「エクスプローラーのディレクトリコンテキストメニューに[Codeで開く]アクションを追加する」 「サポートされているファイルの種類のエディターとして、Codeを登録する」 「インストール」を押下。 Visual Studio Codeの表記を日本語にする Visual Studio Codeを開き、左側のメニューのExtentionを押下 検索窓に「japanese」と入力し、パッケージを選択して「install」を押下してインストールする VScodeの右下に、以下が出力される。再起動が必要です、ということなので「Restart now」を押下 日本語に変化！ フォントサイズやデザインを変えたいとき ファイル→基本設定→設定、を押下。 ここでフォントサイズを変更する。（お好みで） ファイル→基本設定→配色テーマ ここで見た目の配色を変更できる。 Git for windows ここからはターミナルをGit bashに変えたい人向けの設定です。 ダウンロードする Git for Windows インストールを実行。 改行コードの設定に注意する 仮想マシンからファイルを利用することが想定される場合は、仮想マシン側がUnixスタイルになっている。 ダウンロードしたファイルがUnixスタイルにしておく必要がある。 windows環境の git で改行コードの自動変換に注意 - Qiita VScodeのターミナルをGit for Windowsのbashにする 以下の記事が参考になります WindowsのVSCodeでGit Bashをターミナルに設定する - Qiita インストール後の作業 ~/.bashrcをexport TERM=cygwinを設定する Vagrantファイルの言語モードをRubyに設定する場合は、以下のように設定する。 色分けされるので見やすくなる VScodeのsettingを開き、検索画面でfiles.associationsと入力 jsonファイルの編集画面を開き下記のように書き換える Ctrl + s で保存 123456789{ \"terminal.integrated.shell.windows\": \"C:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\" \"files.associations\": { \"Vagrantfile\": \"ruby\" }} 参考 プログラミング学習についてまとめてみました。 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/vscode-environment-with-gitbash/"},{"title":"Twitter APIの登録と利用開始までの流れ","text":"意外と煩雑なTwitter APIを使い始めるまでの流れをまとめます。 自己紹介 omathin ・IT企業のアーキテクト|研究者. ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得・Twitterもやっているのでフォローお願いします！ ✓目次 Twitter APIの利用開始に必要なもの Twitter APIの利用開始までの流れ Twitter APIの利用開始に必要なもの ・携帯電話の番号 ・メールアドレス ・Twitterアカウント Twitter APIの利用開始までの流れ Twitter APIの登録は、TwitterのDeveloperページで行います。 右上の「Apply」をクリック Apply for Accessの画面でApply for a developer accountをクリック Twitter APIの利用目的の選択画面に遷移します。自身の利用目的に即した項目を選択してください。 ユーザ情報の登録を行います。この際、Twitterに電話番号の登録が必要になります。電話番号の登録をアカウントにしておきましょう。電話番号の登録が完了すると携帯電話に認証コードが送られます。認証コードを入力し電話番号の登録を完了させます。 Developer pageでアカウントの登録等が完了したらNextをクリック 所属組織、チーム名を記載しましょう。ツイッターのusernameなどの記述も行います。個人で利用する場合は、Individualを選択すれば所属組織の入力は省略できます。 所属組織の組織の国を入力。組織のカテゴリを入力。サービス分野も記載。「Do you or will you have customers?」にYesかNoを回答。個人利用で顧客もいなければNoで良いと思います。 Twitter APIとデータの使い方の説明文を入力する。英文で200文字以上の入力が必要となります。日本語で説明文を記述しDeepLに投入してコピペで問題有りません。 データ解析のやり方について記述が求められます。これもDeepLを用いて記述しましょう。「Are you planning to analyze Twitter data?」にてYes or Noを選択します。Twitter APIのデータと用いて分析する場合はYESを選択しましょう。 Will your app use Twiit, Retweet, like, follow, or Direct Message functionality?はYES.Please describe your planned use of these featuresにDeepLを用いて英文を記述します。投稿やリツイートなどの機能の使い方を素直に説明しましょう。 Twitter外でのTweetデータの表示についてYES or Noを選択。どのようにどこでデータを示すのかを記述します。研修で使うとか、デモで使うなどの記述をすればOKです。 政府機関におけるデータの利用有無についてYES or NOで回答します。NEXTをクリック。 入力の確認。問題なければLooks Goodをクリック Developer Agreementをチェックして、OKをクリック。 問題なく完了すると、登録したメールアドレス当てに以下のようなメールが届きます。私の場合はすぐに通知が来ましたが人によっては審査が入り１時間位かかるかもしれないようです。 送られてきたメールを利用しているPCで開き、「Confirm your email」をクリック。すると、Dashcoardの画面に遷移します。 左側のメニューバーにある「Overview」を選択し、「Create App」をクリックします。アプリの名前は後から変えられるので何でもOKです。 API keyやAPI key secret等が表示されるので、メモしておきましょう。 Overviewで作成したアプリを選択し、Settingsタブを選択。App permissionsのEditをクリック。読み込みと書き込みを両方許容する場合は、「Read and Write」を選択。 これでTwitter APIの利用開始準備完了です! Twitter APIを活用したアプリ開発したい方へ より詳しくTwitter APIを利用したアプリケーション開発手法を知りたい方は、人工知能（AI）を搭載したTwitterボットを作ろう【Seq2Seq+Attention+Colab】というUdemy講座がおすすめです。","link":"/twitter-api-getstart/"},{"title":"【自然言語処理】Transformerとは何か","text":"✓目次 この記事の対象者 Transformerとは TransformerのEncoderの構造 TransformerのDecoderの構造 まとめ この記事の対象者 ・ ニューラルネットワークの基本的な仕組みを理解している方 ・ RNNやLSTM、Seq2Seqを活用した自然言語処理に関する知識（one-hot表現、分散処理など）を理解している人 RNNの基礎については以下の記事でまとめているので参照してください。 RNNの基礎を学びたい方はこちら↓ Transformerとはディープラーニングモデルの一つで、主に自然言語処理の分野で使用されます。 自然言語処理などの時系列データを処理するように設計されてますが、RNNで用いる再帰を用いていません。 ではどのような仕組みなのかというと、大きくはEncoderとDecorderの２つで構成されています。 もう一つの特徴としては、Attention層のみで構築されています。 以降、EncoderとDecoderに分けて、その構造を解説したいと思います。 TransformerのEncoderの構造Encoderでは、Embedding層により入力文章をベクトルに圧縮変換をしています。要するに、自然言語で記述された文章を、単語の分散表現で一定の次元に変換したベクトルに変換をしています。これを、埋め込みベクトル、といいます。 そして、Positional Encodingによって、単語が文章中のどの位置にあるかの位置情報を加えています。 Multi-Head Attention層とは、その名の通り複数のAttentionが並んでいる領域であり、ここで入力で与えられた各単語との関連度を計算しています。Attentionについては、以下の記事で詳しくまとめていますので、こちらを参照ください。 Add &amp; Normという箇所は、Normalization(正規化)などであり、要はデータの偏りを無くす処理を行っています。 Feed Forwardという部分は、Positionwise fully connected feed-forward networkというものであり、２つの層からなる全結合ニューラルネットワークです。 具体的には、２つの層からなるニューラルネットワークでは、まず入力に重みを掛けてバイアスを足し、活性化関数のReLUに入れる処理を行っています。つまり、0より小さければすべて0にし、0より大きければそのままの値を出力しています。これに重みを掛けて、さらにバイアスを足す、という２層構造のニューラルネットワークになっています。 ちなみにこれらは、単語毎に個別の順伝播を行うニューラルネットワークになっています。こうすることで、他の単語との影響関係を排除することができるのです。 そして再びadd &amp; Normで正規化を行っています。 そして、Multi-Head AttentionとFeed Forwardの箇所は、6回処理が繰り返し行われます。 TransformerのDecoderの構造まず、Embedding層で、入力文章をベクトルに圧縮します。その後、Positional Encoding層によって位置情報を加えています。このあたりは、Encoderと同じです。 そして、Masked Multi-Head Attention層というのが現れます。これもAttentionの一種です。ここでは、特定のKeyに対してAttention weightを0にする処理が行われます。これを行うことで入力した単語の先読みを、すなわち「カンニング」が行われてしまうことを防いでいるのです。この処理を行わないと、入力に基づいて学習が行われてしまい、未知のデータに対して正しく予測することができなくなってしまいます。 Masked Multi-Head Attentionの後、正規化を行い、Multi-Head Attention層に入ります。ここで、Encoderからの出力を受け付けています。Decoderからの流れと、Encoderからの流れがここで合流しています。 そして正規化を行い、次はPositionwise fully connected fedd-forward networkで処理されます。その後、再び正規化が行われています。 最後に、全結合層であるLinearがあり、Softmax関数で値の範囲を0から1の範囲に収めています。 まとめ Transformerとは、 ディープラーニングモデルの一つで、主に自然言語処理の分野で使される。 自然言語処理などの時系列データを処理するように設計されている。しかし、RNNで取り入れている再帰を用いていません。 構造としては、EncoderとDecoderの２つで構成されています。 参考文献 Attention is All You Need, Ashish. V. et al, (2017) 技術ブログ | アクセルユニバース株式会社 より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら","link":"/what-is-transformer/"},{"title":"【自然言語処理】ファインチューニング(Fine-Tuning)とは何か","text":"✓目次 ファインチューニング(Fine-Tuning)とは ファインチューニングのメリット メリット1: データが不足した領域への適用を可能にする メリット2: 学習時間の短縮 メリット3: 既存の優れたモデルを利用できる まとめ ファインチューニング(Fine-Tuning)とはファインチューニングとは、訓練済のモデルを各タスクに合わせて調整するように訓練することです。 転移学習という言い方もします。大まかな例えでいうと、 - 工場Aには学習済のモデルがある - 工場Bにはモデルがない - 工場Bでも同じことができるようにしたい といった場合は、工場Aのモデルを転用することを考えます。 最初の時点で既存のモデルを適用し、そのモデルに対して訓練させたいデータ(例：自然言語処理であれば文章など)を与え、訓練をさせて、新たなモデルを作る処理がファインチューニングになります。 ファインチューニングにおいて、既存の学習済モデルは、「特徴抽出器」として用いられ、パラメータの更新はされません。 出力側に追加した層のパラメータが更新され、学習が行われる形式です。 すなわち、既存の学習済のモデルに、新しく層を追加して、その追加した層のパラメータを更新することで、ファインチューニングにおける学習が行われます。 ファインチューニングのメリットここからはファインチューニングのメリットについていくつかまとめていきます。 メリット1: データが不足した領域への適用を可能にする学習や訓練にはデータが必要になりますが、必ずしも十分なデータを用意できるとは限りません。また、実験回数を多く重ねることが難しい領域も多く存在します。 そんなときは、すでに多くのデータを用いて学習させたモデルを活用するのが有効かと思います。 ある領域で訓練したモデルというのは、実は別の領域に適用可能となるケースは多くあります。 複数のタスクにおいて共通的に捉えるべき特徴というのが存在し、少しだけ調整するだけで適用できたりします。 メリット2: 学習時間の短縮既存の学習モデルを特徴抽出することで学習時間を短縮させることができます。 先でも述べましたが、捉えるべき特徴については共通部分が存在し、それを使い回すことで学習時間を短縮することができます。 メリット3: 既存の優れたモデルを利用できる世の中には、膨大なデータを用いて、たくさんの試行錯誤により確立された既存モデルがアップロードされています。 それらを簡単にダウンロードして利用することができる仕組みになっています。 最初からモデルを構築していくのではなく、既存の学習済のモデルを活用して、自ら最適化されたモデルを構築していくという方法を取ることで、効率化が図れるのです。 まとめ ファインチューニングとは、 訓練済のモデルを各タスクに合わせて調整するように訓練すること ファインチューニングのメリットは、 データが不足した領域への適用を可能にする 学習時間の短縮 既存の優れたモデルを利用できる より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら Seq2seqを活用してAIチャットボットを学びたい方は必見です！ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/what-is-fine-tuning/"},{"title":"【自然言語処理】word2vecとは何か？CBOWとskip-gramも解説","text":"本記事では、word2vecというものについてまとめてみます。 ✓目次 word2vecは言葉をベクトル化するツール CBOW(Continuous bag-of-words)とは skip-gramとは CBOWとskip-gramの比較 word2vecは言葉をベクトル化するツールword2vecは、分散表現を作成することができるツールです。 word2vecを活用すると、言語をベクトル化することができます。 ベクトル化することにより、定量的に単語同士がどれだけ似ているかを算出したり、数値計算のように、言葉を合成させたり、言葉を削除したりする、みたいなのができるようになります。 word2vecでは、下記2つのいずれかのニューラルネットワークが用いられます CBOW(continuous bag-of-words) skip-gram そもそも、ニューラルネットワークとは何か、という方は、以下のUdemyのコースがおすすめです。※セールの時期は1000円前後で購入できます。 【視聴期限なし】現場で使えるChainerによるディープラーニング入門【30日間返金保証付き】 CBOW(Continuous bag-of-words)とはCBOWとは、前後の単語から対象の単語を予想するニューラルネットワークです。 イメージレベルですが概略は以下のような具合です。 入力層、中間層、出力層があり、入力層と中間層の間と中間層と出力層の間に、重みが存在します。 図1において、青い長方形は、one-hot表現という単語を0と1からなるベクトルで表現されたものが当てはまります。 one-hot表現を「となりのととろ」という文章を例にあらわしてみると、以下のようになります。 「となり」、「の」、「ととろ」という風に単語ごとにIDが割り振られます。 one-hot表現は、該当する単語が位置している箇所を「1」と表して表現します。各単語に割り当てられたIDで表現されるのではなく、あくまでもテーブル表の列の位置で表されている点がポイントです。 そして、one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができるのです。 続いて図1において、黄色の長方形は分散表現というベクトルで表現されたものが当てはまります。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法です。 200個、のようにたくさんの値の個数で表現されていることを、高次元である、というので、分散表現をかっこよく説明したければ、「単語を高次元の実数ベクトルで表現する技術」と言えばよいです。 具体的なイメージは以下の通りです。 図3では、「男」、「東京」、「Ruby」という3つの単語があります。 これらは全く異なる単語なので、ベクトルは似ていません。もし、単語の類似度や関連性が高ければ、これらの単語同士の分散表現は、似たものになります。 この分散表現を活用すると、どのようなことができるかというと、例えば、 「王様」ー「男性」＋「女性」=「お姫様」 という風に、単語同士の足し算や引き算が可能になり、かつ、類似度の高い単語を見つけることができます。 次に、オレンジ色の長方形は重みを表す行列です。 重みを表す行列とは、例えば、「となりのととろ」の真ん中の単語の「の」を予測できるように学習させた後に生成される、各単語の分散表現が並んだ行列です。 以上のように、CBOWは前後の単語から対象の単語を予測するようにして分散表現を作成するものです。 skip-gramとはskip-gramとは、ある単語から前後の単語を予測するニューラルネットワークです。 CBOWとの違いは、入力が中央の単語で、出力がその前後の単語である点です。 そのため、CBOWとは逆に、中央の単語からその周囲の単語を予測するように学習が行われます。 skip-gramにおいても、CBOWと同様に学習によって、入力層と中間層の重みの行列は、分散表現のベクトルが並んだ行列になります。 CBOWとskip-gramの比較この辺は別記事で実際に比較評価をしてみようと思います。 一般論としては、CBOWよりもskip-gram方が、学習に時間がかかるが精度がよい、とされているようです。 以下に記事にて、Word2Vecの実装方法をまとめております。実際にpythonを使って実装し、CBOWとskip-gramの比較検証をしてみてください。 自然言語処理を学びたい人へ 以下の、30日間返金保証付きのUdemyの講座を確認ください。30日以内であれば、無料(返金保証付き)です。 【視聴期限なし】自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発【30日間返金保証付き】 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 参考にした記事等 分散表現(単語埋め込み) - 岩波データサイエンス [自然言語処理/NLP] Word2Vec触ったので備忘録としてざっくりまとめておく (理論編) | Developers.IO Word2Vecを理解する - Qiita 【まとめ】自然言語処理における単語分散表現（単語ベクトル）と文書分散表現（文書ベクトル） - Qiita","link":"/word2vec-overview/"},{"title":"【解説】手を動かしながらカウント(len関数、uniqueメソッド)を学ぶ | データサイエンス100本ノック【問21〜問22 回答】","text":"目次 この記事の対象者 本記事で学ぶpythonのメソッド リストの数や文字列の長さを数えるlen()関数 重複を除いた件数(ユニーク件数)を数えるunique()メソッド 実際に手を動かしながらlen()とunique()を使ってみよう 第21問目: len関数 第22問目: unique()メソッド まとめ: len関数とuniqueメソッドを使えるようになりました。 この記事の対象者 ・ データサイエンティストを目指している人 本記事で学ぶpythonのメソッド 本記事では以下3つのメソッドを学びます リストの数や文字列の長さを数える関数 重複を除いた件数（ユニーク件数）を数えるメソッド 以降それぞれの内容についてまとめていきます。 リストの数や文字列の長さを数えるlen()関数len()関数はオブジェクトの長さや要素の数を取得するときに使用します。 len()関数の引数には、str型とlist型を使うことが出来ますが、int型、floot型、bool型などは使用できません。 len()の使い方12len(&quot;python&quot;) # 「6」と出力されるlen([1, 2, 3]) # 「3」と出力される 重複を除いた件数(ユニーク件数)を数えるunique()メソッド重複を除いた件数であるユニーク件数を数えるメソッドは、unique()と書きます。 例えば、以下のようなデータフレームがあったとします。 column 1 column 2 1 12 a 2 3 b 3 46 a 4 61 b このデータフレームのcolumn 2に対してユニーク件数を調べるとします。 要素の数自体は4つありますが、存在するアルファベットは2つなので、ユニーク数は2となります。 注意しなければならないのは、unique()メソッドはDataFrame単体には使えないということです。 つまり、2次元のデータに対してunique()メソッドは使うことが出来ないということです。 データフレーム、二次元のデータ、という言葉が「？」という方のために、改めてPandasにおける基本的なデータ構造についておさらいします。 Pnadasには、SeriesとDataFrameという2種類のデータ構造が存在します。 主に使われるデータ構造は2次元のデーブルで表されるDataFrameで、横方向のデータを行、縦方向のデータを列と呼びます。 各行、各列に対してそれぞれラベルが付けられており、行ラベルはインデックス、列ラベルはカラムといいます。 Seriesは1次元の配列で、DataFrameの行または列として捉えることができます。 こちらも同様にラベルが付いています。 実際に手を動かしながらlen()とunique()を使ってみよう 実際にlen()とunique()を使ってみましょう。 以降は、一般社団法人データサイエンティスト協会がGitHubに公開している「データサイエンス100本ノック」の21問目〜22問目を題材にしています。 データサイエンス100本ノックの環境構築方法は以下の記事にまとめていますので、こちらを参照してください 第21問目: len関数 P-021: レシート明細データフレーム（df_receipt）に対し、件数をカウントせよ。 まずは、レシート明細データフレーム(df_receipt)の全体像を確認しましょう。 1df_receipt 出力12345678910111213sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...104676 20180221 1519171200 S13043 1132 2 ZZ000000000000 P050101001 1 40104677 20190911 1568160000 S14047 1132 2 ZZ000000000000 P071006005 1 218104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 148104680 20190423 1555977600 S13016 1102 2 ZZ000000000000 P050601001 1 138 以下のようにlen関数を用いて、レシート明細データフレーム(df_receipt)の件数をカウントすることができます。 1len(df_receipt) 出力1104681 第22問目: unique()メソッド P-022: レシート明細データフレーム（df_receipt）の顧客ID（customer_id）に対し、ユニーク件数をカウントせよ。 問題の記述通りcustomer_idを列指定しましょう。 1df_receipt[[&quot;customerid&quot;]] 出力1234567891011121314customer_id0 CS0062140000011 CS0084150000972 CS0284140000143 ZZ0000000000004 CS025415000050... ...104676 ZZ000000000000104677 ZZ000000000000104678 CS040513000195104679 CS002513000049104680 ZZ000000000000104681 rows × 1 columns len関数を用いて件数を確認します。 1len(df_receipt[[&quot;customer_id&quot;]]) 出力1104681 ここで、unique()メソッドを使って、ユニーク件数をカウントします。 1len(df_receipt[[&quot;customer_id&quot;]].unique()) 以下のようなエラーが出力されるかと思います。 出力12345678910111213---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-75-317f9e4b944f&gt; in &lt;module&gt;----&gt; 1 len(df_receipt[[&quot;customer_id&quot;]].unique())/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py in __getattr__(self, name) 5460 if self._info_axis._can_hold_identifiers_and_holds_name(name): 5461 return self[name]-&gt; 5462 return object.__getattribute__(self, name) 5463 5464 def __setattr__(self, name: str, value) -&gt; None:AttributeError: 'DataFrame' object has no attribute 'unique' Dataframeオブジェクトには、uniqueメソッドは使えません、というエラーであることが分かります。 つまり、データが二次元([[]]というふうに二重リスト)になっているから、uniqueメソッドが使えないということになります。 なので、DataFrameのcustomer_id列の一次元配列であることを明示的に示すために、[]を１つ外します。 1len(df_receipt[&quot;customer_id&quot;].unique()) こうすることで、以下のようにユニーク件数を出力することが出来ます。 出力18307 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: len関数とuniqueメソッドを使えるようになりました。本記事は、【Python】手を動かしながらカウントを学ぶ | データサイエンス100本ノック【問21〜問22 回答】というテーマでまとめました。 uniqueメソッドは、二次元配列では使用できず、1次元配列でのみ使用できる点に注意しましょう。 &gt;&gt; 続きはこちら","link":"/100knock-21-22/"},{"title":"【解説】標本分散、標本標準偏差、パーセンタイル値、平均の表示方法を学ぶ | データサイエンス100本ノック【問30〜問33 回答】","text":"目次 この記事の対象者 第30問目: 標本分散 第31問目: 標本標準偏差 第32問目: パーセンタイル値 第33問目: 平均値の計算 まとめ: 標本分散、標本標準偏差、パーセンタイル値、平均値の計算を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで標本分散、標本標準偏差、パーセンタイル値、平均の表示方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、標本分散、標本標準偏差、パーセンタイル値、平均の表示方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第30問目: 標本分散 P-030: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）の標本分散を計算し、降順でTOP5を表示せよ。 標本分散とは、値のばらつき具合を表す指標であり、平均値との差を2乗して平均をとった値になります。 n子の標本x1, x2, …., xnがあり、その平均値を$\\bar{X}$としたとき、標本分散は次のように求められます。 s^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{X}\\right)^{2}標本分散を求めるためにはvarメソッドを使用します。 引数にddof=0を指定することで、標本分散の計算が可能となります。 それでは実際に問題をときながら使い方を学びましょう。 groupbyメソッドでstore_cdをグルーピングした後、amountカラムを抽出し、varメソッドを使用して標本分散を表示します。 1df_receipt.groupby('store_cd').amount.var(ddof=0) 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354store_cdS12007 199878.572908S12013 221059.615563S12014 200946.440113S12029 194078.594456S12030 185542.898104S13001 295431.993329S13002 242059.930949S13003 231834.539236S13004 226455.728493S13005 215435.376538S13008 227235.505306S13009 251489.424870S13015 295294.361116S13016 253452.683072S13017 234753.973479S13018 203451.893003S13019 213341.443915S13020 220908.207476S13031 202691.947134S13032 201224.407848S13035 277995.278909S13037 194914.825343S13038 212083.104690S13039 192184.721032S13041 219580.092539S13043 221157.560674S13044 189597.952968S13051 205374.495312S13052 440088.701311S14006 234499.584787S14010 258454.256075S14011 306314.558164S14012 197658.564411S14021 254009.419689S14022 249962.529667S14023 237506.764336S14024 225465.703516S14025 198167.977160S14026 232049.175817S14027 214589.332709S14028 224943.573036S14033 210995.918401S14034 296920.081011S14036 230690.599933S14040 223042.093872S14042 172061.187082S14045 266450.744884S14046 264262.537937S14047 221985.136499S14048 245204.120332S14049 180361.837396S14050 157698.130359Name: amount, dtype: float64 store_ceごとの売上金額(amount)の標準分散を出力できました。 あとは、reset_indexメソッドでindexを付与し、降順でTOP5を出力しましょう。 1df_receipt.groupby('store_cd').amount.var(ddof=0).reset_index().sort_values('amount', ascending=False).head(5) 出力1234567store_cd amount28 S13052 440088.70131131 S14011 306314.55816442 S14034 296920.0810115 S13001 295431.99332912 S13015 295294.361116 これで完了です。 第31問目: 標本標準偏差 P-031: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）の標本標準偏差を計算し、降順でTOP5を表示せよ。 解き方については、第30問目とほぼ同様で、標本標準偏差を出力する点のみが異なります。 標準偏差とは、分散の平方根を取った値であり、分散と同様に、値のばらつき具合の指標になります。 標準偏差は、単位の次元が元の値と同じなので、値の散らばり具合を直感的に表現するのに適しています。 標準偏差は、stdメソッドで計算することが出来ます。ddof=0を引数で指定することで、標本標準偏差を計算することができます。 それでは早速問題を解いていきましょう。 これまでのやり方の通りgroupbyメソッドを用いてstore_cdをグルーピングして、amountカラムを指定し標本標準偏差を計算しましょう。 1df_receipt.groupby('store_cd').amount.std(ddof=0) 出力12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455store_cdS12007 447.077815S12013 470.169773S12014 448.270499S12029 440.543522S12030 430.746907S13001 543.536561S13002 491.995865S13003 481.491993S13004 475.873648S13005 464.150166S13008 476.692254S13009 501.487213S13015 543.409938S13016 503.440844S13017 484.514162S13018 451.056419S13019 461.888995S13020 470.008731S13031 450.213224S13032 448.580436S13035 527.252576S13037 441.491591S13038 460.524814S13039 438.388778S13041 468.593739S13043 470.273921S13044 435.428471S13051 453.182629S13052 663.391816S14006 484.251572S14010 508.383965S14011 553.456916S14012 444.588084S14021 503.993472S14022 499.962528S14023 487.346657S14024 474.832290S14025 445.160620S14026 481.714828S14027 463.237879S14028 474.282166S14033 459.342920S14034 544.903736S14036 480.302613S14040 472.273325S14042 414.802588S14045 516.188672S14046 514.064722S14047 471.152986S14048 495.180897S14049 424.690284S14050 397.112239Name: amount, dtype: float64 いつもどおり、indexが失われているのでreset_indexメソッドでindexを付与し、降順にソートさせ先頭の５件を表示させましょう。 1df_receipt.groupby('store_cd').amount.std(ddof=0).reset_index().sort_values('amount', ascending=False).head(5) 出力123456 store_cd amount28 S13052 663.39181631 S14011 553.45691642 S14034 544.9037365 S13001 543.53656112 S13015 543.409938 これで完成です。 第32問目: パーセンタイル値 P-032: レシート明細データフレーム（df_receipt）の売上金額（amount）について、25％刻みでパーセンタイル値を求めよ。 パーセンタイル値とは、ある列のデータを昇順に並び替え全体を100%としたとき、任意の％の位置にある値を指します。 例えば、[1, 3, 5, 8, 18, 22, 31, 45, 67, 72, 87, 100]という昇順に並び替えられたリストがあったとします。 100%のパーセンタイル値は、最大値になるので100となります。 50%のパーセンタイル値は、中央値を求めることになるので、(22 + 31)/2 = 26.5となります。 Pythonでパーセンタイツ値を求める関数は、numpyのpercentileになります。 percentile関数は、第一引数にデータ、第二引数に求めたいパーセンタイル値のリストを指定します。 問題を解きながら使い方を学びましょう。 以下の通り、percentile関数を使用します。 1np.percentile(df_receipt['amount'], q=[25, 50, 75, 100]) 出力1array([ 102., 170., 288., 10925.]) これでOKです。 第33問目: 平均値の計算 P-033: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）の平均を計算し、330以上のものを抽出せよ。 平均値を求めるには、meanメソッドを使用します。 早速問題を解きながらmeanメソッドの使い方を学びましょう。 これまで学んできたとおりgroupbyメソッドを使用してstore_cdをグルーピングします。その上で、amountカラムの平均値を表示します。 1df_receipt.groupby(&quot;store_cd&quot;).amount.mean() 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354store_cdS12007 307.688343S12013 330.194130S12014 310.830261S12029 315.623908S12030 288.533727S13001 348.470386S13002 313.445736S13003 350.915519S13004 330.943949S13005 316.202811S13008 327.912480S13009 328.141988S13015 351.111960S13016 329.639950S13017 317.581070S13018 312.464427S13019 330.208616S13020 337.879932S13031 307.879634S13032 321.472550S13035 324.804446S13037 299.907832S13038 306.478167S13039 310.918699S13041 329.234177S13043 318.125000S13044 304.718549S13051 309.659942S13052 402.867470S14006 315.136605S14010 348.791262S14011 335.718333S14012 303.027754S14021 314.953174S14022 321.643457S14023 325.561521S14024 308.213897S14025 319.079814S14026 332.340588S14027 314.918466S14028 324.317244S14033 321.506206S14034 326.350974S14036 322.811410S14040 318.447368S14042 278.338886S14045 330.082073S14046 309.098127S14047 330.077073S14048 308.257895S14049 297.816774S14050 290.591304Name: amount, dtype: float64 indexが失われているのでreset_indexメソッドを使用してindexを作成し、queryメソッドを用いてamountが330以上のレコードを出力します。 1df_receipt.groupby(&quot;store_cd&quot;).amount.mean().reset_index().query('amount&gt;=330') 出力1234567891011121314 store_cd amount1 S12013 330.1941305 S13001 348.4703867 S13003 350.9155198 S13004 330.94394912 S13015 351.11196016 S13019 330.20861617 S13020 337.87993228 S13052 402.86747030 S14010 348.79126231 S14011 335.71833338 S14026 332.34058846 S14045 330.08207348 S14047 330.077073 これでOKです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 標本分散、標本標準偏差、パーセンタイル値、平均値の計算を学びました。本記事では、「【Python】標本分散、標本標準偏差、パーセンタイル値、平均の表示方法を学ぶ | データサイエンス100本ノック【問30〜問33 回答】」というテーマでまとめました。 &gt;&gt; 続きはこちら なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-30-33/"},{"title":"【解説】副問合せ（サブクエリ）の設定方法を学ぶ | データサイエンス100本ノック【問34〜問35 回答】","text":"目次 この記事の対象者 第34問目: 検索結果に対するサブクエリ groupbyメソッドは必要な列を抽出してから適用しなければいけません。 第35問目: 条件指定でのサブクエリ データフレームに対してBool型のフィルタを適用する際の注意点 まとめ: 副問合せ(サブクエリ)の設定方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで副問合せ(サブクエリ)の設定方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、副問合せ（サブクエリ）の設定方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第34問目: 検索結果に対するサブクエリ P-034: レシート明細データフレーム（df_receipt）に対し、顧客ID（customer_id）ごとに売上金額（amount）を合計して全顧客の平均を求めよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。 まずは、queryメソッドを使って、customer_idが”Z”から始まる行以外の行を抽出します。 &gt;&gt;queryメソッドを復習する その後、customer_id列をグルーピングし、amount列の合計を、sumメソッドを使って計算します。 最後にmeanメソッドを用いて全顧客の平均値を求めていきます。 1df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').amount.sum().mean() 出力12547.742234529256 これが答えとなります。 groupbyメソッドは必要な列を抽出してから適用しなければいけません。 ちなみに、以下のようにgroupbyメソッドを適用してからqueryメソッドを用いても、AttributeError: 'DataFrameGroupBy' object has no attribute 'query'というエラーが出力されて実行できません。 エラーコード1df_receipt.groupby('customer_id').query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').amount.sum().mean() エラー12345678910111213---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-11-9b5c34b46732&gt; in &lt;module&gt;----&gt; 1 df_receipt.groupby('customer_id').query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').amount.sum().mean()/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py in __getattr__(self, attr) 750 return self[attr] 751 --&gt; 752 raise AttributeError( 753 f&quot;'{type(self).__name__}' object has no attribute '{attr}'&quot; 754 )AttributeError: 'DataFrameGroupBy' object has no attribute 'query' groupbyメソッドは、必要な列を抽出してから適用しなければいけません。 第35問目: 条件指定でのサブクエリ P-035: レシート明細データフレーム（df_receipt）に対し、顧客ID（customer_id）ごとに売上金額（amount）を合計して全顧客の平均を求め、平均以上に買い物をしている顧客を抽出せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。なお、データは10件だけ表示させれば良い。 まずは、第34問のときと同様に、df_receiptに対するcustomer_idごとにamountを合計し、全顧客の平均を求めます。 12df_amount_mean = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').amount.sum().mean()df_amount_mean 次に、顧客ID毎の売上金額の合計のデータを抽出します。 12df_customerid_amount_list = df_receipt.groupby('customer_id').amount.sum().reset_index()df_customerid_amount_list 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 ZZ000000000000 123950038307 rows × 2 columns 各顧客の売上金額が、平均以上か否かを判定するには、以下のようにすればOKです。 1df_customerid_amount_list['amount'] &gt;= df_amount_mean 出力1234567891011120 False1 False2 True3 False4 True ... 8302 False8303 False8304 False8305 False8306 TrueName: amount, Length: 8307, dtype: bool このbool型の判定を、df_customerid_amount_listのindexとして指定すれば答えが出力されます。 1df_customerid_amount_list[df_customerid_amount_list['amount']&gt;=df_amount_mean] 出力12345678910111213 customer_id amount2 CS001115000010 30444 CS001205000006 333713 CS001214000009 468514 CS001214000017 413217 CS001214000052 5639... ... ...8286 CS048415000020 29958287 CS048513000001 25708292 CS049513000008 44508300 CS050415000007 27708306 ZZ000000000000 123950032997 rows × 2 columns このあたり少しわかりにくいかと思いますので、簡単な例を用いて解説します。 データフレームに対してBool型のフィルタを適用する際の注意点 例えば以下のようなデータフレームに対して、bool型でフィルタしてみたいと思います。 12df_temp = df_customerid_amount_list.head(4)df_temp 出力12345customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 1988 ２つのフィルタを用意します。 12filter_4 = [True, False, True, False]filter_3 = [True, False, True] この２つのフィルタをそれぞれ適用してみます。 filter_4を適用1df_temp[filter_4] 出力123 customer_id amount0 CS001113000004 12982 CS001115000010 3044 このようにTrueと指定されたindexのみが抽出されました。 では、filter_3を適用してみます。 filter_3を適用1df_temp[filter_3] エラーが出力される1234567891011121314151617181920---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-9-cbf35eb15a30&gt; in &lt;module&gt;----&gt; 1 df_temp[filter_3]/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key) 3013 # Do we have a (boolean) 1d indexer? 3014 if com.is_bool_indexer(key):-&gt; 3015 return self._getitem_bool_array(key) 3016 3017 # We are left with two options: a single key, and a collection of keys,/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py in _getitem_bool_array(self, key) 3060 ) 3061 elif len(key) != len(self.index):-&gt; 3062 raise ValueError( 3063 f&quot;Item wrong length {len(key)} instead of {len(self.index)}.&quot; 3064 )ValueError: Item wrong length 3 instead of 4. このように、フィルターを書けられる側のデータの数とbool型のフィルタの数は、一致していないといけません。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 副問合せ(サブクエリ)の設定方法を学びました。本記事は、「【Python】副問合せ（サブクエリ）の設定方法を学ぶ | データサイエンス100本ノック【問34〜問35 回答】」というテーマでまとめました。 groupbyメソッドは必要な列を抽出してから適用しなければいけない点や、データフレームに対してBool型のフィルタを適用する際の注意点も補足としてまとめました。 &gt;&gt; 続きはこちら","link":"/100knock-34-35/"},{"title":"【解説】時系列ずらしの方法を学ぶ | データサイエンス100本ノック【問41〜問42 回答】","text":"目次 この記事の対象者 第41問目: データフレームの行ずらし 第42問目: データフレームの行ずらし(2) まとめ この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで時系列ずらしの方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、時系列ずらしの方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第41問目: データフレームの行ずらし P-041: レシート明細データフレーム（df_receipt）の売上金額（amount）を日付（sales_ymd）ごとに集計し、前日からの売上金額増減を計算せよ。なお、計算結果は10件表示すればよい。 まずは、df_receiptのsales_ymd列とamount列のみ抽出し、sales_ymdでグルーピングすれば良いね。「前日からの売上金額増減の計算」はどうやればいいだろう？ 「前日からの売上金額増減の計算」は、与えられたデータフレームの行を1行ずらして差分をとることで、前日からの売上金額の増減を計算することができます。 まずは、df_receiptのsales_ymd列とamount列のみ抽出し、sales_ymdでグルーピングします。 その後に、amountに対して合計値を計算し、indexを再割り当てましょう。 df_receiptのsales_ymd列とamount列のみ抽出し、sales_ymdでグルーピング12df_sales_amount_by_date = df_receipt[['sales_ymd', 'amount']].groupby('sales_ymd').sum().reset_index()df_sales_amount_by_date 出力12345678910111213 sales_ymd amount0 20170101 337231 20170102 241652 20170103 275033 20170104 361654 20170105 37830... ... ...1029 20191027 374841030 20191028 401611031 20191029 360911032 20191030 266021033 20191031 252161034 rows × 2 columns 繰り返しになりますが、この問題に対する方針を整理します。 この問題においては、df_sales_amount_by_dateというデータフレームを1行下にずらしたデータフレームを作成し、両者のデータフレームのamountの差分を取ることで、前日からの売上金額の増減を計算していきたいと思います。 ここで作ったdf_sales_amount_by_dateと、当該データフレームを1行下にシフトしたデータフレームを結合します。 データフレームの行または列をずらすにはshift()を使用します。 &gt;&gt;pandas.DataFrame.shift shift()は、引数に数値を指定することでずらし幅を指定することが出来ます。 引数に数値を指定しなかった場合は、下方向に1行ずれます。行数はそのままなので、最後の行のデータは削除されます。 ``df_sales_amount_by_date``と、当該データフレームを1行下にシフトしたデータフレームを結合12df_sales_amount_by_date = pd.concat([df_sales_amount_by_date, df_sales_amount_by_date.shift()], axis=1)df_sales_amount_by_date 出力12345678910111213 sales_ymd amount sales_ymd amount0 20170101 33723 NaN NaN1 20170102 24165 20170101.0 33723.02 20170103 27503 20170102.0 24165.03 20170104 36165 20170103.0 27503.04 20170105 37830 20170104.0 36165.0... ... ... ... ...1029 20191027 37484 20191026.0 51771.01030 20191028 40161 20191027.0 37484.01031 20191029 36091 20191028.0 40161.01032 20191030 26602 20191029.0 36091.01033 20191031 25216 20191030.0 26602.01034 rows × 4 columns 出力されたデータフレームのカラム名を見てみると、sales_ymdというカラム名とamountというカラム名が2つずつあり区別できません。 なので、カラム名を1列目から順番にsales_ymd, amount, lag_ymd, lag_amountに変更しています。 カラム名を変更12df_sales_amount_by_date.columns = ['sales_ymd', 'amount', 'lag_ymd', 'lag_amount']df_sales_amount_by_date 出力1234567891011121314sales_ymd amount lag_ymd lag_amount0 20170101 33723 NaN NaN1 20170102 24165 20170101.0 33723.02 20170103 27503 20170102.0 24165.03 20170104 36165 20170103.0 27503.04 20170105 37830 20170104.0 36165.0... ... ... ... ...1029 20191027 37484 20191026.0 51771.01030 20191028 40161 20191027.0 37484.01031 20191029 36091 20191028.0 40161.01032 20191030 26602 20191029.0 36091.01033 20191031 25216 20191030.0 26602.01034 rows × 4 columns df_sales_amount_by_dateに新しいカラムdiff_amountを作成し、amount列とlag_amount列の差を取ったデータを追加します。 新しいカラムdiff_amountを作成し、amount列とlag_amount列の差を取ったデータを追加12df_sales_amount_by_date['diff_amount'] = df_sales_amount_by_date['amount'] - df_sales_amount_by_date['lag_amount']df_sales_amount_by_date.head(10) 出力1234567891011 sales_ymd amount lag_ymd lag_amount diff_amount0 20170101 33723 NaN NaN NaN1 20170102 24165 20170101.0 33723.0 -9558.02 20170103 27503 20170102.0 24165.0 3338.03 20170104 36165 20170103.0 27503.0 8662.04 20170105 37830 20170104.0 36165.0 1665.05 20170106 32387 20170105.0 37830.0 -5443.06 20170107 23415 20170106.0 32387.0 -8972.07 20170108 24737 20170107.0 23415.0 1322.08 20170109 26718 20170108.0 24737.0 1981.09 20170110 20143 20170109.0 26718.0 -6575.0 これで完成です。 第42問目: データフレームの行ずらし(2) P-042: レシート明細データフレーム（df_receipt）の売上金額（amount）を日付（sales_ymd）ごとに集計し、各日付のデータに対し、１日前、２日前、３日前のデータを結合せよ。結果は10件表示すればよい。 まずはdf_receiptのsales_ymd列とamount列のみを抽出し、sales_ymdをグルーピングします。その後にamount列に対して合計値を計算し、indexを再割り当てします。算出方法は以下に示すとおり3パタンあります。どの方法でも構いません。 123456789101112# パタン１df_sales_amount_by_date1 = df_receipt[['sales_ymd', 'amount']].groupby('sales_ymd').sum().reset_index()df_sales_amount_by_date1# パタン2df_sales_amount_by_date2 = df_receipt[['sales_ymd', 'amount']].groupby('sales_ymd').amount.sum().reset_index()df_sales_amount_by_date2# パタン3df_sales_amount_by_date3 = df_receipt[['sales_ymd', 'amount']].groupby('sales_ymd').agg({'amount': 'sum'}).reset_index()df_sales_amount_by_date3 出力1234567891011121314sales_ymd amount0 20170101 337231 20170102 241652 20170103 275033 20170104 361654 20170105 37830... ... ...1029 20191027 374841030 20191028 401611031 20191029 360911032 20191030 266021033 20191031 252161034 rows × 2 columns 1日前、2日前、3日前のデータを結合させていくことを考えます。 １つずつデータフレームを作成してから結合していってもよいのですが、ここでは少し応用を効かせてfor文を用いて処理を進めます。 iを1〜3で3回ループさせるようにします。 iが1の場合、df_sales_amount_by_dateと1行シフトしたdf_sales_amount_by_dateを結合します。 i!=1の場合は、df_lagと2行、3行とシフトしたデータフレームと結合します。 1234567for i in range(1, 4): if i == 1: df_lag = pd.concat([df_sales_amount_by_date, df_sales_amount_by_date.shift(i)],axis=1) else: df_lag = pd.concat([df_lag, df_sales_amount_by_date.shift(i)],axis=1)df_lag 出力12345678910111213 sales_ymd amount sales_ymd amount sales_ymd amount sales_ymd amount0 20170101 33723 NaN NaN NaN NaN NaN NaN1 20170102 24165 20170101.0 33723.0 NaN NaN NaN NaN2 20170103 27503 20170102.0 24165.0 20170101.0 33723.0 NaN NaN3 20170104 36165 20170103.0 27503.0 20170102.0 24165.0 20170101.0 33723.04 20170105 37830 20170104.0 36165.0 20170103.0 27503.0 20170102.0 24165.0... ... ... ... ... ... ... ... ...1029 20191027 37484 20191026.0 51771.0 20191025.0 28833.0 20191024.0 31868.01030 20191028 40161 20191027.0 37484.0 20191026.0 51771.0 20191025.0 28833.01031 20191029 36091 20191028.0 40161.0 20191027.0 37484.0 20191026.0 51771.01032 20191030 26602 20191029.0 36091.0 20191028.0 40161.0 20191027.0 37484.01033 20191031 25216 20191030.0 26602.0 20191029.0 36091.0 20191028.0 40161.01034 rows × 8 columns すると上記のような新たなデータフレームdf_lagを得ることができます。 カラム名を見るとamountという名前のカラムが複数存在します。区別がつかないので、名前を変更します。 列名は1列目から順にsales_ymd, amount, lag_ymd_1, lag_amount_1, lag_ymd_2, lag_amount_2, lag_ymd_3, lag_amount_3に変更します。 12df_lag.columns = ['sales_ymd', 'amount', 'lag_ymd_1', 'lag_amount_1', 'lag_ymd_2', 'lag_amount_2', 'lag_ymd_3', 'lag_amount_3']df_lag 12345678910111213 sales_ymd amount lag_ymd_1 lag_amount_1 lag_ymd_2 lag_amount_2 lag_ymd_3 lag_amount_30 20170101 33723 NaN NaN NaN NaN NaN NaN1 20170102 24165 20170101.0 33723.0 NaN NaN NaN NaN2 20170103 27503 20170102.0 24165.0 20170101.0 33723.0 NaN NaN3 20170104 36165 20170103.0 27503.0 20170102.0 24165.0 20170101.0 33723.04 20170105 37830 20170104.0 36165.0 20170103.0 27503.0 20170102.0 24165.0... ... ... ... ... ... ... ... ...1029 20191027 37484 20191026.0 51771.0 20191025.0 28833.0 20191024.0 31868.01030 20191028 40161 20191027.0 37484.0 20191026.0 51771.0 20191025.0 28833.01031 20191029 36091 20191028.0 40161.0 20191027.0 37484.0 20191026.0 51771.01032 20191030 26602 20191029.0 36091.0 20191028.0 40161.0 20191027.0 37484.01033 20191031 25216 20191030.0 26602.0 20191029.0 36091.0 20191028.0 40161.01034 rows × 8 columns 処理としては概ね完了かと思いますが、NaNと表示されている欠損値の削除を行います。 欠損値の削除は、dropnaメソッドを使えばOK。 1df_lag.dropna().head(10) 出力1234567891011 sales_ymd amount lag_ymd_1 lag_amount_1 lag_ymd_2 lag_amount_2 lag_ymd_3 lag_amount_33 20170104 36165 20170103.0 27503.0 20170102.0 24165.0 20170101.0 33723.04 20170105 37830 20170104.0 36165.0 20170103.0 27503.0 20170102.0 24165.05 20170106 32387 20170105.0 37830.0 20170104.0 36165.0 20170103.0 27503.06 20170107 23415 20170106.0 32387.0 20170105.0 37830.0 20170104.0 36165.07 20170108 24737 20170107.0 23415.0 20170106.0 32387.0 20170105.0 37830.08 20170109 26718 20170108.0 24737.0 20170107.0 23415.0 20170106.0 32387.09 20170110 20143 20170109.0 26718.0 20170108.0 24737.0 20170107.0 23415.010 20170111 24287 20170110.0 20143.0 20170109.0 26718.0 20170108.0 24737.011 20170112 23526 20170111.0 24287.0 20170110.0 20143.0 20170109.0 26718.012 20170113 28004 20170112.0 23526.0 20170111.0 24287.0 20170110.0 20143.0 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ本記事は、「【Python】時系列ずらしの方法を学ぶ | データサイエンス100本ノック【問41〜問42 回答】」というテーマでまとめました。 新たに学んだ事項としてはshiftとdropnaかと思います。 &gt;&gt; 続きはこちら なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-41-42/"},{"title":"【解説】手を動かしながら平均値と中央値の抽出方法を学ぶ | データサイエンス100本ノック【問27〜問28 回答】","text":"目次 この記事の対象者 本記事で学ぶpythonのメソッドと関数 第27問目: 平均値の出力方法 第28問目: 中央値の表示方法 まとめ: 平均値と中央値の表示方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonのgroupby, agg, reset_index, sort_valuesメソッドの使い方を知りたい人 ・ aggメソッドを使って平均値、中央値を出力する方法を知りたい人 本記事で学ぶpythonのメソッドと関数 本記事では以下のメソッドを学びます。前回の記事で学んだメソッドの復習も兼ねて学びましょう。 groupbyメソッド: データフレームの特定の列のユニークな値でグルーピングするメソッド。 aggメソッド: aggはgroupbyでグルーピングされた列に対して統計量を取るためのメソッドです。 reset_indexメソッド: reset_indexメソッドは、インデックスが存在しないデータフレームにインデックスを付与するメソッドです。 早速データサイエンス100本ノックの問題を題材に、これらの使い方を学んでいきたいと思います。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第27問目: 平均値の出力方法 P-027: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）の平均を計算し、降順でTOP5を表示せよ。 これまでの問題を取り組んできた方であれば、問題文を読んだ段階で、groupby()メソッドとagg()メソッド、そして、sort_values(), head()を用いることが思いつくと思います。 問題文を読んだ段階でこの発想が出てこなかった方は、以下の記事で紹介している23問目〜26問目の問題を復習しましょう。 &gt;&gt;100本ノックの23問目〜26問目を復習する まずは、df_receiptを確認します。 1df_receipt 出力12345678910111213 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...104676 20180221 1519171200 S13043 1132 2 ZZ000000000000 P050101001 1 40104677 20190911 1568160000 S14047 1132 2 ZZ000000000000 P071006005 1 218104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 148104680 20190423 1555977600 S13016 1102 2 ZZ000000000000 P050601001 1 138104681 rows × 9 columns これまで学んだ通り、groupby()メソッドとagg()メソッドを使ってデータを表示させていきます。 平均を求めるにはagg({'カラム名': 'mean'})のように指定します。 1df_receipt.groupby('store_cd').agg({'amount': 'mean'}) 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 amountstore_cd S12007 307.688343S12013 330.194130S12014 310.830261S12029 315.623908S12030 288.533727S13001 348.470386S13002 313.445736S13003 350.915519S13004 330.943949S13005 316.202811S13008 327.912480S13009 328.141988S13015 351.111960S13016 329.639950S13017 317.581070S13018 312.464427S13019 330.208616S13020 337.879932S13031 307.879634S13032 321.472550S13035 324.804446S13037 299.907832S13038 306.478167S13039 310.918699S13041 329.234177S13043 318.125000S13044 304.718549S13051 309.659942S13052 402.867470S14006 315.136605S14010 348.791262S14011 335.718333S14012 303.027754S14021 314.953174S14022 321.643457S14023 325.561521S14024 308.213897S14025 319.079814S14026 332.340588S14027 314.918466S14028 324.317244S14033 321.506206S14034 326.350974S14036 322.811410S14040 318.447368S14042 278.338886S14045 330.082073S14046 309.098127S14047 330.077073S14048 308.257895S14049 297.816774S14050 290.591304 store_id毎にamountの平均を表示することが出来ました。 indexを設けるために、reset_index()を活用します。 1df_receipt.groupby('store_cd').agg({'amount': 'mean'}).reset_index() 出力1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 store_cd amount0 S12007 307.6883431 S12013 330.1941302 S12014 310.8302613 S12029 315.6239084 S12030 288.5337275 S13001 348.4703866 S13002 313.4457367 S13003 350.9155198 S13004 330.9439499 S13005 316.20281110 S13008 327.91248011 S13009 328.14198812 S13015 351.11196013 S13016 329.63995014 S13017 317.58107015 S13018 312.46442716 S13019 330.20861617 S13020 337.87993218 S13031 307.87963419 S13032 321.47255020 S13035 324.80444621 S13037 299.90783222 S13038 306.47816723 S13039 310.91869924 S13041 329.23417725 S13043 318.12500026 S13044 304.71854927 S13051 309.65994228 S13052 402.86747029 S14006 315.13660530 S14010 348.79126231 S14011 335.71833332 S14012 303.02775433 S14021 314.95317434 S14022 321.64345735 S14023 325.56152136 S14024 308.21389737 S14025 319.07981438 S14026 332.34058839 S14027 314.91846640 S14028 324.31724441 S14033 321.50620642 S14034 326.35097443 S14036 322.81141044 S14040 318.44736845 S14042 278.33888646 S14045 330.08207347 S14046 309.09812748 S14047 330.07707349 S14048 308.25789550 S14049 297.81677451 S14050 290.591304 最後に、上位5位を出力するためにソートを行います。 ソートは、sort_values('amount', ascending=False)でしたね。 &gt;&gt;ソートを復習する 1df_receipt.groupby('store_cd').agg({'amount': 'mean'}).reset_index().sort_values('amount', ascending=False).head(5) 出力1234567store_cd amount28 S13052 402.86747012 S13015 351.1119607 S13003 350.91551930 S14010 348.7912625 S13001 348.470386 上記のコードで、head(5)というふうに明示的に5という数字を入れていますが、head()というふうにしても同じ出力が得られます。headメソッドは、引数を含めない場合、デフォルトで5つを表示する仕様になっているためです。 第28問目: 中央値の表示方法 P-028: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）の中央値を計算し、降順でTOP5を表示せよ。 処理としては、第27問目とほぼ同じになります。 中央値を求めるにはagg({'カラム名': 'medium'})のように指定します。 今回は一気に全てのメソッドを使って表示します。 1df_receipt.groupby('store_cd').agg({'amount': 'median'}).reset_index().sort_values('amount', ascending=False).head(5) 出力123456 store_cd amount28 S13052 19030 S14010 18851 S14050 18544 S14040 1807 S13003 180 これでOKです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 平均値と中央値の表示方法を学びました。本記事は、「【Python】手を動かしながら平均値と中央値の抽出方法を学ぶ | データサイエンス100本ノック【問27〜問28 回答】」というテーマでまとめました。 平均を求めるにはagg({'カラム名': 'mean'})のように指定 中央値を求めるにはagg({'カラム名': 'medium'})のように指定 &gt;&gt; 続きはこちら","link":"/100knock-27-28/"},{"title":"【解説】map関数とpandas.Seriesのmapメソッドの違いを学ぶ | データサイエンス100本ノック【問54 回答】","text":"目次 この記事の対象者 そもそも「関数」と「メソッド」の違いとは map関数とpandas.Seriesにおけるmapメソッド 1. map関数 2. pandas.Seriesのmapメソッド 第54問目: mapメソッドを用いたカテゴリ化 まとめ: 関数とメソッドの違いとmapを使ったカテゴリ化を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonのmap関数とpandas.Seriexのmapメソッドの違いを知りたい人 以降はデータサイエンス100本ノックの問題も題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する そもそも「関数」と「メソッド」の違いとはpythonを学んできた型ならふと思う「関数とメソッドの違いってなんだ？」という点から掘り下げていきます。 先人の方がきちんと整理してくれていました。 【Python】関数とメソッドの違いを実例でわかりやすく解説 要約すると以下になります。 メソッド: 特定のクラスでしか使えない。データ型に紐付いた関数。 例: replaceメソッドはlist(配列)には使えないが、str(文字列)には使える 関数: 幅広いオブジェクトに使える(特定のクラスで縛られない)。単独で呼び出せるもの。 例: print()等 map関数とpandas.Seriesにおけるmapメソッドそれでは本記事の主題であるmapにフォーカスして整理します。 pythonには「map関数」と「mapメソッド」が存在します。 後者のmapメソッドは、pandasのSeries型に適用できるメソッドです。 それぞれ「map関数」と「mapメソッド」に分けて使い方を紹介します。 1. map関数map関数は、listの各要素に関数を適用する場合に使う関数です。 map関数の使い方12345# イテレータ(計算の方法を格納)を返す 計算は行わないmap(適用したい関数, 配列)# 計算結果をlist に返すlist(map(関数, 配列)) イテレータとは複数の要素を順番に取り出す機能を持ったクラスを指します。この、要素を順番に取り出す機能を使うことで、forループを用いるよりも実行時間を短くすることができるので、膨大な要素を持つ配列に関数を適用したい場合にはmap()関数を用います。 このmap関数のように他の関数を引数にできる関数を高階関数と言います。 以下に例を示します。例えばa = [1, -2, 3, -4, 5]という配列の各要素の絶対値を得るには、forループと絶対値を算出する関数であるabs()を用いて、以下のように書きます。 forループを用いて記載123456a = [1, -2, 3, -4, 5,]# forループで関数適用new = []for x in a: new.append(abs(x))new 出力1[1, 2, 3, 4, 5] これをmap()関数を用いると、以下のように簡潔に書くことができます。 map関数を用いて記載123a = [1, -2, 3, -4, 5,]# mapで関数適用list(map(abs, a)) 出力1[1, 2, 3, 4, 5] このようにlist()関数で囲むことによりmap()関数の適用結果(abs関数を適用した結果)を再度リストに格納することができます。 2. pandas.Seriesのmapメソッドpandas.Seriesにおけるmapメソッドは、引数に辞書型を指定することも可能です。 その場合、要素の置換になります。 要素の置換は、過去にデータサイエンス100本ノックの第44問目でreplaceメソッドを使用しました。 しかし、こちらの記事によると、pandas.Seriesまたはpandas.DataFrameの列(=pandas.Series)のすべての要素を別の値に置換する場合、map()のほうが高速になるようです。 pandas.Seriesにおけるmapメソッドの使い方の例を紹介します。 12345678910111213import pandas as pdcolumns = ['都道府県', 'num']data = [['東京都', 1000], ['大阪府', 700], ['京都府', 500]]df = pd.DataFrame(data, columns=columns)print(df['都道府県'].map({'東京都':'0','大阪府':'1','京都府':'2'}))# &gt;&gt;&gt; 出力結果# 0 0# 1 1# 2 2# Name: 都道府県, dtype: object この例を元に、データサイエンス100本ノックの第54問目を解いていきたいと思います。 第54問目: mapメソッドを用いたカテゴリ化 P-054: 顧客データデータフレーム（df_customer）の住所（address）は、埼玉県、千葉県、東京都、神奈川県のいずれかとなっている。都道府県毎にコード値を作成し、顧客ID、住所とともに抽出せよ。値は埼玉県を11、千葉県を12、東京都を13、神奈川県を14とすること。結果は10件表示させれば良い。 まずはdf_customerの構造を確認します。 df_customerの構造を確認1df_customer.head(5) 出力123456 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 問題文には都道府県毎にコード値を作成し、顧客ID、住所とともに抽出せよ、と記載されているので、df_customerの顧客IDと住所のデータを抽出します。 12df_tmp = df_customer[['customer_id', 'address']]df_tmp 出力1234567891011121314customer_id address0 CS021313000114 神奈川県伊勢原市粟窪**********1 CS037613000071 東京都江東区南砂**********2 CS031415000172 東京都渋谷区代々木**********3 CS028811000001 神奈川県横浜市泉区和泉町**********4 CS001215000145 東京都大田区仲六郷**********... ... ...21966 CS002512000474 東京都国分寺市光町**********21967 CS029414000065 千葉県浦安市富士見**********21968 CS012403000043 神奈川県横浜市中区本牧間門**********21969 CS033512000184 神奈川県横浜市泉区和泉町**********21970 CS009213000022 東京都世田谷区駒沢**********21971 rows × 2 columns 次に、都道府県ごとにコード値を作成します。値は、埼玉県を11, 千葉県を12, 東京都を13, 神奈川県を14とします。 このときaddressカラムのstr型データからどのように都道府県の判別をすればよいかがポイントになります。 ここでは先頭の3文字を.str[0:3で抽出し、抽出した文字列がそれぞれ埼玉県, 千葉県, 東京都, 神奈川となっているかどうかで判別していきます。 12df_prefecturecode = df_customer['address'].str[0:3].map({'埼玉県': '11', '千葉県': '12', '東京都': '13', '神奈川':'14'})df_prefecturecode 出力1234567891011120 141 132 133 144 13 ..21966 1321967 1221968 1421969 1421970 13Name: address, Length: 21971, dtype: object これで下準備が整いました。 最後に２つのデータフレームを結合し、顧客IDで、住所、そして都道府県ごとのコード値を出力します。 今回結合する2つのデータフレームには共通するカラムは存在しないので、mergeではなくconcatを用いて結合します。 &gt;&gt; concatの使い方を復習する 1pd.concat([df_tmp, df_prefecturecode], axis=1).head(10) 出力1234567891011 customer_id address address0 CS021313000114 神奈川県伊勢原市粟窪********** 141 CS037613000071 東京都江東区南砂********** 132 CS031415000172 東京都渋谷区代々木********** 133 CS028811000001 神奈川県横浜市泉区和泉町********** 144 CS001215000145 東京都大田区仲六郷********** 135 CS020401000016 東京都板橋区若木********** 136 CS015414000103 東京都江東区北砂********** 137 CS029403000008 千葉県浦安市海楽********** 128 CS015804000004 東京都江東区北砂********** 139 CS033513000180 神奈川県横浜市旭区善部町********** 14 これで完成です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 関数とメソッドの違いとmapを使ったカテゴリ化を学びました。本記事は、「【Python】map関数とpandas.Seriesのmapメソッドの違いを学ぶ | データサイエンス100本ノック【問54 回答】」というテーマでまとめました。 本記事で紹介した方法を元に、データサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-54/"},{"title":"【解説】日付要素の取り出し方法を学ぶ | データサイエンス100本ノック【問49〜問51 回答】","text":"目次 この記事の対象者 第49問目: UNIX時間を日付型に変換し”年”だけ取り出す方法 第50問目: UNIX時間を日付型に変換し”月”だけ取り出す方法 第51問目: UNIX時間を日付型に変換し”日”だけ取り出す方法 まとめ: 日付要素の取り出し方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで日付要素の取り出し方を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、日付要素の取り出し方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第49問目: UNIX時間を日付型に変換し”年”だけ取り出す方法 P-049: レシート明細データフレーム（df_receipt）の売上エポック秒（sales_epoch）を日付型（timestamp型）に変換し、”年”だけ取り出してレシート番号(receipt_no)、レシートサブ番号（receipt_sub_no）とともに抽出せよ。データは10件を抽出すれば良い。 まずは、df_receiptの構造を確認しましょう。 df_receiptの構造を確認1df_receipt.head(5) 出力123456sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 売上エポック秒(sales_epoch)は、UNIX秒になっています。 UNIX秒とは、協定世界時(UTC)での1970年1月1日午前0時0分0秒からの秒数です。 このUNIX時間のままでは、日付や時間がわからないので、日付型に変換します。 日付型への変換はpandasのto_datetime()関数を用います。 to_datetime()関数では、引数でunit='s'を指定することで、与えられたデータがUNIX時間とみなし変換を行います。 そして”年”の取り出しですが、dt.yearを用いることで抽出が可能です。 実際にコードを書いて確認してみましょう。 12tmp = pd.to_datetime(df_receipt['sales_epoch'], unit='s').dt.yeartmp 出力1234567891011120 20181 20182 20173 20194 2018 ... 104676 2018104677 2019104678 2017104679 2017104680 2019Name: sales_epoch, Length: 104681, dtype: int64 ご覧のように、sales_epochが日付型に変更され、”年”のみ抽出することが出来ました。 最後に抽出したtmpデータフレームに、receipt_noとreceipt_sub_noを結合して出力させます。 結合にはconcatを使用すれば良いですね。 &gt;&gt; concatの使い方を復習する concatを用いて結合12df_tmp = pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp], axis=1).head(10)df_tmp 出力123456789101112receipt_no receipt_sub_no sales_epoch0 112 1 20181 1132 2 20182 1102 1 20173 1132 1 20194 1102 2 20185 1112 1 20196 1102 2 20187 1102 1 20198 1112 2 20179 1102 1 2019 本問はこれでOKです。 第50問目: UNIX時間を日付型に変換し”月”だけ取り出す方法 P-050: レシート明細データフレーム（df_receipt）の売上エポック秒（sales_epoch）を日付型（timestamp型）に変換し、”月”だけ取り出してレシート番号(receipt_no)、レシートサブ番号（receipt_sub_no）とともに抽出せよ。なお、”月”は0埋め2桁で取り出すこと。データは10件を抽出すれば良い。 第49問目の処理とほぼ同じですが、問題文にある“月”は0埋め2桁で取り出すことという部分に注意が必要です。 まずは第49問目と同様にUNIX時間を日付型に変換し、dt.monthを使って”月”のみを抽出してみましょう。 12tmp = pd.to_datetime(df_receipt['sales_epoch'], unit='s').dt.monthtmp 出力1234567891011120 111 112 73 24 8 ..104676 2104677 9104678 3104679 3104680 4Name: sales_epoch, Length: 104681, dtype: int64 出力結果を見てみると、0埋め2桁になっていません 実は0埋め2桁で取り出すためにはdt.strftimeを使う必要があります。引数として'%m'を指定することで月を抽出することが出来ます。 12tmp = pd.to_datetime(df_receipt['sales_epoch'], unit='s').dt.strftime('%m')tmp 出力1234567891011120 111 112 073 024 08 ..104676 02104677 09104678 03104679 03104680 04Name: sales_epoch, Length: 104681, dtype: object 0埋め2桁で月を抽出することが出来ました。 最後にconcatを使って結合しましょう。 12df_tmp = pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp], axis=1).head(10)df_tmp 出力1234567891011 receipt_no receipt_sub_no sales_epoch0 112 1 111 1132 2 112 1102 1 073 1132 1 024 1102 2 085 1112 1 066 1102 2 127 1102 1 098 1112 2 059 1102 1 10 本問はこれで完了です。 第51問目: UNIX時間を日付型に変換し”日”だけ取り出す方法 P-051: レシート明細データフレーム（df_receipt）の売上エポック秒（sales_epoch）を日付型（timestamp型）に変換し、”日”だけ取り出してレシート番号(receipt_no)、レシートサブ番号（receipt_sub_no）とともに抽出せよ。なお、”日”は0埋め2桁で取り出すこと。データは10件を抽出すれば良い。 この問題は、第50問目の対応と同じになります。 第50問目と異なる点は、抽出する対象が月ではなく日になっている点です。 日を抽出するにはdt.strftime('%d')を使えばOKです。 なお、dt.dayを用いると、第50問目で紹介したとき同様に、0埋め2桁ではない形式で抽出されてしまうので注意しましょう。 12tmp = pd.to_datetime(df_receipt['sales_epoch'], unit='s').dt.strftime('%d')tmp 出力1234567891011120 031 182 123 054 21 ..104676 21104677 11104678 11104679 31104680 23Name: sales_epoch, Length: 104681, dtype: object 同様にconcatで結合します。 12df_tmp = pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp], axis=1).head(10)df_tmp 出力1234567891011 receipt_no receipt_sub_no sales_epoch0 112 1 031 1132 2 182 1102 1 123 1132 1 054 1102 2 215 1112 1 056 1102 2 057 1102 1 228 1112 2 049 1102 1 10 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"gIjS7\",\"s\":\"s\"}); リンク まとめ: 日付要素の取り出し方法を学びました。本記事は、「【Python】日付要素の取り出し方法を学ぶ | データサイエンス100本ノック【問49〜問51 回答】」というテーマでまとめました。 本記事で紹介した方法を元に、データサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-49-51/"},{"title":"【解説】手を動かしながら後方一致と部分一致を学ぶ | データサイエンス100本ノック【問11〜問12 回答】","text":"目次 この記事の対象者 第11問目: 後方一致(str.endswith()) 第12問目: 部分一致 まとめ: 後方一致と部分一致データの抽出方法を学びました。 この記事の対象者 ・ データから任意の文字列に一致するデータの抽出方法を学びたい人 ・ データサイエンティストを目指している人 一般社団法人データサイエンティスト協会がGitHubに公開している「データサイエンス100本ノック」の第11問目と12問目を例に、後方一致と部分一致するデータの抽出方法をまとめます。 データサイエンス100本ノックは、自身のPCにDockerを用いて環境構築することが出来ます。 データサイエンス100本ノックの環境構築方法は以下の記事にまとめています。 なお、「前方一致」については、第10問で扱っていますので、興味のある方はそちらも参照ください。 &gt;&gt;前方一致のデータを抽出する方法を学ぶ では実際に問題を解きながら後方一致と部分一致するデータの抽出方法を学んでいきましょう。 第11問目: 後方一致(str.endswith()) P-011: 顧客データフレーム（df_customer）から顧客ID（customer_id）の末尾が1のものだけ全項目抽出し、10件だけ表示せよ。 「末尾が1となっているcustomer_idのみを抽出」ということなので、特定の条件を満たした行の取り出しを行うquery()メソッドと後方一致を指定するstr.endswith()を使うことを想定しましょう。 queryメソッドについては以下の記事で学んでいますので、復習しましょう。 &gt;&gt;前方一致のデータを抽出する方法を学ぶ 早速、回答であるコードを書いていきます。 query()メソッドで文字列メソッドを使う場合、第２引数にengine='python'を指定しないといけない点に注意しましょう。 1df_customer.query(&quot;customer_id.str.endswith('1')&quot;, engine='python').head(10) 1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd1 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-03 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-014 CS040412000191 川井 郁恵 1 女性 1977-01-05 42 226-0021 神奈川県横浜市緑区北八朔町********** S14040 20151101 1-20091025-431 CS028314000011 小菅 あおい 1 女性 1983-11-26 35 246-0038 神奈川県横浜市瀬谷区宮沢********** S14028 20151123 1-20080426-556 CS039212000051 藤島 恵梨香 1 女性 1997-02-03 22 166-0001 東京都杉並区阿佐谷北********** S13039 20171121 1-20100215-459 CS015412000111 松居 奈月 1 女性 1972-10-04 46 136-0071 東京都江東区亀戸********** S13015 20150629 0-00000000-063 CS004702000041 野島 洋 0 男性 1943-08-24 75 176-0022 東京都練馬区向山********** S13004 20170218 0-00000000-074 CS041515000001 栗田 千夏 1 女性 1967-01-02 52 206-0001 東京都多摩市和田********** S13041 20160422 E-20100803-F85 CS029313000221 北条 ひかり 1 女性 1987-06-19 31 279-0011 千葉県浦安市美浜********** S12029 20180810 0-00000000-0102 CS034312000071 望月 奈央 1 女性 1980-09-20 38 213-0026 神奈川県川崎市高津区久末********** S14034 20160106 0-00000000-0 第12問目: 部分一致 P-012: 店舗データフレーム（df_store）から横浜市の店舗だけ全項目表示せよ。 特定の文字列を含んだ列を取り出すには、str.contains()を使用します。 今回は”横浜市”という文字列なので、str.contains(&quot;横浜市&quot;)とすることで、その条件を満たす行を抽出することが出来ます。 以下のコードで回答が出力できます。 1df_store.query(&quot;address.str.contains('横浜市')&quot;, engine='python') 出力123456789101112 store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area2 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.07 S14040 長津田店 14 神奈川県 神奈川県横浜市緑区長津田みなみ台五丁目 カナガワケンヨコハマシミドリクナガツタミナミダイゴチョウメ 045-123-4046 139.4994 35.52398 1548.09 S14050 阿久和西店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4053 139.4961 35.45918 1830.012 S14028 二ツ橋店 14 神奈川県 神奈川県横浜市瀬谷区二ツ橋町 カナガワケンヨコハマシセヤクフタツバシチョウ 045-123-4042 139.4963 35.46304 1574.016 S14012 本牧和田店 14 神奈川県 神奈川県横浜市中区本牧和田 カナガワケンヨコハマシナカクホンモクワダ 045-123-4034 139.6582 35.42156 1341.018 S14046 北山田店 14 神奈川県 神奈川県横浜市都筑区北山田一丁目 カナガワケンヨコハマシツヅキクキタヤマタイッチョウメ 045-123-4049 139.5916 35.56189 831.020 S14011 日吉本町店 14 神奈川県 神奈川県横浜市港北区日吉本町四丁目 カナガワケンヨコハマシコウホククヒヨシホンチョウヨンチョウメ 045-123-4033 139.6316 35.54655 890.026 S14048 中川中央店 14 神奈川県 神奈川県横浜市都筑区中川中央二丁目 カナガワケンヨコハマシツヅキクナカガワチュウオウニチョウメ 045-123-4051 139.5758 35.54912 1657.040 S14042 新山下店 14 神奈川県 神奈川県横浜市中区新山下二丁目 カナガワケンヨコハマシナカクシンヤマシタニチョウメ 045-123-4047 139.6593 35.43894 1044.052 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 後方一致と部分一致データの抽出方法を学びました。本記事では、「【Python】手を動かしながら後方一致と部分一致を学ぶ | データサイエンス100本ノック【問11〜問12 回答】」というテーマでまとめました。 繰り返しになりますが、query()メソッドで文字列メソッドを使う場合、第２引数にengine='python'を指定しないといけない点に注意しましょう。 &gt;&gt; 続きはこちらから","link":"/100knock-11-12/"},{"title":"【解説】カテゴリデータの作成方法を学ぶ | データサイエンス100本ノック【問56〜57 回答】","text":"目次 この記事の対象者 第56問目: applyとminを用いた年代カテゴリの作成 第57問目: データの型変換を伴うカテゴリ化 まとめ: 様々なカテゴリ化の方法を学びました この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonでカテゴリデータの作成方法を知りたい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第56問目: applyとminを用いた年代カテゴリの作成 P-056: 顧客データフレーム（df_customer）の年齢（age）をもとに10歳刻みで年代を算出し、顧客ID（customer_id）、生年月日（birth_day）とともに抽出せよ。ただし、60歳以上は全て60歳代とすること。年代を表すカテゴリ名は任意とする。先頭10件を表示させればよい。 まずは顧客データフレーム(df_customer)の構造を確認します。 1df_customer.head(5) 出力123456 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 年齢を元に10刻みで年代を算出する方法を考えます。 まずageカラムをデータとして取り出した上で、何らかの関数処理を施したい場合はapplyメソッドの引数にlambda式を用いればよかったですね。 &gt;&gt; applyメソッドとlambda式を復習する applyとlambda式の使い方を振り返ります。 データフレームと併用する場合は、df.apply(lambda 引数: 返り値)でした。 年代の算出方法はどのように行うでしょうか？ 実は、過去の問題で既に取り組んでいます。 &gt;&gt; 年代の算出方法を確認する 上記の記事で述べていることの繰り返しになりますが、年代は、age列の値を1/10倍し、floor関数で小数点を切り捨てたあとに10倍すれば、年代を算出することが出来ます。 例えば22という値を、2.2にし、小数点を切り捨てて2.0にした後10倍すれば20になりますよね？つまり、22歳は20代であることを算出することができます。 また問題文より、60以上はすべて60歳代にする必要があります。 比較演算子を用いて処理しても良いですね。一方で、関数で処理した値の最小値が60であることを指定すれば良いという考え方もできます。そのため、minを用いることで60以上はすべて60代として算出することが出来ます。早速コードを書いていきます。 12df_age = df_customer['age'].apply(lambda x: min(math.floor(x / 10) * 10, 60))df_age 出力1234567891011120 301 602 403 604 20 ..21966 5021967 4021968 4021969 5021970 20Name: age, Length: 21971, dtype: int64 これを、customer_idとbirth_dayとともに抽出させます。 df_ageとdf_customerの間に共通的なカラムは存在しないので、mergeではなくconcatを用いて結合させます。 concatでdf_ageとdf_customerを結合12df_customer_era = pd.concat([df_customer[['customer_id', 'birth_day']], df_age], axis=1)df_customer_era.head(10) 出力1234567891011 customer_id birth_day age0 CS021313000114 1981-04-29 301 CS037613000071 1952-04-01 602 CS031415000172 1976-10-04 403 CS028811000001 1933-03-27 604 CS001215000145 1995-03-29 205 CS020401000016 1974-09-15 406 CS015414000103 1977-08-09 407 CS029403000008 1973-08-17 408 CS015804000004 1931-05-02 609 CS033513000180 1962-07-11 50 本問はこれで完成です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"文系のための データサイエンスがわかる本\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51pFg1ZaJHL._SL500_.jpg\",\"\\/41SUCa0-1+L._SL500_.jpg\",\"\\/41tFUtTo5rL._SL500_.jpg\",\"\\/41zx+gmqJNL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"Q5cG7\",\"s\":\"s\"}); リンク 第57問目: データの型変換を伴うカテゴリ化 P-057: 前問題の抽出結果と性別（gender）を組み合わせ、新たに性別×年代の組み合わせを表すカテゴリデータを作成せよ。組み合わせを表すカテゴリの値は任意とする。先頭10件を表示させればよい。 「性別×年代の組み合わせを表すカテゴリデータ」とはなにかを補足しておきます。 今回作成する性別×年代の組み合わせを表すカテゴリーデータは、例えばgender_cdが1でageが40だったとしたら、140という風に表す形にしたいと思います。 これを実施するためには、gender_cdとageがともに文字列データにしなければいけません。なぜなら数値型ですと1 + 40は41になってしまうからです。1 + 40 を140にするためには両者を文字列型にしておけば良いことになります。 gender_cdとageはともに数値(int型)なので、これらをastypeメソッドを用いて文字列(str型)に変換させて足し合わせます。その上で新たなカラムであるera_genderに格納させていきます。 12df_customer_era['era_gender'] = df_customer['gender_cd'].astype('str') + df_customer_era['age'].astype('str')df_customer_era 出力12345678910111213 customer_id birth_day age era_gender0 CS021313000114 1981-04-29 30 1301 CS037613000071 1952-04-01 60 9602 CS031415000172 1976-10-04 40 1403 CS028811000001 1933-03-27 60 1604 CS001215000145 1995-03-29 20 120... ... ... ... ...21966 CS002512000474 1959-10-12 50 15021967 CS029414000065 1970-10-19 40 14021968 CS012403000043 1972-12-16 40 04021969 CS033512000184 1964-06-05 50 15021970 CS009213000022 1996-08-16 20 12021971 rows × 4 columns これで完成です。 まとめ: 様々なカテゴリ化の方法を学びました本記事は、「【Python】カテゴリデータの作成方法を学ぶ | データサイエンス100本ノック【問56〜57 回答】」というテーマでまとめました。 本記事で学んだこととしては、applyメソッドとlambda式の復習、そしてastypeメソッドによるデータの型変換可と思います。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 &gt;&gt; 第58問の回答はこちら","link":"/100knock-56-57/"},{"title":"【解説】四分位点を学ぶ | データサイエンス100本ノック【問55 回答】","text":"目次 この記事の対象者 第55問目: pandas.DataFrame.quantileを用いた四分位数の算出 まとめ: pandas.DataFrame.quantileを用いた四分位数の算出方法を学びました この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで分位点を抽出する方法を知りたい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第55問目: pandas.DataFrame.quantileを用いた四分位数の算出 P-055: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計し、その合計金額の四分位点を求めよ。その上で、顧客ごとの売上金額合計に対して以下の基準でカテゴリ値を作成し、顧客ID、売上金額と合計ともに表示せよ。カテゴリ値は上から順に1〜4とする。結果は10件表示させれば良い。 最小値以上第一四分位未満 第一四分位以上第二四分位未満 第二四分位以上第三四分位未満 第三四分位以上 四分位点とは、データを4分の1に分割する分位点です. 四分位数とも言います。 分位数を求める際は、numpy.quantile関数を使用します。 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html 例えば[1, 3, 5, 7, 9, 10, 20, 32, 41]という配列データが与えられた場合の四分位点を求めてみます。 第一四部位12arr = np.array([1, 3, 5, 7, 9, 10, 20, 32, 41])np.quantile(arr, 0.25) 出力15.0 第二四分位1np.quantile(arr, 0.5) 出力19.0 第三四分位1np.quantile(arr, 0.75) 出力120.0 四分位数の出力方法がわかったところで早速問題を解いていきたいと思います。 まずはレシート明細データフレーム(df_receipt)の売上金額(amount)を顧客ID(customer_id)毎に合計することを考えましょう。そのうえで合計金額の四分位点を求めていこうと思います。 グループごとの合計を求めるにはgroupbyとsumを用いればよかったですね。 忘れてしまった方は以下の記事を参照ください。 &gt;&gt; groupbyとsumの使い方を復習する 12df_sales_amount = df_receipt[['customer_id', 'amount']].groupby('customer_id').sum().reset_index()df_sales_amount 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 ZZ000000000000 123950038307 rows × 2 columns ここで四分位点を求めていきます。それぞれ、pctに代入していきます。 123pct25 = np.quantile(df_sales_amount['amount'], 0.25)pct50 = np.quantile(df_sales_amount['amount'], 0.5)pct75 = np.quantile(df_sales_amount['amount'], 0.75) 次に顧客ごとの売上合計金額が、 もし最小値以上第一四分位未満 →1もし第一四分位以上第二四分位未満 →2もし第二四分位以上第三四分位未満 →3もし第三四分位以上 →4 という処理を施していければと思います。 この処理を実施する関数pct_groupを作成します。 123456789def pct_group(x): if x &lt; pct25: return 1 elif pct25 &lt;= x &lt; pct50: return 2 elif pct50 &lt;= x &lt; pct75: return 3 elif pct75 &lt;= x: return 4 最終的に顧客ID、売上金額の合計とともに、カテゴリ値を表示させていきます。 カテゴリ値はpct_groupというカラムに含めることとします。 pct_groupに含める値はlambda関数を用いてデータを適用していきます。 12df_sales_amount['pct_group'] = df_sales_amount['amount'].apply(lambda x: pct_group(x))df_sales_amount 出力12345678910111213 customer_id amount pct_group0 CS001113000004 1298 21 CS001114000005 626 22 CS001115000010 3044 33 CS001205000004 1988 34 CS001205000006 3337 3... ... ... ...8302 CS051513000004 551 28303 CS051515000002 265 18304 CS052212000002 192 18305 CS052514000001 178 18306 ZZ000000000000 12395003 48307 rows × 3 columns これで完成です。 まとめ: pandas.DataFrame.quantileを用いた四分位数の算出方法を学びました本記事は、「【Python】四分位点を学ぶ | データサイエンス100本ノック【問55 回答】」というテーマでまとめました。 本記事で紹介した方法を元に、データサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"文系のための データサイエンスがわかる本\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51pFg1ZaJHL._SL500_.jpg\",\"\\/41SUCa0-1+L._SL500_.jpg\",\"\\/41tFUtTo5rL._SL500_.jpg\",\"\\/41zx+gmqJNL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4862807062\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%96%87%E7%B3%BB%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%20%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E6%9C%AC\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"Q5cG7\",\"s\":\"s\"}); リンク &gt;&gt; 第56問〜57問の回答はこちら","link":"/100knock-55/"},{"title":"【解説】正規化(z-score, Min-Max normalization)を実装 | データサイエンス100本ノック【問59〜60 回答】","text":"目次 この記事の対象者 第59問目: 標準化 第60問目: Min-Max正規化 まとめ: 正規化を学びました この記事の対象者 ・ データサイエンティストを目指している人 ・ 正規化とはなにかをコードを書きながら理解したい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第59問目: 標準化 P-059: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計し、合計した売上金額を平均0、標準偏差1に標準化して顧客ID、売上金額合計とともに表示せよ。標準化に使用する標準偏差は、不偏標準偏差と標本標準偏差のどちらでも良いものとする。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。結果は10件表示させれば良い。 まず「標準偏差」とは何かを解説します。 標準偏差とは、偏差の2乗の合計値の平均に平方根を取った値です。 ？？？と思った方のために分かりやすい例で解説します。 A B C D 合計 長さ 5 12 11 17 45 偏差(長さ-長さの平均)長さの平均=11.25 -6.25 0.75 -0.25 5.75 0 偏差の2乗 39.0625 0.5625 0.0625 33.0625 72.75 このようなデータフレームがあった場合、A、B、C、Dの長さの標準偏差は72.75を4で割った値(18.1875)の平方根をとった、4.26となります。 この値が何を表しているかというと、「AからDまでの値がどれだけバラバラなのか」を定量的に示しているのです。 このとき、平均値が0、標準偏差が1になるようにデータを変換することを、標準化(z-score normalization)と呼びます。 数式で書くと以下となります。(µは平均、σは標準偏差です。) x_{n e w}^{i}=\\frac{x^{i}-\\mu}{\\sigma}なんのために標準化をするのかというと、異なる種類のデータを1つの尺度にまとめるためです。 これを正規化といいます。 ここで扱うz-score normalizationというのは正規化の手法の１つといえます。 Pythonで標準化を行うにはsklearn.preprocessing.StandardScalerクラスを使用します。 早速本問を解きながら使い方を学んでいきましょう。 まずはdf_receiptの構造を確認します。 1df_receipt.head(5) 出力123456sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 問題文より、df_receiptのcustomer_idで”Z”から始まるものをqueryメソッドを用いて除外し、groupbyメソッドを用いてcustomer_idごとの売上金額(amount)の合計を算出します。 engine='pytnon'とreset_indexの付与を忘れずに行いましょう。 &gt;&gt; queryメソッドの復習をする &gt;&gt; groupbyメソッドの復習をする 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales_amount 出力1234567891011121314customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8301 CS051212000001 3368302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 rows × 2 columns 標準化を行うためにSrtandardScalerクラスのインスタンスを作成します。 &gt;&gt; クラスとインスタンスをシンプルに理解する 1scaler = preprocessing.StandardScaler() 作成したインスタンスを用いて標準化を行います。処理の方法は以下のコードのように、標準化に変換するインスタンス（変換モデル）にdf_sales_amount[['amount]]のデータを用いて学習させます。 学習はfitを使用します。 12scaler.fit(df_sales_amount[['amount']])# 出力&gt;&gt; StandardScaler() 変換モデルに基づいて標準化処理を行い、標準化したデータを新たに作成するamount_ssというカラムに格納します。 12df_sales_amount['amount_ss'] = scaler.transform(df_sales_amount[['amount']])df_sales_amount 出力12345678910111213 customer_id amount amount_ss0 CS001113000004 1298 -0.4593781 CS001114000005 626 -0.7063902 CS001115000010 3044 0.1824133 CS001205000004 1988 -0.2057494 CS001205000006 3337 0.290114... ... ... ...8301 CS051212000001 336 -0.8129888302 CS051513000004 551 -0.7339598303 CS051515000002 265 -0.8390868304 CS052212000002 192 -0.8659198305 CS052514000001 178 -0.8710658306 rows × 3 columns これで完了です。 第60問目: Min-Max正規化 P-060: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計し、合計した売上金額を最小値0、最大値1に正規化して顧客ID、売上金額合計とともに表示せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。結果は10件表示させれば良い。 最小値を0、最大値を1となるようにデータを変換することをMin-Max正規化と言います。 Min-Max正規化を行う場合は、sklearn.preprocessing.MinMaxScalerクラスを使用します。 数式で表現すると以下のようになります。 x_{n e w}^{i}=\\frac{x^{i}-x_{\\min }}{x_{\\max }-x_{\\min }}本問を解きながら使い方を学んでいきましょう。 まずは顧客IDがZから始まるものを除外し、売上金額(amount)を顧客ID(customer_id)ごとに合計したデータ算出します。 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales_amount 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8301 CS051212000001 3368302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 rows × 2 columns MinMaxScalerクラスのインスタンスを生成します。 1scaler = preprocessing.MinMaxScaler() 作成したインスがん（変換モデル）をamountデータを用いて学習させます。 12scaler.fit(df_sales_amount[['amount']])# 出力&gt;&gt; MinMaxScaler() MinMax正規化したデータを”amount_mm”というカラムに代入します。 12df_sales_amount['amount_mm'] = scaler.transform(df_sales_amount[['amount']])df_sales_amount.head(10) 出力1234567891011 customer_id amount amount_mm0 CS001113000004 1298 0.0533541 CS001114000005 626 0.0241572 CS001115000010 3044 0.1292143 CS001205000004 1988 0.0833334 CS001205000006 3337 0.1419455 CS001211000025 456 0.0167716 CS001212000027 448 0.0164237 CS001212000031 296 0.0098198 CS001212000046 228 0.0068659 CS001212000070 456 0.016771 これで完成です。 まとめ: 正規化を学びました本記事は、「【Python】正規化(z-score, Min-Max normalization)を実装 | データサイエンス100本ノック【問59〜60 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 &gt;&gt; [続き]第61〜62問の回答・解説を確認する","link":"/100knock-59-60/"},{"title":"【解説】対数化の実装方法 | データサイエンス100本ノック【問61〜62 回答】","text":"目次 この記事の対象者 第61問目: 常用対数化 第62問目: 自然対数化 まとめ: 対数化を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ 対数化についてPythonのコードを書きながら理解したい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第61問目: 常用対数化 P-061: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計し、合計した売上金額を常用対数化（底=10）して顧客ID、売上金額合計とともに表示せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。結果は10件表示させれば良い。 常用対数に変換する場合は、numpy.log10を使用します。 常用対数化の方法12345678import numpy as npimport pandas as pdcolumns = ['product', 'price']data = [['pen', 200], ['book', 500], ['pen', 120]]df = pd.DataFrame(data, columns=columns)np.log10(df['price']) 出力12340 2.3010301 2.6989702 2.079181Name: price, dtype: float64 常用対数化の方法が理解できたところで問題を解いていきましょう。 まずはdf_receiptの構造を確認しましょう 1df_receipt.head(5) 出力1234567sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 問題文より、df_receiptの売上金額(amount)を顧客ID(customer_id)毎に合計値を算出します。この際、顧客IDが”Z”で始まるものを除外しておきます。 &gt;&gt; 検索結果に対するサブクエリとgroupbyメソッドを復習する 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales_amount 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8301 CS051212000001 3368302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 rows × 2 columns 売上金額(amount)を常用対数に変換し、amount_log10というカラムに代入します。 12df_sales_amount['amount_log10'] = np.log10(df_sales_amount['amount'])df_sales_amount.head(10) 出力1234567891011customer_id amount amount_log100 CS001113000004 1298 3.1132751 CS001114000005 626 2.7965742 CS001115000010 3044 3.4834453 CS001205000004 1988 3.2984164 CS001205000006 3337 3.5233565 CS001211000025 456 2.6589656 CS001212000027 448 2.6512787 CS001212000031 296 2.4712928 CS001212000046 228 2.3579359 CS001212000070 456 2.658965 これで完了ではありますが、常用対数化には注意点が必要です。 それは常用対数化するデータの中に0が含まれている場合の対応です。 常用対数化する際に$log_{10} (0)$は計算できないのです。高校数学で学ぶ真数条件というものですね。 これに対処するために、一般的には1を加える対応を行います。なぜ１なのかという理由は特に存在しないようです。 真数条件よりデータに1を加える12df_sales_amount['amount_log10'] = np.log10(df_sales_amount['amount']+1)df_sales_amount.head(10) 出力1234567891011 customer_id amount amount_log100 CS001113000004 1298 3.1136091 CS001114000005 626 2.7972682 CS001115000010 3044 3.4835873 CS001205000004 1988 3.2986354 CS001205000006 3337 3.5234865 CS001211000025 456 2.6599166 CS001212000027 448 2.6522467 CS001212000031 296 2.4727568 CS001212000046 228 2.3598359 CS001212000070 456 2.659916 これで完成です。 第62問目: 自然対数化 P-062: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計し、合計した売上金額を自然対数化(底=e）して顧客ID、売上金額合計とともに表示せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。結果は10件表示させれば良い。 自然対数に変換するには、numpy.logを使用すれば可能です。 12345678import numpy as npimport pandas as pdcolumns = ['product', 'price']data = [['pen', 200], ['book', 500], ['pen', 120], ['book', 500], ['book', 0]]df = pd.DataFrame(data, columns=columns)np.log(df['price']) 出力1234560 5.2983171 6.2146082 4.7874923 6.2146084 -infName: price, dtype: float64 自然対数の場合も、データに0が含まれる場合は、変換できるように+1をします では問題を解いていきます。 前門と同様に売上金額を顧客IDごとに合計したデータを算出します。 12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python').groupby('customer_id').agg({'amount': 'sum'}).reset_index()df_sales_amount 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8301 CS051212000001 3368302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 rows × 2 columns 売上金額を自然対数に変換し、amount_logeという新たなカラムに代入します。 12df_sales_amount['amount_loge'] = np.log(df_sales_amount['amount']+1)df_sales_amount.head(10) 出力1234567891011 customer_id amount amount_loge0 CS001113000004 1298 7.1693501 CS001114000005 626 6.4409472 CS001115000010 3044 8.0212563 CS001205000004 1988 7.5953874 CS001205000006 3337 8.1131275 CS001211000025 456 6.1246836 CS001212000027 448 6.1070237 CS001212000031 296 5.6937328 CS001212000046 228 5.4337229 CS001212000070 456 6.124683 これで完成です。 まとめ: 対数化を学びました。本記事は、「【解説】対数化の実装方法 | データサイエンス100本ノック【問61〜62 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 AI・データサイエンティストのスキルを高めたい場合は、これまでの受講者数30,000人以上！【ikus.ai】にて無料カウンセリングを受けるのが良いと思います。 &gt;&gt; 無料カウンセリング予約はこちら なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜 &gt;&gt; [続き]第63〜65問の回答・解説を確認する","link":"/100knock-61-62/"},{"title":"【解説】データサイエンス100本ノック【問63〜65 回答】","text":"目次 この記事の対象者 第63問目: 引き算 第64問目: 平均値の計算(meanの使い方) 第65問目: 小数点の切り捨て(numpy.floorの使い方) まとめ: 平均値(mean)と小数点の切り捨て方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ データフレームの各カラム同士の四則演算の方法を理解したい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第63問目: 引き算 P-063: 商品データフレーム（df_product）の単価（unit_price）と原価（unit_cost）から、各商品の利益額を算出せよ。結果は10件表示させれば良い。 まずはdf_productの構造を確認します。 1df_product.head(5) 出力123456 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.0 各商品の利益額は、単価から原価を引けばよいですね。 unit_profitというカラムに、利益額を算出します。 この際第53問目: データ型変換(str→int)と2値化で学んだ通り、演算する前に明示的にコピーを用いていることを宣言しないとWarningが出てしまいます。明示的にcopy()を用いてコピーであることを宣言します。 123df_tmp = df_product.copy()df_tmp['unit_profit'] = df_tmp['unit_price'] - df_tmp['unit_cost']df_tmp.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost unit_profit0 P040101001 04 0401 040101 198.0 149.0 49.01 P040101002 04 0401 040101 218.0 164.0 54.02 P040101003 04 0401 040101 230.0 173.0 57.03 P040101004 04 0401 040101 248.0 186.0 62.04 P040101005 04 0401 040101 268.0 201.0 67.05 P040101006 04 0401 040101 298.0 224.0 74.06 P040101007 04 0401 040101 338.0 254.0 84.07 P040101008 04 0401 040101 420.0 315.0 105.08 P040101009 04 0401 040101 498.0 374.0 124.09 P040101010 04 0401 040101 580.0 435.0 145.0 これで完成です。 第64問目: 平均値の計算(meanの使い方) P-064: 商品データフレーム（df_product）の単価（unit_price）と原価（unit_cost）から、各商品の利益率の全体平均を算出せよ。 ただし、単価と原価にはNULLが存在することに注意せよ。 平均値は第34問目: 検索結果に対するサブクエリで学んだ通りmeanを用いることで算出できます。 利益率の計算は(単価-原価)/単価で算出することが出来ます。 まずは利益率を算出してunit_profit_rateという新たなカラムに算出しましょう。 123df_tmp = df_product.copy()df_tmp['unit_profit_rate'] = (df_tmp['unit_price'] - df_tmp['unit_cost'])/df_tmp['unit_price']df_tmp 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost unit_profit_rate0 P040101001 04 0401 040101 198.0 149.0 0.2474751 P040101002 04 0401 040101 218.0 164.0 0.2477062 P040101003 04 0401 040101 230.0 173.0 0.2478263 P040101004 04 0401 040101 248.0 186.0 0.2500004 P040101005 04 0401 040101 268.0 201.0 0.250000... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 0.25000010026 P091503002 09 0915 091503 680.0 510.0 0.25000010027 P091503003 09 0915 091503 1080.0 810.0 0.25000010028 P091503004 09 0915 091503 1130.0 848.0 0.24955810029 P091503005 09 0915 091503 1280.0 960.0 0.25000010030 rows × 7 columns その上でunit_profit_rateの平均値を算出します。 12df_mean = df_tmp['unit_profit_rate'].mean()df_mean 出力10.24911389885176904 「単価と原価にはNULLが存在することに注意せよ」という部分ですが、これはNULLが一つでも含まれていた場合に平均値の算出ができなくならないようにしましょう、ということです。NULLが含まれていてもそれを無視して平均値を算出させる場合は、mean()とするかmean(skipna=True)とすれば良いです。※meanは引数にskipnaを指定しない場合はデフォルトでTrueに設定されます。 試しに、mean(skipna=False)としてみましょう。 試しにmean(skipna12df_mean = df_tmp['unit_profit_rate'].mean(skipna=False)df_mean 出力1nan このようにデータの中にNULLが含まれているデータの平均値を取る際に、mean(skipna=False)とするとnanを返却し、平均値を計算出来ません。 NULLを無視する場合はmean()とするかmean(skipna=True)としましょう。 第65問目: 小数点の切り捨て(numpy.floorの使い方) P-065: 商品データフレーム（df_product）の各商品について、利益率が30%となる新たな単価を求めよ。ただし、1円未満は切り捨てること。そして結果を10件表示させ、利益率がおよそ30％付近であることを確認せよ。ただし、単価（unit_price）と原価（unit_cost）にはNULLが存在することに注意せよ。 少数の切り捨てを行うには、numpy.floor関数を使用します。 小数点の切り捨ては、math.floor関数を用いても良いですが、SeriesデータにNaNが存在するとエラーになってしまいます。 本問ではnumpy.floorを用いて算出していきます。 123df_tmp = df_product.copy()df_tmp['new_price'] = np.floor(df_tmp['unit_cost']/0.7)df_tmp 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price0 P040101001 04 0401 040101 198.0 149.0 212.01 P040101002 04 0401 040101 218.0 164.0 234.02 P040101003 04 0401 040101 230.0 173.0 247.03 P040101004 04 0401 040101 248.0 186.0 265.04 P040101005 04 0401 040101 268.0 201.0 287.0... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 300.010026 P091503002 09 0915 091503 680.0 510.0 728.010027 P091503003 09 0915 091503 1080.0 810.0 1157.010028 P091503004 09 0915 091503 1130.0 848.0 1211.010029 P091503005 09 0915 091503 1280.0 960.0 1371.010030 rows × 7 columns new_profit_rateに改めて算出した利益率を代入し、10件出力することで30%付近になっていることを確認します。 12df_tmp['new_profit_rate'] = (df_tmp['new_price'] - df_tmp['unit_cost'])/df_tmp['new_price']df_tmp 出力1234567891011121314product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price new_profit_rate0 P040101001 04 0401 040101 198.0 149.0 212.0 0.2971701 P040101002 04 0401 040101 218.0 164.0 234.0 0.2991452 P040101003 04 0401 040101 230.0 173.0 247.0 0.2995953 P040101004 04 0401 040101 248.0 186.0 265.0 0.2981134 P040101005 04 0401 040101 268.0 201.0 287.0 0.299652... ... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 300.0 0.30000010026 P091503002 09 0915 091503 680.0 510.0 728.0 0.29945110027 P091503003 09 0915 091503 1080.0 810.0 1157.0 0.29991410028 P091503004 09 0915 091503 1130.0 848.0 1211.0 0.29975210029 P091503005 09 0915 091503 1280.0 960.0 1371.0 0.29978110030 rows × 8 columns new_profit_rateの結果を見ると、すべての値が30%付近に収まっていることが確認できました。 まとめ: 平均値(mean)と小数点の切り捨て方法を学びました。本記事は、「【解説】データサイエンス100本ノック【問63〜65 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 AI・データサイエンティストのスキルを高めたい場合は、これまでの受講者数30,000人以上！【ikus.ai】にて無料カウンセリングを受けるのが良いと思います。 &gt;&gt; 無料カウンセリング予約はこちら なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-63-65/"},{"title":"【解説】データサイエンス100本ノック【問69回答】","text":"目次 データサイエンス100本ノックの始め方 第69問目: 集計と結果の表示 まとめ: データサイエンス100本ノックの69問目の解法を説明しました データサイエンス100本ノックの始め方データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第69問目: 集計と結果の表示 P-069: レシート明細データフレーム（df_receipt）と商品データフレーム（df_product）を結合し、顧客毎に全商品の売上金額合計と、カテゴリ大区分（category_major_cd）が”07”（瓶詰缶詰）の売上金額合計を計算の上、両者の比率を求めよ。抽出対象はカテゴリ大区分”07”（瓶詰缶詰）の購入実績がある顧客のみとし、結果は10件表示させればよい。 まずは、レシート明細データフレーム(df_receipt)と商品データフレーム(df_product)の構造を確認します。 df_receiptの構造を確認1df_receipt.head(5) 出力123456 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 df_productの構造を確認1df_product.head(5) 出力123456 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.0 両者のデータフレームの結合を考えます。mergeを使うのかconcatのどちらを使うのかを判断するために、２つのデータフレームに共通的なカラムが存在するかを確認します。 mergeとconcatの解説はこちら 共通的なカラムの存在を確認する1234df_receipt_columns = df_receipt.columnsdf_product_columns = df_product.columnsdf_and = set(df_receipt_columns) &amp; set(df_product_columns)df_and 出力1{'product_cd'} 共通的なカラムとしてproduct_cdが存在していることがわかったためmergeを用いて結合します。 その上で顧客ごとに全商品の売上金額の合計を算出します。 内部結合とは何かを確認する mergeを用いて内部結合12df_tmp_1 = pd.merge(df_receipt, df_product, how='inner', on='product_cd').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_tmp_1 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 ZZ000000000000 123950038307 rows × 2 columns 次にcategory_major_cdが07となっているデータをqueryメソッドを用いて抽出します。 queryメソッドの使い方を確認する queryメソッドでcategory_mafor_cdが07となっているデータを抽出12df_product_07 = df_product.query('category_major_cd == &quot;07&quot;')df_product_07.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost1609 P070101001 07 0701 070101 38.0 29.01610 P070101002 07 0701 070101 45.0 34.01611 P070101003 07 0701 070101 48.0 36.01612 P070101004 07 0701 070101 55.0 41.01613 P070101005 07 0701 070101 70.0 53.01614 P070101006 07 0701 070101 75.0 56.01615 P070101007 07 0701 070101 75.0 56.01616 P070101008 07 0701 070101 78.0 59.01617 P070101009 07 0701 070101 78.0 59.01618 P070101010 07 0701 070101 80.0 60.0 df_receiptとdf_product_07内部結合し顧客毎の売上金額の合計値を算出します。これで瓶詰缶詰の売上金額合計のデータフレームが作成されます。 df_receiptとdf_product_07内部結合し顧客毎の売上金額の合計値を算出12df_tmp_2 = pd.merge(df_receipt, df_product_07, how='inner', on='product_cd').groupby('customer_id').agg({'amount':'sum'}).reset_index()df_tmp_2.head(10) 出力1234567891011 customer_id amount0 CS001113000004 12981 CS001114000005 4862 CS001115000010 26943 CS001205000004 3464 CS001205000006 20045 CS001212000027 2006 CS001212000031 2967 CS001212000046 1088 CS001212000070 3089 CS001213000018 145 df_tmp_1とdf_tmp_2を共通カラムをcustomer_idに指定して内部結合を行います。 df_tmp_1とdf_tmp_2を共通カラムをcustomer_idに指定して内部結合12df_tmp_3 = pd.merge(df_tmp_1, df_tmp_2, how='inner', on='customer_id')df_tmp_3 出力12345678910111213 customer_id amount_x amount_y0 CS001113000004 1298 12981 CS001114000005 626 4862 CS001115000010 3044 26943 CS001205000004 1988 3464 CS001205000006 3337 2004... ... ... ...6860 CS051212000001 336 686861 CS051513000004 551 2336862 CS052212000002 192 1026863 CS052514000001 178 686864 ZZ000000000000 12395003 69430096865 rows × 3 columns 出力結果のうち、amount_xとなっているのが、全商品の売上金額合計で、amount_yが瓶詰缶詰の売上金額合計になります。 両者の比率を算出し、rate_07という新たなカラムに格納します。 12df_tmp_3['rate_07'] = df_tmp_3['amount_y'] / df_tmp_3['amount_x']df_tmp_3.head(10) 出力1234567891011customer_id amount_x amount_y rate_070 CS001113000004 1298 1298 1.0000001 CS001114000005 626 486 0.7763582 CS001115000010 3044 2694 0.8850203 CS001205000004 1988 346 0.1740444 CS001205000006 3337 2004 0.6005395 CS001212000027 448 200 0.4464296 CS001212000031 296 296 1.0000007 CS001212000046 228 108 0.4736848 CS001212000070 456 308 0.6754399 CS001213000018 243 145 0.596708 これで完成です。 まとめ: データサイエンス100本ノックの69問目の解法を説明しました本記事は、「【解説】データサイエンス100本ノック【問69回答】」というテーマでまとめました。 これまで学んできたmergeやqueryといった各種メソッドの使い方を復習する位置づけの問題だったかと思います。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-69/"},{"title":"【解説】データサイエンス100本ノック【問66〜68 回答】","text":"目次 この記事の対象者 第66問目: 小数の四捨五入 第67問目: 小数の切り上げ 第68問目: 小数の切り捨て まとめ: 小数の扱いを学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ 小数の扱いについて理解したい人 以降はデータサイエンス100本ノックの問題を題材にしながら学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第66問目: 小数の四捨五入 P-066: 商品データフレーム（df_product）の各商品について、利益率が30%となる新たな単価を求めよ。今回は、1円未満を四捨五入すること（0.5については偶数方向の丸めで良い）。そして結果を10件表示させ、利益率がおよそ30％付近であることを確認せよ。ただし、単価（unit_price）と原価（unit_cost）にはNULLが存在することに注意せよ。 小数の四捨五入をround関数で行う場合、SeriesデータにNaNが存在するとエラーになります。 NaNが存在する場合は、numpy.round関数を使用します。 まずはdf_productのコピーをdf_tmpに格納します。 1df_tmp = df_product.copy() 次に利益率が30%となる価格をnew_priceカラムに代入します。 12df_tmp['new_price'] = np.round(df_tmp['unit_cost']/0.7)df_tmp 出力1234567891011121314product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price0 P040101001 04 0401 040101 198.0 149.0 213.01 P040101002 04 0401 040101 218.0 164.0 234.02 P040101003 04 0401 040101 230.0 173.0 247.03 P040101004 04 0401 040101 248.0 186.0 266.04 P040101005 04 0401 040101 268.0 201.0 287.0... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 300.010026 P091503002 09 0915 091503 680.0 510.0 729.010027 P091503003 09 0915 091503 1080.0 810.0 1157.010028 P091503004 09 0915 091503 1130.0 848.0 1211.010029 P091503005 09 0915 091503 1280.0 960.0 1371.010030 rows × 7 columns new_priceで利益率を算出し、new_profit_rateカラムに代入します。 出力12df_tmp['new_profit_rate'] = (df_tmp['new_price'] - df_tmp['unit_cost']) / df_tmp['new_price']df_tmp.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price new_profit_rate0 P040101001 04 0401 040101 198.0 149.0 213.0 0.3004691 P040101002 04 0401 040101 218.0 164.0 234.0 0.2991452 P040101003 04 0401 040101 230.0 173.0 247.0 0.2995953 P040101004 04 0401 040101 248.0 186.0 266.0 0.3007524 P040101005 04 0401 040101 268.0 201.0 287.0 0.2996525 P040101006 04 0401 040101 298.0 224.0 320.0 0.3000006 P040101007 04 0401 040101 338.0 254.0 363.0 0.3002757 P040101008 04 0401 040101 420.0 315.0 450.0 0.3000008 P040101009 04 0401 040101 498.0 374.0 534.0 0.2996259 P040101010 04 0401 040101 580.0 435.0 621.0 0.299517 これで完成です。 第67問目: 小数の切り上げ P-067: 商品データフレーム（df_product）の各商品について、利益率が30%となる新たな単価を求めよ。今回は、1円未満を切り上げること。そして結果を10件表示させ、利益率がおよそ30％付近であることを確認せよ。ただし、単価（unit_price）と原価（unit_cost）にはNULLが存在することに注意せよ。 小数の切り上げをmath.ceil関数で行う場合、SeriesデータにNaNが存在する場合エラーとなります。 NaNが存在する場合は、numpy.ceil関数を使用します。 まずはdf_productのコピーを作成し、利益率が30%となる価格をnew_priceカラムに代入します。 123df_tmp = df_product.copy()df_tmp['new_price'] = np.ceil(df_tmp['unit_cost'] / 0.7)df_tmp 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price0 P040101001 04 0401 040101 198.0 149.0 213.01 P040101002 04 0401 040101 218.0 164.0 235.02 P040101003 04 0401 040101 230.0 173.0 248.03 P040101004 04 0401 040101 248.0 186.0 266.04 P040101005 04 0401 040101 268.0 201.0 288.0... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 300.010026 P091503002 09 0915 091503 680.0 510.0 729.010027 P091503003 09 0915 091503 1080.0 810.0 1158.010028 P091503004 09 0915 091503 1130.0 848.0 1212.010029 P091503005 09 0915 091503 1280.0 960.0 1372.010030 rows × 7 columns new_priceで利益率を算出し、new_profit_rateカラムに代入します。 123df_tmp = df_product.copy()df_tmp['new_price'] = np.ceil(df_tmp['unit_cost'] / 0.7)df_tmp 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price0 P040101001 04 0401 040101 198.0 149.0 213.01 P040101002 04 0401 040101 218.0 164.0 235.02 P040101003 04 0401 040101 230.0 173.0 248.03 P040101004 04 0401 040101 248.0 186.0 266.04 P040101005 04 0401 040101 268.0 201.0 288.0... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 300.010026 P091503002 09 0915 091503 680.0 510.0 729.010027 P091503003 09 0915 091503 1080.0 810.0 1158.010028 P091503004 09 0915 091503 1130.0 848.0 1212.010029 P091503005 09 0915 091503 1280.0 960.0 1372.010030 rows × 7 columns new_priceで利益率を算出し、new_profit_rateカラムに代入します。 12df_tmp['new_profit_rate'] = (df_tmp['new_price'] - df_tmp['unit_cost']) / df_tmp['new_price']df_tmp.head(10) 出力1234567891011product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost new_price new_profit_rate0 P040101001 04 0401 040101 198.0 149.0 213.0 0.3004691 P040101002 04 0401 040101 218.0 164.0 235.0 0.3021282 P040101003 04 0401 040101 230.0 173.0 248.0 0.3024193 P040101004 04 0401 040101 248.0 186.0 266.0 0.3007524 P040101005 04 0401 040101 268.0 201.0 288.0 0.3020835 P040101006 04 0401 040101 298.0 224.0 320.0 0.3000006 P040101007 04 0401 040101 338.0 254.0 363.0 0.3002757 P040101008 04 0401 040101 420.0 315.0 451.0 0.3015528 P040101009 04 0401 040101 498.0 374.0 535.0 0.3009359 P040101010 04 0401 040101 580.0 435.0 622.0 0.300643 これで完成です。 第68問目: 小数の切り捨て P-068: 商品データフレーム（df_product）の各商品について、消費税率10%の税込み金額を求めよ。 1円未満の端数は切り捨てとし、結果は10件表示すれば良い。ただし、単価（unit_price）にはNULLが存在することに注意せよ。 少数の切り捨てをmath.froor関数で行う場合、SeriesデータにNaNが存在する場合エラーとなってしまいます。 NaNが存在する場合は、numpy.floor関数を使用します。 まずはdf_productのコピーを作成し、df_tmpに代入します。 1df_tmp = df_product.copy() 税込価格をprice_taxカラムに代入します。 12df_tmp['price_tax'] = np.floor(df_tmp['unit_price'] * 1.1)df_tmp.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost price_tax0 P040101001 04 0401 040101 198.0 149.0 217.01 P040101002 04 0401 040101 218.0 164.0 239.02 P040101003 04 0401 040101 230.0 173.0 253.03 P040101004 04 0401 040101 248.0 186.0 272.04 P040101005 04 0401 040101 268.0 201.0 294.05 P040101006 04 0401 040101 298.0 224.0 327.06 P040101007 04 0401 040101 338.0 254.0 371.07 P040101008 04 0401 040101 420.0 315.0 462.08 P040101009 04 0401 040101 498.0 374.0 547.09 P040101010 04 0401 040101 580.0 435.0 638.0 こちらで完成です。 まとめ: 小数の扱いを学びました。本記事は、「【解説】データサイエンス100本ノック【問66〜68 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 AI・データサイエンティストのスキルを高めたい場合は、これまでの受講者数30,000人以上！【ikus.ai】にて無料カウンセリングを受けるのが良いと思います。 &gt;&gt; 無料カウンセリング予約はこちら なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-66-68/"},{"title":"【解説】データサイエンス100本ノック【問75〜76 回答】","text":"目次 第75問目: サンプリング（ランダムにサンプリング） 第76問目; サンプリング(層化) まとめ: データサイエンス100本ノック【問75〜76 回答】でサンプリングを学びました データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第75問目: サンプリング（ランダムにサンプリング） P-075: 顧客データフレーム（df_customer）からランダムに1%のデータを抽出し、先頭から10件データを抽出せよ。 データフレームの行や列からランダムにデータを抽出する場合、sampleメソッドを使用します。 引数としてfracを用いて、ランダムに何％抽出するかを指定することができます。 random_stateは、乱数を制御するパラメータで、実行結果を常に同じにするための設定になります。特に指定がなければ任意の数値にすればOKです。 以下、サンプルコードです。 12345import pandas as pdsample_data = list(range(100))df = pd.DataFrame(sample_data)df.sample(frac=0.1, random_state=0) 出力123456789101112026 2686 862 255 5575 7593 9316 1673 7354 5495 95 この前提知識をもとに、本問を解いていきたいと思います。 今回は、ランダムに1%のデータを抽出するため、frac=0.01とします。 12df_result = df_customer.sample(frac=0.01, random_state=0)df_result.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd13517 CS005513000263 大野 はるみ 1 女性 1959-02-13 60 165-0035 東京都中野区白鷺********** S13005 20170420 0-00000000-013442 CS026513000233 本上 愛梨 1 女性 1965-02-28 54 253-0022 神奈川県茅ヶ崎市松浪********** S14026 20150523 2-20090503-510188 CS009301000001 目黒 慶二 0 男性 1984-08-13 34 152-0035 東京都目黒区自由が丘********** S13009 20150323 0-00000000-013413 CS034612000080 成海 里奈 1 女性 1954-08-12 64 213-0013 神奈川県川崎市高津区末長********** S14034 20141208 0-00000000-021900 CS028314000040 堤 夏希 1 女性 1986-08-03 32 246-0038 神奈川県横浜市瀬谷区宮沢********** S14028 20151105 3-20080524-59066 CS034413000147 平尾 恵子 1 女性 1958-01-16 61 211-0013 神奈川県川崎市中原区上平間********** S14034 20160121 4-20080414-54934 CS001312000261 波多野 恵梨香 1 女性 1987-04-07 31 210-0022 神奈川県川崎市川崎区池田********** S13001 20160502 0-00000000-05129 CS030503000037 梅本 悟志 9 不明 1964-09-07 54 272-0823 千葉県市川市東菅野********** S12030 20150529 0-00000000-0641 CS038705000005 加藤 芳正 0 男性 1940-03-18 79 279-0004 千葉県浦安市猫実********** S13038 20151130 0-00000000-016973 CS031414000049 大後 めぐみ 1 女性 1972-06-07 46 151-0071 東京都渋谷区本町********** S13031 20150427 C-20100827-E これで完成です。 第76問目; サンプリング(層化) P-076: 顧客データフレーム（df_customer）から性別（gender_cd）の割合に基づきランダムに10%のデータを層化抽出データし、性別ごとに件数を集計せよ。 層化抽出というのは、元のデータを同じ分布でランダムに抽出することを言います。 例えば、果物グループのデータがデータ全体の8割、野菜グループのデータがデータ全体の2割を締めていたとしましょう。 データからランダムに5つのデータを抽出する時に、果物グループのデータを4つ（8割）、野菜グループのデータを1つ(2割)抽出するようにするイメージです。 層化抽出は、sklearn.model_selection.train_test_split関数を使用します。 サンプルデータを用いて実際にコードを書きながら使い方を確認してみましょう。 まずはsampleメソッドを使用してランダムに抽出してみます。 1234567import pandas as pdcolumns = ['name', 'group']data = [['banana', 0], ['apple', 0], ['mango', 0], ['grape', 0], ['tomato', 1], ['melon', 0], ['peach', 0], ['water-melon', 0], ['cherry', 0], ['broccoli', 1]]df = pd.DataFrame(data, columns=columns)df.sample(frac=0.5, random_state=0) 出力123456 name group2 mango 08 cherry 04 tomato 19 broccoli 11 apple 0 このように元データと同じ分布でランダムに抽出ができません。 次に層化抽出を行ってみます。 12_, df_tmp = train_test_split(df, test_size=0.5, stratify=df['group'], random_state=0)df_tmp 出力123456 name group5 melon 00 banana 06 peach 09 broccoli 13 grape 0 この層化抽出は、機械学習を行う際の訓練データとテストデータに分ける際によく使用されます。 例えば、訓練データとしてdf_train, テストデータとしてdf_testというデータフレームに分けたい場合は以下のような具合になります。 12df_train, df_test = train_test_split(df, test_size=0.5, stratify=df['group'], random_state=0)df_train 出力123456 name group2 mango 08 cherry 04 tomato 17 water-melon 01 apple 0 1df_test 出力123456 name group5 melon 00 banana 06 peach 09 broccoli 13 grape 0 ここまでの前提知識を踏まえて問題を解いていきましょう。 12_, df_tmp = train_test_split(df_customer, test_size=0.1, stratify=df_customer['gender_cd'], random_state=0)df_tmp 出力1234567891011121314customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd1345 CS016513000124 緒方 薫 1 女性 1959-05-14 59 184-0014 東京都小金井市貫井南町********** S13016 20150313 7-20100118-95763 CS040402000021 越智 輝信 0 男性 1975-10-12 43 226-0016 神奈川県横浜市緑区霧が丘********** S14040 20151113 0-00000000-014039 CS004313000451 保坂 涼 1 女性 1985-02-05 34 165-0032 東京都中野区鷺宮********** S13004 20170630 0-00000000-09631 CS014515000248 亀山 恵梨香 1 女性 1962-09-30 56 264-0035 千葉県千葉市若葉区東寺山町********** S12014 20170801 0-00000000-02374 CS005412000415 西谷 コウ 1 女性 1970-06-24 48 166-0001 東京都杉並区阿佐谷北********** S13005 20180121 7-20100419-8... ... ... ... ... ... ... ... ... ... ... ...306 CS027213000025 米倉 朝香 1 女性 1978-11-11 40 167-0021 東京都杉並区井草********** S14027 20150707 0-00000000-01786 CS011511000019 永井 佳乃 1 女性 1959-04-07 59 211-0013 神奈川県川崎市中原区上平間********** S14011 20150314 3-20101004-316819 CS012613000093 塩田 美帆 1 女性 1956-09-06 62 231-0826 神奈川県横浜市中区本牧荒井********** S14012 20160212 3-20100802-33832 CS009315000193 小沼 さやか 1 女性 1985-01-06 34 158-0096 東京都世田谷区玉川台********** S13009 20170307 0-00000000-0753 CS031501000026 真鍋 耕司 0 男性 1965-10-02 53 150-0013 東京都渋谷区恵比寿********** S13031 20180227 0-00000000-02198 rows × 11 columns 問題文より、性別ごとに件数を集計します。 性別ごとの集計は、groupbyメソッドとaggメソッドでcountを指定すれば集計できます。 1df_tmp.groupby('gender_cd').agg({'customer_id' : 'count'}) 出力123456customer_idgender_cd 0 2981 17939 107 これで集計完了です。 まとめ: データサイエンス100本ノック【問75〜76 回答】でサンプリングを学びました本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-75-76/"},{"title":"【解説】データサイエンス100本ノック【問89〜90回答】","text":"目次 第89問目：データ分割（レコードデータの分割） 第90問目：データ分割（時系列データの分割） まとめ：データの分割を学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第89問目：データ分割（レコードデータの分割） P-089: 売上実績のある顧客に対し、予測モデル構築のため学習用データとテスト用データに分割したい。それぞれ8:2の割合でランダムにデータを分割せよ。 データを分割するには、sklearn.model_selection.train_test_split関数を使用します。 train_test_split関数は、pandas.Dataframeやnumpy.ndarrayなどに対してデータをランダムに分割することができます。また、データを分析する際には、再現性を担保するためにrandom_stateを使用します。このrandom_stateを指定することで、生成される乱数が同じになります。 train_test_split関数とrandom_stateについてはデータサイエンス100本ノックの第75問目でも扱っていますので、そちらも参照ください。 【解説】データサイエンス100本ノック【問75〜76 回答】 - omathin blog それでは早速学習用データとテスト用データに分割してみましょう。 まずは顧客ごとの売上金額合計を算出します。 12df_sales = df_receipt.groupby('customer_id').agg({'amount':'sum'}).reset_index()df_sales.head(10) 出力1234567891011 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 33375 CS001211000025 4566 CS001212000027 4487 CS001212000031 2968 CS001212000046 2289 CS001212000070 456 df_salesにある顧客のみをdf_customerから抽出することで、売上実績のある顧客を取り出します。 取り出し方は、内部結合を行えばOKです。 12df_tmp = pd.merge(df_customer, df_sales['customer_id'], how='inner', on='customer_id')df_tmp.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C1 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-22 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B3 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-54 CS011215000048 芦田 沙耶 1 女性 1992-02-01 27 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150228 C-20100421-95 CS040412000191 川井 郁恵 1 女性 1977-01-05 42 226-0021 神奈川県横浜市緑区北八朔町********** S14040 20151101 1-20091025-46 CS029415000023 梅田 里穂 1 女性 1976-01-17 43 279-0043 千葉県浦安市富士見********** S12029 20150610 D-20100918-E7 CS009315000023 皆川 文世 1 女性 1980-04-15 38 154-0012 東京都世田谷区駒沢********** S13009 20150319 5-20080322-18 CS035415000029 寺沢 真希 9 不明 1977-09-27 41 158-0096 東京都世田谷区玉川台********** S13035 20141220 F-20101029-F9 CS015315000033 福士 璃奈子 1 女性 1983-03-17 36 135-0043 東京都江東区塩浜********** S13015 20141024 4-20080219-3 問題の指定通り8:2の割合でランダムにデータを分割します。 123df_train, df_test = train_test_split(df_tmp, test_size=0.2, random_state=1)print('学習データ割合：', len(df_train) / len(df_tmp))print('テストデータ割合：', len(df_test) / len(df_tmp)) 出力12学習データ割合： 0.7999036840837949テストデータ割合： 0.20009631591620516 第90問目：データ分割（時系列データの分割） P-090: レシート明細データフレーム（df_receipt）は2017年1月1日〜2019年10月31日までのデータを有している。売上金額（amount）を月次で集計し、学習用に12ヶ月、テスト用に6ヶ月のモデル構築用データを3セット作成せよ。 まずはdf_receiptの構造を確認します。 1df_receipt.head(10) 出力1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 まずは、日付データであるsales_ymdと売上金額のamountを抽出します。 1df_tmp = df_receipt[['sales_ymd', 'amount']].copy() 月次で集計する必要があるので、西暦と月のみにし、sales_ymに代入します。 12df_tmp['sales_ym'] = df_tmp['sales_ymd'].astype('str').str[0:6]df_tmp.head(10) 出力123456789101112sales_ymd amount sales_ym0 20181103 158 2018111 20181118 81 2018112 20170712 170 2017073 20190205 25 2019024 20180821 90 2018085 20190605 138 2019066 20181205 30 2018127 20190922 128 2019098 20170504 770 2017059 20191010 680 201910 月ごとのamountを算出します。 12df_tmp = df_tmp.groupby('sales_ym').agg({'amount':'sum'}).reset_index()df_tmp.head(10) 出力1234567891011 sales_ym amount0 201701 9020561 201702 7644132 201703 9629453 201704 8475664 201705 8840105 201706 8942426 201707 9592057 201708 9548368 201709 9020379 201710 905739 ここからデータを分割していきます。学習用に12ヶ月分、テスト用に6ヶ月のデータを3セット用意します。3セット分なので、スライスで3つ分数値を直接書き込んで3セット用意しても良いですが、ここではデータを分割する関数を定義して処理していきます。 123456789def split_data(df, train_size, test_size, slide_window, start_point): train_start = start_point * slide_window test_start = train_start + train_size return df[train_start : test_start], df[test_start : test_start + test_size]df_train_1, df_test_1 = split_data(df_tmp, train_size=12, test_size=6, slide_window=6, start_point=0)df_train_2, df_test_2 = split_data(df_tmp, train_size=12, test_size=6, slide_window=6, start_point=1)df_train_3, df_test_3 = split_data(df_tmp, train_size=12, test_size=6, slide_window=6, start_point=2)print(df_train_3) 出力12345678910111213 sales_ym amount12 201801 94450913 201802 86412814 201803 94658815 201804 93709916 201805 100443817 201806 101232918 201807 105847219 201808 104579320 201809 97711421 201810 106993922 201811 96747923 201812 1016425 まとめ：データの分割を学びました。本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-89-90/"},{"title":"【解説】データサイエンス100本ノック【問91回答】","text":"目次 第91問目：不均衡データ(アンダーサンプリング) まとめ：アンダーサンプリングを学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第91問目：不均衡データ(アンダーサンプリング) P-091: 顧客データフレーム（df_customer）の各顧客に対し、売上実績のある顧客数と売上実績のない顧客数が1:1となるようにアンダーサンプリングで抽出せよ。 アンダーサンプリングとは、偏りがあるデータを均一にするアプローチです。 例えば全体のデータの数として100個あった時に、野菜のデータが80個、果物のデータが20個となっている場合が該当します。 この場合、果物のデータが20個あるので、野菜のデータも20個にしてあげることで、機械学習で分類モデルを作成する際のデータの偏りを解決します。 アンダーサンプリングを行う場合、imblearn.under_sampling.RandomUnderSamplerクラスを使用します。 https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html RandomUnderSamplerクラスのインスタンスを生成し、fit_sample(X, y)のようにすることで、yの値が均等になるようにアンダーサンプリングがXに対して行われます。 戻り値あ、アンダーサンプリングされたXとyになります。 簡単なサンプルコードで使い方を確認しましょう。 サンプル12345678910111213import pandas as pdfrom imblearn.under_sampling import RandomUnderSamplercolumns = ['product', 'price']data = [['pen', 200], ['book', 500], ['pen', 120], ['book', 500], ['book', 1200]]df = pd.DataFrame(data, columns=columns)target =[0, 0, 0, 1, 1]rs = RandomUnderSampler(random_state=71)df_sample, _ = rs.fit_resample(df, target)print(df_sample) 出力12345 product price0 pen 2001 pen 1202 book 5003 book 1200 問題に取り掛かります。まずはdf_customerの構造を確認します。 1df_customer.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 売上情報としてdf_receiptの構造も確認します。 1df_receipt.head(10) 出力1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 全体の流れとしては以下のような流れで処理を進めます。 顧客ごとの売上金額の合計を算出する 顧客情報に売上金額の合計を追加する 売上金額合計がない（NaN）のものは0とし、あるものは1とする。このデータは”buy_flg”カラムに結果を代入する アンダーサンプリングを実施。 まずは顧客ごとの売上金額の合計を算出します。顧客ごとの売上金額の合計は、groupbyメソッドを使えばよかったですね。 12df_tmp = df_receipt.groupby('customer_id').agg({'amount':'sum'}).reset_index()df_tmp.head(10) 出力1234567891011 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 33375 CS001211000025 4566 CS001212000027 4487 CS001212000031 2968 CS001212000046 2289 CS001212000070 456 顧客情報に売上金額の合計を追加していきます。 売上金額の合計を追加するには、mergeメソッドで左外部結合を実施します。 12df_tmp = pd.merge(df_customer, df_tmp, how='left', on='customer_id')df_tmp.head(10) 出力123456789101112customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd amount0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-0 NaN1 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-0 NaN2 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C 5088.03 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-0 NaN4 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 875.05 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-0 NaN6 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B 3122.07 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-0 NaN8 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-0 NaN9 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 868.0 売上金額の合計が無い（NaN）のものは0とし、あるものは1にします。 12df_tmp['buy_flg'] = df_tmp['amount'].apply(lambda x : 0 if np.isnan(x) else 1)df_tmp.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd amount buy_flg0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-0 NaN 01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-0 NaN 02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C 5088.0 13 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-0 NaN 04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 875.0 15 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-0 NaN 06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B 3122.0 17 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-0 NaN 08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-0 NaN 09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 868.0 1 アンダーサンプリングを実施していきます。 12345678print('アンダーサンプリング前')print('0の件数', len(df_tmp.query('buy_flg == 0')))print('1の件数', len(df_tmp.query('buy_flg == 1')))rs = RandomUnderSampler(random_state=1)df_sample, _ = rs.fit_resample(df_tmp, df_tmp.buy_flg)print('アンダーサンプリング後')print('0の件数', len(df_sample.query('buy_flg == 0')))print('1の件数', len(df_sample.query('buy_flg == 1'))) 出力123456アンダーサンプリング前0の件数 136651の件数 8306アンダーサンプリング後0の件数 83061の件数 8306 まとめ：アンダーサンプリングを学びました。本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-91/"},{"title":"【解説】データサイエンス100本ノック【問92〜93回答】","text":"目次 第92問目：正規化 第93問目：非正規化 まとめ：正規化・非正規化を学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第92問目：正規化 P-092: 顧客データフレーム（df_customer）では、性別に関する情報が非正規化の状態で保持されている。これを第三正規化せよ。 データの重複をなくし整合的にデータを取り扱える状態にすることを（データベースの）正規化と呼びます。なお、ここで取り扱っている正規化は、異なる種類のデータを1つの尺度にまとめるために行う正規化とは違います。 今回の問題で行うのは、第三正規化と呼ばれる処理です。 第三正規化とはカラム同士で依存関係を持たないようにデータベースの構造を設計することです。 正規化とは何かを具体的に知りたい方は、以下の記事を参照ください。 【5分で分かる】データモデルとデータベースの設計方法と関係性 - omathin blog 早速問題に取り掛かりたいと思います。まずはdf_customerの構造を確認します。 1df_customer.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 問題文に「性別に情報が非正規化状態になっている」と記載されているので、非正規化状態となっているカラムを確認します。 gender_cdとgenderという情報がありますが、仮にgenderを変更するとなった場合、gender_codeまで変更する必要が出てきてしまいます。 そのため、gender_cdとgenderは、依存関係にあるといえます。 どうすればよいかというと、依存関係を表すデータフレームを作成し、もともとのdf_customerからgenderカラムを削除すればOKです。 依存関係を表すデータフレームは、依存関係にあるカラムを取り出し、drop_duplicates()メソッドを使い、重複しているデータを削除すれば良いです。 【解説】データサイエンス100本ノック【問70〜74 回答】 - omathin blog 12df_gender = df_customer[['gender_cd', 'gender']].drop_duplicates()df_gender 出力1234 gender_cd gender0 1 女性1 9 不明5 0 男性 df_customerからgenderカラムを削除したデータフレーム(df_customer_s)を作詞します。 12df_customer_s = df_customer.drop(columns='gender')df_customer.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 これで完成です。 第93問目：非正規化 P-093: 商品データフレーム（df_product）では各カテゴリのコード値だけを保有し、カテゴリ名は保有していない。カテゴリデータフレーム（df_category）と組み合わせて非正規化し、カテゴリ名を保有した新たな商品データフレームを作成せよ。 この問題は、前問とは逆の操作を行います。 すなわち、正規化されている2つのデータフレームを結合します。 まずは、df_productとdf_catecoryの構造を確認しましょう。 1df_product 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.0... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.010026 P091503002 09 0915 091503 680.0 510.010027 P091503003 09 0915 091503 1080.0 810.010028 P091503004 09 0915 091503 1130.0 848.010029 P091503005 09 0915 091503 1280.0 960.010030 rows × 6 columns 1df_category 出力12345678910111213 category_major_cd category_major_name category_medium_cd category_medium_name category_small_cd category_small_name0 04 惣菜 0401 御飯類 040101 弁当類1 04 惣菜 0401 御飯類 040102 寿司類2 04 惣菜 0402 佃煮類 040201 魚介佃煮類3 04 惣菜 0402 佃煮類 040202 海草佃煮類4 04 惣菜 0402 佃煮類 040203 野菜佃煮類... ... ... ... ... ... ...223 09 洗剤 0914 ペットフード 091401 ペットフード224 09 洗剤 0914 ペットフード 091402 ペット用剤225 09 洗剤 0914 ペットフード 091403 ペット用具226 09 洗剤 0915 ＤＩＹ用品 091501 建築・塗装材料227 09 洗剤 0915 ＤＩＹ用品 091503 園芸用品228 rows × 6 columns df_productのcategory_small_cdに一致するdf_categoryのカテゴリ名をくっつけたいので、category_small_cdをキーに内部結合を行います。 【5分で分かる】結合演算とは | 内部結合と外部結合の違いを理解する - omathin blog 1234567df_product_full = pd.merge(df_product, df_category[['category_small_cd', 'category_major_name', 'category_medium_name', 'category_small_name']], how = 'inner', on = 'category_small_cd')df_product_full 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost category_major_name category_medium_name category_small_name0 P040101001 04 0401 040101 198.0 149.0 惣菜 御飯類 弁当類1 P040101002 04 0401 040101 218.0 164.0 惣菜 御飯類 弁当類2 P040101003 04 0401 040101 230.0 173.0 惣菜 御飯類 弁当類3 P040101004 04 0401 040101 248.0 186.0 惣菜 御飯類 弁当類4 P040101005 04 0401 040101 268.0 201.0 惣菜 御飯類 弁当類... ... ... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 洗剤 ＤＩＹ用品 園芸用品10026 P091503002 09 0915 091503 680.0 510.0 洗剤 ＤＩＹ用品 園芸用品10027 P091503003 09 0915 091503 1080.0 810.0 洗剤 ＤＩＹ用品 園芸用品10028 P091503004 09 0915 091503 1130.0 848.0 洗剤 ＤＩＹ用品 園芸用品10029 P091503005 09 0915 091503 1280.0 960.0 洗剤 ＤＩＹ用品 園芸用品10030 rows × 9 columns これで完成です。 まとめ：正規化・非正規化を学びました。本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-92-93/"},{"title":"【解説】データサイエンス100本ノック【問94〜100回答】","text":"目次 第94問目；CSV出力(ヘッダ有り、コード変換なし) 第95問目：CSV出力(ヘッダ有り、UTF-8からSJIS変換) 第96問目：CSV出力(ヘッダ無し、コード変換なし) 第97問目：CSV入力(ヘッダ有り、コード変換なし) 第98問目：CSV入力(ヘッダ無し、コード変換なし) 第99問目：TSV出力(ヘッダ有り、コード変換なし) 第100問目：TSV入力(ヘッダ有り、コード変換あり) まとめ:ファイルの入出力を学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第94問目；CSV出力(ヘッダ有り、コード変換なし) P-094: 先に作成したカテゴリ名付き商品データを以下の仕様でファイル出力せよ。なお、出力先のパスはdata配下とする。 ・ファイル形式はCSV（カンマ区切り）・ヘッダ有り・文字コードはUTF-8 第93問目で作成したdf_product_fullをcsvファイルとして出力させます。 データフレームをcsvファイルとして保存する場合、to_csvメソッドを使用します。 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html to_csvメソッドのheader引数では、ヘッダの有無はbool型で指定できます。 なおデフォルトではTrueとなっています。 index引数ではindexの有無もbool型で指定できます。（デフォルトはTrue） 文字コードは、encoding='utf-8'のように指定ができます。 本問を解きながら使い方を学びましょう。 1df_product_full.to_csv('./data/94.csv', encoding='UTF-8', index=False) dataフォルダの配下に94.csvというファイルが出力されているはずです。 第95問目：CSV出力(ヘッダ有り、UTF-8からSJIS変換) P-095: 先に作成したカテゴリ名付き商品データを以下の仕様でファイル出力せよ。なお、出力先のパスはdata配下とする。 ・ファイル形式はCSV（カンマ区切り）・ヘッダ有り・文字コードはCP932 データフレームをcsvファイルとして保存する際は、to_csvメソッドを使用すればよかったですね。 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html 93問目で作成したdf_product_fullを指定された仕様でファイル出力していきます。 1df_product_full.to_csv('./data/95.csv', encoding='CP932') dataフォルダ配下に95.csvというファイルが出力されているはずです。 第96問目：CSV出力(ヘッダ無し、コード変換なし) P-096: 先に作成したカテゴリ名付き商品データを以下の仕様でファイル出力せよ。なお、出力先のパスはdata配下とする。 ・ファイル形式はCSV（カンマ区切り）・ヘッダ無し・文字コードはUTF-8 93問目で作成したカテゴリ名月商品データ(df_product_full)を指定された仕様で出力します。 本問もこれまで同様to_csvメソッドを使用します。問題では指定されていませんが、indexは無しの形式で出力してみましょう。 1df_product_full.to_csv('./data/96.csv', header=False, encoding='UTF-8', index=False) これで完成です。 第97問目：CSV入力(ヘッダ有り、コード変換なし) P-097: 先に作成した以下形式のファイルを読み込み、データフレームを作成せよ。また、先頭10件を表示させ、正しくとりまれていることを確認せよ。 ・ファイル形式はCSV（カンマ区切り）・ヘッダ有り・文字コードはUTF-8 94問目で作成した94.csvファイルを読み込んでいきます。 csvファイルを読み込みpandas.DataFrameとする場合、pandas.read_csv関数を使用します。 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html read_csv関数のheader引数では、ヘッダの有無はbool型で指定できます。 デフォルトはTrueです。 文字コードは、encoding=’utf-8’のように指定が可能です 12df_tmp = pd.read_csv('./data/94.csv')df_tmp.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost category_major_name category_medium_name category_small_name0 P040101001 4 401 40101 198.0 149.0 惣菜 御飯類 弁当類1 P040101002 4 401 40101 218.0 164.0 惣菜 御飯類 弁当類2 P040101003 4 401 40101 230.0 173.0 惣菜 御飯類 弁当類3 P040101004 4 401 40101 248.0 186.0 惣菜 御飯類 弁当類4 P040101005 4 401 40101 268.0 201.0 惣菜 御飯類 弁当類5 P040101006 4 401 40101 298.0 224.0 惣菜 御飯類 弁当類6 P040101007 4 401 40101 338.0 254.0 惣菜 御飯類 弁当類7 P040101008 4 401 40101 420.0 315.0 惣菜 御飯類 弁当類8 P040101009 4 401 40101 498.0 374.0 惣菜 御飯類 弁当類9 P040101010 4 401 40101 580.0 435.0 惣菜 御飯類 弁当類 無事、csvデータを読み込むことができました。 第98問目：CSV入力(ヘッダ無し、コード変換なし) P-098: 先に作成した以下形式のファイルを読み込み、データフレームを作成せよ。また、先頭10件を表示させ、正しくとりまれていることを確認せよ。 ・ファイル形式はCSV（カンマ区切り）・ヘッダ無し・文字コードはUTF-8 96問目で作成した96.csvを読み込みます。 12df_tmp = pd.read_csv('./data/96.csv', header=None)df_tmp.head(10) 出力1234567891011 0 1 2 3 4 5 6 7 80 P040101001 4 401 40101 198.0 149.0 惣菜 御飯類 弁当類1 P040101002 4 401 40101 218.0 164.0 惣菜 御飯類 弁当類2 P040101003 4 401 40101 230.0 173.0 惣菜 御飯類 弁当類3 P040101004 4 401 40101 248.0 186.0 惣菜 御飯類 弁当類4 P040101005 4 401 40101 268.0 201.0 惣菜 御飯類 弁当類5 P040101006 4 401 40101 298.0 224.0 惣菜 御飯類 弁当類6 P040101007 4 401 40101 338.0 254.0 惣菜 御飯類 弁当類7 P040101008 4 401 40101 420.0 315.0 惣菜 御飯類 弁当類8 P040101009 4 401 40101 498.0 374.0 惣菜 御飯類 弁当類9 P040101010 4 401 40101 580.0 435.0 惣菜 御飯類 弁当類 無事、csvデータを読み込むことができました。 第99問目：TSV出力(ヘッダ有り、コード変換なし) P-099: 先に作成したカテゴリ名付き商品データを以下の仕様でファイル出力せよ。なお、出力先のパスはdata配下とする。 ・ファイル形式はTSV（タブ区切り）・ヘッダ有り・文字コードはUTF-8 TSVファイル出力もto_csvメソッドで行います。 tsvファイルとは、区切り文字が\\tのファイルです。 to_csvメソッドの区切り文字をsep='\\t'のように指定することで保存が可能です。 https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html 本問では93問目で作成したカテゴリ名月商品データdf_product_fullを、問題で指定された仕様でファイル出力を行います。 1df_product_full 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost category_major_name category_medium_name category_small_name0 P040101001 04 0401 040101 198.0 149.0 惣菜 御飯類 弁当類1 P040101002 04 0401 040101 218.0 164.0 惣菜 御飯類 弁当類2 P040101003 04 0401 040101 230.0 173.0 惣菜 御飯類 弁当類3 P040101004 04 0401 040101 248.0 186.0 惣菜 御飯類 弁当類4 P040101005 04 0401 040101 268.0 201.0 惣菜 御飯類 弁当類... ... ... ... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.0 洗剤 ＤＩＹ用品 園芸用品10026 P091503002 09 0915 091503 680.0 510.0 洗剤 ＤＩＹ用品 園芸用品10027 P091503003 09 0915 091503 1080.0 810.0 洗剤 ＤＩＹ用品 園芸用品10028 P091503004 09 0915 091503 1130.0 848.0 洗剤 ＤＩＹ用品 園芸用品10029 P091503005 09 0915 091503 1280.0 960.0 洗剤 ＤＩＹ用品 園芸用品10030 rows × 9 columns 1df_product_full.to_csv('./data/99.tsv', sep='\\t', encoding='UTF-8', index=False) dataフォルダ配下に99.tsvというファイルが作成されたと思います。 第100問目：TSV入力(ヘッダ有り、コード変換あり) P-100: 先に作成した以下形式のファイルを読み込み、データフレームを作成せよ。また、先頭10件を表示させ、正しくとりまれていることを確認せよ。 ・ファイル形式はTSV（タブ区切り）・ヘッダ有り・文字コードはUTF-8 tsvファイルを読み込みpandas.DataFrameとする場合、pandas.read_table関数を使用します。 read_table関数のheader引数では、ヘッダの有無はbool型で指定できます。 デフォルトはTrueとなります。 文字コードは、encoding='utf-8'のように指定ができます。 本問では99問目で作成した99.tsvファイルを読み込んで、データフレームを作成します。 12df_tmp = pd.read_table('./data/99.tsv', encoding='UTF-8')df_tmp.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost category_major_name category_medium_name category_small_name0 P040101001 4 401 40101 198.0 149.0 惣菜 御飯類 弁当類1 P040101002 4 401 40101 218.0 164.0 惣菜 御飯類 弁当類2 P040101003 4 401 40101 230.0 173.0 惣菜 御飯類 弁当類3 P040101004 4 401 40101 248.0 186.0 惣菜 御飯類 弁当類4 P040101005 4 401 40101 268.0 201.0 惣菜 御飯類 弁当類5 P040101006 4 401 40101 298.0 224.0 惣菜 御飯類 弁当類6 P040101007 4 401 40101 338.0 254.0 惣菜 御飯類 弁当類7 P040101008 4 401 40101 420.0 315.0 惣菜 御飯類 弁当類8 P040101009 4 401 40101 498.0 374.0 惣菜 御飯類 弁当類9 P040101010 4 401 40101 580.0 435.0 惣菜 御飯類 弁当類 まとめ:ファイルの入出力を学びました。本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-94-100/"},{"title":"Dockerとは何か、メリット&#x2F;デメリットまとめ","text":"✓目次 この記事の対象者 仮想環境とは Dockerとは 従来の仮想化とコンテナ型仮想化の違い ホスト型仮想化 vs コンテナ型仮想化 その①：「仮想化のオーバーヘッド」 その②： 「アプリケーション実行の再現性」 その③： 「OSの自由度」 その④： 「分離レベル」 DockerイメージとDockerコンテナ Dockerイメージとは Dockerコンテナとは Docker Hubとは まとめ この記事の対象者 ・ 「仮想化」、「Docker」、聞いたことあってなんとなくわかるけど、ちゃんと理解していない気がする人向け ・ だけど細かい内容ではなく概要レベルで何なのか、何がうれしいのかを知りたい、という人向け 仮想環境とは シンプルに言ってしまえば、下図におけるゲストOSとアプリの部分を「仮想環境」と述べることが多いです。 ホストOSというのは、我々が普段使っているノートPCのOSを指します。 そのPCにOracle VirtualBoxとかVMWare Workstation Playerというソフトウェアをインストールし、その中にUbuntuとかCentOSと呼ばれるゲストOSを導入してアプリを動作させている、という構成の場合、ゲストOSからアプリのことを仮想環境といいます。 この辺りは、実際に環境構築して手を動かしてみるとよくわかると思います。 Dockerとは Docker社が提供しているコンテナ型アプリケーション実行環境を指します。 Docker自体はGoで作られており、Dockerには、Docker Community Edition(Docker CE)とDocker Enterprise Edition(Docker EE)が存在します。 Docker EEは有料版で、Docker CEは無償版になります。 有料版は、Docker社が認定したコンテナやプラグインが利用できたり、イメージのセキュリティスキャンが行われる等の恩恵が受けられます。基本的なDockerの機能は、無償版と有償版、共に利用できます。また、無償版は、さらに Stable版と、Edge版の2種類が存在します。 Stable版は4半期ごとにリリースされ、Edge版は1か月ごとにリリースされます。 最新版を使いたい場合は、Edge版を選択しましょう。 従来の仮想化とコンテナ型仮想化の違い 従来のホスト型仮想化とコンテナ型仮想化の違いは、コンテナ型仮想化は、ゲストOSを持たない、という点です。 ホスト型仮想化は、ハイパーバイザというミドルウェア上に各々のアプリを動作させるために、専有されたゲストOSを用意します。 一方、コンテナ型仮想化は、ゲストOSを必要とせず、ホストOSのカーネルを用いて(共有して)動作する仕組みを取ります。 ホスト型仮想化 vs コンテナ型仮想化 以下4つの観点で比較します。 ・ その①：「仮想化のオーバーヘッド」 ・ その②：「アプリケーション実行の再現性」 ・ その③：「OSの自由度」 ・ その④： 「分離レベル」 その①：「仮想化のオーバーヘッド」 ホスト型仮想化 リソース(CPUやメモリの使用率など)の面で、オーバーヘッドが多く、起動や停止に時間がかかる コンテナ型仮想化 コンテナは、アプリケーション実行に必要なものだけを含み、ホストOSのカーネルを使用するため、動作が速くリソースの使用率も少なくて済む。 その②： 「アプリケーション実行の再現性」 ホスト型仮想化 仮想マシンの環境の違いにより、アプリケーションが動作しなくなることが稀に発生する。 コンテナ型仮想化 特定のアプリケーションを動作させるために必要なものは、Dockerイメージにまとまっている。そのため、同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する。Dockerイメージについては後述します。 その③： 「OSの自由度」 ホスト型仮想化 仮想マシン上で任意のOSを動作させることができる。 コンテナ型仮想化 コンテナは、ホストOSのカーネルを使用して動作する。そのため、WindowsOS上で直接Linuxコンテナを動作させることはできない。その逆の、LinuxOS上で直接Windowsコンテナも動作させることもできない。 その④： 「分離レベル」 ホスト型仮想化 ハードウェアレベルで仮想化されており、ホストOSや仮想マシン間の分離レベルが高い。そのため、先ほどの図でいうVM1がVM2に影響を与える、といったことが起こりにくい。 コンテナ型仮想化 OSの機能を使用した仮想化は、ホスト型仮想化に比べて分離レベルが低い。そのため、要求されるセキュリティレベルが高いシステムを構築するには不向きと言われている。 外部から侵入されにくい設定や構成にし、不用意にパブリックなNWに公開しない点に注意する必要がある。また、不必要なパッケージをインストールしない、常にアップデートを心がけるなど、細かいケアが必要になる。 上記の記述を表でまとめると以下の通りです。 項目 ホスト型仮想化 コンテナ型仮想化 オーバーヘッド 多 少 アプリ実行の再現性 低 高 OSの自由度 高 低 分離レベル 高 低 DockerイメージとDockerコンテナ DockerイメージとDockerコンテナの違いを把握しておくことは、今後Dockerを実際に使ったり、kubernetesと言われるコンテナオーケストレーションツールを活用する際など、重要になってきます。 以降で簡単にまとめておきます。 Dockerイメージとは Dockerイメージとは、コンテナ実行に必要なファイルをまとめたファイルシステム Webサーバだったら、Apacheが既に含まれているもの。そのほかRubyの実行環境が入っていたりもする。要するに最初からパッケージ化されていて、実行環境を定義したもの。 aufsなどの特殊なファイルシステムが使用されている。aufs (AnotherUnionFS) は Linux のファイルシステムサービスであり、複数の異なるファイルシステム (ブランチと呼ばれる) のファイルやディレクトリ同士を透過的に重ねる (マージする) ことができる技術。 Dockerイメージを作成する方法は、基本的に、「ソースコードを作って、ビルドして、イメージを作る」という流れになります。 ソースコードというのは、Dockerfileというもので、必要なソフトウェアのインストールやアプリケーションの起動などのコマンド郡を記述したファイルです。 ソフトウェアのインストールやアプリケーションの起動というのは、例えば、pipコマンドでインストールしたり、所定のファイルをコピーしてコマンドを実行したり等です。 ビルドというのは、Docker社またはDockerコミュニティが提供しているOSのベースイメージ(CentOSやAlpine等のイメージ)に対して、Dockerfileでまとめた操作を実施することで機能を加えることを指します。そしてその結果として生成されるのが、自身で作成したDockerイメージになります。 Dockerコンテナとは Dockerコンテナとは、Dockerイメージを実行してできる実際の実行環境。 Dockerイメージが実行環境のテンプレートであり、Dockerコンテナは、このテンプレートを用いて構築された実際の環境、と理解しておけばよい。 Docker Hubとは クラウド上に展開されたDockerイメージのレジストリサービスです。 https://hub.docker.com Docker Hubを使用することで以下のことを行うことができます。 Dockerイメージの管理(検索、管理、取得、送信)を行うことができる。 GitHubなどのレポジトリからImageの自動構築(レポジトリを自動更新) グループ作成とグループ内ユーザでのコミュニティ作成 Docker Hubには、フレームワークやツールを作成した会社やコミュニティが公式に作成したイメージも公開されています。 そのため、何らかのツールを使う場合、まずはDocker Hubに公式イメージがあるかと確認してみると良いでしょう。 まとめ最後に本記事でまとめたDockerの特長とメリット・デメリットをまとめます。 Dockerとは、Docker社が提供しているコンテナ型アプリケーション実行環境 従来のホスト型仮想環境との違いは、ゲストOSを持たない、という点 ホスト型仮想化ではなく、Dockerを活用するメリットは、「動作が速くリソースの使用率も少なくて済む」、「同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する」という点。 一方、ホスト型仮想化と比較した場合のデメリットとしては、「OSの自由度が低い」、「分離レベルが低く、セキュリティ面でケアが必要になる」という点 Dockerイメージはテンプレート。DockerコンテナはDockerイメージを実行してできる実際の実行環境。 Dockerに関する基礎知識はこれで問題ないかと思います。 より専門的な内容や実装スキルを身に着けたい場合は、Udemyを活用した学習が効率的です。 30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 Udemyが提供しているDockerのベストセラー講座をご確認ください。 &gt;&gt; ゼロからはじめる Dockerによるアプリケーション実行環境構築 &gt;&gt; Docker + Kubernetes で構築する Webアプリケーション 実践講座 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"仕組みと使い方がわかる Docker\\u0026Kubernetesのきほんのきほん\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/514Mfb930CL._SL500_.jpg\",\"\\/41G+4LdNGmL._SL500_.jpg\",\"\\/41qh0svED1L._SL500_.jpg\",\"\\/410ZyjijKAL._SL500_.jpg\",\"\\/41fqGahRYuL._SL500_.jpg\",\"\\/51gxCtm4+CL._SL500_.jpg\",\"\\/51p9d5zTG6L._SL500_.jpg\",\"\\/41XJMfFWbdL._SL500_.jpg\",\"\\/51LTmIBg6zL._SL500_.jpg\",\"\\/415FAIN8ZQL._SL500_.jpg\",\"\\/41a4CLuAaUL._SL500_.jpg\",\"\\/51NI2avawnL._SL500_.jpg\",\"\\/41mnn0PzgaL._SL500_.jpg\",\"\\/51pDI1xjJ8L._SL500_.jpg\",\"\\/41e4PVfuW8L._SL500_.jpg\",\"\\/41grpORVbvL._SL500_.jpg\",\"\\/51GtMeleLTL._SL500_.jpg\",\"\\/41KhfdrFPxL._SL500_.jpg\",\"\\/41wj6X11seL._SL500_.jpg\",\"\\/41LiVIb+p6L._SL500_.jpg\",\"\\/51NSFx-477L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839972745\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839972745\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E4%BB%95%E7%B5%84%E3%81%BF%E3%81%A8%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%20Docker%26Kubernetes%E3%81%AE%E3%81%8D%E3%81%BB%E3%82%93%E3%81%AE%E3%81%8D%E3%81%BB%E3%82%93\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"WvmSK\",\"s\":\"s\"}); リンク Dockerを用いてRails開発環境構築方法もまとめているので参照ください 2020-12-29【Windows】DockerでRuby on Rails開発環境構築方法IT","link":"/Docker/"},{"title":"【解説】データサイエンス100本ノックの始め方","text":"目次 この記事の対象者 Dockerのインストール データサイエンス100本ノックのGitHubリポジトリURLをコピー ターミナルを起動してDockerを起動する Jupyter Labにアクセス 100本ノックの問題を確認する 100本ノックの問題を解いてみよう！ 100本ノックを終える方法 100本ノックを再開する方法 まとめ この記事の対象者 ・ M1 Macでデータサイエンスの勉強をしたい人 ・ データサイエンティスト協会がGithubに公開している問題演習をやりたい人 DockerのインストールまずはM1 MacにDockerをインストールしましょう。 以下の記事にまとめられている方法で導入可能です。https://qiita.com/ao41/items/5feb96cd01c312407a2b 本記事におけるDockerとDocker Composeののバージョンは以下のとおりです。 terminal12345$ docker --versionDocker version 20.10.1, build 831ebeae96$ docker-compose --versiondocker-compose version 1.27.4, build 40524192 データサイエンス100本ノックのGitHubリポジトリURLをコピー 以下が一般社団法人データサイエンス100本ノックのGitHubです。 https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess/tree/master 100本ノックのGitHubを開いたら「Code」というボタンをクリックし、Dockerfileをダウンロードする元のURLであるリポジトリをコピーしましょう。 2021年5月30日時点でのリポジトリのURLはhttps://github.com/The-Japan-DataScientist-Society/100knocks-preprocess.gitです。 ターミナルを起動してDockerを起動するターミナルを起動し、先程のリポジトリURLを用いて以下のコマンドを実行しましょう。 terminal1$ git clone https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess.git すると、コマンドを実行したディレクトリに、100knocks-preprocessというフォルダが作成されます。 以下のコマンドで、100knocks-preprocessというフォルダに移動します。 terminal1$ cd 100knocks-preprocess lsコマンドを実行し、Dockerfileとdocker-compose.ymlファイルが含まれていたらOKです。 以下のコマンドを実行し、ビルドを実行します。 terminal1$ docker-compose up -d --build 5分くらい様々な処理が走ると思います。最後に以下のような出力が得られたら成功かと思います。 terminal1234Successfully built 301a64dee71bSuccessfully tagged dss-notebook:latestCreating dss-postgres ... doneCreating dss-notebook ... done docker desktopのDashboardも確認してみましょう。 ちゃんと起動していますね。 Jupyter LabにアクセスDockerの起動が確認できたら以下のURLをクリックしてください。 http://localhost:8888 ブラウザにてJupyterLabの場面に遷移するはずです。 これで完了です。 「そもそもDockerってなに？」という方は、以下の記事も参考にしてください。 100本ノックの問題を確認する環境構築が完了したら、問題を確認しましょう。 問題は、docという名前のフォルダ配下にあるpdfファイルです。 docフォルダまで移動したら、open .コマンドでFinderを開きましょう。 terminal12$ cd ~/100knocks-preprocess/docker/doc $ open . Finderが開けたら、100knocks_questions.pdfというファイルを開きましょう。問題が確認できます。 100本ノックの問題を解いてみよう！ 第１問目だけ、本記事で解いてみたいと思います。 問題は以下のとおりです。 レシート明細のデータフレーム(df_receipt)から全項目の先頭10件を表示し、どのようなデータを保有しているか目視で確認せよ。 この問題は、Pandasというライブラリを使って、データの確認を行います。 Pandasは、一般的なデータベースで行える操作が実行でき、数値の他にも氏名や住所などの文字列データも簡単に扱うことができるライブラリです。 JupyterLabのセルに以下のコードを記載し、shift + Enterを押しましょう。 pandasをインポート1import pandas as pd dataフォルダに配置してあるreceipt.csvファイルを読み込みます。 receipt.csvの読み込み1df_receipt = pd.read_csv('./data/receipt.csv') 以下のコードで先頭10件を表示します。先頭10件を表示するためには.head()メソッドを使います。 全項目の先頭10件を表示1df_receipt.head(10) 以下のような出力が得られれば成功です。 コンソール1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 回答は、docフォルダに配置されているans_preprocess_knock_Python.htmlで確認できます。 問題の続きを解いていきたい人は、以下の記事に参考にしてください。 100本ノックを終える方法 基本的には、そのままPCをシャットダウンしていただいて大丈夫です。 明示的にdockerの起動を停止したい場合は、以下の通りstopコマンドを実行すればOKです。 docker-composeの停止123$ docker-compose stopStopping dss-notebook ... doneStopping dss-postgres ... done Docker Desktopの画面を確認し、以下のようになっていれば停止しています。 100本ノックを再開する方法100本ノックを再開する場合は、以下のコマンドを実行しましょう。 100本ノックを再開する際のコマンド1$ docker-compose up -d 上記のコマンドを実行し、以下のような出力が得られたらOKです。 出力12Starting dss-postgres ... doneStarting dss-notebook ... done Google Chromeなどのブラウザで、localhos:8888にアクセスすれば、Jupyter Labにアクセスできると思います。 まとめ本記事では「【M1 Mac】データサイエンス100本ノックの始め方」というテーマでまとめました。 今回紹介した教材を使って、コスパ良くプログラミングを学んでいきましょう。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースがおすすめです。 無料体験可能なのでご確認ください。 データサイエンス100本ノックの各問題の回答は、以下のリンクから確認できます。 データサイエンス100本ノックの回答集 | タグ: datascience - omathin blog","link":"/100knocks-getstart/"},{"title":"【プログラミング】Anaconda Navigatorによるpython環境構築","text":"プログラミング環境の構築で挫折したことありませんか？ 絶対に挫折しない環境構築方法を紹介します。 人気No1プログラミング言語ともいわれるPythonを学ぶための環境構築は、Anacondaを使えば安心です。 人工知能や自然言語処理の勉強のために必要なライブラリのインストール方法もまとめています。 ニューラルネットワークや自然言語処理の勉強のために、Anacondaを使って環境構築したのでその方法をまとめます。 ✓目次 使用しているPCとAnacondaのバージョン 手順①：Anaconda Navigatorのインストール 手順②：ライブラリの導入 手順③Jupyter Notebookを開き動作確認 まとめ: pythonを学ぶ環境が作成できました！ 使用しているPCとAnacondaのバージョンWindows10 proAnaconda Navigator 1.9.12 ※Macでも同様の方法で導入が可能です。適宜読み替えて実施してください。 手順①：Anaconda Navigatorのインストール anaconda.comにアクセス トップページにDownloadsのリンクがあるのでこれをクリック&lt;br&gt; 環境を選択(Win, Mac, Linux) Python 3.6のバージョンを選択。ダウンロードが始まる。 インストーラがダウンロードされているのでダブルクリック。指示されたとおりにプロセスを進める。 MS VScodeをインストールするかを聞かれるが必要であればOK。すでにVScodeをインストール済みであれば無視してよい。 インストールが完了したら、Anaconda-Navigator.appを開く。 手順②：ライブラリの導入AI学習や自然言語処理を実装するためのライブラリとして、以下を導入しました。(お好みで他のライブラリを導入してもOKですし、導入しなくても構いません。) NumPy matplotlib TensorFlow Keras nomkl gensim Janome 以降、実際の手順をまとめます。 Anaconda navigatorを起動。Enviromentsを選択。以下のような画面になります。 画面下にある、「create」をクリックする。 新しい仮想環境の名前を聞かれるので任意の名前を設定し、pythonにチェックを入れて、バージョンを3.6に設定する。 createをクリックすると、creating environmetという表記と共に、仮想環境の作成が開始されます。仮想環境の構築が完了したら、タブを「installed」にし、”numpy”と入力して検索。何も表示されない場合、numpyがインストールされていないことを示しています。 タブを「Not installed」に変更して”numpy”と入力するとnumpyが見つかります。numpyを選択して、「Apply」をクリック。 再びApplyをクリックするとnumpyのインストールが開始されます。 この要領で、matplotlib、tensorflow、Keras、gensimをインストール。gensimはword2vecを使うためのライブラリ。 nomklをインストールする際、Enviromentsにnomklが表示されません。(Anaconda Navigatorのバージョンによっては表示されるかもしれません。) Enviromentsにインストールしたいライブラリが表示されない場合は、Anaconda navigatorのterminalからインストールします。terminalは、▶ボタンをクリックして「open terminal」をクリックするとterminalが開きます。 今回はconda install -c anaconda nomklコマンドでインストールします。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950(test_env) C:\\Users\\user&gt;conda install -c anaconda nomklCollecting package metadata (repodata.json): doneSolving environment: done## Package Plan ## environment location: C:\\Users\\omashi\\Anaconda3\\envs\\nlp_bot added / updated specs: - nomklThe following packages will be downloaded: package | build ---------------------------|----------------- ca-certificates-2020.1.1 | 0 165 KB anaconda certifi-2020.4.5.1 | py36_0 159 KB anaconda nomkl-2.0 | 0 2 KB anaconda openssl-1.1.1 | he774522_0 5.7 MB anaconda ------------------------------------------------------------ Total: 6.1 MBThe following NEW packages will be INSTALLED: nomkl anaconda/win-64::nomkl-2.0-0The following packages will be UPDATED: openssl pkgs/main::openssl-1.1.1f-he774522_0 --&gt; anaconda::openssl-1.1.1-he774522_0The following packages will be SUPERSEDED by a higher-priority channel: ca-certificates pkgs/main --&gt; anaconda certifi pkgs/main --&gt; anacondaProceed ([y]/n)? yDownloading and Extracting Packagesopenssl-1.1.1 | 5.7 MB | ############################################################################ | 100%nomkl-2.0 | 2 KB | ############################################################################ | 100%ca-certificates-2020 | 165 KB | ############################################################################ | 100%certifi-2020.4.5.1 | 159 KB | ############################################################################ | 100%Preparing transaction: doneVerifying transaction: doneExecuting transaction: done(test_env) C:\\Users\\user&gt; janomeも同様にterminalからインストールします。janomeは、pip install janomeコマンドでインストールします。 123456(test_env) C:\\Users\\user&gt;pip install janomeCollecting janome Downloading Janome-0.3.10-py2.py3-none-any.whl (21.5 MB) |████████████████████████████████| 21.5 MB 3.3 MB/sInstalling collected packages: janomeSuccessfully installed janome-0.3.10 これで完了です。 手順③Jupyter Notebookを開き動作確認Anaconda NavigatorのHomeに戻り、Jupyter Notebookを選択しましょう。 すると、ブラウザが起動し、jupyter notebookがlocalhost環境に立ち上がります。 新規にpythonファイルを作成します。 作成する場所は、デスクトップなど、どこでもOKです。 下図のように、「新規」を選択し、「Python 3」を選択しましょう。 Jupyter notebookの新規ファイルが作成されます。 print('hello world')と打ち込み、shiftを押しながらEnterを押してみましょう。 以下のように、’hello world’と出力されたら成功です！ 続いて、先程インストールしたライブラリが使えるかどうかを確認しましょう。 本記事では、先程インストールしたjanomeが導入されているかを確認します。 jupyter notebookにimport janomeを入力し、shiftキーを押しながらEnterを押しましょう。 以下のようにエラーがでなければ成功です。 まとめ: pythonを学ぶ環境が作成できました！ これで、pythonの実行確認が完了しました。あとは、手を動かして学ぶだけです。 なお、Pythonを始めとするプログラミング学習は、書籍でも良いですが、動画で学ぶほうが効率的です。 たとえば、シリコンバレーの現役エンジニアによるUdemyの講座「現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル」が良いかと思います。30日間の返金保証付きなので安心です。 学習方法について専門家からのアドバイスが欲しい場合は、Aidemyの無料相談を利用してはいかがでしょうか？ &gt;&gt; 【無料】オンライン相談会を確認する プログラミングをコスパ良く学べるお手伝いができるように、今後も本ブログで情報発信していきたいと思います。 本記事が役立ったらTwitterのフォローもよろしくおねがいします！","link":"/anaconda-enviroment/"},{"title":"【31.5インチ】目に優しい大型4Kモニター(4社製品)をITエンジニアが徹底比較して購入した話","text":"皆様、リモートワークお疲れさまです！ずっとディスプレイとにらめっこしているあなた！視力の低下、どんどん進んでますよ！視力を落としたら本当にQOL下がります。本記事では最強に目に優しい大型4Kモニターを探し求め、ASUSのVA32Uに行き着いた話をまとめます。 本記事で整理するモニターの要件 30インチ以上の4Kモニターで絞り込み 4社製品(DELL, ASUS, LG, Acer)を比較評価！ 【結論】ASUS VA32Uを購入！ 本記事で整理するモニターの要件 モニターの要件 1. とにかく目に優しい!!!2. （せっかくなので）4Kモニター!3. プログラミングの作業効率を最強にする30インチ以上の大型ディスプレイ!4. 保証付きで壊れても安心!5. 予算は5万円! 30インチ以上の4Kモニターで絞り込み 早速30インチ以上の4Kモニターで5万円以下のものをAmazon、楽天市場で絞り込みました！ ちなみにですが、過去にすぐに壊れてしまったiiyamaさん、I-O DATAさんは除外しました。(すみません。。。) 30インチ以上の4Kモニター ・DELL・ASUS・LG・acer 4社製品(DELL, ASUS, LG, Acer)を比較評価！ DELL S3221QS ASUS VA32U LG 32UN500-W acer ET322QKwmiipx ノンブレア ○ ○ ○ ○ フリッカーフリー ○ ○ ○ ○ ブルーライトカット ○ ○ ○ ○ 高さ調整 ○ × × × 角度調整 ○ ○ ○ ○ VESA規格対応 ○ ○ ○ ○ 保証 3年(無輝点交換保証) 3年保証 3年保証 3年保証 評判(主に悪い評判) 湾曲画面が不自然(?) ボタンが少し不便(?) スタンドが不安定(?) HDMIケーブルが付属してない ポート HDMI×2, ディスプレイポート×1, USB, イヤホンジャック×1 HDMI×2, ディスプレイポート×1, イヤホンジャック×1 HDMI×2, ディスプレイポート×1, イヤホンジャック×1 HDMI×2, ディスプレイポート×1, イヤホンジャック×1 価格2021年2月時点 ￥49,800 ￥47,800 ￥45,980 ￥44,800 特に大きな差異はないものの、若干価格が高めのDell S3221QSが高さ調整、保証、USBポートがついている点で優位なのかなという印象です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Dell 4K ワイドフレームレス曲面モニター 31.5インチ S3221QS(3年間無輝点交換保証\\/AMD FreeSync™\\/4K\\/VA非光沢\\/DP,HDMIx2\\/高さ調節\\/スピーカー付\\/曲面)\",\"b\":\"Dell\",\"t\":\"S3221QS\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51vomYDOwbL.jpg\",\"\\/51pZHYjru1L.jpg\",\"\\/51XihRnfFtL.jpg\",\"\\/51i+ZZYp-SL.jpg\",\"\\/41AHwqqcNdL.jpg\",\"\\/41IOzEwpy0L.jpg\",\"\\/41B5oUjEanL.jpg\",\"\\/416RKdehU-L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HJ9XBM5\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HJ9XBM5\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Dell%204K%20%E3%83%AF%E3%82%A4%E3%83%89%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%83%AC%E3%82%B9%E6%9B%B2%E9%9D%A2%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%2031.5%E3%82%A4%E3%83%B3%E3%83%81%20S3221QS(3%E5%B9%B4%E9%96%93%E7%84%A1%E8%BC%9D%E7%82%B9%E4%BA%A4%E6%8F%9B%E4%BF%9D%E8%A8%BC%2FAMD%20FreeSync%E2%84%A2%2F4K%2FVA%E9%9D%9E%E5%85%89%E6%B2%A2%2FDP%2CHDMIx2%2F%E9%AB%98%E3%81%95%E8%AA%BF%E7%AF%80%2F%E3%82%B9%E3%83%94%E3%83%BC%E3%82%AB%E3%83%BC%E4%BB%98%2F%E6%9B%B2%E9%9D%A2)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"djKQ3\",\"s\":\"xs\"}); リンク しかしながら、曲面ディスプレイが不自然という意見もあります。 曲面ではなく平面ディスプレイということであれば、ASUS, LG, acerのいずれかの製品かと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ASUS 4K UHD HDR10対応31.5インチ モニターディスプレイVA32UQ 広視野角DCI-P3 HDMI 2ポート ブルーライト軽減 フリッカーフリー スピーカー内蔵3年保証\",\"b\":\"ASUSTek\",\"t\":\"VA32UQ\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41LMe0jMUKL.jpg\",\"\\/51-KjBTO50L.jpg\",\"\\/51MnyqZdMtL.jpg\",\"\\/51EwyXJYlkL.jpg\",\"\\/41mZkkNlVGL.jpg\",\"\\/31Tq6gttKpL.jpg\",\"\\/51Mxu+OsWUL.jpg\",\"\\/5126YIuDK9L.jpg\",\"\\/41Eq7NfZ-NL.jpg\",\"\\/41FDSDHIMcL.jpg\",\"\\/21L+Kl1-FAL.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B084C4G1G7\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B084C4G1G7\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/ASUS%204K%20UHD%20HDR10%E5%AF%BE%E5%BF%9C31.5%E3%82%A4%E3%83%B3%E3%83%81%20%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4VA32UQ%20%E5%BA%83%E8%A6%96%E9%87%8E%E8%A7%92DCI-P3%20HDMI%202%E3%83%9D%E3%83%BC%E3%83%88%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A9%E3%82%A4%E3%83%88%E8%BB%BD%E6%B8%9B%20%E3%83%95%E3%83%AA%E3%83%83%E3%82%AB%E3%83%BC%E3%83%95%E3%83%AA%E3%83%BC%20%E3%82%B9%E3%83%94%E3%83%BC%E3%82%AB%E3%83%BC%E5%86%85%E8%94%B53%E5%B9%B4%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"Fw5Fb\",\"s\":\"xs\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"LG モニター ディスプレイ 32UK550-B 31.5インチ\\/4K\\/HDR10\\/VA非光沢\\/HDMI×2、DP\\/FreeSync\\/スピーカー\\/高さ調節\\/フリッカーセーフ、ブルーライト低減\",\"b\":\"LG\",\"t\":\"32UK550\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51ZvBUpIAfL.jpg\",\"\\/5176WpCjfZL.jpg\",\"\\/41uUB93yLDL.jpg\",\"\\/41pFMM-XTuL.jpg\",\"\\/51+SZi6s3XL.jpg\",\"\\/51klAovvqQL.jpg\",\"\\/51Np+g-WFOL.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07HRZ7LFB\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07HRZ7LFB\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/LG%20%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%20%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4%2032UK550-B%2031.5%E3%82%A4%E3%83%B3%E3%83%81%2F4K%2FHDR10%2FVA%E9%9D%9E%E5%85%89%E6%B2%A2%2FHDMI%C3%972%E3%80%81DP%2FFreeSync%2F%E3%82%B9%E3%83%94%E3%83%BC%E3%82%AB%E3%83%BC%2F%E9%AB%98%E3%81%95%E8%AA%BF%E7%AF%80%2F%E3%83%95%E3%83%AA%E3%83%83%E3%82%AB%E3%83%BC%E3%82%BB%E3%83%BC%E3%83%95%E3%80%81%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A9%E3%82%A4%E3%83%88%E4%BD%8E%E6%B8%9B\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"sRf5d\",\"s\":\"xs\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Acer 4K モニター ディスプレイ OmegaLine 31.5インチ ET322QKwmiipx VA HDMIx2 DisplayPort HDR FreeSync スピーカー内蔵 ブルーライト軽減\",\"b\":\"日本エイサー\",\"t\":\"ET322QKWMIIPX\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51pzzbdOrpL.jpg\",\"\\/51GTDlYlPFL.jpg\",\"\\/61amVrF4x9L.jpg\",\"\\/51BWzE+3pCL.jpg\",\"\\/61AtaRWIrmL.jpg\",\"\\/51VDOfIA91L.jpg\",\"\\/51H5BGrEKML.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0771DQYT5\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0771DQYT5\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Acer%204K%20%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%20%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4%20OmegaLine%2031.5%E3%82%A4%E3%83%B3%E3%83%81%20ET322QKwmiipx%20VA%20HDMIx2%20DisplayPort%20HDR%20FreeSync%20%E3%82%B9%E3%83%94%E3%83%BC%E3%82%AB%E3%83%BC%E5%86%85%E8%94%B5%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A9%E3%82%A4%E3%83%88%E8%BB%BD%E6%B8%9B\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"hAWvA\",\"s\":\"xs\"}); リンク 一番価格が安いAcerはどうだろうか？、ということで調査したところ以下の動画を見つけました。 うーん、保証がついているとはいえ、HDMIケーブルがついていない事も考えると、、、ちょっと危険かもな、と思い、Acer社製品は今回は無しにしました。 残るは、ASUSかLGになります。 正直、性能面では特に差異はないですね。。。。 【結論】ASUS VA32Uを購入！ 結論としては、ASUSの31.5インチ4Kモニターを購入しました。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ASUS 4K UHD HDR10対応31.5インチ モニターディスプレイVA32UQ 広視野角DCI-P3 HDMI 2ポート ブルーライト軽減 フリッカーフリー スピーカー内蔵3年保証\",\"b\":\"ASUSTek\",\"t\":\"VA32UQ\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41LMe0jMUKL.jpg\",\"\\/51-KjBTO50L.jpg\",\"\\/51MnyqZdMtL.jpg\",\"\\/51EwyXJYlkL.jpg\",\"\\/41mZkkNlVGL.jpg\",\"\\/31Tq6gttKpL.jpg\",\"\\/51Mxu+OsWUL.jpg\",\"\\/5126YIuDK9L.jpg\",\"\\/41Eq7NfZ-NL.jpg\",\"\\/41FDSDHIMcL.jpg\",\"\\/21L+Kl1-FAL.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B084C4G1G7\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B084C4G1G7\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/ASUS%204K%20UHD%20HDR10%E5%AF%BE%E5%BF%9C31.5%E3%82%A4%E3%83%B3%E3%83%81%20%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4VA32UQ%20%E5%BA%83%E8%A6%96%E9%87%8E%E8%A7%92DCI-P3%20HDMI%202%E3%83%9D%E3%83%BC%E3%83%88%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A9%E3%82%A4%E3%83%88%E8%BB%BD%E6%B8%9B%20%E3%83%95%E3%83%AA%E3%83%83%E3%82%AB%E3%83%BC%E3%83%95%E3%83%AA%E3%83%BC%20%E3%82%B9%E3%83%94%E3%83%BC%E3%82%AB%E3%83%BC%E5%86%85%E8%94%B53%E5%B9%B4%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"Fw5Fb\",\"s\":\"xs\"}); リンク DELLのモニターを家電量販店で実物をみたところ、 「おぉ、曲面かっこいい！」 と思う反面、 「もう一つモニタを導入する事も考えると、曲面はちょっと微妙かも？」、 「確かに平面に慣れているせいか、ちょっと違和感があるかも。」 ということで、平面モニターを購入することにしました。 ASUSとLGどちらでも良かったのですが、楽天ポイントでだいぶ安く購入できそうだったのでASUSにしました。 商品に「EYE CARE MONITOR」と大きく書かれているので、「あぁ、目に優しいんだろうな。」と思ったのも決め手です。 [2021/3/31追記]実際にASUSの31.5インチモニターを使ってみたレビュー記事をまとめました！","link":"/4k-monitor/"},{"title":"明日から実践できる5つのアンガーマネジメント","text":"本記事では、明日から使えるアンガーマネジメント方法についてまとめていきます。 本記事の対象者 アンガーマネジメントとは [準備]自分の「怒り」の正体を知る [NG]絶対にしてはいけないこと（3つ） [実践]許せるゾーンの範囲を決める [実践]怒りを感じた瞬間に怒りの点数をつける [実践]体調とメンタルを整えるために休む まとめ 本記事の対象者 ついつい子供に感情的になって起こってしまう人。 仕事で付き合う人、もしくは事象に対して怒りが止まらない人。 誰かを叱って公開した経験がある人。 アンガーマネジメントとは一言でいうと、、怒りと上手に付き合うための心理トレーニングです。 怒りは、人間にとって自然な感情の１つです。 怒りを感じることは、ごく自然なことであり、何も悪いことではないのです。 大切なのは、どう扱うのか、どう表現するのかです。 明日から実践できる「怒り」の扱い方、表現方法をまとめていきます。 [準備]自分の「怒り」の正体を知るまず、怒りをコントロールするために重要な考え方があります。 それは、怒りは私達自身が生み出した感情であり、他人や出来事によって生み出されるものではないということです。 怒りの正体は何か？というと、その答えは、 「自分が持つ理想像」 この「自分が持つ理想像」が破られた時に怒りが生まれるのです。 ポイント 「怒りの正体」 = 「自分が持つ理想像」と「現実」のギャップ もしあなたが、 「私の怒りは〇〇さんが引き起こしている」 とか 「仕事で起こる〇〇が原因でイライラする」 という考え方ではアンガーマネジメントはできません。 [NG]絶対にしてはいけないこと（3つ）以下にまとめる3つは、何も価値を生み出さないので明日からやめましょう。 1. 人を傷つける（暴言、暴力をしてはいけない） 2. モノを壊す（八つ当たりする） 3. 自分を傷つける（自傷行為） はい、これで準備は完了です。 以降は、明日からできるアンガーマネジメント実践方法をまとめていきます。 [実践]許せるゾーンの範囲を決める「子供がおもちゃを片付けなかったので怒ってしまった」を例にします。 この「言うことを聞かなかった」という事象が、絶対に許せない範囲だったのか？を考えます。 次に、「まぁ許せる範囲」。その次に、「許せる範囲」を考えます。 「子供がおもちゃを片付けなかった」 許せないゾーン：「子供が納得しおもちゃを片付ける約束をしたのに片付けない。」 まぁ許せるゾーン：「おもちゃで遊んでいる最中であり、おもちゃを片付ける時間とタイミングを約束していなかった。」 許せるゾーン：「おもちゃを片付けるよりも優先すべき事（宿題など）があった。」 「許せないゾーン」と「まぁ許せるゾーン」の境界線が、怒る or 怒らないの境界線になります。 そして重要なことは、境界線を相手に伝える、ということです。 今回のケースだと、以下のように怒るのが良いです。 [事実]7時になったらおもちゃを片付ける約束をした。 [ギャップ]7時を過ぎてもおもちゃを片付けてなく、約束を守ってくれなかった。 [リクエスト]信用を失わないように約束を守る人になってほしい。守れないなら守れない理由を事前に言えるようになってほしい。 このように、事実→理想とのギャップ→リクエストの順番で伝えましょう。 こうすることでお互いが「なぜ怒ったのか」、「なぜ怒られたのか」が明確になり、お互いの「べき」のギャップを相互に理解することが出来ます。 そして怒る側の人間は、「相手の成長を願って行動を改善してほしい」という願いを込め、それを伝えることが大切なのです。 [実践]怒りを感じた瞬間に怒りの点数をつける人生最大の怒りを10点、穏やかな状態を0点とします。 怒りを感じたら、その怒りが何点なのか点数をつけましょう。 これをすることで以下のような効果が得られます。 衝動のコントロール（6秒ルール） 怒りを客観的に把握 脳の仕組みとして、怒りを感じてから6秒経過すると理性が働くと言われています。 怒りを感じた時に点数を計算していると、自然と6秒の時間が過ぎるため、本当に怒るべきか否かを冷静に判断することが出来ます。 [実践]体調とメンタルを整えるために休む大きな怒りの原因は、ネガティブな感情です。 不安な感情を持っている 悲しい出来事があった 余裕がない etc こういったマイナスな感情が溜まっていると大きな怒りになることを認識しましょう。 そして日頃から心と体の安定を意識し、十分な睡眠、休養をトリましょう。 まとめ本記事では、「明日から実践できる5つのアンガーマネジメント」というテーマでまとめてみました。 他にもいろいろな方法論などありますが、「明日からすぐに実践できる」というポイントに絞ってまとめると以下になります。 ポイント 1. 「怒り」は他人や出来事によって生み出されるものではないことを理解する 2. 絶対にしてはいけないこと（３つ）を理解する 3. 許せるゾーンの範囲を決める4. 怒りを感じた瞬間に怒りの点数をつける5. 体調とメンタルを整えるために休む 怒りとうまく付き合うことで、お互いの理解を深めましょう。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"アンガーマネジメント (日経文庫)\",\"b\":\"日本経済新聞出版社\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51EGdilCBEL.jpg\",\"\\/41p8kSBcMbL.jpg\",\"\\/41hk1Vr5PgL.jpg\",\"\\/41F+-T6pTsL.jpg\",\"\\/31XM7XnlbvL.jpg\",\"\\/41uqp32YKJL.jpg\",\"\\/41vPuEV3OwL.jpg\",\"\\/41832urUTEL.jpg\",\"\\/41tHdZ3I59L.jpg\",\"\\/41+80cEuxrL.jpg\",\"\\/41WYxdm2NAL.jpg\",\"\\/41kakAAVK-L.jpg\",\"\\/31qcwXjnH4L.jpg\",\"\\/41mIs3E8ORL.jpg\",\"\\/41JCVKoobFL.jpg\",\"\\/41n7PJo7tdL.jpg\",\"\\/41E5HveGz6L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4532114209\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4532114209\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":0},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%A2%E3%83%B3%E3%82%AC%E3%83%BC%E3%83%9E%E3%83%8D%E3%82%B8%E3%83%A1%E3%83%B3%E3%83%88%20(%E6%97%A5%E7%B5%8C%E6%96%87%E5%BA%AB)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":1}],\"eid\":\"mYA2E\",\"s\":\"xs\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"「つい怒ってしまう」がなくなる 子育てのアンガーマネジメント\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51-Nw7QpV7L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4413230558\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4413230558\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":0},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%80%8C%E3%81%A4%E3%81%84%E6%80%92%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E3%80%8D%E3%81%8C%E3%81%AA%E3%81%8F%E3%81%AA%E3%82%8B%20%E5%AD%90%E8%82%B2%E3%81%A6%E3%81%AE%E3%82%A2%E3%83%B3%E3%82%AC%E3%83%BC%E3%83%9E%E3%83%8D%E3%82%B8%E3%83%A1%E3%83%B3%E3%83%88\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":1}],\"eid\":\"zIkw9\",\"s\":\"xs\"}); リンク","link":"/anger-management/"},{"title":"【Python】Bubble Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Bubble Sortとは Pythonの基礎 [Python基礎]関数定義 [Python基礎]関数の引数と返り値の宣言 [Python基礎]関数アノテーション [Python基礎]__name__と__main__ [Python基礎]内包表記 Bubble Sortのコーディング まとめ Bubble Sortとはソートアルゴリズムの一種です。 要素の1番目と2番目を比較し、順番が逆であれば入れ換える。 次に2番目と3番目を比較して入れ換える。 これを最後まで行うと、最後の数だけが最小または最大の数として確定するので、確定していない部分について1つずつ減らしながら繰り返す。 詳しくは以下のWikipediaを参照ください。 バブルソート - Wikipedia 本記事では、プログラミングにおけるアルゴリズムの練習として、Bubble Sortアルゴリズムを実装したいと思います。 いきなり実装に入る前に、実装する上で必要なpythonの基礎もまとめていきたいと思います。 Pythonの基礎Bubble Sortをコーディングするために必要な、基本的なPythonの基礎をまずはまとめていきます。 [Python基礎]関数定義基本的な関数定義としては以下のようなコードがあります。注意点としては、def say_something()前にsay_something()と書いた場合、”関数定義がされてないよ”とエラーになります。pythonは、コードを上から読み込まれるためです。あと()をちゃんとつけましょう。 1234def say_something(): print('hi')say_something()# -&gt; hi ちなみに、print(type(say_something))とすると、say_somethingが何者なのかを確認することができます。 1234def say_something(): print('hi')type(say_something)# -&gt; function 返り値を返したい場合は、以下のようにreturnを用います。以下の例だと、sにhiが入り、返してくれます。 1234567def say_something(): s = 'hi' return sresult = say_something()print(result)# -&gt; hi 引数を用いれば、何度もif文を返さなくてOKになるので便利です。 12345678910111213141516def what_is_this(color): if color == 'red': return 'tomato' elif color == 'green': return 'green pepper' else: return \"I don't know\" result1 = what_is_this('green')print(result)result2 = what_is_this('red')print(result2)# -&gt; green pepper# -&gt; tomato [Python基礎]関数の引数と返り値の宣言関数は引数と返り値を明示的に宣言することができます。 123456def add_nums(a: int, b: int) -&gt; int: return a + br = add_nums(10, 20)print(r)# -&gt; 30 ここで、引数にあえてstringを入れてみます。 123456def add_nums(a: int, b: int) -&gt; int: return a + br = add_nums('a', 'b')print(r)# -&gt; ab 結果は、abという文字列を返します。 何を言いたいかというと、関数定義の際に、明示的にa, bにはintを宣言しているにも関わらず、aとbにstringを入れても、pythonはエラーを返してくれません。 この点は気をつけておきましょう。 [Python基礎]関数アノテーションPython3.0i以降では、関数アノテーションという仕組みが導入されました。 関数の引数や返り値にアノテーション（注釈）となる式を記述することができます。 1234567from typing import Union, Listdef func_u(x: List[Union[int, float]]) -&gt; float: return sum(x) ** 0.5print(func_u([0.5, 9.5, 90]))# 10.0 あくまでも注釈なので、コードが実行される際に型チェックは行われたりしません。 つまり、アノテーションで指定した型以外の引数を渡してもエラーになりません。 [Python基礎]__name__と__main__よく「おまじない」としてスルーされがちなコードですね。 pythonで関数を用いたコードを記述する際に、編集しているpythonファイルが他のコードからimportされて実行されないようにif __name__ = '__main__':を用いることが良しとされています。 作成しているコードが、プロジェクトの一部で使われることが想定される場合、関数を用いる場合は、以下のようにif __name__ = '__main__':を記述して関数を指定しましょう。 12345def main(): lesson_package.talk.animal.sing()if __name__ = '__main__': main() 詳しくは、Pythonのif name == “main“ とは何ですか？への回答 - Python学習チャンネル by PyQを参照ください。 [Python基礎]内包表記内包表記は、リストの要素を操作した上で、新しいリストを作成するための記法です。 通常、そのような処理はforやwhileによるループを使用しますが、内包表記を用いると、簡潔に記述することができます。内包表記は、以下の形式で記述します。 新たなリスト = [ 要素への処理 for 要素 in リスト] リスト内の要素を1つ1つ取り出して、要素への処理を実行した上で新しいリストを作成します。 123a = [1, 2, 3, 4, 5, 6]b = [c*3+1 for c in a] # aの要素を3倍して1を足し新たなリストを作るprint(b) Bubble Sortのコーディングまずは、数値のlistを扱いたいので、from typing import Listとしておきます。丁寧にアノテーションでlistを受け付けて、listを返す関数であるということを明示的に示しておきます。先述したとおり、指定した型に従った変数でなくてもエラーは返しません。 123from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: そして、数値のリストを作成し、bubble_sort()に引数として渡してあげます。 123456from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]:if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums) Bubble Sortの仕組みを考慮し、リストのindexの数を取り出したいので、lenメソッドを使い、indexの数を取り出し、それをprintします。 12345678910from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) print(len_numbers)if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums)# -&gt; 6 len_numbersを用いてループを回したいので、for文使います。 12345678910111213141516from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): print(i)if __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] bubble_sort(nums)# 0# 1# 2# 3# 4# 5 2つの数字を比較する回数は、今回でいうと6つの数字に対して、5回比較を行うため、len_numbers - 1回行えば良いことがわかります。 さらに、その回数は1回ずつ減っていくことから、len_numbers - 1 -iとすれば良いことがわかると思います。最初iには、0が入り、len_numbersには6が入るので、初期値は5になります。そしてループが回るごとに4, 3, 2, 1、となりますね。 123456789101112131415from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): for j in range(len_numbers - 1 - i): if numbers[j] &gt; numbers[j+1]: numbers[j], numbers[j+1] = numbers[j+1], numbers[j] return numbersif __name__ == '__main__': nums = [2, 5, 4, 6, 8, 1] print(bubble_sort(nums))# -&gt; [1, 2, 4, 5, 6, 8] もう少し大きな数字でもやってみます。内包表記を用いてlist内部で処理を記述します。 12345678910111213141516from typing import Listdef bubble_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): for j in range(len_numbers - 1 - i): if numbers[j] &gt; numbers[j+1]: numbers[j], numbers[j+1] = numbers[j+1], numbers[j] return numbersif __name__ == '__main__': import random nums = [random.randint(0, 1000) for i in range(10)] print(bubble_sort(nums))# -&gt; [15, 218, 219, 230, 306, 308, 320, 390, 625, 876] まとめ本記事では、Bubble Sortというソートアルゴリズムを学びながら、以下のPythonの基礎を学びました。 関数定義 関数の引数と返り値の宣言 関数アノテーション __nameと__main__ 内包表記 アルゴリズムをより詳しく学びプログラミング力を高めたい方 以下の、Udemyのコースがおすすめです。セール時は、1200円で購入可能です。セール時でなくても、講師の方に、Twitterでクーポンコードの発行をお願いすれば、10$(1200円)で受講可能となります。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/bubble-sort/"},{"title":"【収益報告】ブログで100記事書いたら1ヶ月で4,117円稼げた話","text":"本記事では、本ブログで100記事作成した結果4,117円の収益を得ることが出来たことを報告するとともに、100記事作成まで継続できたポイントをまとめたいと思います。 記事を書いている人 omathin ・大手IT企業の機械学習研究者. ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得 では早速まとめていきます。 目次 この記事の対象者: 「ブログ100記事書いたらどうなるの？」という疑問に答えます 本ブログはHexoという静的サイトジェネレータを使用している 100記事書いたら1ヶ月で「4,117円」の収益が出た 本ブログの収益の内訳 本ブログのPV数: 30日間で「1,803PV」 ブログ記事は一貫して「過去の自分」に向けた記事を作成 モチベーション維持のコツ: 収益化を最大のモチベーションにしない まとめ: 100記事までは「過去の自分の悩みを解決する記事を書き続ける」 この記事の対象者: 「ブログ100記事書いたらどうなるの？」という疑問に答えます 以下にまとめた疑問や興味がある方に対して記事をまとめます。 ・ このブログがどのように運営されているのかを知りたい！ ・ 100記事書くとどのくらい収益が出るの？ ・ 収益化するために工夫したことは？ ・ 100記事書き続けるために必要なマインドを知りたい！ 本ブログはHexoという静的サイトジェネレータを使用している 極稀に「WordPress使ってるんですか？」とか「テーマは何使ってますか？」と聞かれますが、本ブログはWordPressを使用していません。 レンタルサーバーも未使用で、GitHub Pagesを使って公開しています。 なぜWordPressを使っていないのかというと、セキュリティを気にする必要がなく、お金も掛からないからです。 WordPressも多くの費用を必要としませんが、レンタルサーバー代など地味な出費があります。 HexoとGithub Pagesを使用すれば、レンタルサーバー代は掛からず毎月の出費も0円なので、固定費がかかりません。 毎月の出費が無いと「毎日ブログを書かなければ」という焦燥感もないので、ゆっくりとブログを続けることができます。 静的サイトジェネレータを使ったブログ構築の欠点は、WordPressに比べてノウハウが少ない点です。 静的サイトジェネレータを使ってブログを運営する場合は、少ないノウハウを元に自らノウハウを作り切り開いていく気概が必要かとおもいます。 ちなみに本ブログのデザインは「Icarus」というテーマを少しカスタマイズして作られています。 デザインのカスタマイズについては「Hexo」というタグを付けた記事にいくつかまとめています。興味があれば参考にしていただければと思います。 &gt;&gt;Icarusのカスタマイズノウハウ集 100記事書いたら1ヶ月で「4,117円」の収益が出た 「4,117円」という金額を聞いて、「え、たったそれだけ？」と思われるかもしれません（笑） しかし、私個人としては思っていた以上に収益が出たなと思っています。 以下の図を御覧ください。 引用:アフィリエイト・プログラムに関する意識調査2020 2020年7月、NPO法人アフィリエイトマーケティング協会の出した「アフィリエイト・プログラムに関する意識調査2020」によると、アフィリエイトでの1ヶ月の収入は、全回答者のうち「収入なし」が31.6%、1000円未満が50%弱と報告されています。 つまり私のブログは、全体のアフィリエイターの中で真ん中よりも上の層に位置している計算になります。 本ブログの収益の内訳 ここで一旦私のブログの収益の内訳を紹介します。 A8.net: 1,411円 もしもアフィリエイト: 2,622円 Googleアドセンス: 84円 合計「4,117円」です。 主にオンライン学習教材やAmazonや楽天アフィリエイトが中心となっています。 正直な話、Amazonで商品を購入する前の比較評価や実際に使用したレビュー記事をちゃんと書けば稼げるという印象です。 本ブログのPV数: 30日間で「1,803PV」以下が本ブログのGoogle Analyticsのユーザー概要欄です。 月間PV数の推移は以下のとおりです。 ブログを開始した当初は一桁だったPV数が徐々に増え、1年かけて80記事作成した段階で月間100PVだったのが600PVに跳ね上がりました。 本当、急にアクセスが増えました。不思議です。 ブログ記事は一貫して「過去の自分」に向けた記事を作成 ブログで収益を得るために工夫したことですが、実はあまり特筆するようなテクニックはありません。 ブログ記事を作成する際のノウハウはたくさんあります。 例えば、競合調査、見出しの作成、記事構成の設計、リライトのタイミング、などなどです。 ブログを始めた当初から現在まで、私は一貫して「過去の自分が知りたかった情報」を発信し続けてきました。 こういったノウハウはもちろん大事ですが、最初からここを突き詰める必要は無いかな、と思います。 結局ブログで大事なのは、 「読者の悩みを解決に導く」 これだけなんです。 肝心の「悩み」ですが、どんな小さなことでも良いです。 過去に自分が悩んでいたことやもっと早く知りたかったことをネタにしましょう。 それが、読者の悩み解決に繋がります。 そして何より「実体験」であることが記事の信頼性を高める要因になります。 私の例を1つ紹介しますね。 私は過去に膝の靭帯を損傷し全身麻酔の手術をしました。 膝の靭帯を損傷した当時の自分の悩みは以下でした。 「全身麻酔ってどんな感じなんだろう？」 「手術までにどんな処置をされるんだろう？」 「痛いのかな？」 そんな過去の自分に対して以下の記事を作成したのです。 &gt;&gt;[実体験]前十字靭帯再建手術を受けて復帰するまで①[ケガ→手術→リハビリ開始まで] 結果、今もこの記事は多くの人に読まれています。 結構シンプルな考え方ですよね？ 悩んでいた過去の自分を勇気づける記事を書くことが、結果として多くの人の悩みを解決する記事になるのです。 最初は「過去の自分の悩み」を解決に導く記事をたくさん書けば良いんだね！ このように「過去の自分」に語りかけ、なおかつ分かりやすい記事構成と文章で記事を作成すればOKです。 &gt;&gt;【テクニカルライティング】これだけ押さえれば大丈夫！わかりやすい文章の書き方 モチベーション維持のコツ: 収益化を最大のモチベーションにしない ブログ界隈でよく聞く話で、「1年以内にブログをやめてしまう人が大半」というのがあります。 これはブログのモチベーションを「収益化」にすることが原因だと思っています。 そのため、私はブログ記事作成のモチベーションを「収益化」以外に設定しました。 今のところ、私のブログ運営の最大のモチベーションは、「Webマーケティングスキルの取得」、「プログラミングなどのIT技術の知識体系化」、「ブログをきっかけに今後のキャリアを広げる」といったあたりです。 ブログラボのゴーゴーケンゴ(@KNGrits)さんのツイートでも、ブログによる収益化には時間がかかるものだと言及しています。 ブログを継続するコツの１つとして「収益化を最大のモチベーションにしない」はポイントになるかと思います。 余談ですが、ブログには必ず「問い合わせ」ページと「コメント欄」を作りましょう。 意外と仕事に関する連絡や感謝のコメントが来たりします。 「私のブログが読まれている」という事実は１つのモチベーションになると思います。 まとめ: 100記事までは「過去の自分の悩みを解決する記事を書き続ける」 本記事は、「【100記事】ブログで100記事書いたら1ヶ月で4,117円稼げた話」というテーマでまとめました。 ポイントと改めてまとめますね。 100記事書き続けるためのポイント 1. 収益化を最大のモチベーションにしない 2. 過去の自分の悩みを解決する記事を書き続ける 3. 細かいノウハウは記事を書きながら少しずつ学べばOK 「なんだ、これだけかよ。」と思われるかもしれませんが、私の場合は本当にこれだけです。 細かいノウハウは、記事を書きながらインフルエンサーの方のブログ記事やYoutubeで少しずつ学んでいけば良いと思います。 書籍であれば以下の書籍がおすすめです。こういった書籍に書かれている基本を学び少しずつ実践していけばよいかと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"今日からはじめて、月10万円稼ぐ アフィリエイトブログ入門講座\",\"b\":\"SBクリエイティブ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51+rX53tk1L._SL500_.jpg\",\"\\/41NSZ2rCOqL._SL500_.jpg\",\"\\/51I9PC+BEsL._SL500_.jpg\",\"\\/41zOBbltmbL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4815601674\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4815601674\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E4%BB%8A%E6%97%A5%E3%81%8B%E3%82%89%E3%81%AF%E3%81%98%E3%82%81%E3%81%A6%E3%80%81%E6%9C%8810%E4%B8%87%E5%86%86%E7%A8%BC%E3%81%90%20%E3%82%A2%E3%83%95%E3%82%A3%E3%83%AA%E3%82%A8%E3%82%A4%E3%83%88%E3%83%96%E3%83%AD%E3%82%B0%E5%85%A5%E9%96%80%E8%AC%9B%E5%BA%A7\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E4%BB%8A%E6%97%A5%E3%81%8B%E3%82%89%E3%81%AF%E3%81%98%E3%82%81%E3%81%A6%E3%80%81%E6%9C%8810%E4%B8%87%E5%86%86%E7%A8%BC%E3%81%90%20%E3%82%A2%E3%83%95%E3%82%A3%E3%83%AA%E3%82%A8%E3%82%A4%E3%83%88%E3%83%96%E3%83%AD%E3%82%B0%E5%85%A5%E9%96%80%E8%AC%9B%E5%BA%A7\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"K6FCn\",\"s\":\"s\"}); リンク","link":"/blog-progress/"},{"title":"[チートシート]minikube, dockerコマンドまとめ","text":"よく使うコマンドを一覧化しました。 ✓目次 Version確認 docker version確認 kubectl version確認 kubernetesクラスタを操作(minikube) minikube起動 minikube停止 状態確認 アドオン操作 アドオン追加 アドオン削除 アドオン一覧確認 リソース作成 リソース確認 リソース削除 Secretリソースのコマンド作成 Podに入ってコンテナ実行 Podとホスト間でファイル転送 ファイル転送(ホスト→Pod) ファイル転送(Pod→ホスト) Podの状態(概況)確認 Podのログ(詳細)を確認 Deploymentにおけるロールアウト履歴確認とロールバック ロールアウト履歴を表示 ロールバック dockerコマンド 指定されたイメージ取得 イメージ一覧 イメージ削除 コンテナ実行 コンテナ停止 コンテナ一覧 コンテナ削除(指定型) コンテナ削除(非指定型) コンテナ・イメージ削除 ビルド Dockerイメージの公開(DockerHub) Dockerイメージにタグ名追加 DockerHubへログイン DockerHubへ公開 Version確認docker version確認1$ docker version kubectl version確認1$ kubectl version kubernetesクラスタを操作(minikube)minikube起動1$ minikube start minikube停止1$ minikube stop 状態確認1$ minikube status ただし、実行環境がVirtualBoxではなくVMWare workstation等の場合は、--vm-driver=noneをコマンドの末尾に付与する必要がある。例えば、移動する場合は以下の通り 1$ minikube start --vm-driver=none アドオン操作 アドオンはminikubeに付属している機能で、様々なオプションを追加削除できる。 アドオン追加1$ minikube addons enable ADDON_NAME アドオン削除1$ minikube addons disable ADDON_NAME アドオン一覧確認1$ minikube addons list リソース作成 マニフェストファイルを作成したら、マニフェストファイルを指定してリソース作成/変更を行う オプション: -f &lt;filename&gt;: マニフェストファイルパス 例：kubectl apply -f hoge.yml 1$ kubectl apply -f &lt;filename&gt; リソース確認 作成したリソースを確認 オプション -f &lt;filename&gt;: マニフェストファイルパス TYPE: リソース種別(pod, replicasetなど) 例：kubectl get pod 1$ kubectl get [-f &lt;filename&gt; [TYPE]] リソース削除 指定したリソースを削除 オプション: -f &lt;filename&gt;: マニフェストファイルパス TYPE/NAME: リソース種別 or リソース名 参考（以下の-o wideオプションなどは、deleteコマンドにかかわらずgetコマンドでも使用可能。） -o [wide|yaml]: 出力形式を指定 wide: 追加情報の表示 yaml: YAML形式で表示 例：kubectl delete -f hoge.yml 例：kubectl get pod -o wide getコマンドに-o wideオプションを付与することでPodのIPアドレスが確認できる。 1$ kubectl delete [-f &lt;filename&gt;] [TYPE/NAME] [-o [wide | yaml]] Secretリソースのコマンド作成 Secretとは機微情報を扱うリソース。Secretのような秘密データは運用として手動登録になる。 引数: NAME: Secretリソース名 OPTION: --from-literal=KEY=VALUE: キーバリューペアを指定して登録 from-file=[KEY=]PATH: ファイルを指定して登録 1$ kubectl create secret generic NAME OPTION Podに入ってコンテナ実行 Podを作成後、作成したPodに入りシェル操作を行えるようにする。 引数: POD: 中に入りたいPod名 1$ kubectl exec -it POD sh Podとホスト間でファイル転送ファイル転送(ホスト→Pod) 指定されたファイルを指定された転送先に送る 引数: src: 転送元ファイル名/フォルダ名。ホスト側のカレントディレクトリからの相対パスでファイルを指定する。 pod-name: 転送先のPod名 dest: 転送先フォルダ名/ファイル名 例：kubectl cp ./hoge.txt debug:/var/tmp/hoge.txt 1$ kubectl cp &lt;src&gt; &lt;pod-name&gt;:&lt;dest&gt; ファイル転送(Pod→ホスト) 指定されたファイルを指定された転送先に送ります 引数: pod-name: 転送元のPod名 src: 転送元ファイル名/フォルダ名 dest: 転送先フォルダ名/ファイル名 例: kubectl cp debug:/root/hoge.txt ./hoge.txt 1$ kubectl cp &lt;pod-name&gt;:&lt;src&gt; &lt;dest&gt; Podの状態(概況)確認 Podがうまく動作しなかったときに必要となる。 引数: TYPE/NAME: リソース種別とリソース名を指定 例：kubectl describe pod/debug 1$ kubectl describe [TYPE/NAME] Podのログ(詳細)を確認 Podがうまく動作しなかったときに必要となる 引数: TYPE/NAME: リソース種別とリソース名を指定 —tail=n: 直近のnレコードだけ取得 例：kubectl logs pod/nginx 1$ kubectl logs [TYPE/NAME] [--tail=n] Deploymentにおけるロールアウト履歴確認とロールバックロールアウト履歴を表示 引数: TYPE: リソース種別 NAME: リソース名 1$ kubectl rollout history TYPE/NAME ロールバック ロールバックの実施 引数: TYPE: リソース種別 NAME: リソース名 —to-revision=N: 指定されたリビジョンに戻す。デフォルトは0(=直前の履歴) 1$ kubectl rollout undo TYPE/NAME --to-revision=N dockerコマンド指定されたイメージ取得 引数： NAME: Dockerイメージ名 TAG: タグ名。省略した場合はlatestになる。 例：docker image pull centos:7 1$ docker image pull NAME[:TAG] 省略コマンドは以下 1$ docker pull イメージ一覧 取得済みDockerイメージ一覧を表示 引数： なし 1$ docker image ls 省略コマンドは以下 1$ docker images イメージ削除 指定されたイメージを削除 引数： IMAGE: DockerイメージID [参考]Dockerイメージの削除にはdocker image pruneというコマンドもある。 これは、使われていないイメージを一括削除してくれるコマンド。 実際に作業するときは、このコマンドが使いやすい。 1$ docker image rm IMAGE 省略コマンドは以下 1$ docker rmi コンテナ実行 指定されたイメージを実行する 引数： OPTION -d:バックグラウンド実行 -it:shell実行する際に合わせて指定する 例：docker container run -it NAME sh -e KEY=VALUE: 環境変数を与える --name NAME: 実行時のコンテナ名を指定 -p CONTANER:HOST: コンテナポートをホストにマッピング COMMAND: 実行時に上書きしたいコマンド COMMANDは、Docker実行時にDockerコンテナに与えるコマンド。 例：docker container run -d nginx:1.17.2-alpine 1$ docker container run [OPTION] NAME[:TAG] [COMMAND] 省略コマンドは以下 1$ docker run コンテナ停止 指定したコンテナを停止する 引数: CONTAINER: コンテナID 1$ docker container stop CONTAINER 省略コマンドは以下 1$ docker stop コンテナ一覧 コンテナを一覧表示する 引数: OPTION -a: 停止中のコンテナも表示 オプション指定しない場合、起動中のコンテナのみが表示される。 1$ docker container ls [OPTION] 省略コマンドは以下 1$ docker ps コンテナ削除(指定型) 指定されたコンテナを削除する 引数: CONTAINER:Dockerコンテナ名 1$ docker container rm CONTAINER 省略コマンドは以下 1$ docker rm コンテナ削除(非指定型) 使用されていないコンテナを削除 引数: なし 1$ docker container prune コンテナ・イメージ削除 使用されていないデータを削除 引数: なし 1$ docker system prune ビルド 指定されたDockerfileを利用してDckerイメージを作詞絵 引数: OPTION: -t: イメージ名を指定する。「ユーザ名/イメージ名:バージョン名」で指定する形式が一般的 例：docker build -f hogehoge/test:v1.0.0 -f: Dockerfileの名前を指定する PATH: Dockerfileが保存されているパス 例:docker build -t test . 1$ docker build [OPTION] PATH Dockerイメージの公開(DockerHub)Dockerイメージにタグ名追加 引数: SRC_NAME: タグ付けしたいDockerイメージ名 TRG_NAME: 追加したいタグ名 1$ docker tag SRC_NAME[:TAG] TRG[:TAG] DockerHubへログイン 引数: -u USER: ユーザ名 -p PASSWORD: パスワード 1$ docker login [-u USER] [-p PASSWORD] DockerHubへ公開 引数: IMAGE_NAME: 公開したいDockerイメージ名 例：docker push hogehoge/test:v1.0.0 1$ docker push IMAGE_NAME[:TAG]","link":"/commandsheat-docker-minikube/"},{"title":"【特許技術】腰痛の人のために作られた座椅子がリモートワークに最適過ぎた","text":"腰に優しい座椅子がほしいなぁ。 この記事では、 ・100%リモートワーク中の腰痛持ちITエンジニアによるオススメ座椅子を紹介します！ 記事の信頼性(自己紹介) omathin ・完全フルリモート勤務中のIT企業のアーキテクト|研究者. ・腰痛持ちだが本記事で紹介する座椅子を活用して腰痛解消！ 結論：産学連携 腰をいたわるヘッドリクライニング座椅子３ 以下の座椅子です。この椅子のおかげでリモートワークによる腰痛とおさらばできました！ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js\",\"msmaflink\"); msmaflink({\"n\":\"腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック\",\"b\":\"座椅子ヤマザキ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41uPBv7FFVL.jpg\",\"\\/41EvXO8MjfL.jpg\",\"\\/41lt8iYbQmL.jpg\",\"\\/41UFS55D9NL.jpg\",\"\\/31G3TSfbndL.jpg\",\"\\/31OgOTB38oL.jpg\",\"\\/41JOz8gi67L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016113HBU\",\"t\":\"amazon\",\"r_v\":\"\"},\"aid\":{\"amazon\":\"2391505\",\"rakuten\":\"2390941\",\"yahoo\":\"2391506\"},\"eid\":\"LQGK3\",\"s\":\"s\"}); リンク >>腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック この椅子が、なぜ腰痛とおさらばできるのかの理由を以下にまとめます。 ・人間の体の構造をデータ分析して作られている ・特許技術化された唯一無二の座椅子 ・製造会社の企業理念 腰痛にならない理由①：背骨のS字カーブをサポートする構造 理想の姿勢ってどんな姿勢なのかご存知ですか？？ 背骨がまっすぐの状態だと思いますよね。 実は違います。S字が理想なのです。 この椅子は、人間の理想の姿勢とされる背骨のS字カーブをサポートする構造になっています。 具体的には、腰が丸くならないようにお尻の後ろの隙間を埋め、背すじの自然なS字カープをサポートする構造になっています。 この正しいS字カーブの姿勢を座りながらにして実現させるために、「姿勢」と「座り心地」をデータで検証し、検証結果を踏まえて作られた椅子なのです。 腰痛にならない理由②：特許技術化された唯一無二の座椅子 この椅子の特徴であるS字カーブをサポートするの構造は、大学との共同研究によって開発されてます。 そしてこの構造は特許化されています。 つまりこの椅子と同じ構造の椅子は他に存在しないということです。 唯一無二の椅子なのです。 腰痛にならない理由③：製造会社の企業理念 この椅子は、株式会社ヤマザキという会社が製造しています。 歴史は長く、1963年創業の座椅子専門メーカーです。 会社概要｜国産 座椅子、フロアチェアーの専門メーカー株式会社ヤマザキ 社長あいさつでは以下のように述べられています。 株式会社ヤマザキは座椅子専門メーカーとして「腰の負担を軽減して楽に座るための座具」というコンセプトを第一に考え、①使う人の立場で考えた人間工学に基づく商品開発 ②産学共同研究による客観的な製品性能評価 ③自社工場での丁寧な品質管理この３つの方針を大切にして、楽に長く座れる「理想的な姿勢」を追求した座椅子の開発と生産に日々努力しています。 まさに、腰痛持ちの人のために作られた椅子といっても過言では有りません。 日本の歴史ある会社の努力によって生み出された椅子であることがおわかりになったかなと思います。 まとめ：腰痛持ちはこの椅子で決定 座り心地がとても良くてずっと座ってられます。 腰痛に苦しんでいると仕事も日常のクオリティオブライフが下がる一方です。 腰痛に悩んでおられる方はぜひこの座椅子を試していただければと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js\",\"msmaflink\"); msmaflink({\"n\":\"腰をいたわるヘッドリクライニング座椅子３ (グレー) 日本製 ヤマザキ リクライニング ハイバック\",\"b\":\"座椅子ヤマザキ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41uPBv7FFVL.jpg\",\"\\/41EvXO8MjfL.jpg\",\"\\/41lt8iYbQmL.jpg\",\"\\/41UFS55D9NL.jpg\",\"\\/31G3TSfbndL.jpg\",\"\\/31OgOTB38oL.jpg\",\"\\/41JOz8gi67L.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016113HBU\",\"t\":\"amazon\",\"r_v\":\"\"},\"aid\":{\"amazon\":\"2391505\",\"rakuten\":\"2390941\",\"yahoo\":\"2391506\"},\"eid\":\"LQGK3\",\"s\":\"s\"}); リンク","link":"/chair-remote/"},{"title":"Djangoの開発環境をDockerで構築した後の初期設定","text":"Djangoでアプリを開発し始める際の初期設定をまとめていきます。 環境構築方法は、以下の記事を参照ください。 ✓目次 アプリの作成 settings.pyファイルに作成したアプリを記述する settings.pyファイルに.htmlファイルの配置場所を記述する プロジェクトのurls.pyにアプリのurls.pyファイルへのルーティングを記述する アプリにurls.pyファイルを作成する アプリのurls.pyにURLパスを設定 views.pyファイルに関数を定義 templatesに.htmlファイルを作成 localhost:8000/signupにアクセスする まとめ アプリの作成ここで言う「アプリ」というのは、一般的にいうスマホアプリとかWebアプリのことではありません。 Djangoが機能として備えているアプリです。 Djangoの構造は大きく分けて、プロジェクトとアプリという要素に分けられます。 ざっくりいうと、プロジェクトはそれぞれのアプリを統括する役割。 アプリは、個々の機能部という分担です。 環境構築の段階でプロジェクトは作成済なので、以下のコマンドでアプリを作成します。 terminal1docker-compose exec web python manage.py startapp hogehogeapp これでhogehogeappというフォルダと各種ファイルが生成されます。 プロジェクトとアプリに分けると機能を分割できるので、ごちゃごちゃにならなくて済むよ。複数人で開発する際も、データへのアクセスが分離されてカオスにならなくて済むね！ settings.pyファイルに作成したアプリを記述するsettings.pyファイルはプロジェクトフォルダ配下にあります。このファイルに、先程作成したhogehogeappというのを記述し、プロジェクトにアプリの存在を認識させます。 /examplepj/settings.py123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'hogehogeapp.apps.HogehogeappConfig'] 「INSTALLED_APPS」というのは、Djangoにおけるアプリケーションを意味しているんだね。adminと書かれているものは管理画面でauthは認証だよ。 settings.pyファイルに.htmlファイルの配置場所を記述するまずは、manage.pyファイルというファイルと同じ階層にtemplatesという空のフォルダを作成します。 次にsettings.pyファイルのTEMPLATESのDIRSにBASE_DIR / 'templates'と記述 /examplepj/settings.py123456789101112131415TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [BASE_DIR / 'templates'], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, },] プロジェクトのurls.pyにアプリのurls.pyファイルへのルーティングを記述するブラウザなどから送られるHTTPリクエストは、プロジェクトのurls.pyが受け取ります。 プロジェクトのurls.pyファイルは、受け取ったリクエストURLの文字列（リソースパス）を識別して、どのアプリのurls.pyファイルに送ればよいか振り分けます。 ここでは、いかなるURLリクエストにおいてもhogehogeappのurls.pyファイルの定義に従う記述にしておきます。 /examplepj/urls.py1234567from django.contrib import adminfrom django.urls import path, includeurlpatterns = [ path('admin/', admin.site.urls), path('', include('hogehogeapp.urls'))] アプリにurls.pyファイルを作成する作成したhogehogeappフォルダにはデフォルトでurls.pyが存在しません。 なので新規にurls.pyを作成します。コードはプロジェクトのurls.pyファイルのコードをコピペして以下のように編集します。 /examplepj/hogehogeapp/urls.py1234567from django.contrib import adminfrom django.urls import path, includefrom django.urls import pathurlpatterns = [ path('admin/', admin.site.urls),] アプリのurls.pyにURLパスを設定adminのpathは削除して、任意のURLパスを設定します。今回はsignup/というパスを作成します。 合わせて、これから作成するsignupfuncという関数も記述。 /examplepj/hogehogeapp/urls.py1234567from django.contrib import adminfrom django.urls import path, includefrom .views import signupfuncurlpatterns = [ path('signup/', signupfunc),] views.pyファイルに関数を定義signupfunc関数を記述します。 renderというのは、HTTPレスポンスオブジェクトをs買う制するモジュールです。 renderは引数と3つ必要とします。 request: リクエストそのもの '.html': templatesに作成したhtmlファイル '{ }': モデルのデータ or 任意に指定したデータ /examplepj/hogehogeapp/views.py123456from django.shortcuts import render# Create your views here.def signupfunc(request): return render(request, 'signup.html', {}) templatesに.htmlファイルを作成前に作成したtemplatesフォルダに、views.pyファイルに記述したsignup.htmoファイルを作成する。 適当に「hello world!」とでも書いておきましょう。 /examplepj/templates/signup.html1hello world! localhost:8000/signupにアクセスするブラウザでlocalhost:8000/signupにアクセスして、以下のような画面が出てくれがOKです。 まとめ本記事では、「Djangoの開発環境をDockerで構築した後の初期設定」というテーマでまとめました。 早速DjangoでWebアプリを開発していきましょう。 これから本格的にプログラミングを学んでいく方向けに、おすすめのプログラミングスクール・教材を記事にまとめてますので、よろしければ以下の記事も見ていってください。 &gt;&gt; 【厳選4つ】未経験におすすめのプログラミングスクール・教材！ - omathin blog 「1万円以上お金が出せない」「低コストでRailsの基礎を学びたい」という方はUdemyを活用した学習も検討してみてください。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームなので安心です。 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） こちらは大橋亮太先生のUdemy講座です。具体例をたくさん入れた解説が好評であり、「なぜ」の説明が丁寧です。 ＼ 無料登録でセール情報をGET! ／ UdemyでDjangoの基礎をマスターする","link":"/django-startapp/"},{"title":"DjangoのUserモデルを使用してみる","text":"DjangoでUserモデルを使用する方法をまとめます。 ✓目次 Userオブジェクトとは HTTPメソッドの適用 views.pyファイルでUserモデルをimportする Userモデルをテーブル化してDB化(migrateコマンド) ユーザ登録 Userデータの表示 UserオブジェクトとはUserオブジェクトとは、認証システムです。Djangoアプリ開発に関わるユーザ情報を登録することができます。 登録ユーザのプロパティは以下の通りです。 username password email first_name last_name 本記事では、htmlファイル(signup.html) のFormにHTTPメソッドを適用し、Userオブジェクトの取得方法をまとめます。 HTTPメソッドの適用HTTPメソッドについては以下の記事でまとめているので参照ください。 Djangoで作成したHTMLファイルのformタグの部分にPOSTメソッドを適用する際は、formタグの内部にmethod='POST'と、csrf_tokenを記述します。 templates/signup.html1&lt;form class=&quot;form-signin&quot; method='POST'&gt;{% csrf_token %} これでPOSTメソッドでデータを送ることができます。 views.pyファイルでUserモデルをimportするUserモデルは、Djangoがデフォルトで具備しているモデルであり、models.pyに自らモデルを記述する必要はありません。 まずは、Djangoの公式ドキュメントに従ってUserモデルをインポートします。 hogehogeapp/views.py1234567from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): return render(request, 'signup.html', {}) Userモデルからオブジェクトデータすべてを抽出する記述にしていきます。 hogehogeapp/views.py12345678910from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.all() print(object_list) return render(request, 'signup.html', {}) User.objects.all()という記述で、Userモデルのすべてのオブジェクトデータを取得できます。 取得して全オブジェクトデータをprint(object_list)として表示させます。 Userモデルをテーブル化してDB化(migrateコマンド)以下の通りmigrateコマンドを実行。 makemigrationコマンドは、models.pyファイルに新しいモデルを定義していないので、実施する必要はありません。 terminal12345678910111213141516171819202122docker-compose exec web python manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying sessions.0001_initial... OK usernameやemailという記述が確認できます。Userモデルが作成されたように見えますね。 ユーザ登録 ここではsatoとtanakaというユーザを作成していきます。Email addressはtanakaさんだけbbb@example.comというアドレスを登録しておきます。他は、ひとまず何も入力せずEnterでOKです。passwordは適当にpasswordと入力しておきます。 terminal12345678910111213141516$ docker-compose exec web python manage.py createsuperuserUsername: tanakaEmail address: bbb@example.comPassword: Password (again): This password is too common.Bypass password validation and create user anyway? [y/N]: ySuperuser created successfully.$ docker-compose exec web python manage.py createsuperuserUsername: satoEmail address: Password: Password (again): This password is too common.Bypass password validation and create user anyway? [y/N]: ySuperuser created successfully. docker-compose psコマンドでWebとDBが起動していることを確認し、chromeなどのブラウザで、localhost:8000/adminにアクセスしてみましょう。ユーザ名はroot, パスワードはpasswordです。 Userデータの表示docker-compose upコマンドで、フォアグラウンドモードでコンテナを起動させ、localhost:8000/signupにアクセスして、GETメソッドを送ってみましょう。 Terminal上に、QuerySetというリストが確認できます。 terminal1web_1 | &lt;QuerySet [&lt;User: root&gt;, &lt;User: tanaka&gt;, &lt;User: sato&gt;]&gt; 次に、個別のデータを取得してみましょう。 個別のデータを取得したい場合は、views.pyにて以下のように.get(username = 'tanaka)'とすればOKです。 hogehogeapp/views.py123456789from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.get(username = 'tanaka') print(object_list) return render(request, 'signup.html', {}) localhost:8000/signupにアクセスすると、tanakaというのがterminal上で確認できます。 terminal1web_1 | tanaka 次にtanakaさんのemailアドレスを取得したい場合は、取得したオブジェクトに対して、emailというプロパティを指定すればOKです。 hogehogeapp/views.py123456789from django.shortcuts import renderfrom django.contrib.auth.models import User# Create your views here.def signupfunc(request): object_list = User.objects.get(username = 'tanaka') print(object_list.email) return render(request, 'signup.html', {}) localhost:8000/signupにアクセスしてGETメソッドを送信してterminalを確認してみましょう。 terminal1web_1 | bbb@example.com Djangoをより深く学びたい方へ(Udemyのオススメ講座) 【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） こちらは大橋亮太先生のUdemy講座です。具体例をたくさん入れた解説が好評であり、「なぜ」の説明が丁寧です。 この講座を確認する","link":"/django-userobject/"},{"title":"【M1 Mac】Djangoの開発環境をdocker-composeで作成する","text":"M1 MacでもDockerでDjango開発環境作れるの？という疑問に答えていきます！ ✓目次 この記事の対象者 この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 requirement.txtの作成 docker-compose,ymlの作成 Djangoプロジェクトの作成 DBの設定 起動 この記事の対象者 ・ M1 MacでDjango開発環境をDockerで構築したい方(Django 3.1.2 / PostgreSQL) この記事でやること Docker Desktop for Macのインストール Dockerfileの作成 requirements.txtの作成 docker-compose.ymlの作成 Djangoプロジェクトの作成 DB(postgresql)の設定 起動 Docker Desktop for Macのインストール 以下の記事にまとめられているインストール方法で問題なく導入できます。Macbook Pro M1(Apple Silicon) で Dockerを動かす - Qiita インストールが完了したらバージョンと動作確認。 terminal12345$ docker --versionDocker version 20.10.1, build 831ebeae96$ docker-compose --versiondocker-compose version 1.27.4, build 40524192 Dockerfileの作成 まずは任意の空のディレクトリを用意して、Dockerfileを用意していきます。 この記事では``django``という名前の空ディレクトリを作ります。 terminal123$ mkdir ~/django$ cd ~/django$ vim Dockerfile docker-composeを使う場合、docker-compose.ymlがおいてあるディレクトリ名が、コンテナ名やvolume名の接頭字として使用されます。 実際の開発においては、プロジェクトの名前など、意味のあるディレクトリ名にしておいたほうが望ましいです。 例えば、ToDoアプリを作るプロジェクトなら、Todoapppjという名前のフォルダを用意したほうが良いということだね。 また、作成したディレクトリをビルドコンテキストとするので、不要なファイルは含めないようにしましょう。 Dockerfileでは、pythonの実行環境のイメージを作成します。 Dockerfile1234567FROM python:3ENV PYTHONUNBUFFERED 1RUN mkdir /codeWORKDIR /codeCOPY requirements.txt /code/RUN pip install -r requirements.txtCOPY . /code/ Dockerfileの中身を以下にまとめます。 FROM python:3: イメージ名にpython3の実行環境のイメージを指定 ENV PYTHONUNBUFFERED 1: PYTHONUNBUFFERED`という環境変数に1という値を設定している。環境変数の意味は、pythonの標準出力、標準エラー出力をバッファーにため込まないための設定。1という数字自体に意味はないがこの環境変数に何らかの値を設定するとバッファーを無効化できます。 RUN mkdir /codeとWORKDIR /code: codeディレクトリを作成し、作業ディレクトリをcodeディレクトリに移動しています。 COPY requirements.txt /code/: ビルドコンテキスト上に存在するrequirements.txtをcodeディレクトリ内に置き、RUN pip install -r requirements.txtでpipインストールを実行しています。pipはpythonのパッケージ管理ツールで、pip installコマンドは、-rで指定した、requirements.txtに記載されているパッケージのインストールを実行します。rewuirements.txtは、この後ビルドコンテキスト内に作成しますが、このファイルにはDjangoとPosgreのドライバのパッケージ名を記載します。 COPY . /code/: ビルドコンテキストの内容をすべて/code内に置いています。 requirement.txtの作成 terminal1$ vim requirements.txt requirements.txtは、pipインストールコマンドで、インストールするパッケージを定義したもの。 本記事作成時点で最新バージョンの、Djangoパッケージ3.1.2を指定します。 psycopg2は、pythonでPostgreSQLに接続するためにドライバです。こちらについてはバージョンの指定はしません。 requirements.txt12Django==3.1.2psycopg この時点でフォルダの中には、Dockerfileとrequirements.txtの２つのみが存在しているかな？この２つ以外のファイルがあったら別の場所に移すか削除しようね！ docker-compose,ymlの作成 docker-compose.ymlで最後だから頑張ろう！ terminal1$ vim docker-compose.yml docker-compose.yml12345678910111213141516171819202122version: '3'services: db: image: postgres environment: POSTGRES_PASSWORD: password POSTGRES_USER: postgres volumes: - pgdatavol:/var/lib/postgresql/data # postgresqlのデータ領域である/var/lib/postgresql/dataのディレクトリにマウント web: build: . command: python3 manage.py runserver 0.0.0.0:8000 volumes: - .:/code ports: - &quot;8000:8000&quot; depends_on: - dbvolumes: pgdatavol: # データ永続化のため、pgdatavolというvolumeを作成 各コードの意味を以下にまとめます。 services:: dbとwebの2つが定義されている。2つのコンテナが起動する想定。dbにはpostgresQLを使用。 buildには.が`定義されているので、先ほど定義したdockerfileからイメージをビルドして使用する command:: コンテナ起動時に実行されるコマンドを意味している。ここでは、python3でmanage.pyを実行し、引数に開発用に軽量なサーバを立ち上げるrunサーバとlistenするIPアドレス、ポート番号を指定している。manage.pyはDjangoをインストールすると自動で生成されるファイル。ただし、ここに記載しているコマンドはコンテナ実行時にコマンドが渡された場合に上書きされる。そのため、引数にコマンドを渡さなかった場合にdocker-composeのコマンドが実行される volumes:: カレントディレクトリを/codeにbindマウントしている。 ports:: 8000番で公開して、コンテナの8000番に転送されるように設定している。転送先のポートは先ほどのrunserverのlistenポートで指定した8000番と合わせる必要がある。 depends_on:: dbが指定されている。これはWebサービスを起動する前にdbサービスが起動するように依存関係を定義している。これによってWebサービスを起動する際は自動的にdbサービスが先に起動するようになる。 これで、コンテナを立ち上げる設定ファイルの準備が完了しました。 Djangoプロジェクトの作成 ここまで作成した、Dockerfile, requirements.txt, docker-compose.ymlの３ファイルのみが配置されているフォルダで、以下のコマンドを実行しましょう。 ここでは、プロジェクト名をexamplepjとしていますが、任意のプロジェクト名でOKです。 1$ docker-compose run web django-admin.py startproject examplepj . このコマンドは、今いるディレクトリに配置されたdocker-compose.ymlファイルで定義している「web」というコンテナに対して、\"django-admin.py startproject examplepj .\"というコマンドを実施してね、という命令を出しているんだね。 すると、examplepjフォルダとmanage.pyファイルがカレントディレクトリに自動生成されます。この時点で以下のようなディレクトリ構成になっていると思います。 tree123456789101112131415161718.├── Dockerfile├── docker-compose.yml├── examplepj│ ├── __init__.py│ ├── __pycache__│ │ ├── __init__.cpython-39.pyc│ │ ├── settings.cpython-39.pyc│ │ ├── urls.cpython-39.pyc│ │ ├── views.cpython-39.pyc│ │ └── wsgi.cpython-39.pyc│ ├── asgi.py│ ├── settings.py│ ├── urls.py│ ├── views.py│ └── wsgi.py├── manage.py├── requirements.txt DBの設定 作成されたexamplepjのsettings.pyファイルに、DBの設定を記述していきます。 /examplepj/settings.py1234567891011121314# Database# https://docs.djangoproject.com/en/3.1/ref/settings/#databasesDATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'postgres', 'USER': 'postgres', 'PASSWORD': 'password', 'HOST': 'db', 'PORT': 5432 }} PASSWORDは簡単なものにしているけど、ちゃんとした開発のときは注意しようね！ 起動デタッチドモードで各サービスを起動します。 terminal1$ docker-compose up -d localhost:8000にブラウザでアクセスすると、以下のようにDjangoの画面が表示されます。 おめでとう！これで開発できるね！ これから本格的にプログラミングを学んでいく方向けに、おすすめのプログラミングスクール・教材を記事にまとめてますので、よろしければ以下の記事も見ていってください。 &gt;&gt; 【厳選4つ】未経験におすすめのプログラミングスクール・教材！ - omathin blog Djangoでアプリ開発する際の初期設定は以下の記事を参照してください。 &gt;&gt; Djangoでアプリ開発する際の初期設定方法を確認する あわせて読みたい記事 2020-01-11【プログラミング学習】Progateの後はUdemyかSkillHacksがおすすめIT 2020-03-14Dockerとは何か、メリット/デメリットまとめIT","link":"/docker-compose-django/"},{"title":"【特保＋楽痩せ食材】食べるだけで痩せる方法","text":"特保飲料と楽痩せ食材で簡単に痩せる方法を紹介。楽痩せこそが、リバウンドしない秘訣です。 この記事を見ている人は以下のような悩みがあるのではないでしょうか。 楽にやせたい 在宅期間中、なるべく運動せずに痩せたい。 バランスの良い食事が大事なのはわかるが、手間のかかる料理はしたくない or する余裕がない。 食べるだけで痩せる料理はどれも手間がかかる。怠け者の私でも実践できる良いものはないだろうか。 お金も時間もなるべくかけずに、食べるだけで痩せる食事を教えてほしい。 一つでも当てはまったら、この記事を読む価値はいくらかあると思いますので、お付き合いください。 かなりの怠け者でも継続して摂取できる食材、かつ、効果が示されているものを厳選してまとめております。 これから紹介する食材を摂取し、健康的な体を手に入れるだけでなく、リバウンドせずに体形をキープできるようになると思います。 ✓目次 本記事の対象者 本記事の信憑性 食材一覧 ✓焼き梅干し ✓ブロッコリースプラウト ✓特茶とからだすこやか茶 まとめ オススメ 本記事の対象者まずこの記事を読んでいる人の対象は以下とします。 医師からメタボリックシンドロームと診断された人 つまり、医学的に普通体系である人が、更に痩せて美しい体形を手に入れるための手法ではありませんので、ご注意ください。 とは言いつつも、実践すれば幾ばくか効果はあるかもしれないので、やってみる価値はあると思います。 本記事の信憑性現に私は、80kgから68kgまでこの方法で痩せました。 また私はビジネスサプリメントアドバイザーをはじめとした資格を持っており、栄養や食に関する知識があります。 そのため、これから紹介する食材がなぜ食べるだけで痩せるのかという理由も明確も示しながらまとめていきたいと思います。 食材一覧結論を言ってしまいます。以下が怠け者でも継続して摂取し続けられるお食事一覧です。 焼き梅干し ブロッコリースプラウト 特茶 からだすこやか茶W 以降は、作り方と効果が得られる理由をそれぞれまとめたいと思います。 ✓焼き梅干し焼き梅干しの作り方はとても簡単です。フライパンに少量の油をかけ、梅干しを投入し、少し焼き色がつくまで熱すればよいだけです。 「なんだよ、フライパンと加熱が必要だなんてめんどくさいじゃないか」 と言いたくなりましたよね？ なぜ焼き梅干しが怠け者向けなのかは、後々説明するとして、ひとまず、なぜ焼き梅干しが良いのかの理由を述べたいと思います。 梅干しには、「バニリン」という物資が含まれており、脂肪燃焼効果が備わっていることが分かっています。参考：脂肪燃焼作用 | 梅(梅干し)・バニリンの効能 | 紀州梅効能研究会 また梅干しには、バニリンによく似た「バニリングリコシド」という物質も多く含まれています。 このバニリングリコシドは、加熱することによって、バニリンに変化します。つまり、梅干しを加熱してから食べたほうが脂肪燃焼効果が高まるということです。 そしてさらに、ここが怠け者でも続けられるポイントなのですが、バニリングリコシドから変化したバニリンは、梅干しが冷めてもバニリングリコシドに戻らないということも明らかになっています。 つまり、、、 梅干しをまとめて加熱した後、冷蔵庫に入れても、バニリンが増えた状態を保つことができる ということです。 なので、梅干しを買ってきたら、全部の梅干しをフライパンで焼いてしまい、その後は冷蔵庫に入れ、隙間時間に食べればよいのです。 私は、朝起きたらとりあえず2粒。夜に小腹がすいたら1粒。みたいな形で食べています。 「塩分が気になる」という方は減塩の梅干しを用いる or 食べる量を控えめにするなどの工夫をしながら実施してみてはいかがでしょうか。 ✓ブロッコリースプラウトこちらは複数のメディアでも紹介されている食材ですね。 「スルフォラファン」という物質が、肝臓の働きを上げ、体質改善やダイエット効果があることが認められています。 怠け者でも続けられるポイントとしては、スルフォラファンを15g程食べた後、その効果が3日間継続する点です。 つまり 3日に1度、少し食べるだけで良い ということです。 また価格も安価でありお財布にも優しい点がGoodポイントだと思います。 サプリメントで手軽にスルフォラファンを取りたい、という方は以下がおすすめです。 ✓特茶とからだすこやか茶最後は、特保飲料の特茶とからだすこやか茶です。 「なぜ2種類なの？」と気になると思います。 理由は、特保飲料には、脂肪の燃焼を助けるタイプと脂肪の吸収を穏やかにするタイプの2種類が存在するということです。 特茶は、「脂肪の燃焼を助けるタイプ」であり、からだすこやか茶は「脂肪の吸収を穏やかにするタイプ」になります。 更に、からだすこやか茶Wは、脂肪だけでなく、糖質の吸収を穏やかにする効果もあるため、白米やラーメンが好きな方は特にこれを飲むことを推奨します。 そのため、私のお勧めは、以下のように飲み分けることです。 特茶→朝の通勤時に飲むからだすこやか茶→食事中 or 食後に飲む まとめ最後にまとめます。 怠け者向けの食べるだけで良いお食事は以下です。 焼き梅干し パックで買ったらまとめて焼いて、適宜食べる ブロッコリースプラウト 3日に1ど15g程度食べる。 特茶 朝にコンビニや自動販売機で買って飲む Amazonでまとめて買えば、ちょっとお得。 からだすこやか茶W コンビニなどで買って飲む Amazonでまとめてかえば、ちょっとお得。 その都度購入しても良いと思いますが、このような食品系は通販などでまとめて購入すると安く済みます。私は特茶やからだすこやか茶Wは、Amazonで購入しています。 ダイエットに成功すると、「もっと引き締まった体にしたい」という欲求が生まれてくると思います。そのような方向けの記事も、今後まとめていこうと思います。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです","link":"/easy_diet/"},{"title":"【実体験】オンライン英会話レアジョブを毎日続る3つのポイントを紹介 | Twitterで毎日受講レポート発信中！","text":"レアジョブでオンライン英会話って効果あるの？勉強始めたいけど、うまくやれるか不安だなぁ そんなあなたのために、レアジョブを毎日続け、英語力を効果的に上げるポイントを実体験に基づいてまとめていきます。 本記事の対象者 1. オンライン英会話自体が初めての人2. 自分の英語力に自身がない人3. 毎日オンライン英会話と続けられるか不安な人 Twitterで毎日の受講レポート発信中！フォローよろしくおねがいします! &gt;&gt;フォローする ✓目次 筆者の英語学習歴 レアジョブ英会話とはなにか 結論：「誰でも毎日続けられて英語力も上げられます。」 ポイント.1 毎日25分コースを受講する ポイント2. 自分の英語レベルより2レベル程度低いレッスンからはじめる ポイント3. 毎日レッスンを受ける時間を固定する 予約・予習・レッスン受講の流れ まとめ 筆者の英語学習歴 学生時代は、学校のカリキュラムに沿った学習しかしてきませんでした。（単語、熟語、英文法、長文読解をひたすらやらされる。） 社会人になった時点での英語力はひどいもので、TOEICは500点くらい。 PROGOSという英会話のテストは、2021年2月時点でレベル5という結果でした。 そして、大学入試でお世話になった先生が、なんともタイムリーな本を出版してました。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"英語が話せるようになりたければ、今すぐオンライン英会話をやりなさい! (語学シリーズ)\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51C8YhO4vVL.jpg\",\"\\/41+EnaU6JbL.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4142132822\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4142132822\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E8%8B%B1%E8%AA%9E%E3%81%8C%E8%A9%B1%E3%81%9B%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%AA%E3%82%8A%E3%81%9F%E3%81%91%E3%82%8C%E3%81%B0%E3%80%81%E4%BB%8A%E3%81%99%E3%81%90%E3%82%AA%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%B3%E8%8B%B1%E4%BC%9A%E8%A9%B1%E3%82%92%E3%82%84%E3%82%8A%E3%81%AA%E3%81%95%E3%81%84!%20(%E8%AA%9E%E5%AD%A6%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"w2jAb\",\"s\":\"s\"}); リンク やはり実際の会話でアウトプットしないとレベルアップは難しいと感じてきたため、忙しい毎日でもオンラインで好きな時に英会話レッスンを受講できるレアジョブ英会話を始めることにしました。 レアジョブ英会話とはなにか 講師数6,000人以上を誇る国内最大級のオンライン英会話サービスです。 &gt;&gt; レアジョブ英会話を詳しく見る 導入実績は素晴らしいもので、企業研修への導入社数3,100社以上、教育機関への導入数も300校以上と企業や学校にも選ばれています。 1. 1レッスン129円～から始められる！ 2. 国際基準(CEFR-J*1)に則った教材開発や講師のトレーニング 3. 日本人の専門カウンセラーに学習相談できる 4. Skype不要でレッスンを受講できる独自システム「レッスンルーム」 5. レッスンの予約から受講、復習まで完結するスマホアプリ 会員登録（無料）をいただくと通常2回（1回25分間）の体験レッスンを受講できます。 どんなものなのか体験するのが手っ取り早いと思います。 無料なので、興味のある方は無料体験レッスンの内容を確認してみてください。 &gt;&gt;無料体験レッスンの内容を確認する 結論：「誰でも毎日続けられて英語力も上げられます。」 これから紹介するポイントを押さえれば、毎日継続できますし英語力も上げられます。 ポイントを大まかに言うと、徹底してストレスの無い学習にするということです。 早速まとめていきます。 ポイント.1 毎日25分コースを受講する 英語力向上に不可欠なことは、毎日継続して英語を話す習慣を作るということです。 本当にこれだけです。 そのためにまずは、毎日25分 9,800円/月のコースを選択しましょう 私は、英語力向上に効果的だと言われるシャドーイングやディクテーションに取り組んだことあります。 毎日英語を聞いて文字を書きだしたりするの、かなり億劫じゃないですか？ モチベーションの維持が難しいと思いました。 レアジョブは、好きなタイミングで気軽にオンラインで英会話のレッスンが受けられます。 先生は経験豊富な方々が多く、英語初心者の人でも毎日続けられるようにレベルを合わせてくれます。 先生は自分で選択可能です。年齢層も60歳〜20歳くらいの人まで幅広いため、ジェネレーションギャップみたいなものも心配有りません。※私はもっぱら優しそうな40歳くらいの女性を選んでます（笑） &gt;&gt;無料体験レッスンの内容を確認する ポイント2. 自分の英語レベルより2レベル程度低いレッスンからはじめる オンライン英会話に初めて挑戦する人は、必ず自分のレベルよりも2〜3レベルほど低いレベルから開始しましょう。 実は私、それなりに海外出張をして英語を用いて仕事をした経験がありました。 そのため、レベル1〜10のレベル4から開始しました。 結果、「毎日続けるのしんどい。。。」という感じになり、挫折しました。 オンライン英会話学習で大事なことは、毎日続けることです。 「毎日続ける」というのは、とても大変なことです。 しかし、英会話力の向上のためには毎日継続して英語を話すという習慣をつけるしかないのです。 オンライン英会話に初めて挑戦する人は、当面は以下を目標にしてレッスンを受講するべきだと思います。 当面の目標 1. 毎日続けて習慣化する。2. 習慣化するために、無理のないレベル（自分の英語レベルの2レベル下くらい）から開始してストレス無く始める3. オンラインでの英会話レッスンに慣れる。 &gt;&gt;無料体験レッスンの内容を確認する ポイント3. 毎日レッスンを受ける時間を固定する 「英会話レッスンを受講する」という行為を習慣化させるために、レッスンを受ける時間を固定しましょう。 私は22:00くらいにレッスンを受講しています。 理由は、レッスン中のフリートークの時に、「今日何をしたのか？」「何を食べたの？」という感じの話題が作れるからです。 各々の生活リズムに合わせて受講する時間帯を固定させるのが、習慣化の秘訣かなと思います。 予約・予習・レッスン受講の流れ 実際にどうやって予約を行い、レッスンを受講するのかを体験談ベースで以下の記事にまとめています。 私が初めてレッスンを受講した時に、いくつか失敗したことがあるので、以下の記事を元に予約と準備をすれば安心です。 まとめ 今回は、「【実体験】オンライン英会話はレアジョブで決まり | 毎日続けられるポイント3つを紹介」というテーマで記事をまとめてみました。 私のTwitterで、毎日受講しているレアジョブの学習内容とレビューについてつぶやいていますので、もしよろしければフォローお願いします。 またレアジョブは現在無料体験レッスンを提供しています。どんなものなのか試しに受講してみると良いと思います。 &gt;&gt;無料体験レッスンの内容を確認する よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/get-start-rarejob/"},{"title":"マジメすぎると不幸になる話","text":"仕事はまじめに取り組まずにふざけたほうが成果も出るし評価も高くなる仕組みをご存じですか？ 研究結果に基づき、まじめにきっちり仕事をせずに遊び心を持って仕事をするほうが良いことが分かりました。 何のために仕事をしているのか？という疑問に対する答えが見つかるかもしれません。 目次 仕事は何のためにするのでしょうか？ 研究内容と結果 ユーモアは才能ではない まとめ 仕事は何のためにするのでしょうか？メンタリストDaiGoさんもYoutubeの中で以下のように述べています。 そもそも、仕事は何のためにしてますか？お金を稼ぐためですか？お金を稼ぐのは何のためですか？生きるためですか？生きるのって何のためですか？幸せになるためですよね。楽しく生きたいからみんな頑張っているわけですよね。不幸になるために頑張る人はいませんよね。でもこれってみんな見失うんです。私、講演会に呼ばれたりするときに、社長の人とかいっぱいいるんですが、よく聞く質問があるんですよ。「なんで起業したんですか？」って。するとですね、面白いことに、答えられない人が多いんですよ「お金が欲しいから」「成功したいから」って答える人がいるんですけど、「既にお金持ってるじゃないですか。成功してるじゃないですか。何が不満なんですか？」って聞きかえすんです。一見成功している人が幸せなのかというと必ずしもそうではなく漠然とした不安を抱えているんですね。 「何のために仕事をしているのか」という問いに対して、「生活のため」、とか、「仕事をするのは当たり前」というふうに、漠然と何気なく日常を過ごしている人は結構おおいのかな、と思います。 お金があって地位もある人が必ずしも幸せなのかというと、そうでもないな、と思う部分もありますしね。 結局、お金を稼ぐのも、仕事をするのも、幸せな状態でないと意味がないということだと改めて感じさせられます。 では、幸福になるためには何が必要なのでしょう、というのを調べてくれたのがチューリッヒ大学の研究なのです。 Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 研究内容と結果18歳～92最までのドイツ人4100名を対象にしたもので、全員にオンラインでアンケートを実施して、遊び心(Playfulness)が、幸福度に与える還元度を研究したものです。 要するに仕事でも人生でも遊び心を持って、悪い言い方するとふざけて生きている人と、まじめに生きている人とどっちの方が幸せなの？ という研究なんです。 遊び心の定義ですが、「ふざける」と述べましたがすべてを適当にやるというわけではないです。 例えば、自分が苦しい状況、まじめにやらなくちゃいけない状況、緊張している状況でも、周りに楽しさをふりまいたり、ユーモアを周りに与えたり、ということができるかどうか。目の前で起こっていることをいろんな視点で見て、面白さをもって、それを解釈することができるかどうか、ということです。 上手い突込みをいれたりとか、ちょっとぼけてみて周りから突っ込みが入る、みたいなユーモラスに会話ができる人っているじゃないですか。 一方で、上司の言うことを全部真に受けちゃったりとか、人に面白いことを言ったり冗談を言ったりすることをはばかるような人とか、仕事の時に冗談を絶対に言わない人、バカ話しないと決めちゃっている人とかいますよね。 それに対して遊び心がある人がどう影響を与えるかを調べたんですね。 結果として何が分かったかというと、遊び心をあらゆる場面で考えられる感覚は、すべての年齢に対してポジティブな体験を増やす、という効果が判明しました。 つまり、普段からユーモアをふりまいている人とか、ちょっと物事を嫌味にならない程度、反感を買わない程度でちゃかしたりとかができる人は、ポジティブな体験が増えたんですね。 つまり幸せになったということです。 ユーモアは才能ではないポイントは、ただユーモアを秘めている、だけではダメなんです。 少しでも良いから表に出す、というのが大事、とのことです。 笑いのセンスが必要というわけではなく、「茶目っ気があるなぁ」、とか、「遊び心があるなぁ」、というのを表現することが幸福感をあげる、ということなんです。 才能ではない、ということなんですね。 遊び心でを持って、ちょっとしたことを楽しむ、という姿勢が大事、という理解で良いと思います。 まとめ 「何のために仕事をするのか」の答えは、「幸せに生きるため」。今、自分は幸せだろうか。仕事で不幸になっていないだろうか、というのを自問自答してみるといいかもしれない。 仕事はまじめにやりすぎない。ちょっとしたことでもいいから遊び心を持つことが大事。 遊び心を持てることは才能ではない。ちょっとしたことを表現するだけでOK。 ユーモアのある人間に近づくためにオンライン学習をしませんか？ 遊び心を持てるようになれるには、自分のできることや引き出しを増やすことではないでしょうか。「本が苦手」、「毎日が忙しい」という方は、私も普段から取り組んでいるオンライン学習がおすすめです。プログラミングを例に、以下に記事をまとめているので、興味があれば読んでみてください。 エンジニアではなく、ビジネスや営業系の方は、以下の講座がおすすめです。私も受講しましたが、手書きで「誰に、どのような価値を、どのように提供すればよいのか」という思考法やフレームワークが学べます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWB6I0o\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/business_model/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1846780_8afd_2.jpg\"}}); ビジネスモデルを見える化しよう! その場で伝わる手書きの図解スケッチ 参考 Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 https://yuchrszk.blogspot.com/2016/08/blog-post_22.html https://www.youtube.com/watch?v=werZT4hc26A&amp;t=13s","link":"/happy-method/"},{"title":"【Python】Insertion Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Insertion Sortとは Pythonの基礎について [Python基礎]while文 Insertion Sortのコーディング 別解 まとめ Insertion Sortとはソートアルゴリズムの一種です。 まず0番目と1番目の要素を比較し、順番が逆であれば入れ換える。次に、2番目の要素が1番目までの要素より小さい場合、正しい順に並ぶように「挿入」する（配列の場合、前の要素を後ろに一つずつずらす）。この操作で、2番目までのデータが整列済みとなる（ただし、さらにデータが挿入される可能性があるので確定ではない）。このあと、3番目以降の要素について、整列済みデータとの比較と適切な位置への挿入を繰り返す。 挿入ソート - Wikipedia Pythonの基礎についてInsertion Sortを実装するために必要なPythonの基礎知識は、以下の記事にもまとめていますので参照ください。 ここでは、上記の記事でまとめた基礎事項に加えて学んでおくべきPythonの基礎について整理します。 [Python基礎]while文whileはある条件が満たされる限り繰り返される処理を記述する際に使用します。 例えば以下のようなコードです。 123456789count = 0while count &lt; 5: print(count) count += 1# 0# 1# 2# 3# 4 注意すべきは、上記のコードでcount += 1の記述をせずに実行すると、無限ループが発生してしまう点です。 違う書き方としては、breakを用いた書き方があります。if判定に引っかかったら、breakされる、という内容です。 123456789101112count = 0while True: if count &gt;= 5: break print(count) count += 1# 0# 1# 2# 3# 4 また、continueを活用した方法もあります。continueは、一言でいうと、「次の文を飛ばして次のループに行ってください。」という命令になります。breakは完全に抜けるのに対して、continueは、continueの次の行をスキップしてコードを実行させるものになります。 123456789101112131415count = 0while True: if count &gt;= 5: break if count == 2: count += 1 continue print(count) count += 1# 0# 1# 3# 4 Insertion Sortのコーディングまずは関数を定義します。 123from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: 数字の配列を簡単に設定し、定義した関数に渡してあげます。 12345678from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums) 設定したlistの長さを取得したいので、lenメソッドを使って取得しrangeを用いてループ文を設定します。printでindexを表示してみます。 12345678910111213141516171819from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): print(i) if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums)# 0# 1# 2# 3# 4# 5# 6 Insertion Sortアルゴリズムがどのようなものかを改めて確認します。まず、[4, 3, 2, 5, 7, 6, 1]というリストがあった時に、まず最初に、4と3を比較します。そのとき、前のindexの数字（今でいうと4）が、次の数字（今でいうと3）よりも大きかったら3をtempに一旦保管し、そうでなかったらそのまま、という処理をします。 そしてtmpに保管した数値と、その数値よりも前のindexに格納されている数値の大小関係の比較処理を繰り返し、tmpよりも小さかったらOK、という処理を繰り返します。 もう少しわかりやすく説明すると、ある程度処理が進んでリストとして[2, 3, 4, 5, 6, 7, 1]という状態になったとします。 同様の流れで、7と1を比較し、7の方が大きいので、1をtmpに一旦保管し、次に6とtmp(tmpは1)を比較して6のほうが大きいので次の5と比較し、5のほうが大きいので次の4と比較して・・・・という処理を繰り返し、最終的に、[1, 2, 3, 4, 5, 6, 7]という状態にするのがInsersion Sortでした。 まずは、indexが0である4と、indexが1である3を比較することを見据え、forループのrangeを1からlen_numbersの範囲にします。 123456789101112131415161718from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): print(i) if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums)# 1# 2# 3# 4# 5# 6 tempは、初期値はindexが1の数値なので、temp = numbers[i]としておきます。 そして比較対象の数値は、i - 1のindexに含まれている数値なので、これをjという変数に代入しておきます。 123456789101112from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] insertion_sort(nums) ここでwhile文を用いて、jが0以上である限りループを回すようにします。こうすることで、index番号を徐々に小さくする処理を組めることになります。 123456789101112131415161718192021222324from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0: print(j, end=' ') j -= 1 print() if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums))# 0 # 1 0 # 2 1 0 # 3 2 1 0 # 4 3 2 1 0 # 5 4 3 2 1 0 # None ここで、jを用いて、数値を入れ替えるという処理を含めます。 12345678910111213141516from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0: numbers[j+1] = numbers[j] j -= 1 print() if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums)) この入れ替え処理をいつまでやるかというと、numbers[j]がtempよりも大きい限り処理を続けさせるので、while j &gt;= 0 and numbers[j] &gt; temp:という風にします。 numbers[j]がtempよりも大きい限りはj + 1番目の数値と、j番目の数値を入れ替えるという処理を繰り返し、tempのほうが大きくなったら、while文を抜けます。 123456789101112131415from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: # numbers[j] &gt; tempを追記 numbers[j+1] = numbers[j] j -= 1 if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums)) while文を抜けた後どうするかを考えます。tempの数値を挿入する箇所は、j+1番目です。tempはj番目の数値と比較し、j番目の数値のほうが数が小さい場合、tempは、j + 1番目のindexに値を挿入されることが望ましいためです。 そして、numbersというリストをreturnで返却します。 コードを実行するとうまくソートされていることがわかります。 12345678910111213141516171819from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: numbers[j+1] = numbers[j] j -= 1 numbers[j + 1] = temp return numbers if __name__ == '__main__': nums = [4, 3, 2, 5, 7, 6, 1] print(insertion_sort(nums))# [1, 2, 3, 4, 5, 6, 7] 固定したリストではなく、randomを活用して試してみます。 1234567891011121314151617181920from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(1, len_numbers): temp = numbers[i] j = i - 1 while j &gt;= 0 and numbers[j] &gt; temp: numbers[j+1] = numbers[j] j -= 1 numbers[j + 1] = temp return numbers if __name__ == '__main__': import random nums = [random.randint(0, 100) for _ in range(10)] print(insertion_sort(nums))# [2, 7, 14, 18, 39, 50, 68, 69, 80, 98] うまくいきました。 別解以下のようなコードでも問題なくソートできました。 1234567891011121314151617181920212223from typing import Listdef insertion_sort(numbers: List[int]) -&gt; List[int]: len_numbers = len(numbers) for i in range(len_numbers): count = i while count &gt;= 0: if count == len_numbers - 1: break elif numbers[i] &gt; numbers[i + 1]: numbers[i], numbers[i + 1] = numbers[i + 1], numbers[i] count -= 1 else: count -= 1 return numbers if __name__ == '__main__': nums = [1, 3, 2, 5, 7, 6, 9] print(insertion_sort(nums)) まとめ本記事では、Insertion Sortを学びながら、以下のPythonの基礎を学びました。 While文 アルゴリズムをより詳しく学びプログラミング力を高めたい方 以下の、Udemyのコースがおすすめです。セール時は、1200円で購入可能です。セール時でなくても、講師の方に、Twitterでクーポンコードの発行をお願い、10$(1200円)で受講可能となります。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/insertion-sort/"},{"title":"【Python】メモアプリを作成してpythonの配列操作、辞書型、while文を学ぶ","text":"Pythonの基礎を身につけるために簡単なメモアプリを作ります。 メモアプリの仕様 メモを追加するのか、メモを出力するのかのモードを選択させる。 追加モードを選択した場合の動作は以下とする。 「メモのタイトルを入力してください。」という表示をさせる メモのタイトルを入力 「メモの本文を入力してください」という表示をさせる 本文を入力 メモの出力を選択した場合、作成したメモを出力させる 定義していないモードを選択した場合は「エラーです」と出力させる メモは常に起動状態にさせておく。 Pythonの基礎メモアプリを作成するためにPythonの基礎を簡単にまとめておきます。 リストの操作 ひとまずリストを作成します。 123&gt;&gt;&gt; s = ['a', 'b', 'c', 'd', 'e', 'f']&gt;&gt;&gt; s['a', 'b', 'c', 'd', 'e', 'f'] リストの0番目を取り出したいときは以下のとおりです。 12&gt;&gt;&gt; s[0]'a' 2番目から5番目の文字列を取り出したいときは以下のように記述します。 12&gt;&gt;&gt; s[2:5]['c', 'd', 'e'] 2番目から5番目の文字列を入れ替えたいときは以下のように記述します 123&gt;&gt;&gt; s[2:5] = ['C', 'D', 'E']&gt;&gt;&gt; s['a', 'b', 'C', 'D', 'E', 'f'] 2番目から5番目の文字列を削除したい場合は、空のリストを代入すれば削除できます。 123&gt;&gt;&gt; s[2:5]=[]&gt;&gt;&gt; s['a', 'b', 'f'] [:]とすると全部のリストを取得できます。これに空のリストを指定すれば、全削除になります。 12345&gt;&gt;&gt; s[:]['a', 'b', 'f']&gt;&gt;&gt; s[:] = []&gt;&gt;&gt; s[] 次に文字列を加えたい場合は、.append()メソッドを使用します。 123&gt;&gt;&gt; s.append('a')&gt;&gt;&gt; s['a'] 先頭に文字列を加えたい場合は、insert()で0を指定して以下のように記述します。 123&gt;&gt;&gt; s.insert(0, 'z')&gt;&gt;&gt; s['z', 'a'] リストの中の末尾の文字を取り出したい場合は以下のように.pop()を使います。 1234&gt;&gt;&gt; s.pop()'a'&gt;&gt;&gt; s['z'] リストの先頭の文字を取り出したいときは0を指定すればOKです。 12&gt;&gt;&gt; s.pop(0)'z' リストの中の値を削除するものとしてはdelというのがあります。 1234&gt;&gt;&gt; s = [1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; del s[0]&gt;&gt;&gt; s[2, 3, 4, 5, 6, 7, 8, 9] 特定の値を指定して削除したい場合は、remove()を用います。 1234&gt;&gt;&gt; n = [1, 2, 2, 2, 3]&gt;&gt;&gt; n.remove(2)&gt;&gt;&gt; n[1, 2, 2, 3] remove()は、該当する値がなくなるまで有効です。 12345678&gt;&gt;&gt; n.remove(2)&gt;&gt;&gt; n.remove(2)&gt;&gt;&gt; n.remove(2)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: list.remove(x): x not in list&gt;&gt;&gt; n[1, 3] リストの結合は、extend()が便利です。 123456&gt;&gt;&gt; s[2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; n.extend(s)&gt;&gt;&gt; n[1, 3, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; 辞書型 辞書型は、キーとバリューの組み合わせが含まれているデータのことです。 早速作成してみます。 123&gt;&gt;&gt; memo = {'title': 10, 'content':20}&gt;&gt;&gt; memo{'title': 10, 'content': 20} typeを見てみると’dict’となります。 12&gt;&gt;&gt; type(memo)&lt;class 'dict'&gt; キーを指定すればバリューが取り出せます。 1234&gt;&gt;&gt; memo['title']10&gt;&gt;&gt; memo['content']20 キーを指定して値を代入することができます。 123&gt;&gt;&gt; memo['title']='XXXX'&gt;&gt;&gt; memo{'title': 'XXXX', 'content': 20} 新たなキーとバリューを作成することも可能です。 123&gt;&gt;&gt; memo['email'] = 'aaa@example.com'&gt;&gt;&gt; memo{'title': 'XXXX', 'content': 20, 'email': 'aaa@example.com'} キーは文字だけでなくint(数値)でもOKです。 123&gt;&gt;&gt; memo[1] = 10000&gt;&gt;&gt; memo{'title': 'XXXX', 'content': 20, 'email': 'aaa@example.com', 1: 10000} 辞書の作成はdictを用いても可能です 123&gt;&gt;&gt; dict(a=20, b=40){'a': 20, 'b': 40}&gt;&gt;&gt; input関数 input関数は、Whileループとセットでよく使われます。何らかの入力をコンソール上で要求し、条件を満たす入力がされたらプログラムが終了するコードの例を以下に記載します。 sample.py12345678while True: word = input('enter:') if word == 'ok': breakprint('next')# enter:ok ← okと入力# next メモアプリの実装 学んだpythonの知識を用いてメモアプリを実装していきましょう。 メモアプリの仕様の中で、簡単に作れそうな部分からコードを書いていきます。 まずは、”メモのタイトルを入力してください”という文字列を出力し、何らかの文字を入力させて出力させてみます。 memoapp.py12345678910print('メモを入力してください')a = input()print('入力された文字は')print(a)# メモを入力してください# aiueo# 入力された文字は# aiueo 次に辞書型でメモのタイトルとメモの本文を定義して、タイトルと本文を登録させるところまで実装します。 memoapp.py123456789101112131415161718192021memo = {&quot;タイトル&quot;:&quot;未設定&quot;, &quot;本文&quot;:&quot;未設定&quot;}print('メモのタイトルを入力してください')memo[&quot;タイトル&quot;] = input()print('メモの本文を入力してください')memo[&quot;本文&quot;] = input()print(&quot;######################################&quot;)print(&quot; &quot;)print(&quot;入力されたメモは&quot;)print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])# $ ~/python-study /usr/local/bin/python3 &quot;/Users/omathin/python-study/memoapp.py&quot;# メモのタイトルを入力してください# pythonコード書いてます# メモの本文を入力してください# メモ作成まで完成しました# ###################################### # 入力されたメモは# pythonコード書いてます:メモ作成まで完成しました 次に複数のメモを管理できるように配列を使います。まずは２つのメモを管理できるようにします。 memoapp.py123456789101112131415161718192021222324252627282930memos = [{&quot;タイトル&quot;:&quot;未設定&quot;, &quot;本文&quot;:&quot;未設定&quot;}, {&quot;タイトル&quot;:&quot;未設定&quot;, &quot;本文&quot;:&quot;未設定&quot;}]print('1つ目のメモのタイトルを入力してください')memos[0][&quot;タイトル&quot;] = input()print('1つ目のメモの本文を入力してください')memos[0][&quot;本文&quot;] = input()print('2つ目のメモのタイトルを入力してください')memos[1][&quot;タイトル&quot;] = input()print('2つ目のメモの本文を入力してください')memos[1][&quot;本文&quot;] = input()print(&quot;######################################&quot;)print(&quot; &quot;)print(&quot;入力されたメモは&quot;)print(memos[0][&quot;タイトル&quot;] + &quot;:&quot; + memos[0][&quot;本文&quot;])print(memos[1][&quot;タイトル&quot;] + &quot;:&quot; + memos[1][&quot;本文&quot;])# 1つ目のメモのタイトルを入力してください# python# 1つ目のメモの本文を入力してください# コーディング# 2つ目のメモのタイトルを入力してください# ruby# 2つ目のメモの本文を入力してください# コーディング２# ###################################### # 入力されたメモは# python:コーディング# ruby:コーディング２ 次に空の配列を用意して、そこにメモを追加していくような処理にします。 memoapp.py1234567891011121314151617181920212223242526272829303132333435363738memos = []# memos = [{&quot;タイトル&quot;:&quot;未設定&quot;, &quot;本文&quot;:&quot;未設定&quot;}, {&quot;タイトル&quot;:&quot;未設定&quot;, &quot;本文&quot;:&quot;未設定&quot;}]print('1つ目のメモのタイトルを入力してください')title = input()print('1つ目のメモの本文を入力してください')content = input()memo = {&quot;タイトル&quot;: title, &quot;本文&quot;: content}memos.append(memo)print('2つ目のメモのタイトルを入力してください')title = input()print('2つ目のメモの本文を入力してください')content = input()memo = {&quot;タイトル&quot;: title, &quot;本文&quot;: content}memos.append(memo)print(&quot;######################################&quot;)print(&quot; &quot;)print(&quot;入力されたメモは&quot;)print(memos[0][&quot;タイトル&quot;] + &quot;:&quot; + memos[0][&quot;本文&quot;])print(memos[1][&quot;タイトル&quot;] + &quot;:&quot; + memos[1][&quot;本文&quot;])# 1つ目のメモのタイトルを入力してください# python1# 1つ目のメモの本文を入力してください# code1# 2つ目のメモのタイトルを入力してください# ruby1# 2つ目のメモの本文を入力してください# code2# ###################################### # 入力されたメモは# python1:code1# ruby1:code2 メモの出力部分をfor文を用いて出力させます。 memoapp.py12345678910111213141516171819202122232425262728293031323334353637memos = []print('1つ目のメモのタイトルを入力してください')title = input()print('1つ目のメモの本文を入力してください')content = input()memo = {&quot;タイトル&quot;: title, &quot;本文&quot;: content}memos.append(memo)print('2つ目のメモのタイトルを入力してください')title = input()print('2つ目のメモの本文を入力してください')content = input()memo = {&quot;タイトル&quot;: title, &quot;本文&quot;: content}memos.append(memo)print(&quot;######################################&quot;)print(&quot; &quot;)print(&quot;入力されたメモは&quot;)for memo in memos: print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])# 1つ目のメモのタイトルを入力してください# python1# 1つ目のメモの本文を入力してください# code1# 2つ目のメモのタイトルを入力してください# ruby1# 2つ目のメモの本文を入力してください# code2# ###################################### # 入力されたメモは# python1:code1# ruby1:code2 メモを作成する部分をメソッド化させましょう。 memoapp.py1234567891011121314151617181920212223242526def create_memo(): print('メモのタイトルを入力してください') title = input() print('メモの本文を入力してください') content = input() return {&quot;タイトル&quot;:title, &quot;本文&quot;:content}memos = []memos.append(create_memo())print(&quot;######################################&quot;)print(&quot; &quot;)print(&quot;入力されたメモは&quot;)for memo in memos: print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])# メモのタイトルを入力してください# 記事作成# メモの本文を入力してください# ブログ１記事作成# ###################################### # 入力されたメモは# 記事作成:ブログ１記事作成 メモを出力する部分をメソッド化させましょう。 12345678910111213141516171819202122232425262728293031def create_memo(): print('メモのタイトルを入力してください') title = input() print('メモの本文を入力してください') content = input() return {&quot;タイトル&quot;:title, &quot;本文&quot;:content}def show_memo(): print(&quot;######################################&quot;) print(&quot; &quot;) print(&quot;入力されたメモは&quot;) for memo in memos: print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])memos = []memos.append(create_memo())show_memo()# メモのタイトルを入力してください# 記事作成# メモの本文を入力してください# ブログ１記事作成# ###################################### # 入力されたメモは# 記事作成:ブログ１記事作成 モードの選択表示をさせます。 memoapp.py1234567891011121314151617181920212223242526272829303132333435363738394041def create_memo(): print('メモのタイトルを入力してください') title = input() print('メモの本文を入力してください') content = input() return {&quot;タイトル&quot;:title, &quot;本文&quot;:content}def show_memo(): print(&quot;######################################&quot;) print(&quot; &quot;) print(&quot;入力されたメモは&quot;) for memo in memos: print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])memos = []print(&quot;メモを追加【add】&quot;)print('メモを表示【show】')mode = input(&quot;モードを選んでください：&quot;)if mode == &quot;add&quot;: memos.append(create_memo())elif mode == &quot;show&quot;: show_memo()else: print(&quot;エラーです&quot;)# メモを追加【add】# メモを表示【show】# モードを選んでください：add# メモのタイトルを入力してください# ブログ作成# メモの本文を入力してください# １記事作成# $ ~/python-study /usr/local/bin/python3 &quot;/Users/omathin/python-study/memoapp.py&quot;# メモを追加【add】# メモを表示【show】# モードを選んでください：show# ###################################### これだとメモが消えてしまうので、メモアプリが常に起動状態にさせるためにwhileを使用します。 memoapp.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def create_memo(): print('メモのタイトルを入力してください') title = input() print('メモの本文を入力してください') content = input() return {&quot;タイトル&quot;:title, &quot;本文&quot;:content}def show_memo(): print(&quot;######################################&quot;) print(&quot; &quot;) print(&quot;入力されたメモは&quot;) for memo in memos: print(memo[&quot;タイトル&quot;] + &quot;:&quot; + memo[&quot;本文&quot;])memos = []while True: print(&quot;メモを追加【add】&quot;) print('メモを表示【show】') mode = input(&quot;モードを選んでください：&quot;) if mode == &quot;add&quot;: memos.append(create_memo()) elif mode == &quot;show&quot;: show_memo() else: print(&quot;エラーです&quot;)# メモを追加【add】# メモを表示【show】# モードを選んでください：add# メモのタイトルを入力してください# ブログを作成# メモの本文を入力してください# １記事作成# メモを追加【add】# メモを表示【show】# モードを選んでください：add# メモのタイトルを入力してください# 料理を作る# メモの本文を入力してください# 卵焼きを作る# メモを追加【add】# メモを表示【show】# モードを選んでください：show# ###################################### # 入力されたメモは# ブログを作成:１記事作成# 料理を作る:卵焼きを作る# メモを追加【add】# メモを表示【show】# モードを選んでください： ひとまず仕様通りのメモアプリの作成はできたかな、と思います。 他にも、「メモの上限を５つまでにする」とか「メモを削除するモードを加える」とかもチャレンジしてみてください。 まとめ 本記事では、メモアプリを作成しながらpythonの基礎を学ぶ、というテーマでまとめていきました 本記事でまとめた内容をベースに、プログラミングの学習を楽しんでいただけたら幸いです。 Pythonの基礎を学びた方へ(Udemy) シリコンバレーの現役エンジニアによるUdemyの講座「現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル」を参照してください。30日間の返金保証付きです。","link":"/memoapp-python/"},{"title":"【データサイエンス】Pythonで最頻値を表示する方法 | データサイエンス100本ノック【問29 回答】","text":"✓目次 本記事の対象者 本記事で学ぶPythonの基礎 第29問目: 最頻値の出力方法 lambda式とは 第29問目の回答 まとめ: 最頻値を表示する方法を学びました。 本記事の対象者 ・ データサイエンティストを目指している人 ・ lambda式の使い方の基礎を知りたい人 ・ 最頻値の求め方を知りたい人 本記事で学ぶPythonの基礎 本記事では以下のメソッドおよび記法を学びます。 applyメソッド: データフレームの各行もしくは各列に対してなんらかしらの関数を適用するメソッド modeメソッド: 離散データの最頻値を表示する。 lambda式: Pythonにおける関数作成を簡素化することができる記述様式 早速データサイエンス100本ノックの問題を題材に、これらの使い方を学んでいきたいと思います。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第29問目: 最頻値の出力方法 P-029: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに商品コード（product_cd）の最頻値を求めよ。 最頻値を求める際は、少し特殊な方法が用いられます。 データフレームの各行もしくは各列に対してなんらかしらの関数を適用するメソッドであるapplyメソッドを使用します。 applyメソッドの使い方としては、データに適用したい関数もしくはlambda式を定義し、applyの引数に渡します。 最頻値を求めるメソッドは、modeメソッドになりますので、lambda式を用いてmodeメソッドを適用することになります。 lambda式とはlambda式とは、Pythonにおける関数作成を簡素化することができる記述様式です。 例えば、以下のように2乗を出力関数を定義したとします。 通常の関数定義12def func(x): return x ** 2 これをlambda式を用いると以下のようにコードを簡素化することが出来ます。 lambda式による関数定義1func = lambda x: x**2 このようにlambda式の構造はlambda 引数: 返り値という構造になります。 lambda式に引数を渡して実際に計算する場合は、以下のように指定するだけで、defで作成した関数と同じように使用できます。 lambda式に引数を渡して計算12# funcに引数aを渡して、計算結果をyに格納するy = func(a) データフレームと併用する場合は、df.apply(lambda 引数: 返り値)とすれば良いです。 データフレームと併用する場合のlambdaの使い方12df = DataFrame({&quot;id&quot;: [10, 20, 30], &quot;age&quot;: [5, 10, 15], &quot;weight&quot;:[30, 40, 50]})df.apply(lambda x: x+10) 実際にlambda式を使う例を以下に紹介します。 12345import pandas as pdfrom pandas import DataFramedf = DataFrame({&quot;id&quot;: [10, 20, 30], &quot;age&quot;: [5, 10, 15], &quot;weight&quot;:[30, 40, 50]})df.apply(lambda x: x+10) 出力1234 id age weight0 20 15 401 30 20 502 40 25 60 このように、全てのフィールドに10がプラスされたことが分かります。 これらの知識を用いて問題を解いていきます。 第29問目の回答過去の問題で学んだgroupbyメソッドを用いて、store_cdをグルーピングし、product_cdに対してapplyメソッドを適用し、modeで最頻値を表示します。 &gt;groupbyメソッドの使い方の詳細はこちら 1df_receipt.groupby('store_cd').product_cd.apply(lambda x: x.mode()) 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657store_cd S12007 0 P060303001S12013 0 P060303001S12014 0 P060303001S12029 0 P060303001S12030 0 P060303001S13001 0 P060303001S13002 0 P060303001S13003 0 P071401001S13004 0 P060303001S13005 0 P040503001S13008 0 P060303001S13009 0 P060303001S13015 0 P071401001S13016 0 P071102001S13017 0 P060101002S13018 0 P071401001S13019 0 P071401001S13020 0 P071401001S13031 0 P060303001S13032 0 P060303001S13035 0 P040503001S13037 0 P060303001S13038 0 P060303001S13039 0 P071401001S13041 0 P071401001S13043 0 P060303001S13044 0 P060303001S13051 0 P050102001 1 P071003001 2 P080804001S13052 0 P050101001S14006 0 P060303001S14010 0 P060303001S14011 0 P060101001S14012 0 P060303001S14021 0 P060101001S14022 0 P060303001S14023 0 P071401001S14024 0 P060303001S14025 0 P060303001S14026 0 P071401001S14027 0 P060303001S14028 0 P060303001S14033 0 P071401001S14034 0 P060303001S14036 0 P040503001 1 P060101001S14040 0 P060303001S14042 0 P050101001S14045 0 P060303001S14046 0 P060303001S14047 0 P060303001S14048 0 P050101001S14049 0 P060303001S14050 0 P060303001Name: product_cd, dtype: object indexがなくなっているので、reset_index()メソッドでindexを付与します。 &gt;reset_indexの使い方の詳細はこちら 1df_receipt.groupby('store_cd').product_cd.apply(lambda x: x.mode()).reset_index() 出力1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 store_cd level_1 product_cd0 S12007 0 P0603030011 S12013 0 P0603030012 S12014 0 P0603030013 S12029 0 P0603030014 S12030 0 P0603030015 S13001 0 P0603030016 S13002 0 P0603030017 S13003 0 P0714010018 S13004 0 P0603030019 S13005 0 P04050300110 S13008 0 P06030300111 S13009 0 P06030300112 S13015 0 P07140100113 S13016 0 P07110200114 S13017 0 P06010100215 S13018 0 P07140100116 S13019 0 P07140100117 S13020 0 P07140100118 S13031 0 P06030300119 S13032 0 P06030300120 S13035 0 P04050300121 S13037 0 P06030300122 S13038 0 P06030300123 S13039 0 P07140100124 S13041 0 P07140100125 S13043 0 P06030300126 S13044 0 P06030300127 S13051 0 P05010200128 S13051 1 P07100300129 S13051 2 P08080400130 S13052 0 P05010100131 S14006 0 P06030300132 S14010 0 P06030300133 S14011 0 P06010100134 S14012 0 P06030300135 S14021 0 P06010100136 S14022 0 P06030300137 S14023 0 P07140100138 S14024 0 P06030300139 S14025 0 P06030300140 S14026 0 P07140100141 S14027 0 P06030300142 S14028 0 P06030300143 S14033 0 P07140100144 S14034 0 P06030300145 S14036 0 P04050300146 S14036 1 P06010100147 S14040 0 P06030300148 S14042 0 P05010100149 S14045 0 P06030300150 S14046 0 P06030300151 S14047 0 P06030300152 S14048 0 P05010100153 S14049 0 P06030300154 S14050 0 P060303001 これで完成です。 まとめ: 最頻値を表示する方法を学びました。本記事は、「【データサイエンス】Pythonで最頻値を表示する方法 | データサイエンス100本ノック【問29 回答】」というテーマでまとめました。 最頻値を表示するためには以下のメソッドを活用しましょう。 applyメソッド: データフレームの各行もしくは各列に対してなんらかしらの関数を適用するメソッド modeメソッド: 離散データの最頻値を表示する。 lambda式: Pythonにおける関数作成を簡素化することができる記述様式 以上です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク","link":"/lambda-style/"},{"title":"Google Colaboratoryで形態素解析 | MeCabとJanomeの使い方","text":"本記事では、Gllgle Colaboratoryで形態素解析を行う方法についてまとめます。 ✓目次 形態素解析とは | 形態素解析の必要性 形態素解析ツール 形態素解析の実装 | MeCab MeCabを用いて分かち書きをしたい場合 形態素解析の実装 | Janome Janomeを用いて分かち書きをしたい場合 まとめ 形態素解析とは | 形態素解析の必要性形態素解析とは、コンピュータを利用して機械的な方法で文を形態素（言葉で意味を持つ最小の単位）に区切る技術のことを言います。 我々の身近な言語としては、日本語、英語があります。 この２つの言語は、当然ですが、使用する言葉と文法が異なります。 例えば、日本語で「これはペンです。」という文は、英語だと「This is a pen.」です。 英語は、”This”, “is”, “a”, “pen”という風に、単語と単語の間に空白が存在しますが、日本語は単語と単語の間に空白が存在しません。 このように、単語と単語の間に空白を入れる書き方を分かち書きといいます。 そして、分かち書きされていない日本語の文章を機械に理解させるためには、単語分割を行うとともに品詞を明確にする必要があるのです。 なぜなら文章は、決められた文法法則に従い単語に付与されている品詞を並べて構成されているからです。 機械に対して、単語の意味、品詞、文法を理解させなければ意味を解釈させることもできなければ、文を作成させることもできません。 形態素解析ツール「形態素解析、難しくね？」と思われたかもしれませんが、形態素解析をするためのツールが用意されています。 日本語の主な形態素解析ツールには以下のようなものがあります。 ・MeCab ・ChaSen ・JUMAN ・Janome 本記事では、上記のツールの中でも広く使われているMeCabとJanomeの使用方法を紹介します。 形態素解析の実装 | MeCab実装環境には、Google Colaboratoryを使用します。 ローカル環境で動かしてみたい方は、以下の記事に、Jupyter Notebookの実行環境を作る方法をまとめておりますので参照してください。 まずは、python3で動作するMeCabライブラリをインストールします。 Google colaboratoryのセルに、以下を入力し実行してください。 1!pip install mecab-python3 以下のような出力が得られたら成功です。 12345Collecting mecab-python3 Downloading https://files.pythonhosted.org/packages/c1/72/20f8f60b858556fdff6c0376b480c230e594621fff8be780603ac9c47f6a/mecab_python3-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (487kB) |████████████████████████████████| 491kB 8.6MB/s Installing collected packages: mecab-python3Successfully installed mecab-python3-1.0.3 次に、辞書データとしてUniDicをインストールします。 UniDicは国立国語研究所が開発している辞書です。 以下を入力し実行してください。 1!pip install unidic 以下のような出力が得られたら成功です。 1234567891011121314151617Collecting unidic Downloading https://files.pythonhosted.org/packages/86/04/c18832fd9959a78fc60eeaa9e7fb37ef31a250e8645cc2897eb1f07939ee/unidic-1.0.3.tar.gzRequirement already satisfied: requests&lt;3.0.0,&gt;=2.22.0 in /usr/local/lib/python3.7/dist-packages (from unidic) (2.23.0)Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.41.1 in /usr/local/lib/python3.7/dist-packages (from unidic) (4.41.1)Requirement already satisfied: wasabi&lt;1.0.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from unidic) (0.8.2)Requirement already satisfied: plac&lt;2.0.0,&gt;=1.1.3 in /usr/local/lib/python3.7/dist-packages (from unidic) (1.1.3)Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.22.0-&gt;unidic) (1.24.3)Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.22.0-&gt;unidic) (2020.12.5)Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.22.0-&gt;unidic) (2.10)Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.22.0-&gt;unidic) (3.0.4)Building wheels for collected packages: unidic Building wheel for unidic (setup.py) ... done Created wheel for unidic: filename=unidic-1.0.3-cp37-none-any.whl size=5497 sha256=78ab4afc1982544644d7782dac00a36b55b71aceeb11cb7d0d692f01bd995f10 Stored in directory: /root/.cache/pip/wheels/d3/26/e2/fb76c79fd14391eb994eab021c9129c24814125298e1e5b96aSuccessfully built unidicInstalling collected packages: unidicSuccessfully installed unidic-1.0.3 更に、辞書データもダウンロードします。 以下のコードを実行しましょう。 1!python -m unidic download 以下のような出力が得られたら成功です。 123456download url: https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic.zipDictionary version: 2.3.0+2020-10-08Downloading UniDic v2.3.0+2020-10-08...unidic.zip: 100% 608M/608M [00:22&lt;00:00, 27.3MB/s]Finished download.Downloaded UniDic v2.3.0+2020-10-08 to /usr/local/lib/python3.7/dist-packages/unidic/dicdir 本記事では、「私は形態素解析を学んでいます」という文章を解析します。 以下のコードで解析できます。 1234import MeCabimport unidicmecab = MeCab.Tagger()print(mecab.parse(&quot;私は形態素解析を学んでいます。&quot;)) 出力結果は以下の通りとなりました。 123456789101112私 代名詞,,,,,,ワタクシ,私-代名詞,私,ワタクシ,私,ワタクシ,和,,,,,,,体,ワタクシ,ワタクシ,ワタクシ,ワタクシ,0,,,11345327978324480,41274は 助詞,係助詞,,,,,ハ,は,は,ワ,は,ワ,和,,,,,,,係助,ハ,ハ,ハ,ハ,,動詞%F2@0,名詞%F1,形容詞%F2@-1,,8059703733133824,29321形態 名詞,普通名詞,一般,,,,ケイタイ,形態,形態,ケータイ,形態,ケータイ,漢,,,,,,,体,ケイタイ,ケイタイ,ケイタイ,ケイタイ,0,C2,,3024215389381120,11002素 接尾辞,名詞的,一般,,,,ソ,素,素,ソ,素,ソ,漢,,,,,,,接尾体,ソ,ソ,ソ,ソ,,C3,,5752103704338944,20926解析 名詞,普通名詞,サ変可能,,,,カイセキ,解析,解析,カイセキ,解析,カイセキ,漢,,,,,,,体,カイセキ,カイセキ,カイセキ,カイセキ,0,C2,,1590177315299840,5785を 助詞,格助詞,,,,,ヲ,を,を,オ,を,オ,和,,,,,,,格助,ヲ,ヲ,ヲ,ヲ,,動詞%F2@0,名詞%F1,形容詞%F2@-1,,11381878116459008,41407学ん 動詞,一般,,,五段-バ行,連用形-撥音便,マナブ,学ぶ,学ん,マナン,学ぶ,マナブ,和,,,,,,,用,マナン,マナブ,マナン,マナブ,0,2,C2,,9878570876936837,35938で 助詞,接続助詞,,,,,テ,て,で,デ,で,デ,和,,,,,,,接助,デ,デ,デ,デ,,動詞%F1,形容詞%F2@-1,,6837330270888448,24874い 動詞,非自立可能,,,上一段-ア行,連用形-一般,イル,居る,い,イ,いる,イル,和,,,,,,,用,イ,イル,イ,イル,0,C4,M4@1,710568013079169,2585ます 助動詞,,,,助動詞-マス,終止形-一般,マス,ます,ます,マス,ます,マス,和,,,,,,,助動,マス,マス,マス,マス,,動詞%F4@1,,9812325267808939,35697。 補助記号,句点,,,,,,。,。,,。,,記号,,,,,,,補助,,,,,,,,6880571302400,25EOS 出力された内容を確認しましょう。出力される形態素解析の結果は、左から順に以下の通りとなります。 表層形（surface）（文章中で使用されている単語） 品詞（part_of_speech） 品詞細分類1〜3（part_of_speech） 活用型（infl_type） 活用形（infl_form） 原形（base_form）（文章中で使用されている単語の原形） 読み（reading） 発音（phonetic） MeCabを用いて分かち書きをしたい場合分かち書きをしたい場合は、Tagger()オブジェクトの出力モードに('-Owakati')を指定すればOKです。 ('-Owakati')を指定することで、品詞などを付与せず、形態素ごとに区切りの空白を入れることができます。 1234import MeCabimport unidicmecab = MeCab.Tagger('-Owakati')print(mecab.parse(&quot;私は形態素解析を学んでいます。&quot;)) 以下のように分かち書きされた文章が出力されます。 1私 は 形態 素 解析 を 学ん で い ます 。 Tagger()オブジェクトの出力モードには、以下も指定できます。 -Oyomi: 読みのみを出力 -Ochasen: ChaSen互換形式 -Odump: 全ての情報を出力 実行したい処理に応じて使い分けましょう。 形態素解析の実装 | Janomeまずは、janomeをインストールしましょう。Google Colaboratoryのセルに以下を入力し実行すればOKです。 1!pip install janome 以下のような出力が得られれば成功です。 12345Collecting janome Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB) |████████████████████████████████| 19.7MB 50.0MB/s Installing collected packages: janomeSuccessfully installed janome-0.4.1 早速、janomeを使って形態素解析をしてみましょう。 以下のコードでjanomeを使った形態素解析を行うことができます。 123456from janome.tokenizer import Tokenizert = Tokenizer()tokens = t.tokenize(&quot;私は形態素解析を学んでいます。&quot;)for token in tokens: print(token) 以下のような実行結果が得られます。 12345678910私 名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシは 助詞,係助詞,*,*,*,*,は,ハ,ワ形態素 名詞,一般,*,*,*,*,形態素,ケイタイソ,ケイタイソ解析 名詞,サ変接続,*,*,*,*,解析,カイセキ,カイセキを 助詞,格助詞,一般,*,*,*,を,ヲ,ヲ学ん 動詞,自立,*,*,五段・バ行,連用タ接続,学ぶ,マナン,マナンで 助詞,接続助詞,*,*,*,*,で,デ,デい 動詞,非自立,*,*,一段,連用形,いる,イ,イます 助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス。 記号,句点,*,*,*,*,。,。,。 出力された内容は、MeCabと同様に、左から順に以下の通りとなります。 表層形（surface）（文章中で使用されている単語） 品詞（part_of_speech） 品詞細分類1〜3（part_of_speech） 活用型（infl_type） 活用形（infl_form） 原形（base_form）（文章中で使用されている単語の原形） 読み（reading） 発音（phonetic） Janomeを用いて分かち書きをしたい場合Janomeで分かち書きをしたい場合は、tokenize()メソッドの引数にwakati=Trueを指定すると、分かち書きのみを行います。 以下のコードを実行してみましょう。 123456from janome.tokenizer import Tokenizert = Tokenizer()tokens = t.tokenize(&quot;私は形態素解析を学んでいます。&quot;, wakati=True)for token in tokens: print(token) 以下のような出力が得られると思います。 12345678910私は形態素解析を学んでいます。 まとめ本記事では、「Google Colaboratoryで形態素解析 | MeCabとJanomeの使い方」というテーマでまとめました。 本記事を参考に、自然言語処理の世界を楽しんでいただけたらと思います。 参考にさせていただいた記事など 分かち書き ［文章生成］MeCabをインストールして分かち書きを試してみよう 自然言語処理のオススメ教材 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 本格的にAIを学びたい人へ 以下の何れかに該当する方は、キカガクさんのオンラインスクールがおすすめです。まずは無料のカウンセリングに参加し、自分が目指すキャリアや身に着けたいスキルが学べるか、等確認してみてください。無料カウンセリング予約はこちら ・プログラミング初学者（Pythonで機械学習を学びたい方）・機械学習を学び、キャリアに活かしたい方・何かAIサービスを企画、開発したい方・技術を身に着けて転職したい方・E資格を取得したい方 Aidemyのプレミアムプランもオススメ AIを学ぶならアイデミープレミアムプラン python学習に役立つ記事","link":"/morphological-analysis/"},{"title":"【入門】Swagger EditorでOpen APIを作る","text":"✓目次 この記事の対象者 Open APIとは Open APIの基本要素「ルートオブジェクト」 簡単なAPIをつくってみよう まとめ この記事の対象者 ・ REST APIをSwaggerで作成したいが、1歩を踏み出せない人 ・ REST APIについてなんとなく理解している(GET, POST等のメソッドやステータスコードの使い分け等)が、設計→仕様書作成に踏み込めていない人 REST APIを設計する際に気を付けるべき主なポイントを以下の記事にまとめています。 Open APIとは そもそもOpen APIとは何かを説明します。 Open APIとは、WSDLやXMLと比較されるようなフォーマットを意味します。 このフォーマットを使うと、「機械可能なREST API仕様」が記述できます。 Open APIはJSONまたはYAMLで記述可能ですが、YAMLで記述するケースが多い気がします。 そしてこのOpen APIを記述するエディタがSwagger Editorです。 Open APIの基本要素「ルートオブジェクト」 Open APIをSwagger Editorで記述する際、ルートオブジェクトをしっかり把握する必要があります。 ルートオブジェクトとは、平たく言えば、YAMLで記述する際に最も階層が浅い部分に記載する要素です。 Open APIの主なルートオブジェクトは7種類存在し、そのうち3種類が必須項目となっています。 以下の通りです。 openapi:: 必須。Open APIのバージョンを指定するオブジェクトです。 info:： 必須。APIのメタデータを定義します。 servers:： これから記載するAPI仕様書において、APIがどのような環境で提供されるのかを定義したもの。APIを提供するサーバを定義します。 tags:: APIを分類するタグを定義する。 paths:: 必須。APIとして利用可能なパスおよび操作を定義する。 security:: API全体にかけるセキュリティ要件。 components:: Open APIの中で利用する様々なオブジェクトをコンポーネント化して再利用可能にする。 要するに、必須のルートオブジェクトである、openapi:, info:, paths:のみ記述しておけば、APIが作れるのです。 簡単なAPIをつくってみよう 今回は簡単な例として、GETメソッドで/messageというURLをたたくと、「Hello World」が返ってくるAPIを作ってみたいと思います。 インターネット上のSwagger Editorを用いてもよいですが、ここではVisualStudioCodeにSwagger viewerを導入した環境で作成を進めてみたいと思います。 VisualStudioCodeにSwagger viewerを導入する方法は、以下の記事を参照ください。 VisualStudioCodeを起動し、新規ファイルを作成しましょう。 ファイル名は何でも良いですが、openapi.yamlという風に、yamlファイル形式のものを作成しましょう。 まずは、先ほど整理したルートオブジェクトのうち、必須のオブジェクトを書きましょう。必須のオブジェクトは、以下の通りでした。 openapi.yaml12345678openapi: \"3.0.3\"info: title: \"Sample API\" # 必須 version: \"1.0.0\" # 必須paths: {} なお、info:オブジェクトは、APIのタイトルを記述するtitle:と、APIドキュメントのバージョンを記述するversion:の記載が必須となっているので注意してください。 ここで、SHIFT + ALT + PでSwagger viewerを表示してみましょう。以下のようになっていればOKです。 続いて、URLを記述していきます。今回は/messageというURLをたたくと「Hello World」が返ってくるAPIなので、paths:に&quot;/message&quot;と記述し、メソッドとしてGETを指定しましょう。 openapi.yaml12345678910openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: 次にレスポンスを記述していきます。 レスポンスの記述も同様にpathsオブジェクトの配下に記述をしていきます。responses:として&quot;200&quot;を指定しましょう。※エラーが出てると思いますがひとまず気にしなくてOKです。 openapi.yaml1234567891011openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": 次に「Hello World」という文字列データを返してくれるように記述しましょう。 これは、content:というオブジェクトを用います。 content:は、レスポンスボディ部を記述する箇所であり、メディアタイプやデータの型を指定できます。 今回はメディアタイプはJsonとし、返却するデータは”Hello World”という文字列なので、データの型はstringにしたいと思います。そして、データの例として”Hello World”を指定しておきましょう。 openapi.yaml12345678910111213141516openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": content: application/json: schema: type: string example: \"Hello World !\" これで完成！ではありません。 こちらのコードをSwagger Editorに張り付けてみると以下のようなエラーが出力されます。 エラーの内容をよく見ると、「レスポンス 200の部分に”description”というプロパティが必要だよ。」と記載されています。 descriptionとは、APIが操作する内容等の説明を記述する要素です。 というわけで指示通りに記述します。 openapi.yaml123456789101112131415161718openapi: \"3.0.3\"info: title: \"Sample API\" version: \"1.0.0\"paths: \"/message\": get: responses: \"200\": description: \"Sample API operation\" content: application/json: schema: type: string example: \"Hello World !\" これで完成になります。 今回はとても簡単な例でしたが、以上がAPIを作成する流れになります。 なお、OpenAPIの記述ルールは、以下のgithubで確認できます。各ルートオブジェクトごとに定義できる項目として、何が用意されているのかが気になる方はこちらを参照いただければと思います。https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md 更に詳しく学びたい方は、以下のUdemy講座を確認ください。30日以内であれば、無料（返金保証付き）です。 【視聴期限無し】UdemyでSwaggerを学ぶ【30日間返金保証付き】 まとめOpenAPIを作成する際の大まかな流れは以下の通りです。 作成するAPIを設計する。 設計する際の主なポイントはこちらを参照ください。 ルートオブジェクトを記述する。 必須項目であるopenapi:, info:, paths:の3つを必ず記述。 設計に従い追記。 githubに掲載されているオブジェクトを確認しながら追記。","link":"/openapi-helloworld/"},{"title":"【入門】OpenShiftを用いてビルドとデプロイメントを行う方法","text":"✓目次 1. Githubにソースコードをpushしておく 2. OpenShift Web Consoleでプロジェクト作成と設定を行う 3. 作成したプロジェクトを確認する まとめ OpenShiftを実機で動かすための環境構築方法は以下を参考にしてください。 Dockerって何？ビルドって何？という方は以下の記事を参照いただければと思います。 1. Githubにソースコードをpushしておく 今回は簡単なデモなので、python on Flaskの簡単なコードをご自身のGithubリポジトリにおいておきましょう。この記事で使用するのは、以下のapp.pyファイルと、requirement.txtファイルの2つです。 app.py1234567891011121314import osfrom flask import Flaskapp = Flask(__name__)@app.route(\"/\")def main(): return \"Welcome!\"@app.route('/how are you')def hello(): return 'I am good, how about you?'if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", port=8080) requirement.txt1Flask 2. OpenShift Web Consoleでプロジェクト作成と設定を行うOpenShiftのWebコンソールを開き、ログインします。 今回は、pythonのプログラムを動かすので、pythonというカタログを選択します。すると以下のような画面が現れるので、nextをクリックしましょう。 プロジェクト名等を入力しましょう。これらは任意の名称で問題ありません。そして、Git Repository欄に、GithubリポジトリのURLを入力し、Createをクリックしましょう。 以下のように表示されれば、プロジェクトの作成と設定は完了です。 3. 作成したプロジェクトを確認する以下のように、Webコンソール画面の右側に作成したプロジェクトが表示されます。本記事の場合ですと、Python testというプロジェクトが、それにあたります。My Projectというのは、デフォルトで存在するプロジェクトであり、今回は使用しません。 作成したプロジェクトをクリックし、左側のメニューの「Builds」→「Builds」とクリックすると、自動的に作成されたビルド設定があることが確認できます。 「View Logs」をクリックしてログを確認してみましょう。以下のようになっています。 1234567891011121314151617181920212223242526272829303132333435363738Cloning &quot;https://github.com/xxxxxxxxxx/openshift-sample-app.git &quot; ... Commit: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (update) Author: xxxx xxxx &lt;xxxxxx@xxxx.com&gt; Date: Thu Dec 10 12:45:37 2020 +0900Using 172.30.1.1:5000/openshift/python@sha256:ac50754646f0d37616515fb30467d8743fb12954260ec36c9ecb5a94499447e0 as the s2i builder image---&gt; Installing application source ...---&gt; Upgrading pip to version 19.3.1 ...Collecting pip==19.3.1Downloading https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl (1.4MB)Installing collected packages: pipFound existing installation: pip 9.0.1Uninstalling pip-9.0.1:Successfully uninstalled pip-9.0.1Successfully installed pip-19.3.1---&gt; Installing dependencies ...Collecting FlaskDownloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)Collecting itsdangerous&gt;=0.24Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl Collecting Jinja2&gt;=2.10.1Downloading https://files.pythonhosted.org/packages/30/9e/f663a2aa66a09d838042ae1a2c5659828bb9b41ea3a6efa20a20fd92b121/Jinja2-2.11.2-py2.py3-none-any.whl (125kB)Collecting click&gt;=5.1Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)Collecting Werkzeug&gt;=0.15Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)Collecting MarkupSafe&gt;=0.23Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl Installing collected packages: itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, FlaskSuccessfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0WARNING: You are using pip version 19.3.1; however, version 20.3.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command.Pushing image 172.30.1.1:5000/python-test/python-flask:latest ...Pushed 0/10 layers, 3% completePushed 1/10 layers, 16% completePushed 2/10 layers, 23% completePushed 3/10 layers, 38% completePushed 4/10 layers, 40% completePush successful ログからは以下が読み取れます。 最初にGithubリポジトリのクローンを実施。 アプリケーションのソースと依存関係をインストール ビルドが完了すると、172.30.1.1:5000にある内部のDockerレジストリにイメージをプッシュ プッシュが完了すると、自動的にkubernetesのリソースの一つであるDeploymentが作成され、アプリケーションイメージのインスタンスが生成されます。kubernetesのDeploymentとは、Podの集合であるReplicaSetの世代管理ができ、ロールバックやロールフォワードができるものです。余談ですが、Podの集合として、StatefulSetというリソースもあります。Deploymentとの違いは、StatefulSetはPodをスケールする際の名前が一定である点です。 Webコンソールの左側のメニューのOverviewをクリックし、作成されたアプリケーションメニューをみてみると、外部アクセス用に生成されたRouteがあります。 これをクリックすると、Flaskアプリケーションが確認できます。これが、エンドユーザに提供するリンクになるわけです。 まとめデモで見たように、OpenShiftは、Githubにあるソースコードをダウンロードし、Dockerイメージをビルドし、それをDockerレジストリにプッシュし、Deploymentを作成してアプリケーションをKubernetesクラスタにデプロイしてくれます。 Openshiftは、インフラ管理タスクを抽象化したツールを提供することで、開発者がKubernetesベースのインフラ上でアプリケーションを簡単にデプロイして管理できるようにしてくれる、ということが分かったと思います。 また、Openshiftは、Githubのようなソースコード管理ソフトウェアとの連携も可能であり、アプリ開発、ビルド、テスト、デプロイを一貫して担ってくれることも分かったと思います。 もっと詳しく学びたい方へ - 以下のUdemyの講座で、OpenShiftの基礎を学ぶことができます。ビルド、ビルドトリガー、イメージストリーム、デプロイメントの理解などをハンズオンで学ぶことができます。Udemyは30日間の返金保証が付いているため、「ちょっと違うな。」と思ったら返金も可能なので気軽に試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sii7ibQ\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/learn-openshift/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1685508_5cbe_3.jpg?_DOhkU4tHD4sMV2ocoxcydj3RISUqG6hmRkxzTsyxkEw8boc6Fkl0w-awjeYUCaesvaeTxw_LK4rSDiqulHny6bun1wQVKSPbq64Erphfc-ErhgZeHCereo1vY30wHb4\"}}); [セール時は1200円]Dockerに特化した専門知識を身に着けたい方は以下がオススメ Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/openshift-builds-and-deployments/"},{"title":"【React】axiosを用いてREST APIを叩く方法","text":"Reactでaxiosという3rd partyアプリを用いて外部のREST APIを叩き、取得した情報をブラウザ上に出力する方法をまとめました。 実行環境 使用端末: M1 MacbookPro 以下の通りM1 MacでHomebrewをインストール済であることを前提としています。 ・ M1 Macbookpro ・ Homebrewはインストール済 利用するAPIは「Json Placeholder」を使用します。JSONPlaceholder - Free Fake REST API 目次 ReactでAPIにアクセスする方法は2つある Reactの開発環境作成 コンポーネントの作成 アクセスするAPIの確認 axiosのインストール ApiFetch.jsファイルを編集 App.jsにApiFetch.jsコンポーネントをimport ブラウザを確認 ReactでAPIにアクセスする方法は2つある ReactでAPIにアクセスする方法は以下の2通りがあります。 ・axiosという3rd Partyのアプリを使用する方法 ・JavaScriptのfetchメソッドを使う方法 本記事では、axiosという3rd Partyアプリを利用する方法をまとめます。 fetchメソッドを使った方法は以下の記事を参照ください。 &gt;&gt; fetchメソッドを使ってAPIを叩く方法を確認する Reactの開発環境作成まずは、Reactの開発環境を作成していきましょう。 Node.jsのインストール含め、Reactの開発環境整備については以下の記事に詳細をまとたのでこちらを参照ください。以下の記事でまとめた開発環境構築が完了している前提で以降まとめていきます。 &gt;&gt; Node.jsのインストール方法やReactの開発環境構築方法を確認する まずは以下のコマンドでReactでAPIにアクセスするアプリの雛形を作成します。 terminal1npx create-react-app react-api もしエラーなどが出力されたら、Node.jsのバージョンを疑いましょう。 nodebrew lsコマンドで設定されているNode.jsのバージョン確認とnode -vコマンドで実際のバージョンを確認してみてください。nodebrewではv14が設定されているのに、実際はv11になっていたりします。 そのような場合はsource ~/.zprofileコマンドを実施すれば、期待するNode.jsのバージョンに切り替えることができます。 terminal1234567891011$ nodebrew lsv11.13.0v14.15.4v14.15.5current: v14.15.5$ node -vv11.13.0$ source ~/.zprofile $ node -vv14.15.5 作成したreact-apiフォルダに移動し、必要なフォルダ類が導入されていれば準備完了です。 terminal1234$ cd react-api ~/react-api $ lsREADME.md package-lock.json publicnode_modules package.json src npm startコマンドを実行しlocalhost:3000というURLにアクセスして以下のようなReactの画面が表示されたら成功です。 コンポーネントの作成まずはsrcフォルダ配下にcomponentsという名前のフォルダを作成します。 terminal1mkdir src/components componentsフォルダ配下にApiFetch.jsというファイルを作成し、以下のようなコードを記載します。 src/components/ApiFetch.js1234567891011import React from 'react'const ApiFetch = () =&gt; { return ( &lt;div&gt; &lt;/div&gt; )}export default ApiFetch ちなみにこちらのコードはVisal Studio Codeの拡張機能であるes7 reactをインストールしておくと、rafceと入力するだけでコードを生成してくれます。 アクセスするAPIの確認今回はJSON Placeholderの/postsを呼び出します。 https://jsonplaceholder.typicode.com/posts このAPIには、1〜100までのidが割り当てられた投稿が含まれています。 このAPIを叩くことでJSONオブジェクトが取得できます。 axiosのインストール起動しているReactをCtr + Cで停止させます。 そして/react-apiフォルダで、以下のコマンドを実行し、axiosをインストールしましょう。 /react-api1npm install axios 再度npm startコマンドでReactを起動しましょう。 /react-api1npm start ApiFetch.jsファイルを編集ApiFetch.jsファイルでuseStateとuseEffect、そしてaxiosをimportします。 src/components/ApiFetch.js123456789101112import React, {useState, useEffect} from 'react'import axios from 'axios'const ApiFetch = () =&gt; { return ( &lt;div&gt; &lt;/div&gt; )}export default ApiFetch Stateを定義していきます。 src/components/ApiFetch.js123456789101112131415161718192021222324252627import React, {useState, useEffect} from 'react'import axios from 'axios'const ApiFetch = () =&gt; { const [posts, setPosts] = useState([]) useEffect(() =&gt; { axios.get('https://jsonplaceholder.typicode.com/posts') .then(res =&gt; { setPosts(res.data) }) }, []) return ( &lt;div&gt; &lt;ul&gt; { posts.map(post =&gt; &lt;li key={post.id}&gt; {post.title} &lt;/li&gt;) } &lt;/ul&gt; &lt;/div&gt; )}export default ApiFetch 上記のコードの説明をします。 今回は、JSON Placeholderの/postsのデータを格納するpostsというStateを定義し、postsを更新するsetPostsというメソッドを定義します。初期値は空のリストにしておきます。 useEffectでブラウザ起動時にAPIが1度だけ叩くように定義していきます。 axios.get('')の文字列の部分に、APIを叩くURLを記述します。 そして、Getメソッドでアクセスし、返り値を.themのresという変数に代入し、アロー関数(=&gt;)で処理を記載します。 setPostsを用いて、postsという変数にAPIで収集したデータを格納します。この場合、res.dataとすることで、JSONオブジェクトを取得することができます。 ブラウザ起動時に1度だけAPIを呼び出すので、useEffectの第２引数に[]という風に空のリストを記述します。 これでuseEffectを使用して、100件のオブジェクトデータを取得できます。 今回は100件のうち10件のデータをブラウザ上に表示するところを作っていきます。 リスト表示ということでulタグを用いて10件のデータを表示させます。 postsに対してmapメソッドを用いて、データを1つずつ取り出し、取り出したデータをpostという変数に格納させ、ループで1つずつ表示させます。 mapメソッドで展開する場合は、ユニークなkeyを設定する必要があるので注意してください。 App.jsにApiFetch.jsコンポーネントをimport次にApp.jsにApiFetchコンポーネントを登録します。 src/App.js123456789101112131415161718192021222324252627282930import logo from './logo.svg';import './App.css';// 追記import ApiFetch from './components/ApiFetch';// 追記function App() { return ( &lt;div className=&quot;App&quot;&gt; &lt;header className=&quot;App-header&quot;&gt; &lt;img src={logo} className=&quot;App-logo&quot; alt=&quot;logo&quot; /&gt; {/* 追記 */} &lt;ApiFetch /&gt; {/* 追記 */} &lt;p&gt; Edit &lt;code&gt;src/App.js&lt;/code&gt; and save to reload. &lt;/p&gt; &lt;a className=&quot;App-link&quot; href=&quot;https://reactjs.org&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; &gt; Learn React &lt;/a&gt; &lt;/header&gt; &lt;/div&gt; );}export default App; ブラウザを確認ブラウザでlocalhost:3000にアクセスしてみましょう。以下の通りJSON Placeholderに投稿されているtitleが10つ取得され、表示されていることがわかります。 これがaxiosを用いたAPIのアクセス方法になります。 この記事が役に立った！という方はTwitterのフォローなどよろしくおねがいします。 もっと詳しくReactを学びたい方 Udemyの[基礎編]React Hooks + Django REST Framework API でフルスタックWeb開発で学ぶのがおすすめです。","link":"/react-api/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで④[長い長いリハビリ]","text":"前の記事で松葉杖の卒業までをまとめました。 この記事では7か月続いたリハビリの内容をまとめるよ！ 以下のようなことを意識してまとめたいと思います。 ・ 復帰までの大まかなリハビリの内容 ・ 復帰を早めるためにリハビリ期間中に工夫したことと効果 ・ リハビリ期間中、辛かったことと乗り越え方 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 復帰までに取り組んだリハビリメニュー(全体像) 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ リハビリでつらかったこと その①：関節拘縮 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 関節拘縮の克服その3：膝伸ばしのリハビリ リハビリでつらかったこと その②：モチベーションの維持 リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 まとめ 復帰までに取り組んだリハビリメニュー(全体像) 大きく分けて２つのリハビリを頑張りました！ 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ 1. 膝の回復状態にかかわらず実施したリハビリ 膝の伸び具合のチェック マッサージ 超音波 電気を当てる ※本記事トップの写真 EMS 2. 膝の回復状態別のリハビリ 歩く練習 両足スクワット 両足を開いて片足スクワット 踏み出してスクワット 片足のみでスクワット 中腰で左右に移動・方向転換 ジャンプして両足着地 ジャンプして方向転換して着地 ジャンプして片足着地 片足ジャンプ 片足ジャンプして方向転換して着地 30％ダッシュ 50%ダッシュ 100%ダッシュ ダッシュからの片足・・・・ リハビリ、、、というかトレーニングだね。。。 リハビリでつらかったこと その①：関節拘縮 私の膝は手術した内部の癒着がひどく、リハビリ初期の段階で膝が伸びない状態が予定よりも長く続いてしまいました。 手術後などに関節の動きが制限されてしまうことを関節拘縮と言い、この状態になってしまったのです。 膝関節の中は連続した空間であり、ここに癒着が生じると関節可動域が制限されるのです。 場合によっては、再度、関節鏡視下手術を行い、膝内部の癒着を剥がす処置をしなければなりません。 これは、癒着しやすい人と、そうでない人がいるらしく、私は不幸にも癒着を起こしやすい体質だったようです。 癒着の厄介なところは、仮に癒着をはがす手術をしたとしても、再度癒着してしまう可能性もある点です。 このような懸念もあり、「なんとか工夫をして手術せずに膝の可動域を確保せねば」と思ったのです。 結果として私はこれから紹介する方法で、癒着の剥離手術をせずに膝の可動域を確保することができました。 その方法をまとめていきます。もちろん理学療法士の先生とも相談しながら取り組んでください。 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 美顔ローラーで膝の癒着部分を皮膚を吸い上げるような具合でコロコロさせると良いです。 これはかなり効果がありました。 癒着をはがすために、指で皮膚をつまみ上げる作業を行うのですが、なかなかしんどいです。 美顔ローラで皮膚を吸い上げることで、効率的に癒着をはがせます。 美顔ローラはこちら この方法は、理学療法士の先生に教えてもらった方法です。まさか、美顔器が膝の癒着回避に役立つとは思いませんでした。 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 皮膚を柔らかくする効果があります。膝全体をマッサージするように軟膏を刷り込んで癒着を取る努力をしました。 軟膏自体は、お医者様の診察を受けてから、処方していただいたほうが良いと思います。 関節拘縮の克服その3：膝伸ばしのリハビリ 以下の記事で掲載している膝の力入れリハビリです。 何度も何度も自宅で集中して全力でやりました。 私と同じように、癒着がひどい方は参考になればと思います。 先生からは、「膝伸ばしを頑張れば頑張るほど良くなる」と言われました。 リハビリでつらかったこと その②：モチベーションの維持 リハビリ期間中はプレーしたい思いが先行して、焦りの気持ちや悲観的になることもあると思います。 しかし、リハビリを通じて正しい体の動かし方や、ケアの仕方を学ぶ良いきっかけだと思い込むようにしました。 野球選手であれば、小久保裕紀さんの本はとても勇気づけられると思いますのでお勧めです。 小久保さんは、以下の記事にある通り、「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という大けがをしました。 辛いリハビリを乗り越え復帰し、キャリアハイの成績を残した方です。 「けがをしたことは不幸なことだったが、結果として栄養や体のことを学び、選手としての寿命を延ばす結果につながった。」という言葉は、とても勇気づけられました。 なお私自身もリハビリを通じて体のバランスやキレが良くなり、ケガをする前以上のパフォーマンスを発揮できています。 今思えば、このリハビリが自分にとって大きな学びを与えてくれたと思っています。 是非、前向きな気持ちでリハビリに取り組んでください。結果は必ず付いてくるはずです。 リハビリを真面目に頑張ることで、怪我する前よりも良いプレーができるようなるはず！ リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 リハビリは、筋力の回復が重要視されます。 リハビリの後は、直ちにプロテインを取るのが有効です。 以下の論文によると、タンパク質+炭水化物を摂取したグループが最も筋肉の肥大につながっているとされております。 L. Holm, B. Esmarck, M. Mizuno, H. Hansen, C. Suetta, P. Ho¨lmich, M. Krogsgaard, M. Kjær(2006). “The Effect of Protein and Carbohydrate Supplementation onStrength Training Outcome of Rehabilitation in ACL Patients”. Journal of orthopaedic research, 2114-2123 プロテインは、基本的に吸収効率が良いとされるホエイプロテインが良いとされています。 牛乳等を飲むと、おなかが痛くなる方とかは、アミノ酸(BCAA)が良いでしょう。 筋肉が作られる仕組みは、すでに多くのサイトなどでまとめられていますので詳しくはまとめませんが、基本的に筋繊維が破壊された後、30分間がもっとも吸収効率が高いと言われています。 リハビリが終わったら、30分以内にプロテインを飲めば良いんだね！ 摂取したたんぱく質が筋肉になる流れは以下の通りです。 1. タンパク質が分解されアミノ酸になる 2. アミノ酸がされに分解され代謝性物質になる 3. 代謝性物質が血液で循環され、壊れた筋肉に運ばれる 4. 代謝性物質がアミノ酸に戻りタンパク質となり筋肉になる そして、タンパク質を分解するときに必要になるのが、ビタミンだといわれています。 ここで私は思いました。 プロテインとビタミンが両方含まれたサプリメントがほしいな。 プロテインについて調べてみると、1000円くらいで買えるものから、10000円を超えるものまでピンキリです。 よくよく成分表をみてみると、安いものは、純粋にタンパク質の粉末のみのものだったり、人工甘味料を使ってコストが抑えられているものでした。 一方、10000円を超える高級プロテインは、タンパク質だけでなく、多くのアミノ酸、ビタミン、抵抗力を上げるグルタミン、人工甘味料不使用、等々、筋肉をつけるために計算された配合になっていました。 つまりは安かろう悪かろう、という感じです。 私としては、そんなにお金かけて購入したくないな、という一方で、人工甘味料は体によくなさそうだし、可能であれば味がおいしいものがいいな、と思いました。 そしてビーレジェンドのプロテインを購入しました。 プロテインはこちら このプロテインの成分表は以下の通りです。 これでタンパク質とビタミンが同時に取れる！ まとめ 膝の回復とともにリハビリはハードになる。 手術後の癒着で膝関節の可動域を確保するのが大変でした。 美顔ローラー、軟膏、膝伸ばしリハビリが有効でした プロテインを活用しよう。 回復が早いという研究結果の論文があります。 おすすめは、ビーレジェンドのプロテイン 美顔ローラはこちら プロテインはこちら 他のおすすめ記事 ダルビッシュ選手も実践する風邪予防サプリメントが知りたい方はこちら↓ 特保飲料と食べるだけで痩せられる食材を使った楽痩せメソッドを知りたい方はこちら↓","link":"/rehabilitation/"},{"title":"【Python】手を動かしながら正規表現を学ぶ | データサイエンス100本ノック【問13〜問15 回答】","text":"目次 この記事の対象者 正規表現とはなにか 実際に手を動かして正規表現を使ってみよう 13問目:前方一致 14問目：後方一致 15問目：複数条件 まとめ: 手を動かしながら正規表現を学びました この記事の対象者 ・ 正規表現を手を動かしながら学びたい人 ・ データサイエンティストを目指している人 正規表現とはなにか 正規表現とは、様々なパターンで並んでいる文字列を特殊文字などを使って表現する表記法です。 正規表現は、大量のデータから特定の条件に合致したデータを抽出する際に使用されます。 基本的な表記法としては以下のものがあります。 任意の1文字：. 文字列の先頭：^ 文字列の最後：$ 同一文字の繰り返し：*, +, ? 範囲指定：- 角括弧に含まれるいずれか１文字にマッチ：[ ] 角括弧に含まれる文字以外にマッチ：[^] その他の表記法は以下のリファレンスを参照いただければと思います。 re —- 正規表現操作 — Python 3.9.4 ドキュメント (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク 実際に手を動かして正規表現を使ってみよう 正規表現の主な表記法はなんとなく分かったかと思いますが、実際に使おうと思うと、なかなか使いこなすのは難しいものです。 そこで、一般社団法人データサイエンティスト協会がGitHubに公開している「データサイエンス100本ノック」の環境を使って、正規表現の具体的な使い方を学んでいきましょう。 データサイエンス100本ノックは、自身のPCにDockerを用いて環境構築することが出来ます。 データサイエンス100本ノックの環境構築方法は以下の記事にまとめています。 以降にデータサイエンス100本ノックの中で、正規表現に関連する問題をピックアップしてますので、実際に手を動かしながら正規表現の使い方を学んでいきましょう。 13問目:前方一致 P-013: 顧客データフレーム（df_customer）から、ステータスコード（status_cd）の先頭がアルファベットのA〜Fで始まるデータを全項目抽出し、10件だけ表示せよ。 この問題を解くためには正規表現を使う必要があります。 文字列の先頭を表す^と、文字列の範囲を指定する-と、文字列のマッチ条件を指定する[]を用いて^[A-F]のように記述すればOKです。 問13回答1df_customer.query(&quot;status_cd.str.contains('^[A-F]', regex=True)&quot;, engine='python').head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd2 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C6 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B12 CS011215000048 芦田 沙耶 1 女性 1992-02-01 27 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150228 C-20100421-915 CS029415000023 梅田 里穂 1 女性 1976-01-17 43 279-0043 千葉県浦安市富士見********** S12029 20150610 D-20100918-E21 CS035415000029 寺沢 真希 9 不明 1977-09-27 41 158-0096 東京都世田谷区玉川台********** S13035 20141220 F-20101029-F32 CS031415000106 宇野 由美子 1 女性 1970-02-26 49 151-0053 東京都渋谷区代々木********** S13031 20150201 F-20100511-E33 CS029215000025 石倉 美帆 1 女性 1993-09-28 25 279-0022 千葉県浦安市今川********** S12029 20150708 B-20100820-C40 CS033605000005 猪股 雄太 0 男性 1955-12-05 63 246-0031 神奈川県横浜市瀬谷区瀬谷********** S14033 20150425 F-20100917-E44 CS033415000229 板垣 菜々美 1 女性 1977-11-07 41 246-0021 神奈川県横浜市瀬谷区二ツ橋町********** S14033 20150712 F-20100326-E53 CS008415000145 黒谷 麻緒 1 女性 1977-06-27 41 157-0067 東京都世田谷区喜多見********** S13008 20150829 F-20100622-F では、postal_cdの先頭が150〜159で始まるデータを全項目抽出し、10件だけ表示させたい場合は、どうするでしょうか。 その場合は、[1][5][0-9]と記述します。 1df_customer.query(&quot;postal_cd.str.contains('^[1][5][0-9]', regex=True)&quot;, engine='python').head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd2 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C11 CS035614000014 板倉 菜々美 1 女性 1954-07-16 64 154-0015 東京都世田谷区桜新町********** S13035 20150804 0-00000000-013 CS009413000079 市川 コウ 1 女性 1975-12-28 43 158-0093 東京都世田谷区上野毛********** S13009 20151209 0-00000000-016 CS009315000023 皆川 文世 1 女性 1980-04-15 38 154-0012 東京都世田谷区駒沢********** S13009 20150319 5-20080322-121 CS035415000029 寺沢 真希 9 不明 1977-09-27 41 158-0096 東京都世田谷区玉川台********** S13035 20141220 F-20101029-F24 CS035513000134 市川 美帆 1 女性 1960-03-27 59 156-0053 東京都世田谷区桜********** S13035 20150227 8-20100711-932 CS031415000106 宇野 由美子 1 女性 1970-02-26 49 151-0053 東京都渋谷区代々木********** S13031 20150201 F-20100511-E41 CS008615000055 二宮 コウ 1 女性 1953-06-15 65 157-0074 東京都世田谷区大蔵********** S13008 20150623 5-20100531-853 CS008415000145 黒谷 麻緒 1 女性 1977-06-27 41 157-0067 東京都世田谷区喜多見********** S13008 20150829 F-20100622-F54 CS008413000302 池谷 由樹 1 女性 1969-09-27 49 157-0067 東京都世田谷区喜多見********** S13008 20180813 0-00000000-0 14問目：後方一致 P-014: 顧客データフレーム（df_customer）から、ステータスコード（status_cd）の末尾が数字の1〜9で終わるデータを全項目抽出し、10件だけ表示せよ。 こちらの問題でも、正規表現を使用します。 今回は、末尾の数字の範囲を指定します。 文字列の最後の範囲指定は[]$という書き方になります。 今回は1〜9の範囲なので[1-9]$ということになります。 問14回答1df_customer.query(&quot;status_cd.str.contains('[1-9]$', regex=True)&quot;, engine='python').head(10) 出力123456789101112customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd4 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-29 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-512 CS011215000048 芦田 沙耶 1 女性 1992-02-01 27 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150228 C-20100421-914 CS040412000191 川井 郁恵 1 女性 1977-01-05 42 226-0021 神奈川県横浜市緑区北八朔町********** S14040 20151101 1-20091025-416 CS009315000023 皆川 文世 1 女性 1980-04-15 38 154-0012 東京都世田谷区駒沢********** S13009 20150319 5-20080322-122 CS015315000033 福士 璃奈子 1 女性 1983-03-17 36 135-0043 東京都江東区塩浜********** S13015 20141024 4-20080219-323 CS023513000066 神戸 そら 1 女性 1961-12-17 57 210-0005 神奈川県川崎市川崎区東田町********** S14023 20150915 5-20100524-924 CS035513000134 市川 美帆 1 女性 1960-03-27 59 156-0053 東京都世田谷区桜********** S13035 20150227 8-20100711-927 CS001515000263 高松 夏空 1 女性 1962-11-09 56 144-0051 東京都大田区西蒲田********** S13001 20160812 1-20100804-128 CS040314000027 鶴田 きみまろ 9 不明 1986-03-26 33 226-0027 神奈川県横浜市緑区長津田********** S14040 20150122 2-20080426-4 15問目：複数条件 P-015: 顧客データフレーム（df_customer）から、ステータスコード（status_cd）の先頭がアルファベットのA〜Fで始まり、末尾が数字の1〜9で終わるデータを全項目抽出し、10件だけ表示せよ。 この問題は、ここまで解いてきた13問目と14問目の条件を同時に満たすような正規表現を書かなければいけません。 13問目の正規表現は、^[A-F] 14問目の正規表現は、[1-9]$ この２つの条件をつなげるには、.*を用いればOKです。 .は任意の1文字をマッチさせ、*は直前のパターンを0回以上繰り返しを意味します。 ^[A-F].*[1-9]$とすることで、先頭がアルファベットのA〜Fで始まり、末尾が数字の１〜９で終わるデータを抽出することができます。 問15回答1df_customer.query(&quot;status_cd.str.contains('^[A-F].*[1-9]$', regex=True)&quot;, engine='python').head(10) 出力123456789101112customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd12 CS011215000048 芦田 沙耶 1 女性 1992-02-01 27 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150228 C-20100421-968 CS022513000105 島村 貴美子 1 女性 1962-03-12 57 249-0002 神奈川県逗子市山の根********** S14022 20150320 A-20091115-771 CS001515000096 水野 陽子 9 不明 1960-11-29 58 144-0053 東京都大田区蒲田本町********** S13001 20150614 A-20100724-7122 CS013615000053 西脇 季衣 1 女性 1953-10-18 65 261-0026 千葉県千葉市美浜区幕張西********** S12013 20150128 B-20100329-6144 CS020412000161 小宮 薫 1 女性 1974-05-21 44 174-0042 東京都板橋区東坂下********** S13020 20150822 B-20081021-3178 CS001215000097 竹中 あさみ 1 女性 1990-07-25 28 146-0095 東京都大田区多摩川********** S13001 20170315 A-20100211-2252 CS035212000007 内村 恵梨香 1 女性 1990-12-04 28 152-0023 東京都目黒区八雲********** S13035 20151013 B-20101018-6259 CS002515000386 野田 コウ 1 女性 1963-05-30 55 185-0013 東京都国分寺市西恋ケ窪********** S13002 20160410 C-20100127-8293 CS001615000372 稲垣 寿々花 1 女性 1956-10-29 62 144-0035 東京都大田区南蒲田********** S13001 20170403 A-20100104-1297 CS032512000121 松井 知世 1 女性 1962-09-04 56 210-0011 神奈川県川崎市川崎区富士見********** S13032 20150727 A-20100103-5 まとめ: 手を動かしながら正規表現を学びました本記事では【Python】手を動かしながら正規表現を学ぶ | データサイエンス100本ノック【問13〜問15 回答】というテーマでまとめました。 今回は正規表現の使い方の代表例をデータサイエンス100本ノックの問題を題材にして紹介しました。 データサイエンス100本ノックは、その他にも多くのPythonの使い方を学べる良教材です。 無料なので、本ブログの内容を参考に、チャレンジしてみてください。 &gt;&gt; 続きはこちらから","link":"/regular-expression/"},{"title":"【Python】Selection Sortを学びながらPythonの基礎を身につける記事","text":"✓目次 Selection Sortとは Pythonの基礎について [Python基礎]range関数 Selection Sortのコーディング まとめ Selection Sortとはソートアルゴリズムの一種です。 データ列中で一番小さい値を探し、1番目の要素と交換する。次に、2番目以降のデータ列から一番小さい値を探し、2番目の要素と交換する。これを、データ列の最後まで繰り返す（厳密には、データ列の最後より1つ手前までの繰り返しでよい。一つ前まで交換済みであれば、最後（残り）は必ず最大値になるからである）。 選択ソート - Wikipedia Pythonの基礎についてSelection Sortを実装するために必要な知識は以下の記事にもまとめていますので参照ください。Bubble Sortの学習もしていただくと良いと思います。 ここでは、追加で学んでおくべきPythonの基礎について整理します。 [Python基礎]range関数例えば、1から9までの数字を表示しなさい、と言われた時に、num_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]とリストを作って、これを表示するコードを書いてもいいですが、面倒ですよね。 こんな時に、pythonのrange関数が役に立ちます。 12345678910111213for i in range(10): print(i)# 0# 1# 2# 3# 4# 5# 6# 7# 8# 9 では、リストの3番目から表示してほしい、という場合はどうするでしょうか？その場合は、以下のような書き方をすればOKです。 12345678910for i in range(3, 10): print(i)# 3# 4# 5# 6# 7# 8# 9 では、2つ飛ばしで値を表示してほしい、という場合はどうでしょうか？これも簡単で、3つめの引数に2と入れるだけです。 1234567for i in range(3, 10, 2): print(i)# 3# 5# 7# 9 これを応用して、10回’hello’という文字列を出力する事もできます。ここではついでにindex番号も出力しています。 12345678910111213for i in range(10): print(i, \"hello!\")# 0 hello!# 1 hello!# 2 hello!# 3 hello!# 4 hello!# 5 hello!# 6 hello!# 7 hello!# 8 hello!# 9 hello! また、for i in range(10)としてforループで10回ループを回した後、「もうiは不要ですよ」というのを明示的に示すために、_を用いたりします。 forループの中でもiを使う必要もありません。index番号を使わない場合は、このような書き方をしてもOKです。 12345678910111213for _ in range(10): print(\"hello!\")# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello!# hello! Selection Sortのコーディング基本的な思考の流れは、Bubble Sortの時と同じです。 まずは、Bubble Sortと同様、関数宣言します。 123from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: 次に、リストの定義と定義した関数にリストを渡し、range関数とlenメソッドを用いて、リストのindexをprintしてみます。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): print(i) if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums)# 0# 1# 2# 3# 4# 5 Selection Sortは、先頭の数字を取り出し、前から順番に数字の大小を比較し、もし先頭の数字のほうが大きかったら入れ替える、という処理を繰り返します。 まず、最初の数字のindexを取り出すために、min_index = iを追記します。printは削除します。 123456789101112from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums) forループで、先頭のindex番号を一つ先のindex番号から最後のindex番号まで、先頭の数字とそれ以降の数字を比較する処理を記述します。 123456789101112from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] selection_sort(nums) もし、先頭のindex番号に含まれた数字のほうが大きかった場合は、数字を入れ替えるので、以下のように記載します。そして最後にreturnでリストを返却します。結果をprintするとうまくソートされていることがわかると思います。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: numbers[min_index], numbers[j] = numbers[j], numbers[min_index] return numbers if __name__ == '__main__': nums = [2, 5, 7, 6, 7, 1,] print(selection_sort(nums))# -&gt; [1, 2, 5, 6, 7, 7] 最後に、randomを用いて大きめの数字でも試してみるとうまくソートできていることが確認できると思います。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: numbers[min_index], numbers[j] = numbers[j], numbers[min_index] return numbersif __name__ == '__main__': import random nums = [random.randint(0, 1000) for _ in range(10)] print(selection_sort(nums))# -&gt; [66, 167, 205, 242, 294, 319, 339, 629, 913, 976] 別海としては、min_index = jと記述して、数値比較の際に小さい方の数のindex番号を入れ替える処理をすることを明示的に示すコードの書き方もあります。 1234567891011121314151617from typing import Listdef selection_sort(numbers: List[int]) -&gt; List[int]: for i in range(len(numbers)): min_index = i for j in range(i + 1, len(numbers)): if numbers[min_index] &gt; numbers[j]: min_index = j numbers[i], numbers[min_index] = numbers[min_index], numbers[i] return numbers if __name__ == '__main__': import random nums = [random.randint(0, 1000) for _ in range(10)] print(selection_sort(nums))# -&gt; [8, 9, 51, 268, 322, 413, 599, 780, 858, 996] まとめ本記事では、Selection Sortとは何かを理解し、Pythonの基本を学びながらコードを作成してみました。 Pythonの基礎としては、Bubble Sortで学んだ内容に加えて、range関数について学びました。 より詳しく学びたい方 以下の、Udemyのコースがおすすめです。30日間の返金保証もついているので、是非試してみてください。 本記事も、以下のコースで学んだ内容をもとに作成しております。講師の方に、Twitterでクーポンコードの発行をお願いすれば、10$(1200円)で受講可能です。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOxH3C\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-algo/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/3187702_80ef.jpg?XcNbGN5nRQNfTZFzm7R2KOrIVgitASRFtYheLGpFDDtYGCrTq95GhaAufPG2aZMZrhi4qPRuDOUY5ujEfAicb4RjaukscmrFKYgdrAVIrP9n8-z0vzebcV7u1PE\"}}); 現役シリコンバレーエンジニアが教えるアルゴリズム・データ構造・コーディングテスト入門 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjOzxCG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/python-beginner/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/480x270/1134722_3100_2.jpg?secure=reJhBAqyDecgJtSbnWEUWQ%3D%3D%2C1608620950\"}}); 現役シリコンバレーエンジニアが教えるPython 3 入門 + 応用 +アメリカのシリコンバレー流コードスタイル","link":"/selection-sort/"},{"title":"REST API設計時に気を付ける主なポイント","text":"✓目次 この記事の対象者 APIの設計 リクエスト URIの設計 ①誰もが読んで意味が理解できる ②サーバー側の構造が見えないようにする ③ルールが統一化されている HTTPメソッド クエリパラメータとパスパラメータの使い分け レスポンス HTTPメソッドとステータスコード データフォーマット この記事の対象者 ・ REST APIの設計方法の概要を知りたい人 ・ REST APIについてなんとなく理解している(GET, POST等のメソッドやステータスコードの使い分け等)が、設計→仕様書作成に踏み込めていない人 APIの設計 APIの設計は、大きく「リクエスト」と「レスポンス」に分けて考えられます。APIの設計は、○○が最も望ましい！というようなものは存在しません。企業だったり提供しているサービスによって考え方はまちまちなのかなと思います。その中でも、API設計時に、特に意識したほうが良い点をピックアップして整理したいと思います。以降は、「リクエスト」と「レスポンス」に分けて、要点を絞って、API設計時の考慮ポイントを整理します。 リクエストリクエストの設計時に考慮することは主に以下の3点があります。 ・ URIの設計 ・ HTTPメソッド ・ クエリパラメータとパスパラメータの使い分け URIの設計そもそもURIとは何を表すものなのかというと、「リソース」を表現するものです。 リソースとは、基本的には名前が付けられているものはすべてリソースになります。 例えば、サーバー側に保持されているデータもリソースです。そのほかにも、ドキュメント、サービス、商品、状態・・・これらすべて「リソース」です。よく見かけるものとしては、latestというのがあると思います。これは「latest(最新)」という「状態」を表すリソースです。 一方、リソースとしないものとして、これも所説ありますが、「動詞」は含まないことが多いです。 こういった前提を踏まえて、URI設計時に気を付ける主なポイントを以下にまとめます。 ・ ①誰もが読んで意味が理解できる ・ ②サーバー側の構造が見えないようにする ・ ③ルールが統一化されている ①誰もが読んで意味が理解できる例えば、 http://example.com/r/u みたいに、rとかuみたいな何らかの単語が省略されたようなURIになっているのは、あまりよくありません。 http://example.com/resources みたいに省略せずに記載し、誤認識を防ぐような書き方をすべきと考えます。 また http://example.com/リソース という風なのも基本的にはNGです。 理由は、「リソース」というような2バイト文字を用いると、エンコードが必要となり、URLとしては、 http://example.com/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9 となってしまい、意味が理解できなくなってしまうためです。 この点も気をつけましょう。 ②サーバー側の構造が見えないようにする例えば、 http://example.com/resources.php?id=abcde というURLとすると、サーバーサイドでPHPが用いられているのではないか、と予測できてしまいます。 これにより、悪意のある人間が脆弱性を狙い、情報漏洩等のインシデントにつながる可能性があります。 なるべくサーバーサイドの情報や仕組みをURLには反映しないように気をつけましょう。 ③ルールが統一化されている例えばあるAPIではクエリパラメータを使用し、他のAPIではパスパラメータを活用していたりすると、ルールが統一化されておらず、APIを利用する人にとってフレンドリーではなく間違いが発生します。 具体的には、顧客情報の取得として GET http://example.com/customers?id=1234567 という風にクエリパラメータを使用しているのに対し、顧客情報の登録では、 POST http://example.com/customers/1234123 という風にパスパラメータで指定しているケースです。 この場合は、例えば両方ともパスパラメータを活用するように、統一化するのが望ましいと思います。 HTTPメソッド以下の4つを最低限抑えておけば良いと思います。 GET → 通常のアクセス、ページ表示、情報などのリソース取得 POST → データ送信、新規登録、等リソースの新規登録 PATCH/PUT → データの更新等、リソースの更新 DELETE → データの削除等、リソースの削除 PATCHとPUTの違いは以下です。 PATCHは、データが既に存在しているものにたいして更新をかける処理 PUTは、データが存在しているかどうかわからないときに使い、データが存在しているときは更新をし、データが存在していないときは新規作成を行う処理になります。 設計したURLに対して、これらのメソッドを適用することで、そのリソース自体に対する操作を切り替えることができます。 クエリパラメータとパスパラメータの使い分けリソースを一意に表す必要がある場合：パスパラメータを使用例えばユーザIDとかがそれにあたります。 リソースを一意に表す必要がなく複数パタンが考えられる場合:クエリパラメータを使用例えば検索条件を指定する場合、検索条件は複数パタンが考えられるのでパスには含めずにクエリパラメータを使用します。 以下に記事に分かりやすくまとめられておりますので、気になる方は参照いただければと思います。 [RESTful API]パスパラメータ、クエリパラメータ、リクエストボディの違いと設計 - Qiita レスポンスリクエストの設計時に考慮することは主に以下の2点があります。 ・ HTTPメソッドとステータスコード ・ データフォーマット この他、データの内部構造や、エラー表現など細かい点で気を付けたほうが良いことはありますが、まずは大枠としてこの2点のみ整理したいと思います。 HTTPメソッドとステータスコードステータスコードは、HTTPリクエストを行った後、受け取るレスポンスの最初の行に記載されている3桁の数字です。これにより処理結果の概要を把握することができます。 100番台から500番台まで存在しますが、基本的には100番台はそこまで使用せず、200番台から500番台までを使います。 詳細な意味はその都度検索して把握すれば良いと思いますが、大まかな意味としては以下の通りとなります。 200番台：成功 300番台：リダイレクト 400番台：クライアントサイドに起因するエラー 500番台：サーバーサイドに起因するエラー ステータスコードとメソッドの対応関係は、基本的には、以下の表にまとめている通りとなります。 ステータスコード GET POST PUT DELETE 200 OK 〇 〇登録データあり 〇データあり 〇 201 Created 〇データなし 〇新規作成データなし 202 Accepted 〇 〇 〇 204 No Content 〇更新データなし 〇 304 Not Modified 〇キャッシュ 400 Bad Request 〇 〇 〇 〇 401 Unauthorized 〇 〇 〇 〇 403 Forbidden 〇 〇 〇 〇 404 Not Found 〇 〇 〇 409 Conflict 〇データ重複など 〇ロックなど 429 Too Many Requests 〇 〇 〇 〇 500 Internal Server Error 〇 〇 〇 〇 503 Service Unavailable 〇 〇 〇 〇 データフォーマット主要なレスポンスフォーマットは2種類で、XMLかJSONになります。しかし、XMLにくらべてデータ量を減らせるJSONが主流なのではと思います。XMLのタグは末尾にも同じ文字が必要なため冗長な記述であり、JSONと比較してデータ量が多くなってしまいます。 REST APIの設計を詳しく学びSwaggerを用いてAPI設計をしたい方は以下がおすすめ REST APIの設計を重点的に学びたい方は以下のUdemy講座がおすすめです。質、ボリューム共に豊富で、不明点もWeb経由で質問し講師が直接回答してくれるため、挫折する心配もありません a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-seZAKTG\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rest-webapi-development/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2641334_7977_6.jpg?tQnHFB7pu2rjtgmRqdDrZqHnUNTMsGAspswDZd7agOUondO9kbLFpMNfi87HFWc4E1gpBZmlURm7aQ1JvEWRcrcF20SfqIUhFhf5IBU0kYKMsSCOb3M0GImDyz3qvkQ2\"}});","link":"/swagger-editor-design-firststep/"},{"title":"EPAと葉酸は精神疾患に有用である可能性がある","text":"精神医学誌に掲載された論文によるとEPAと葉酸が精神疾患に有用であることが分ったので、その内容についてまとめます！ EPAと葉酸は精神疾患に有用である可能性がある。 脳機能の改善や認知症予防にサプリメントの活用が注目されつつあるようです。 学術誌World Psychiatry(世界精神医学誌)の以下の論文で、EPAや葉酸が精神疾患に有用である可能性を指摘しています。 引用文献 (PDF) The efficacy and safety of nutrient supplements in the treatment of mental disorders: a meta-review of meta-analyses of randomized controlled trials In conclusion, clinicians should be informed of the nutrient supplements with established efficacy for certain conditions (such as eicosapentaenoic acid in depression), but also made aware of those currently lacking evidentiary support. Future research should aim to determine which individuals may benefit most from evidence‐based supplements, to further elucidate the underlying mechanisms. EPAとは：魚の油 EPAとは「エイコサペンタエン酸」の略称です。いわし・さば・あじなどの青魚に多く含まれるn-3系脂肪酸のひとつです。主に青魚の油に多く含まれるEPA（エイコサペンタエン酸）は、体内でほとんど作ることができない「必須脂肪酸」の一種です。必須脂肪酸にはほかに、同じく魚油に含まれるDHA（ドコサヘキサエン酸）、肉やリノール酸（植物油のひとつ）に偏った食事により体内に増加するAA（アラキドン酸）などがあります。EPAとは？ | サラサラ生活向上委員会 | ニッスイより 要するに魚の油ですね。 精神疾患だけでなく、血液をサラサラにしてくれたりする効果もあるようです。 毎日魚を食べるのもしんどいので、私はサプリメントで摂取しています。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"DHC EPA 30日分【機能性表示食品】\",\"b\":\"DHC(ディー・エイチ・シー)\",\"t\":\"1\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51ABqG1qHHL._SL500_.jpg\",\"\\/21PR3DtGRdL._SL500_.jpg\",\"\\/61MYKebUS8L._SL500_.jpg\",\"\\/61uLMCZ7pGL._SL500_.jpg\",\"\\/51BEpYZE6OL._SL500_.jpg\",\"\\/61Gim4VqoBL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HNKVQCY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HNKVQCY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/DHC%20EPA%2030%E6%97%A5%E5%88%86%E3%80%90%E6%A9%9F%E8%83%BD%E6%80%A7%E8%A1%A8%E7%A4%BA%E9%A3%9F%E5%93%81%E3%80%91\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=DHC%20EPA%2030%E6%97%A5%E5%88%86%E3%80%90%E6%A9%9F%E8%83%BD%E6%80%A7%E8%A1%A8%E7%A4%BA%E9%A3%9F%E5%93%81%E3%80%91\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"vSEEx\",\"s\":\"s\"}); リンク 葉酸は枝豆、鶏レバー、焼きのりに多く含まれている。 葉酸を多く含む食べ物は、野菜ではえだまめ、肉は鶏レバー、海藻では焼きのり…などが特に葉酸を多く含む食べ物です。他にも豆類や果物など、多くの食べ物に葉酸は含まれている葉酸とは：どの食べ物に含まれているの？種類や適正量は？｜エレビット (Elevit)｜バイエル薬品より 日常的にえだまめ、や鶏レバーを取るのも正直しんどいですよね。こちらも手軽にサプリメントで取ってしまいましょう。400円前後で購入できます。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"大塚製薬 ネイチャーメイド 葉酸 150粒 75日分\",\"b\":\"NATUREMADE(ネイチャーメイド)\",\"t\":\"267317\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51emSvenlLL._SL500_.jpg\",\"\\/51nuYJOV8FL._SL500_.jpg\",\"\\/51Ym+L8NcBL._SL500_.jpg\",\"\\/51mJ4XxOTNL._SL500_.jpg\",\"\\/51vvHeVmAGL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B000FQTQUY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B000FQTQUY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E8%91%89%E9%85%B8%20150%E7%B2%92%2075%E6%97%A5%E5%88%86\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E8%91%89%E9%85%B8%20150%E7%B2%92%2075%E6%97%A5%E5%88%86\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"ZfDkJ\",\"s\":\"s\"}); リンク サプリメントを上手く活用して健康で健やかな毎日を送りましょう！ おしまい 合わせて読みたい記事 ダルビッシュ有投手も実践する風邪を引かないサプリメントについては以下の記事を参照ください。私もこれを始めてから風邪で寝込んでいません。","link":"/spl-mental-health/"},{"title":"【pipが使えない？】Cloud9でtweepyをインストールする方法","text":"TwitterのAPIを利用するライブラリであるTweepyのインストール方法です。Cloud9環境で実施しています。確認できたエラー、それに対する対応についてもまとめています。 ✓目次 Twitter API登録 Cloud9でTweepyのインストール Cloud9の環境をPython3環境にする Tweepyをインストール Twitter API登録以下の記事が大変参考になります。 Twitter API 登録 (アカウント申請方法) から承認されるまでの手順まとめ ※2019年8月時点の情報 - Qiita customer API keys(API keyとAPI secret key)とAccess token、Access token secretを取得しましょう。 Cloud9でTweepyのインストール以降はAWSが提供しているIDE環境であるCloud9環境での手順になります。 Cloud9の環境をPython3環境にするまずは、cloud9の環境をpython3の環境に変更します。 でなければpipのバージョンとpythonのバージョンがあわなくて、tweepyがインストールできません。以下の記事を参考に、環境設定を行いましょう。 【Python】Cloud9上でPython3系を使うとき絶対にやっておくべき環境設定【AWS】 | Utarog Cloud9のターミナルで、python -Vコマンドを実施し、以下の状態になったらOKです。 12345ec2-user:~\\environment $ python -VPython 3.6.8ec2-user:~\\environment $ pip -Vpip 9.0.3 from \\usr\\lib\\python3.6\\dist-packages (python 3.6)ec2-user:~\\environment $ Tweepyをインストールtweepyをpip install tweepyコマンドでインストールすると、下記エラーになります。 12345678910111213141516171819202122232425ec2-user:~\\environment $ pip install tweepyException:Traceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\basecommand.py\", line 215, in main status = self.run(options, args) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\commands\\install.py\", line 342, in run prefix=options.prefix_path, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_set.py\", line 784, in install **kwargs File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 1064, in move_wheel_files isolated=self.isolated, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 345, in move_wheel_files clobber(source, lib_dir, True) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 316, in clobber ensure_dir(destdir) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\utils\\__init__.py\", line 83, in ensure_dir os.makedirs(path) File \"\\usr\\lib64\\python3.6\\os.py\", line 220, in makedirs mkdir(name, mode)PermissionError: [Errno 13] Permission denied: '\\usr\\lib\\python3.6\\dist-packages\\urllib3'You are using pip version 9.0.3, however version 19.3.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command. pipをpip install --upgrade pipコマンドで、アップグレードしなさい、というメッセージなので、 以下のコマンドでpipをアップグレード 1ec2-user:~\\environment $ sudo pip install --upgrade pip pipコマンドを実行してみると、なぜかpipが使えなくなってしまいました。 12345678910111213141516171819202122232425262728ec2-user:~ $ pipTraceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 658, in _build_master ws.require(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 972, in require needed = self.resolve(parse_requirements(requirements)) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 863, in resolve raise VersionConflict(dist, req).with_context(dependent_req)pkg_resources.VersionConflict: (pip 19.3.1 (\\usr\\local\\lib\\python3.6\\site-packages), Requirement.parse('pip==9.0.3'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"\\usr\\bin\\pip\", line 6, in &lt;module&gt; from pkg_resources import load_entry_point File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3049, in &lt;module&gt; @_call_aside File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3033, in _call_aside f(*args, **kwargs) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3062, in _initialize_master_working_set working_set = WorkingSet._build_master() File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 660, in _build_master return cls._build_from_requirements(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 673, in _build_from_requirements dists = ws.resolve(reqs, Environment()) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 858, in resolve raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The 'pip==9.0.3' distribution was not found and is required by the application whichコマンドにallオプションをつけてpipの場所を探します。 123ec2-user:~ $ which -a pip\\usr\\local\\bin\\pip\\usr\\bin\\pip pipのインストールディレクトリがおかしかったようです。 この場合、python -m pipという風に-mオプションをつければOKです。 12ec2-user:~ $ python -m pip -Vpip 19.3.1 from \\usr\\local\\lib\\python3.6\\site-packages\\pip (python 3.6) 改めてtweepyをインストール。 --userをつけてね、とエラーが出たので以下のコマンドでTweepyをインストールします。 12345678910111213141516171819202122ec2-user:~ $ python -m pip install tweepy --userCollecting tweepy Using cached https:\\\\files.pythonhosted.org\\packages\\36\\1b\\2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec\\tweepy-3.8.0-py2.py3-none-any.whlRequirement already satisfied: six&gt;=1.10.0 in \\usr\\local\\lib\\python3.6\\site-packages (from tweepy) (1.13.0)Collecting requests&gt;=2.11.1 Using cached https:\\\\files.pythonhosted.org\\packages\\51\\bd\\23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb\\requests-2.22.0-py2.py3-none-any.whlCollecting PySocks&gt;=1.5.7 Using cached https:\\\\files.pythonhosted.org\\packages\\8d\\59\\b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9\\PySocks-1.7.1-py3-none-any.whlCollecting requests-oauthlib&gt;=0.7.0 Using cached https:\\\\files.pythonhosted.org\\packages\\a3\\12\\b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379\\requests_oauthlib-1.3.0-py2.py3-none-any.whlCollecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 Using cached https:\\\\files.pythonhosted.org\\packages\\b4\\40\\a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539\\urllib3-1.25.7-py2.py3-none-any.whlCollecting idna&lt;2.9,&gt;=2.5 Using cached https:\\\\files.pythonhosted.org\\packages\\14\\2c\\cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9\\idna-2.8-py2.py3-none-any.whlCollecting certifi&gt;=2017.4.17 Using cached https:\\\\files.pythonhosted.org\\packages\\b9\\63\\df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99\\certifi-2019.11.28-py2.py3-none-any.whlCollecting chardet&lt;3.1.0,&gt;=3.0.2 Using cached https:\\\\files.pythonhosted.org\\packages\\bc\\a9\\01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\\chardet-3.0.4-py2.py3-none-any.whlCollecting oauthlib&gt;=3.0.0 Using cached https:\\\\files.pythonhosted.org\\packages\\05\\57\\ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704\\oauthlib-3.1.0-py2.py3-none-any.whlInstalling collected packages: urllib3, idna, certifi, chardet, requests, PySocks, oauthlib, requests-oauthlib, tweepySuccessfully installed PySocks-1.7.1 certifi-2019.11.28 chardet-3.0.4 idna-2.8 oauthlib-3.1.0 requests-2.22.0 requests-oauthlib-1.3.0 tweepy-3.8.0 urllib3-1.25.7 ちゃんとインストールされているか確認します。 インタプリタモードで確認します。 12345ec2-user:~ $ pythonPython 3.6.8 (default, Oct 14 2019, 21:22:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import tweepy Tweepyのversionも確認してみます。 12ec2-user:~ $ python -m pip list | grep tweepytweepy 3.8.0 Tweepyがインストールできていることが確認できました。 APIを活用したアプリケーション講座 Rubyでビットコインを自動で売買するプログラムを作成できるようになります。bitFlyerのAPIドキュメントをマスターし、１人で開発ができるようになります。こちらの講座もCloud9を活用しているので、複雑な環境構築などは不要です。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXJ0Y7e\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム 絶対に躓かないオンラインプログラミング講座「SkillHacks」もおすすめです。LINE@による無制限質問サポートで挫折しない仕組みができており、合計94本のしっかりした動画があります。他のプログラミングスクールよりも安くて手頃です。 -Skill Hacks- 動画で学ぶWebアプリ開発講座","link":"/twitter-api-tweepy-error/"},{"title":"【自然言語処理】Attentionとは何か","text":"✓目次 本記事の対象者 Attentionとは Self-Attention SourceTarget-Attention Multi-Head Attention Masked Multi-Head Attention まとめ 本記事の対象者 ・ ニューラルネットワークの基本的な仕組みを理解している方 ・ RNNやLSTM、Seq2Seqを活用した自然言語処理に関する知識（one-hot表現、分散処理など）を理解している人 ・ Transformerを理解していることが望ましいです。 RNNの基礎を学びたい方はこちら↓ Transformerの基礎を学びたい方はこちら↓ AttentionとはAttentionとは、一言でいうと文章中のどの単語に注目すればよいのかを表すスコアです。 Attentionは、Query, Key, Valueという３つの要素に分かれて計算されます。 Queryとは、Inputデータであり、入力データの中で検索したいものを表します。 Keyとは、検索すべき対象とQueryの近さを図るために使用します。どれだけ似ているかを図るために使用します。 Valueとは、Keyに基づいて適切なValueを出力する要素です。 少し複雑ですが、Attentionとは何かをより詳しく見てみます。以下の図に、Attentionの構造をまとめます。 黒線の四角はベクトルまたはテンソルを示し、青い四角は処理を表しています。 Inputというのは、入力である文章に相当します。 当然、自然言語で記述された文章ではなく、単語の分散表現で一定の次元に変換されたベクトルに変換されたものです。 これを埋め込みベクトルと言ったりします。 具体的には、「好き」、「な」、「アニメ」、「は」といった単語に分けられ、それぞれの単語にidが割り当てられています。 Memoryというのは、Inputデータに対する元データになります。具体的には、「ドラゴンボール」、「が」、「好き」といった具体のものです。これも、各単語はidで表されます。 まず、Inputが全結合層で処理を行い、各単語のQueryを作成します。 そして、Memoryを全結合層に入れてKeyを作成し、QueryとKeyで内積を取っています。 内積を取ることでQueryとKeyの類似度/関連度を計算するのです。結果として、InputとMemoryの各単語の関連度を計算することができます。 そしてこの関連度は、Softmax関数に入れられます。 Softmax関数は、Sigmoid関数を使用しており、主に確率を表現するために使われる関数です。 Softmax関数を適用すると、値の範囲を0から1に収めることができます。 そして、0から1の範囲に収められた関連度が、attention_weightになります。これは、Memoryのどの単語に注意を向けるかの重みをつけることになります。 QueryとKeyのベクトルが似ていれば、Attention_weightは大きくなりそうでなければ小さくなります。 このようにして、このニューラルネットワークは、学習していくことになります。 また、memoryから全結合層を介して、Valueが作られます。Valueは、Memoryの各単語を表す埋め込みベクトルです。 この埋め込みベクトルをAttention_weightとの間で内積を取っています。 具体的にこの例で述べると、「ドラゴンボール」というValueにアニメに対するAttention_weightである0.7を掛けた値と「が」というValueにアニメに対するAttention_weightである0.03を掛けた値と、「好き」というValueにアニメに対するAttention_weightである0.34を掛けた値を全部足し合わせた値になります。 こうすることで、もっとも関連度の高い「ドラゴンボール」という単語をそのものを出力するのではなく、他の単語との関係性も考慮することができるということになります。 そして全結合層に入れて、outputを得ることができます。 Attentionというのは奥が深く、実はここで説明したもの以外の他に様々なタイプのものが存在します。 以降は主に、Transformerに関わる以下の4つに着目して整理します。 Self-Attention SourceTarget-Attention Multi-Head Attention Masked Multi-Head Attention Self-Attention Self-Attentionは、InputとMemoryが同一のAttentionです。 Self-Attentionは、文法の構造だったり、単語同士の関係性を得るために使われます。 SourceTarget-Attention SourceTarget-Attentionは、InputとMemoryが異なるAttentionです。 Transformerにおいて、Encoderの出力とDecoder側の入力からの流れで合流する箇所があるのですが、そこでSourceTarget-Attentionが用いられています。 Multi-Head Attention Multi-Head Attentionは、Attentionを平行に並べたものです。図における「V」はValueで、「K」はKey, 「Q」はQuery, です。 Concatというのは、結合を意味します。 そして、Multi-Head Attentionにおいて、それぞれのAttentionはHeadと呼ばれています。 なぜこのようにAttentionを並列に並べるのかというと、性能が向上するからです。 機械学習では、アンサンブル学習という分野があります。これは複数の機械学習モデルを並列に並べて機能させることです。これにより、性能が向上することが知られています。 Masked Multi-Head Attention Masked Multi-Head Attentionは、特定のkeyに対して、Attention weightを0にする処理です。 Transformerでは、Decoderで、このMasked Multi-Head Attentionが用いられています。Transformerで、Masked Multi-Head Attentionが行われる理由は、入力した単語の先読みである「カンニング」を防ぐためです。 そのため、入力に予測すべき結果が入らないように、情報をMASKで遮断し、未知のデータに対して正しく予測することができなくなることを防いでいるのです。 まとめ Attentionとは何か Attentionとは、一言でいうと文章中のどの単語に注目すればよいのかを表すスコアです。 Query, Key, Valueという３つの要素に分かれて計算され Query: Queryとは、Inputデータ。入力データの中で検索したいものを表します。 Key: 検索すべき対象とQueryの近さを図るために使用します。 Value: Keyに基づいて適切なValueを出力する要素です。 Attentionには複数の種類があり用途も様々 Self-Attention: InputとMemoryが同一のAttention。文法の構造だったり、単語同士の関係性を得るために使われます。 SourceTarget-Attention: InputとMemoryが異なるAttention。Transformerにおいて、Encoderの出力とDecoder側の入力からの流れで合流点。 Multi-Head Attention: Attentionを平行に並べたものです。Attentionを並列に並べて性能を向上させる。 Masked Multi-Head Attention: 特定のkeyに対して、Attention weightを0にする処理。入力した単語の先読みである「カンニング」を防ぐ。 参考文献 - Attention is All You Need, Ashish. V. et al, (2017) - [技術ブログ \\| アクセルユニバース株式会社](https://www.acceluniverse.com/blog/developers/2019/08/attention.html) より詳しく学びたい方 以下の、Udemyのコースがおすすめです。セール時は、2000円で購入可能であり、30日間の返金保証もついているので、是非試してみてください。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sjLnnWy\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/nlp-bert/\",\"imu\":\"h\"+\"ttps://img-b.udemycdn.com/course/240x135/3624588_1489_3.jpg?secure=viVLT-O-tdr3EzVzv9Vxaw%3D%3D%2C1608537409\"}}); AIエンジニアを目指す方は、以下の無料カウンセリングを受けてみてはいかがでしょうか？ 無料カウンセリング予約はこちら","link":"/what-is-attention-1/"},{"title":"【テクニカルライティング】これだけ押さえれば大丈夫！わかりやすい文章の書き方","text":"皆さん、わかりやすい文章書けていますか？わかりやすい文章とは1秒で理解できる文章、または、ななめ読みでも理解できる文章です。本記事では、わかりやすい文章を書くためのポイントを紹介します。 目次 本記事の対象者 わかりやすい文を書く4つの方法 1. できるだけ主語と述語の揃った文を書く 2. 新しい用語や馴染みのない用語は、定義して用いる 3. できるだけ平易（わかりやすい）な言葉を使う 4. できるだけ文を短くする まとめ 本記事の対象者 理系の人で卒論やレポート、論文を書く人 ブログを書く人 良い日本語の文章を書くためのポイントを知りたい人 わかりやすい文を書く4つの方法 わかりやすい文の書き方 1. できるだけ主語と述語の揃った文を書く2. 新しい用語や馴染みのない用語は、定義して用いる3. できるだけ平易(わかりやすい)な言葉を使う4. できるだけ文は短くする わかりやずい文を記述するポイントは、上記の４つです。 ポイントの2, 3で、「できるだけ」と書いている理由は、文が長くなってしまう場合があるためです。 それぞれのポイントについて詳しく説明します。 1. できるだけ主語と述語の揃った文を書くわかりやすい文を書く上で大事なことを、主語と述語の揃った文を書くということです。 以下に、悪い例と良い例を記載します。 ・ (悪い例)購入予定の4Kモニターの大きさを、メジャーを用いて測定した。4Kモニターは、31.5インチだった。 ・ (良い例)購入予定の4Kモニターの大きさを、メジャーを用いて測定した。4Kモニターの大きさは、31.5インチだった。 「31.5インチ」という大きさを示す数値データの主語は、「4Kモニター」ではなく、「4Kモニターの大きさ」です。 細かいかもしれませんが、正確性という観点では重要なポイントになりますので注意しましょう。 そして、もう一つ重要なポイントがあります。 わかりやすい文を書くという観点では、主語を省くことはNGということです。 日本語は、主語が無い文を書くことができます。 しかし、主語を省こことにより、正確性に欠けてしまいます。 以下に例を見てみましょう。 ・ (悪い例)購入予定の4Kモニターのサイズを確認した。31.5インチだった。 ・ (良い例)購入予定の4Kモニターのサイズを確認した。それは、31.5インチだった。 わかりやすい文を書く際は、主語を省略せずに明記することを意識しましょう。 2. 新しい用語や馴染みのない用語は、定義して用いる文を作成する場合、想定される読み手が存在します。 その読み手が理解できない用語を用いる場合は、必ず定義して用いることが大事です。 ・ (悪い例)（「温室効果」を知らない読み手に対して）CO2の温室効果により、世界の気温は上昇した。 ・ (良い例)温室効果とは、物質が熱線を吸収して再放出することにより大気を暖める効果であり、CO2やCH4などがそれを持つ。CO2の温室効果により、世界の気温は上昇した。 3. できるだけ平易（わかりやすい）な言葉を使う不必要に難しい言葉を使うのは控えましょう。 文章の目的と読み手に合わせた言葉を使うのが大事です。 ・ (悪い例)地球温暖化の環境的影響と人類的危機への対応が、喫緊の課題である。 ・ (良い例)今なすべきことは、地球温暖化による環境への影響を調べ、人がどうすれば生存できるかを検討することである。 一方で、読み手が専門家を想定している場合、専門用語を使わなすぎると、筆者の専門性を疑われます。 学術論文によっては、必要に応じて専門用語を使うことを意識しましょう。 4. できるだけ文を短くする人間は文を読むとき、言葉を短期記憶に保存しながら読みます。 短期記憶は、脳の前頭葉のワーキングメモリに保存されます。 短期記憶の容量は、4つ程度とされています。 つまり、4つを超える言葉は保存できないという事になります。 具体的な例を見てみましょう。 ・ (悪い例)化学的・熱的に安定で、フッ素・塩素・炭素を含み、多様な構造を持ち、冷媒として用いられるフロンは、オゾン層を破壊する。 ・ (良い例)化学的・熱的に安定で、フッ素・塩素・炭素を含み、冷媒として用いられるフロンは、オゾン層を破壊する。 悪い例では、①「化学的・熱的に安定」、②「フッ素・塩素・炭素を含み」、③「多様な構造を持ち」、④「冷媒として用いられる」、という４つの文節が、「フロンは」を修飾しています。 人間の脳の短期記憶の観点ではギリギリセーフのレベルですが、ほとんどの人はすんなりと理解できません。 悪い例の修正案は以下です。 文を短くする方法 1. 関連性の低い言葉を削除する2. 別文とする 今回の例では、「1. 関連性の低い言葉を削除する」を採用しています。 まとめ本記事では、「【テクニカルライティング】これだけ押さえれば大丈夫！わかりやすい文章の書き方」というテーマでまとめました。 ポイントをおさらいします。 わかりやすい文の書き方 1. できるだけ主語と述語の揃った文を書く2. 新しい用語や馴染みのない用語は、定義して用いる3. できるだけ平易(わかりやすい)な言葉を使う4. できるだけ文は短くする 特に3, 4を意識すると良いと思います。 難解で複雑な文章を良しとする人もいますが、基本は読者ファーストな文を書くことが望ましいです。 わざわざ時間を割いて文章を作成したなら、多くの人に理解されるわかりやすい文章を作ったほうが良いかとおもいます。 おすすめの本 &gt;[Amazon]研究報告書のテクニカルライティング: 論理的でわかりやすい研究報告書の書き方 (実用) Kindle版 &gt;[Amazon]理系のための文章術入門: 作文の初歩から,レポート,論文,プレゼン資料の書き方まで","link":"/technical-writing/"},{"title":"【解説】手を動かしながらグループ分け、最大最小値の抽出方法を学ぶ | データサイエンス100本ノック【問23〜問26 回答】","text":"目次 この記事の対象者 本記事で学ぶpythonのメソッドと関数 第23問目: groupby()メソッド 第24問目: max関数 第25問目: min関数 第26問目: 総合問題 まとめ: pythonのgroupby, agg, reset_index, min関数, max関数の使い方を学びました この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonのgroupby, agg, reset_index, min, maxメソッドの使い方を知りたい人 本記事で学ぶpythonのメソッドと関数 本記事では以下のメソッドを学びます。 groupbyメソッド: データフレームの特定の列のユニークな値でグルーピングするメソッド。 aggメソッド: aggはgroupbyでグルーピングされた列に対して統計量を取るためのメソッドです。 reset_indexメソッド: reset_indexメソッドは、インデックスが存在しないデータフレームにインデックスを付与するメソッドです。 min関数: 最小の要素を抽出する関数。 max関数: 最大の要素を抽出する関数。 では早速データサイエンス100本ノックの問題を題材に、これらの使い方を学んでいきたいと思います。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第23問目: groupby()メソッド P-023: レシート明細データフレーム（df_receipt）に対し、店舗コード（store_cd）ごとに売上金額（amount）と売上数量（quantity）を合計せよ。 まずはdf_receiptというデータフレーム全体を確認します。 1df_receipt 出力1234567891011121314sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...104676 20180221 1519171200 S13043 1132 2 ZZ000000000000 P050101001 1 40104677 20190911 1568160000 S14047 1132 2 ZZ000000000000 P071006005 1 218104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 148104680 20190423 1555977600 S13016 1102 2 ZZ000000000000 P050601001 1 138104681 rows × 9 columns まずは、store_cdにおいて、ユニークな値でグルーピングをしてみます。 グルーピングをしたあと、ちゃんとグルーピングが出来ているかの確認をするために、グループ数がどの程度あるかを確認します。一旦以下のコードで、グループの数を確認します。 1len(df_receipt['store_cd'].unique()) unique()メソッドを忘れてしまった方は、以下の記事で復習をしましょう。 &gt;&gt;uniqueメソッドの使い方 出力152 52という数値が出力されました。 すなわちグループの数は52つであることが分かりました。 グループの数が確認できたので、早速groupby()メソッドを使ってstore_cdカラムのデータをグループ分けしたいと思います。 グループ分けしたいカラムは、store_cdなので、groupby()引数にstore_cdを指定してグルーピングしていきます。 最後にlen(df_group)のコードで、グルーピングの数を確認します。 12df_group = df_receipt.groupby('store_cd')len(df_group) 出力152 52という出力が得られました。先程uniqueメソッドで調べたグループの数と一致しているので、グルーピングがうまく出来ていることが確認できました。 続いて、各グループごとに売上金額(amount)と売上数量(quantity)の合計を算出していきます。 各グループごとに統計量を取る方法は、agg()というメソッドを使うことで実現できます。 12df_group_sum = df_group.agg({'amount': 'sum', 'quantity': 'sum'})df_group_sum 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 amount quantitystore_cd S12007 638761 2099S12013 787513 2425S12014 725167 2358S12029 794741 2555S12030 684402 2403S13001 811936 2347S13002 727821 2340S13003 764294 2197S13004 779373 2390S13005 629876 2004S13008 809288 2491S13009 808870 2486S13015 780873 2248S13016 793773 2432S13017 748221 2376S13018 790535 2562S13019 827833 2541S13020 796383 2383S13031 705968 2336S13032 790501 2491S13035 715869 2219S13037 693087 2344S13038 708884 2337S13039 611888 1981S13041 728266 2233S13043 587895 1881S13044 520764 1729S13051 107452 354S13052 100314 250S14006 712839 2284S14010 790361 2290S14011 805724 2434S14012 720600 2412S14021 699511 2231S14022 651328 2047S14023 727630 2258S14024 736323 2417S14025 755581 2394S14026 824537 2503S14027 714550 2303S14028 786145 2458S14033 725318 2282S14034 653681 2024S14036 203694 635S14040 701858 2233S14042 534689 1935S14045 458484 1398S14046 412646 1354S14047 338329 1041S14048 234276 769S14049 230808 788S14050 167090 580 一応これでstore_cd毎にamountとquantityの合計を得ることは出来ましたが、もともと各レコードに付いていたindex番号が失われていることが分かります。 各レコードにindex番号を割り当てるためには、reset_indexというメソッドを使用すればOKです。 1df_group_sum.reset_index().head() 出力1234567store_cd amount quantity0 S12007 638761 20991 S12013 787513 24252 S12014 725167 23583 S12029 794741 25554 S12030 684402 2403 これで完成です。 第24問目: max関数 P-024: レシート明細データフレーム（df_receipt）に対し、顧客ID（customer_id）ごとに最も新しい売上日（sales_ymd）を求め、10件表示せよ。 最も新しい売上日は、max関数を用いることで抽出できます。「最も新しい売上日」＝「yyyymmdd」の値が最も大きい値と読み替えることができるわけですね。 12df_max = df_receipt.groupby('customer_id').sales_ymd.max()df_max 出力12345678910111213customer_idCS001113000004 20190308CS001114000005 20190731CS001115000010 20190405CS001205000004 20190625CS001205000006 20190224 ... CS051513000004 20190719CS051515000002 20191025CS052212000002 20191017CS052514000001 20190822ZZ000000000000 20191031Name: sales_ymd, Length: 8307, dtype: int64 こちらもindexが失われているのでreset_index()メソッドでindex番号を付与していきたいと思います。 1df_max.reset_index().head(10) 出力1234567891011 customer_id sales_ymd0 CS001113000004 201903081 CS001114000005 201907312 CS001115000010 201904053 CS001205000004 201906254 CS001205000006 201902245 CS001211000025 201903226 CS001212000027 201701277 CS001212000031 201809068 CS001212000046 201708119 CS001212000070 20191018 これで完成です。 第25問目: min関数 P-025: レシート明細データフレーム（df_receipt）に対し、顧客ID（customer_id）ごとに最も古い売上日（sales_ymd）を求め、10件表示せよ。 この問題に関しては、第24問目で用いたmax関数を、minに変更すればOKです。 12df_min = df_receipt.groupby('customer_id').sales_ymd.min()df_min 出力12345678910111213customer_idCS001113000004 20190308CS001114000005 20180503CS001115000010 20171228CS001205000004 20170914CS001205000006 20180207 ... CS051513000004 20190719CS051515000002 20191025CS052212000002 20191017CS052514000001 20190822ZZ000000000000 20170101Name: sales_ymd, Length: 8307, dtype: int64 indexが失われているのでreset_index()メソッドでindex番号を付与していきたいと思います。 1df_min.reset_index().head(10) 出力1234567891011customer_id sales_ymd0 CS001113000004 201903081 CS001114000005 201805032 CS001115000010 201712283 CS001205000004 201709144 CS001205000006 201802075 CS001211000025 201903226 CS001212000027 201701277 CS001212000031 201809068 CS001212000046 201708119 CS001212000070 20191018 第26問目: 総合問題 P-026: レシート明細データフレーム（df_receipt）に対し、顧客ID（customer_id）ごとに最も新しい売上日（sales_ymd）と古い売上日を求め、両者が異なるデータを10件表示せよ。 まずは、問23のコードである、f_group_sum = df_group.agg({'amount': 'sum', 'quantity': 'sum'})を真似てコードを書いてみましょう。 1df_receipt.groupby('customer_id').agg({'sales_ymd':'max', 'sales_ymd':'min'}).reset_index() 出力12345678910111213 customer_id sales_ymd0 CS001113000004 201903081 CS001114000005 201805032 CS001115000010 201712283 CS001205000004 201709144 CS001205000006 20180207... ... ...8302 CS051513000004 201907198303 CS051515000002 201910258304 CS052212000002 201910178305 CS052514000001 201908228306 ZZ000000000000 201701018307 rows × 2 columns max列とmin列の２つが欲しかったのですが、minしか作成されませんでした。sales_ymdにおいて、max列とmin列の２つを設けたい場合は、以下のようにすればOKです。 12df_salesymd_maxmin = df_receipt.groupby('customer_id').agg({'sales_ymd':['max', 'min']}).reset_index()df_salesymd_maxmin 出力1234567891011121314 customer_id sales_ymd max min0 CS001113000004 20190308 201903081 CS001114000005 20190731 201805032 CS001115000010 20190405 201712283 CS001205000004 20190625 201709144 CS001205000006 20190224 20180207... ... ... ...8302 CS051513000004 20190719 201907198303 CS051515000002 20191025 201910258304 CS052212000002 20191017 201910178305 CS052514000001 20190822 201908228306 ZZ000000000000 20191031 201701018307 rows × 3 columns 出力をみると、sales_ymdの配下に、maxとminというカラム名が設定されています。 これを、sales_ymd_maxとsales_ymd_minという２つのカラム名に変更したいと思います。 まずは、このデータフレームからカラム名だけ抽出してみます。カラム名の抽出は、データフレームに対して.columnsを指定すればよかったですね。 第19問目でも使っているので、忘れてしまった方は復習しましょう。 &gt;&gt;第19問目の回答を確認する 1df_salesymd_maxmin.columns 出力1234MultiIndex([('customer_id', ''), ( 'sales_ymd', 'max'), ( 'sales_ymd', 'min')], ) マルチインデックスになっていることが分かります。 マルチインデックスを解除し、改めて各カラムに一意のカラム名を割り当てるために、for文とjoin関数を用いて、各インデックスを連結させたいと思います。 まずはdf_salesymd_maxmin.columnsをfor文で回して出力されるとどうなるのかを確認します。 12for pair in df_salesymd_maxmin.columns: print(pair) 出力123('customer_id', '')('sales_ymd', 'max')('sales_ymd', 'min') ここで出力された各タプルを解除し、文字列を連結させて新たな配列に組み込んでいきたいと思います。 その前にjoin関数について説明します。 join関数の引数には、結合させたい文字列をそのまま設定するわけではなく、結合させたい文字列が格納されたリストまたはタプルを指定します。 今回でいうと、for文で1つ1つ抽出される各タプルをjoin関数の引数として指定して連結させていきます。 連結する文字列は_を指定します。 12345df_tmp = []for pair in df_salesymd_maxmin.columns: column = &quot;_&quot;.join(pair) df_tmp.append(column)df_tmp 出力1['customer_id_', 'sales_ymd_max', 'sales_ymd_min'] 作成できた新たなカラム名のリストであるdf_tmpを、df_salesymd_maxmin.columnsに代入したいと思います。 12df_salesymd_maxmin.columns = df_tmpdf_salesymd_maxmin 出力12345678910111213 customer_id_ sales_ymd_max sales_ymd_min0 CS001113000004 20190308 201903081 CS001114000005 20190731 201805032 CS001115000010 20190405 201712283 CS001205000004 20190625 201709144 CS001205000006 20190224 20180207... ... ... ...8302 CS051513000004 20190719 201907198303 CS051515000002 20191025 201910258304 CS052212000002 20191017 201910178305 CS052514000001 20190822 201908228306 ZZ000000000000 20191031 201701018307 rows × 3 columns カラム名の修正が完了しました。 最後に、問題文に従って、最も新しい売上日であるsales_ymd_maxと古い売上日であるsales_ymd_minが異なるデータを10件表示します。これは以前取り組んだ.queryを使用します。 &gt;&gt;queryメソッドの使い方を復習する 1df_salesymd_maxmin.query('sales_ymd_max != sales_ymd_min').head(10) 出力1234567891011 customer_id_ sales_ymd_max sales_ymd_min1 CS001114000005 20190731 201805032 CS001115000010 20190405 201712283 CS001205000004 20190625 201709144 CS001205000006 20190224 2018020713 CS001214000009 20190902 2017030614 CS001214000017 20191006 2018082816 CS001214000048 20190929 2017110917 CS001214000052 20190617 2018020820 CS001215000005 20181021 2017020621 CS001215000040 20171022 20170214 これで完成です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: pythonのgroupby, agg, reset_index, min関数, max関数の使い方を学びました本記事は、「【Python】手を動かしながらグループ分け、最大最小値の抽出方法を学ぶ | データサイエンス100本ノック【問23〜問26 回答】」というテーマでまとめました。 最後の問題は、今まで取り組んできた内容の総復習の位置づけにもなって、良い問題だったかなとおもいます。 少しずつデータの扱いを学び、スキルを伸ばしていきましょう。 &gt;&gt; 続きはこちら","link":"/100knock-23-26/"},{"title":"【解説】手を動かしながらソートと表連結を学ぶ | データサイエンス100本ノック【問17〜問20 回答】","text":"目次 この記事の対象者 本記事で学ぶpythonのメソッド ソート 順位・ランク付け 表の連結 実際に手を動かしながら学んでみよう 第17問目: ソート（昇順） 第18問目: ソート(降順) 第19問目: 順位・ランク付け、表連結 第20問目: 順位・ランク付け、表連結 まとめ: Pythonでソート、表連結、順位・ランキング付けができるようになりました。 この記事の対象者 ・ ソートと表連結を手を動かしながら学びたい人 ・ データサイエンティストを目指している人 本記事で学ぶpythonのメソッド 本記事では以下3つのメソッドを学びます ソート 順位・ランク付け 表連結 以降それぞれの内容についてまとめていきます。 ソートソートとは、データを降順または昇順に並び替えることです。 pythonを用いてソートする場合は、sort_values()というメソッドを使用します。 使い方は以下のとおりです。 sort_values()の使い方1df.sort_values('カラム名', ascending=True) ascending=Trueにすると昇順、ascending=Falseにすると降順に並び替えられます。 順位・ランク付けソートした値に順位をつけたい場合は、rank()メソッドを使用します。 使い方の例は以下のとおりです。 rank()メソッドの使い方1df.rank(method='min', ascending=False) method='min'は、重複値を持つ場合の順位が、最小値の順位となります。 method='first'とすることで、値が重複してても出てきた順番にランク付けされます。 表の連結表の連結は以下のとおりです。 縦方向に連結 pandas.concat([DataFrameのリスト], axis=0) 横方向に連結 pandas.concat([DataFrameのリスト], axis=1) 実際に手を動かしながら学んでみよう ソート、順位・ランク付け、表の連結を実際に使ってみましょう。 以降は、一般社団法人データサイエンティスト協会がGitHubに公開している「データサイエンス100本ノック」の17問目〜20問目を題材にします。 データサイエンス100本ノックの環境構築方法は以下の記事にまとめていますので、こちらを参照してください。 第17問目: ソート（昇順） P-17: 顧客データフレーム（df_customer）を生年月日（birth_day）で高齢順にソートし、先頭10件を全項目表示せよ。 この問題を解くためにはソートを用います。 第17問目回答1df_customer.sort_values('birth_day', ascending=True).head(10) 出力123456789101112customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd18817 CS003813000014 村山 菜々美 1 女性 1928-11-26 90 182-0007 東京都調布市菊野台********** S13003 20160214 0-00000000-012328 CS026813000004 吉村 朝陽 1 女性 1928-12-14 90 251-0043 神奈川県藤沢市辻堂元町********** S14026 20150723 0-00000000-015682 CS018811000003 熊沢 美里 1 女性 1929-01-07 90 204-0004 東京都清瀬市野塩********** S13018 20150403 0-00000000-015302 CS027803000004 内村 拓郎 0 男性 1929-01-12 90 251-0031 神奈川県藤沢市鵠沼藤が谷********** S14027 20151227 0-00000000-01681 CS013801000003 天野 拓郎 0 男性 1929-01-15 90 274-0824 千葉県船橋市前原東********** S12013 20160120 0-00000000-07511 CS001814000022 鶴田 里穂 1 女性 1929-01-28 90 144-0045 東京都大田区南六郷********** S13001 20161012 A-20090415-72378 CS016815000002 山元 美紀 1 女性 1929-02-22 90 184-0005 東京都小金井市桜町********** S13016 20150629 C-20090923-C4680 CS009815000003 中田 里穂 1 女性 1929-04-08 89 154-0014 東京都世田谷区新町********** S13009 20150421 D-20091021-E16070 CS005813000015 金谷 恵梨香 1 女性 1929-04-09 89 165-0032 東京都中野区鷺宮********** S13005 20150506 0-00000000-06305 CS012813000013 宇野 南朋 1 女性 1929-04-09 89 231-0806 神奈川県横浜市中区本牧町********** S14012 20150712 0-00000000-0 第18問目: ソート(降順) P-18: 顧客データフレーム（df_customer）を生年月日（birth_day）で若い順にソートし、先頭10件を全項目表示せよ。 第18問目回答1df_customer.sort_values('birth_day', ascending=False).head(10) 出力123456789101112customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd15639 CS035114000004 大村 美里 1 女性 2007-11-25 11 156-0053 東京都世田谷区桜********** S13035 20150619 6-20091205-67468 CS022103000002 福山 はじめ 9 不明 2007-10-02 11 249-0006 神奈川県逗子市逗子********** S14022 20160909 0-00000000-010745 CS002113000009 柴田 真悠子 1 女性 2007-09-17 11 184-0014 東京都小金井市貫井南町********** S13002 20160304 0-00000000-019811 CS004115000014 松井 京子 1 女性 2007-08-09 11 165-0031 東京都中野区上鷺宮********** S13004 20161120 1-20081231-17039 CS002114000010 山内 遥 1 女性 2007-06-03 11 184-0015 東京都小金井市貫井北町********** S13002 20160920 6-20100510-13670 CS025115000002 小柳 夏希 1 女性 2007-04-18 11 245-0018 神奈川県横浜市泉区上飯田町********** S14025 20160116 D-20100913-D12493 CS002113000025 広末 まなみ 1 女性 2007-03-30 12 184-0015 東京都小金井市貫井北町********** S13002 20171030 0-00000000-015977 CS033112000003 長野 美紀 1 女性 2007-03-22 12 245-0051 神奈川県横浜市戸塚区名瀬町********** S14033 20150606 0-00000000-05716 CS007115000006 福岡 瞬 1 女性 2007-03-10 12 285-0845 千葉県佐倉市西志津********** S12007 20151118 F-20101016-F15097 CS014113000008 矢口 莉緒 1 女性 2007-03-05 12 260-0041 千葉県千葉市中央区東千葉********** S12014 20150622 3-20091108-6 第19問目: 順位・ランク付け、表連結 P-19: レシート明細データフレーム（df_receipt）に対し、1件あたりの売上金額（amount）が高い順にランクを付与し、先頭10件を抽出せよ。項目は顧客ID（customer_id）、売上金額（amount）、付与したランクを表示させること。なお、売上金額（amount）が等しい場合は同一順位を付与するものとする。 少し難しく感じるかと思いますが、順を追って欲しいデータを取得しましょう。 まずは、df_receiptというデータフレーム全体を確認しましょう。 1df_receipt 出力12345678910111213 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...104676 20180221 1519171200 S13043 1132 2 ZZ000000000000 P050101001 1 40104677 20190911 1568160000 S14047 1132 2 ZZ000000000000 P071006005 1 218104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 148104680 20190423 1555977600 S13016 1102 2 ZZ000000000000 P050601001 1 138104681 rows × 9 columns 次に、1件あたりの売上金額(amount)を高い順にランクを付与して取得してみましょう。 12df_tmp = df_receipt['amount'].rank(method='min', ascending=False)df_tmp 以下のような出力が得られるかと思います。 出力1234567891011120 55059.01 95294.02 51700.03 104339.04 89871.0 ... 104676 103127.0104677 38644.0104678 52588.0104679 57032.0104680 62707.0Name: amount, Length: 104681, dtype: float64 上記の出力結果において、右側の数字がランキングになります。 これを顧客ID（customer_id）、売上金額（amount）列を抽出した表に、横方向に連結させます。 横方向に連結させるためにはpandas.concat([DataFrameのリスト], axis=1)とすればよかったですね。 12df_merge = pd.concat([df_receipt[['customer_id','amount']], df_tmp], axis=1)df_merge 出力12345678910111213 customer_id amount amount0 CS006214000001 158 55059.01 CS008415000097 81 95294.02 CS028414000014 170 51700.03 ZZ000000000000 25 104339.04 CS025415000050 90 89871.0... ... ... ...104676 ZZ000000000000 40 103987.0104677 ZZ000000000000 218 39599.0104678 CS040513000195 168 53996.0104679 CS002513000049 148 61293.0104680 ZZ000000000000 138 66061.0104681 rows × 3 columns 上記の出力をみると、amountというカラムが2つ存在していますね。 一番右側のamount列はランキングなので、一番右側の列名をrankingに変更します。 12df_merge.columns = ['customer_id', 'amount', 'ranking']df_merge 出力12345678910111213 customer_id amount ranking0 CS006214000001 158 55059.01 CS008415000097 81 95294.02 CS028414000014 170 51700.03 ZZ000000000000 25 104339.04 CS025415000050 90 89871.0... ... ... ...104676 ZZ000000000000 40 103127.0104677 ZZ000000000000 218 38644.0104678 CS040513000195 168 52588.0104679 CS002513000049 148 57032.0104680 ZZ000000000000 138 62707.0104681 rows × 3 columns 一番右側の列名をrankingに変更することが出来ました。 最後にranking列の値を昇順にし、先頭の10件を表示させましょう。 1df_merge.sort_values('ranking', ascending=True).head(10) 出力1234567891011 customer_id amount ranking1202 CS011415000006 10925 1.062317 ZZ000000000000 6800 2.054095 CS028605000002 5780 3.04632 CS015515000034 5480 4.072747 ZZ000000000000 5480 4.010320 ZZ000000000000 5480 4.097294 CS021515000089 5440 7.028304 ZZ000000000000 5440 7.092246 CS009415000038 5280 9.068553 CS040415000200 5280 9.0 これで完了です。 第20問目: 順位・ランク付け、表連結 P-020: レシート明細データフレーム（df_receipt）に対し、1件あたりの売上金額（amount）が高い順にランクを付与し、先頭10件を抽出せよ。項目は顧客ID（customer_id）、売上金額（amount）、付与したランクを表示させること。なお、売上金額（amount）が等しい場合でも別順位を付与すること。 20問目は、19問目とほぼ同じ処理を行いますが、違いは重複値を持つ際のランキングの付け方です。 method = 'first'とすることで、重複値は値が同じでも出てきた順番にランク付けされます。 それでは解いていきます。 19問目と同じように、まずは1件あたりの売上金額(amount)を高い順にランクを付与して取得してみましょう。method='first'とすることを忘れずに。 12df_tmp = df_receipt['amount'].rank(method='first', ascending=False)df_tmp 出力1234567891011120 55059.01 95294.02 51700.03 104339.04 89871.0 ... 104676 103987.0104677 39599.0104678 53996.0104679 61293.0104680 66061.0Name: amount, Length: 104681, dtype: float64 同様に横方向に連結させます。 12df_merge = pd.concat([df_receipt[['customer_id','amount']], df_tmp], axis=1)df_merge 出力12345678910111213 customer_id amount amount0 CS006214000001 158 55059.01 CS008415000097 81 95294.02 CS028414000014 170 51700.03 ZZ000000000000 25 104339.04 CS025415000050 90 89871.0... ... ... ...104676 ZZ000000000000 40 103987.0104677 ZZ000000000000 218 39599.0104678 CS040513000195 168 53996.0104679 CS002513000049 148 61293.0104680 ZZ000000000000 138 66061.0104681 rows × 3 columns 19問目と同様に、一番右側の列名はランキングなので、amountという列名をrankingに変更します。 12df_merge.columns = ['customer_id', 'amount', 'ranking']df_merge 出力12345678910111213 customer_id amount ranking0 CS006214000001 158 55059.01 CS008415000097 81 95294.02 CS028414000014 170 51700.03 ZZ000000000000 25 104339.04 CS025415000050 90 89871.0... ... ... ...104676 ZZ000000000000 40 103987.0104677 ZZ000000000000 218 39599.0104678 CS040513000195 168 53996.0104679 CS002513000049 148 61293.0104680 ZZ000000000000 138 66061.0104681 rows × 3 columns 最後にranking列の値を昇順にし、先頭の10件を表示させましょう。 1df_merge.sort_values('ranking', ascending=True).head(10) 出力1234567891011 customer_id amount ranking1202 CS011415000006 10925 1.062317 ZZ000000000000 6800 2.054095 CS028605000002 5780 3.04632 CS015515000034 5480 4.010320 ZZ000000000000 5480 5.072747 ZZ000000000000 5480 6.028304 ZZ000000000000 5440 7.097294 CS021515000089 5440 8.0596 CS015515000083 5280 9.011275 CS017414000114 5280 10.0 これでOKです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: Pythonでソート、表連結、順位・ランキング付けができるようになりました。本記事は、【Python】手を動かしながらソートと表連結を学ぶ | データサイエンス100本ノック【問17〜問20 回答】というテーマでまとめました。 後半の問題は、少し難しかったかもしれませんね。 しかしながら、一つ一つの要素の分解しながら整理していけば、「全然無理」なんてことは無いと思います。 この辺は、様々な処理を実際に手を動かしながらこなしていくことで慣れていけば良いと思います。 &gt;&gt; 続きはこちらから","link":"/100knock-17-20/"},{"title":"【解説】内部結合の方法を学ぶ | データサイエンス100本ノック【問36〜問37 回答】","text":"目次 この記事の対象者 第36問目: 内部結合(共通カラムが1つ) 第37問目: 内部結合(共通カラムが複数) 2つのデータフレームにおける共通カラムの抽出方法 1. 各データフレームのカラムデータのみを抽出 2. 各カラムデータの重複値のみを抽出して出力する まとめ: 内部結合の方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで内部結合の設定方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、内部結合の方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方 第36問目: 内部結合(共通カラムが1つ) P-036: レシート明細データフレーム（df_receipt）と店舗データフレーム（df_store）を内部結合し、レシート明細データフレームの全項目と店舗データフレームの店舗名（store_name）を10件表示させよ。 表の「結合」といえばconcatを使えば良いのかな？ &gt;&gt;concatの復習をする 結論としては、concatではなくmergeを使います。 concatは、シンプルに２つの表を横方向または縦方向に連結させる関数です。 この問題は、「内部結合」という結合方式であり、concatのようなシンプルな連結ではありません。 内部結合とは、２つのデータフレームに共通するカラムが存在した場合、そのカラムの値を軸に結合する方式です。こういった結合を行う場合は、mergeという関数を使います。 &gt;&gt; 内部結合とは何かを詳しく学ぶ 実際に問題を解きながらmergeの使い方を学んでいきましょう。 まずは、問題で述べられているdf_receiptというデータフレームと、df_storeというデータフレームを出力し、共通するカラムの存在を確認しましょう。 まずは、df_receiptから出力します。 1df_receipt 出力123456 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 次に、df_storeを出力します。カラム名だけ把握できれば良いので、head()を付与します。 1df_store.head() 出力1234567store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area0 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.01 S13002 国分寺店 13 東京都 東京都国分寺市本多二丁目 トウキョウトコクブンジシホンダニチョウメ 042-123-4008 139.4802 35.70566 1735.02 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.04 S14036 相模原中央店 14 神奈川県 神奈川県相模原市中央二丁目 カナガワケンサガミハラシチュウオウニチョウメ 042-123-4045 139.3716 35.57327 1679.0 共通のカラムは、store_cdが目視で確認できます。 共通のカラムは、目視で確認しないといけないの？カラムがたくさん存在したら確認するの大変だよね？ 共通のカラムを機械的に抽出する方法もあります。その方法については本記事の後半でまとめたいと思います。 共通のカラムがstore_cdであることが分かったので、早速merge関数を用いて内部結合していきます。 回答であるコードを先に記述した上で、merge関数の使い方を解説します。 回答1pd.merge(df_receipt, df_store[['store_cd', 'store_name']], how='inner', on='store_cd').head(10) merge関数の第１引数と第２引数は、結合するデータフレームを指定します。 問題文よりdf_receiptに対してdf_storeを内部結合しdf_receiptの全項目とdf_storeの店舗名（store_name）を10件表示させたいので、第２引数には、df_storeから共通カラムであるstore_cdとstore_nameのみを抽出したデータフレームを結合する対象として指定します。 第３引数のhowは、結合方法を指定します。 howで指定できる結合方法は以下のとおりです。 inner: 内部結合 left: 左結合 right: 右結合 outer: 完全外部結合 今回は内部結合なので、how='inner'とします。 第4引数のonは、共通するカラム名を指定します。 結合する２つのデータフレームに共通するカラムは、store_cdなので、on='store_cd'とします。 回答のコードを実行すると以下のような出力が得られ、正常に内部結合がされていることが確認できます。 出力1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount store_name0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 158 葛が谷店1 20181116 1542326400 S14006 112 2 ZZ000000000000 P080401001 1 48 葛が谷店2 20170118 1484697600 S14006 1162 1 CS006815000006 P050406035 1 220 葛が谷店3 20190524 1558656000 S14006 1192 1 CS006514000034 P060104003 1 80 葛が谷店4 20190419 1555632000 S14006 112 2 ZZ000000000000 P060501002 1 148 葛が谷店5 20181119 1542585600 S14006 1152 2 ZZ000000000000 P050701001 1 88 葛が谷店6 20171211 1512950400 S14006 1132 2 CS006515000175 P090903001 1 80 葛が谷店7 20191021 1571616000 S14006 1112 2 CS006415000221 P040602001 1 405 葛が谷店8 20170710 1499644800 S14006 1132 2 CS006411000036 P090301051 1 330 葛が谷店9 20190805 1564963200 S14006 112 1 CS006211000012 P050104001 1 115 葛が谷店 第37問目: 内部結合(共通カラムが複数) P-037: 商品データフレーム（df_product）とカテゴリデータフレーム（df_category）を内部結合し、商品データフレームの全項目とカテゴリデータフレームの小区分名（category_small_name）を10件表示させよ。 この問題もmerge関数を用いて2つのデータフレームを内部結合します。 内部結合をするために、まずは２つのデータフレームにおいて共通する絡むを把握します。 ２つのデータフレームそれぞれを出力します。 まずは、df_productです。 1df_product 出力1234567891011121314product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.0... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.010026 P091503002 09 0915 091503 680.0 510.010027 P091503003 09 0915 091503 1080.0 810.010028 P091503004 09 0915 091503 1130.0 848.010029 P091503005 09 0915 091503 1280.0 960.010030 rows × 6 columns 続いて、df_categoryです。 1df_category 出力12345678910111213 category_major_cd category_major_name category_medium_cd category_medium_name category_small_cd category_small_name0 04 惣菜 0401 御飯類 040101 弁当類1 04 惣菜 0401 御飯類 040102 寿司類2 04 惣菜 0402 佃煮類 040201 魚介佃煮類3 04 惣菜 0402 佃煮類 040202 海草佃煮類4 04 惣菜 0402 佃煮類 040203 野菜佃煮類... ... ... ... ... ... ...223 09 洗剤 0914 ペットフード 091401 ペットフード224 09 洗剤 0914 ペットフード 091402 ペット用剤225 09 洗剤 0914 ペットフード 091403 ペット用具226 09 洗剤 0915 ＤＩＹ用品 091501 建築・塗装材料227 09 洗剤 0915 ＤＩＹ用品 091503 園芸用品228 rows × 6 columns さて、共通するカラムは何でしょうか？ 目視で共通するカラムを抽出するのは少し厳しいですよね。 ここからは共通するカラムをpythonを使って抽出する方法をまとめたいと思います。 2つのデータフレームにおける共通カラムの抽出方法 大まかな流れは以下です。 1. 各データフレームのカラムデータのみを抽出 2. 各カラムデータの重複値のみを抽出して出力する 1. 各データフレームのカラムデータのみを抽出 まずは、各データフレームのカラムデータのみを抽出します。 データフレームのカラムデータの抽出は、columnsメソッドを使うことで簡単に抽出できます。 まずはdf_productからカラムデータを抽出し、df_product_columnsという変数に代入します。 12df_product_columns = df_product.columnsdf_product_columns 出力123Index(['product_cd', 'category_major_cd', 'category_medium_cd', 'category_small_cd', 'unit_price', 'unit_cost'], dtype='object') では、もう一方のデータフレームであるdf_categoryについても同様に、カラムデータを抽出し、df_category_columnsという変数に代入します。 12df_category_columns = df_category.columnsdf_category_columns 出力123Index(['category_major_cd', 'category_major_name', 'category_medium_cd', 'category_medium_name', 'category_small_cd', 'category_small_name'], dtype='object') これで各データフレームのカラムデータのみの抽出が完了しました。 2. 各カラムデータの重複値のみを抽出して出力する 各カラムデータは配列として抽出されています。 2つの配列データから共通のデータを抽出するにはsetを使います。 12df_and = set(df_product_columns) &amp; set(df_category_columns)df_and 出力1{'category_major_cd', 'category_medium_cd', 'category_small_cd'} 各カラムデータの重複値が出力されました。 つまり、本問題で内部結合をする上で考慮が必要な共通するカラムデータは、category_major_cd, category_medium_cd, category_small_cdの3つであることが分かりました。 早速mergeメソッドを用いて、df_productに対して、df_categoryの共通カラム3つとcategory_small_cdを抽出したデータフレームを内部結合します。 123pd.merge(df_product , df_category[['category_major_cd', 'category_medium_cd','category_small_cd','category_small_name']] , how='inner', on=['category_major_cd', 'category_medium_cd','category_small_cd']).head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost category_small_name0 P040101001 04 0401 040101 198.0 149.0 弁当類1 P040101002 04 0401 040101 218.0 164.0 弁当類2 P040101003 04 0401 040101 230.0 173.0 弁当類3 P040101004 04 0401 040101 248.0 186.0 弁当類4 P040101005 04 0401 040101 268.0 201.0 弁当類5 P040101006 04 0401 040101 298.0 224.0 弁当類6 P040101007 04 0401 040101 338.0 254.0 弁当類7 P040101008 04 0401 040101 420.0 315.0 弁当類8 P040101009 04 0401 040101 498.0 374.0 弁当類9 P040101010 04 0401 040101 580.0 435.0 弁当類 これで完了です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 内部結合の方法を学びました。本記事は、【Python】内部結合の方法を学ぶ | データサイエンス100本ノック【問36〜問37 回答】というテーマでまとめました。 内部結合のポイントは、共通カラムを把握することです。 本記事では共通カラムを抽出する方法も合わせて紹介しました。 &gt;&gt; 続きはこちら","link":"/100knock-36-37/"},{"title":"【解説】縦横変換の方法を学ぶ | データサイエンス100本ノック【問43〜問44 回答】","text":"目次 この記事の対象者 第43問目: 縦並びのデータを横並びに変換 第44問目: 横並びのデータを縦並びに変換 まとめ: 縦から横、横から縦にデータの並びを変換する方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで縦横変換(pivot_table関数とstackメソッド)の方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、縦横変換の方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第43問目: 縦並びのデータを横並びに変換 P-043： レシート明細データフレーム（df_receipt）と顧客データフレーム（df_customer）を結合し、性別（gender）と年代（ageから計算）ごとに売上金額（amount）を合計した売上サマリデータフレーム（df_sales_summary）を作成せよ。性別は0が男性、1が女性、9が不明を表すものとする。 ただし、項目構成は年代、女性の売上金額、男性の売上金額、性別不明の売上金額の4項目とすること（縦に年代、横に性別のクロス集計）。また、年代は10歳ごとの階級とすること。 問題文で触れられているdf_receiptとdf_customerがどのようなデータフレームなのかを把握しましょう。 まずはdf_receiptから確認します。 1df_receipt.head(5) 出力1234567sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 続いて、df_customerです。 1df_customer.head(5) 出力123456 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 データフレームの結合で着目するのは「共通するカラムの確認」だったね！ 両者のデータフレームを見る限り、共通するカラムはcustomer_idであることがわかります。 これを踏まえ、df_receiptとdf_customerをcustomer_id列を基準に内部結合したいと思います。 &gt;&gt;【問36〜問37 回答】内部結合について復習する 内部結合したデータフレームはdf_tmpとします。 df_receiptとdf_customerをcustomer_id列を基準に内部結合12df_tmp = pd.merge(df_receipt, df_customer, how ='inner', on='customer_id')df_tmp.head(5) 出力1234567 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 158 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F1 20170509 1494288000 S14006 112 1 CS006214000001 P071401004 1 1100 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F2 20170608 1496880000 S14006 112 1 CS006214000001 P060104021 1 120 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F3 20170608 1496880000 S14006 112 2 CS006214000001 P080403001 1 175 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F4 20181028 1540684800 S14006 112 2 CS006214000001 P050102004 1 188 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 年代毎に売上金額を合計した値を表示する必要があるので、df_tmpに新しい列として年代era列を作成します。 年代は、age列の値を1/10倍し、floor関数で小数点を切り捨てたあとに10倍すれば、年代を算出することが出来ます。例えば22という値を、2.2にし、小数点を切り捨てて2.0にした後10倍すれば20になりますよね？つまり、22歳は20代であることを算出することができます。 この処理に関してはlambda式を用いて実施します。lambda式を忘れてしまった方は、以下のページで復習しましょう。 &gt;&gt;lambda式の復習をする era列を新設し年代を算出12df_tmp['era'] = df_tmp['age'].apply(lambda x: math.floor(x / 10) * 10)df_tmp 出力123456789101112 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd era0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 158 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 201 20170509 1494288000 S14006 112 1 CS006214000001 P071401004 1 1100 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 202 20170608 1496880000 S14006 112 1 CS006214000001 P060104021 1 120 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 203 20170608 1496880000 S14006 112 2 CS006214000001 P080403001 1 175 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 204 20181028 1540684800 S14006 112 2 CS006214000001 P050102004 1 188 志水 佳乃 1 女性 1996-12-08 22 224-0057 神奈川県横浜市都筑区川和町********** S14006 20150201 E-20100908-F 20... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...65677 20171202 1512172800 S13004 1152 1 CS004613000146 P071302002 1 308 玉木 恵麻 1 女性 1953-02-01 66 165-0032 東京都中野区鷺宮********** S13004 20160813 4-20081202-1 6065678 20180421 1524268800 S13002 1142 2 CS002314000037 P070703051 1 228 島崎 愛 1 女性 1979-01-07 40 185-0012 東京都国分寺市本町********** S13002 20151202 2-20090421-1 4065679 20180421 1524268800 S13002 1142 1 CS002314000037 P060702014 1 108 島崎 愛 1 女性 1979-01-07 40 185-0012 東京都国分寺市本町********** S13002 20151202 2-20090421-1 4065680 20190416 1555372800 S14040 1182 2 CS040311000022 P071401017 1 2200 五十嵐 南朋 1 女性 1986-08-11 32 194-0014 東京都町田市高ヶ坂********** S14040 20150419 B-20100416-4 3065681 20190416 1555372800 S14040 1182 1 CS040311000022 P071101020 1 980 五十嵐 南朋 1 女性 1986-08-11 32 194-0014 東京都町田市高ヶ坂********** S14040 20150419 B-20100416-4 30 このデータフレームから、最終的にどのようなデータフレームを出力したいかを改めて考えましょう。 問題文より、この問題で出力したいデータフレームは、カラムとしては「年代」と「性別」になります。 すなわち、era, male, female, unknownという4つのカラムが必要になります。 そして、eraカラムには、10代、20代、30代、、、と年代が連なり、各年代のレコードには、性別ごとの売上金額がまとめられているテーブルになるかと思います。例えば以下のような形です。 era male female unknown 0 10 1000 2000 4000 1 20 2000 3000 2000 2 30 3000 2000 5000 今まで学んできた手法を駆使すれば、答えとなるデータフレームを作れそう！ 確かに、これまで学んできた複数の手法を活用してもOKですが、pivot_table関数を使えば、たった1行のpythonコードで上記のデータフレームを作成することが出来ます。 pivot_table関数の使い方 pd.pivot_table(対象とするデータフレーム, index='インデックスとするカラム（縦方向のデータ）', columns='カラムとして設定する（横方向のデータ）', values='計算対象のカラム名', aggfunc='計算方法)という使い方になります。 少しわかりにくかと思うので、実際にこの問題を解きながら、pivot_table関数の使い方を学んでいきましょう。 12df_sales_summary = pd.pivot_table(df_tmp, index='era', columns='gender_cd', values='amount', aggfunc='sum').reset_index()df_sales_summary 出力12345678910gender_cd era 0 1 90 10 1591.0 149836.0 4317.01 20 72940.0 1363724.0 44328.02 30 177322.0 693047.0 50441.03 40 19355.0 9320791.0 483512.04 50 54320.0 6685192.0 342923.05 60 272469.0 987741.0 71418.06 70 13435.0 29764.0 2427.07 80 46360.0 262923.0 5111.08 90 NaN 6260.0 NaN 最後にカラム名を0, 1, 9ではなくmale, female, unknownに変換します。 12df_sales_summary.columns = ['era', 'male', 'female', 'unknown']df_sales_summary 出力12345678910 era male female unknown0 10 1591.0 149836.0 4317.01 20 72940.0 1363724.0 44328.02 30 177322.0 693047.0 50441.03 40 19355.0 9320791.0 483512.04 50 54320.0 6685192.0 342923.05 60 272469.0 987741.0 71418.06 70 13435.0 29764.0 2427.07 80 46360.0 262923.0 5111.08 90 NaN 6260.0 NaN これで完了です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"新装版 問題解決のためのデータ分析\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51J0JQh4qeL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07NHBSZ9W\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07NHBSZ9W\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%96%B0%E8%A3%85%E7%89%88%E3%80%80%E5%95%8F%E9%A1%8C%E8%A7%A3%E6%B1%BA%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%96%B0%E8%A3%85%E7%89%88%E3%80%80%E5%95%8F%E9%A1%8C%E8%A7%A3%E6%B1%BA%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"6sgcW\",\"s\":\"s\"}); リンク 第44問目: 横並びのデータを縦並びに変換 P-044： 前設問で作成した売上サマリデータフレーム（df_sales_summary）は性別の売上を横持ちさせたものであった。このデータフレームから性別を縦持ちさせ、年代、性別コード、売上金額の3項目に変換せよ。ただし、性別コードは男性を’00’、女性を’01’、不明を’99’とする。 まずは第43問目で作成したデータフレームであるdf_sales_summaryのera列をset_indexメソッドを用いて、indexに変換します。 &gt;&gt;set_indexメソッドの使い方 12df_sales_summary = df_sales_summary.set_index('era')df_sales_summary 出力1234567891011 male female unknownera 10 1591.0 149836.0 4317.020 72940.0 1363724.0 44328.030 177322.0 693047.0 50441.040 19355.0 9320791.0 483512.050 54320.0 6685192.0 342923.060 272469.0 987741.0 71418.070 13435.0 29764.0 2427.080 46360.0 262923.0 5111.090 NaN 6260.0 NaN 次にstackメソッドを使って、male, female, unknownカラムの各値を、各年代ごとに縦持ちにさせます。 &gt;&gt;stackメソッドの使い方 具体的には以下のような形式に変換します。 era 10 male 1000 female 2000 unknown 3000 20 male 123 female 456 unknown 789 以下のコードを実行します。 12df_sales_summary = df_sales_summary.stack().reset_index()df_sales_summary 出力1234567891011121314151617181920212223242526 era level_1 00 10 male 1591.01 10 female 149836.02 10 unknown 4317.03 20 male 72940.04 20 female 1363724.05 20 unknown 44328.06 30 male 177322.07 30 female 693047.08 30 unknown 50441.09 40 male 19355.010 40 female 9320791.011 40 unknown 483512.012 50 male 54320.013 50 female 6685192.014 50 unknown 342923.015 60 male 272469.016 60 female 987741.017 60 unknown 71418.018 70 male 13435.019 70 female 29764.020 70 unknown 2427.021 80 male 46360.022 80 female 262923.023 80 unknown 5111.024 90 female 6260.0 replaceメソッドでmaleを00, femaleを01, unknownを99に変更します。 12df_sales_summary = df_sales_summary.replace({'female': '01', 'male': '00', 'unknown': '99'})df_sales_summary 出力1234567891011121314151617181920212223242526 era level_1 00 10 00 1591.01 10 01 149836.02 10 99 4317.03 20 00 72940.04 20 01 1363724.05 20 99 44328.06 30 00 177322.07 30 01 693047.08 30 99 50441.09 40 00 19355.010 40 01 9320791.011 40 99 483512.012 50 00 54320.013 50 01 6685192.014 50 99 342923.015 60 00 272469.016 60 01 987741.017 60 99 71418.018 70 00 13435.019 70 01 29764.020 70 99 2427.021 80 00 46360.022 80 01 262923.023 80 99 5111.024 90 01 6260.0 最後にカラム名を適切にするためにrenameメソッドを用いてgender_cdとamountに変更します。 12df_sales_summary = df_sales_summary.rename(columns={'level_1':'gender_cd', 0: 'amount'})df_sales_summary 出力1234567891011121314151617181920212223242526 era gender_cd amount0 10 00 1591.01 10 01 149836.02 10 99 4317.03 20 00 72940.04 20 01 1363724.05 20 99 44328.06 30 00 177322.07 30 01 693047.08 30 99 50441.09 40 00 19355.010 40 01 9320791.011 40 99 483512.012 50 00 54320.013 50 01 6685192.014 50 99 342923.015 60 00 272469.016 60 01 987741.017 60 99 71418.018 70 00 13435.019 70 01 29764.020 70 99 2427.021 80 00 46360.022 80 01 262923.023 80 99 5111.024 90 01 6260.0 これで完成です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"gIjS7\",\"s\":\"s\"}); リンク まとめ: 縦から横、横から縦にデータの並びを変換する方法を学びました。 本記事は、「【Python】縦横変換の方法を学ぶ | データサイエンス100本ノック【問43〜問44 回答】」というテーマでまとめました。 本記事のポイント ・縦から横： pivot_table関数 ・横から縦： stuckメソッド なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-43-44/"},{"title":"【解説】日付データの変換方法を学ぶ | データサイエンス100本ノック【問45〜問48 回答】","text":"目次 この記事の対象者 第45問目: 日付型→YYYYMMDD形式(文字列型)に変換する方法 第46問目: YYYYMMDD形式(文字列型)→日付型に変換する方法 第47問目: YYYYMMDD形式(数値型)→日付型に変換する方法 別解: astypeメソッドを用いたパタン 第48問目: 数値型のUNIX秒データ→日付型に変換する方法 まとめ: 日付型のデータ変換の方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで日付データの型を変換する方法(to_datetime関数やastypeメソッド)を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、日付データの変換方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第45問目: 日付型→YYYYMMDD形式(文字列型)に変換する方法 P-045: 顧客データフレーム（df_customer）の生年月日（birth_day）は日付型（Date）でデータを保有している。これをYYYYMMDD形式の文字列に変換し、顧客ID（customer_id）とともに抽出せよ。データは10件を抽出すれば良い。 この問題は、日付型→YYYYMMDD形式に変換する問題です。 to_datetime関数を使って、df_customerのbirth_day列のデータを日付を表す特有のdatetime64型に変換します。 その後、dtメソッドを使うことで、列全体に一括処理することにし、strtimeでフォーマットを指定します。 まずは、df_customerデータの構造を確認します。 df_customerの構造を確認1df_customer.head(5) 出力123456customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 birth_dayカラムを抽出してdatetime64型に変換し、tmpに代入します。 birth_dayカラムを抽出12tmp = pd.to_datetime(df_customer['birth_day'])tmp 出力1234567891011120 1981-04-291 1952-04-012 1976-10-043 1933-03-274 1995-03-29 ... 21966 1959-10-1221967 1970-10-1921968 1972-12-1621969 1964-06-0521970 1996-08-16Name: birth_day, Length: 21971, dtype: datetime64[ns] 次に、YYYY-MM-DDとなっている日付データを、YYYYMMDD形式の文字列に変換します。 一括処理はdtメソッドを使用し、日付から文字列への変換はstrftimeメソッドを使用します。フォーマットは%Y%m%dとします。フォーマットについては、Pythonの公式ドキュメントを参照してください。 12tmp = tmp.dt.strftime('%Y%m%d')tmp 出力1234567891011120 198104291 195204012 197610043 193303274 19950329 ... 21966 1959101221967 1970101921968 1972121621969 1964060521970 19960816Name: birth_day, Length: 21971, dtype: object tmpデータフレームをcustomer_idとともに出力するために、concatを用いてデータフレームの結合を行います。 &gt;&gt; concatの使い方を復習する 1pd.concat([df_customer['customer_id'], tmp], axis = 1).head(10) 出力1234567891011customer_id birth_day0 CS021313000114 198104291 CS037613000071 195204012 CS031415000172 197610043 CS028811000001 193303274 CS001215000145 199503295 CS020401000016 197409156 CS015414000103 197708097 CS029403000008 197308178 CS015804000004 193105029 CS033513000180 19620711 第46問目: YYYYMMDD形式(文字列型)→日付型に変換する方法 P-046: 顧客データフレーム（df_customer）の申し込み日（application_date）はYYYYMMDD形式の文字列型でデータを保有している。これを日付型（dateやdatetime）に変換し、顧客ID（customer_id）とともに抽出せよ。データは10件を抽出すれば良い。 この問題は、第45問目の逆パタンだね！ まずは、df_customerの構造を確認しましょう。 df_customerの構造を確認1df_customer.head(5) 出力123456 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 application_date列の文字列データ型をdatetime64型に変換するには、to_datetime関数を使えばOKでした。 変換したデータフレームはtmpに格納しておきます。 application_date列をdatetime64型に変換12tmp = pd.to_datetime(df_customer['application_date'], format='%Y%m%d')tmp 出力1234567891011120 2015-09-051 2015-04-142 2015-05-293 2016-01-154 2017-06-05 ... 21966 2017-11-1021967 2015-03-1321968 2015-04-0621969 2016-02-0621970 2015-04-24Name: application_date, Length: 21971, dtype: datetime64[ns] これをcustomer_idとともに出力させるために、concatを用いて結合します。 &gt;&gt; concatの使い方を復習する customer_idをtmpと結合させて10件表示1pd.concat([df_customer['customer_id'], tmp], axis=1).head(10) 出力1234567891011 customer_id application_date0 CS021313000114 2015-09-051 CS037613000071 2015-04-142 CS031415000172 2015-05-293 CS028811000001 2016-01-154 CS001215000145 2017-06-055 CS020401000016 2015-02-256 CS015414000103 2015-07-227 CS029403000008 2015-05-158 CS015804000004 2015-06-079 CS033513000180 2015-07-28 第47問目: YYYYMMDD形式(数値型)→日付型に変換する方法 P-047: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）はYYYYMMDD形式の数値型でデータを保有している。これを日付型（dateやdatetime）に変換し、レシート番号(receipt_no)、レシートサブ番号（receipt_sub_no）とともに抽出せよ。データは10件を抽出すれば良い。 YYYYMMDDが文字型ではなく数値型になっている点が第46問目と異なる点ですが、基本的な処理はほぼ同じです。 まずは、df_receiptの全体像を確認します。 df_receiptの全体像を確認1df_receipt.head(5) 出力123456 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 前問と同様の方法でsales_ymdをto_datetime関数を用いて日付型に変換します。 12tmp = pd.to_datetime(df_receipt['sales_ymd'], format='%Y%m%d')tmp 出力1234567891011120 2018-11-031 2018-11-182 2017-07-123 2019-02-054 2018-08-21 ... 104676 2018-02-21104677 2019-09-11104678 2017-03-11104679 2017-03-31104680 2019-04-23Name: sales_ymd, Length: 104681, dtype: datetime64[ns] そしてconcatを用いて結合します。 1pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp], axis=1).head(10) 出力1234567891011 receipt_no receipt_sub_no sales_ymd0 112 1 2018-11-031 1132 2 2018-11-182 1102 1 2017-07-123 1132 1 2019-02-054 1102 2 2018-08-215 1112 1 2019-06-056 1102 2 2018-12-057 1102 1 2019-09-228 1112 2 2017-05-049 1102 1 2019-10-10 別解: astypeメソッドを用いたパタン別解としてastypeメソッドを用いた解放も紹介します。 &gt;&gt; astypeの詳しい使い方 astype('str')とすることで、数値型のデータをstring型に変更することが出来ます。 12tmp1 = pd.to_datetime(df_receipt['sales_ymd'].astype('str'))tmp1 出力1234567891011120 2018-11-031 2018-11-182 2017-07-123 2019-02-054 2018-08-21 ... 104676 2018-02-21104677 2019-09-11104678 2017-03-11104679 2017-03-31104680 2019-04-23Name: sales_ymd, Length: 104681, dtype: datetime64[ns] 抽出したtmp1とdf_receipt[['receipt_no', 'receipt_sub_no']]をconcatで結合します。 1pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp1], axis=1).head(10) 出力123456789101112receipt_no receipt_sub_no sales_ymd0 112 1 2018-11-031 1132 2 2018-11-182 1102 1 2017-07-123 1132 1 2019-02-054 1102 2 2018-08-215 1112 1 2019-06-056 1102 2 2018-12-057 1102 1 2019-09-228 1112 2 2017-05-049 1102 1 2019-10-10 第48問目: 数値型のUNIX秒データ→日付型に変換する方法 P-048: レシート明細データフレーム（df_receipt）の売上エポック秒（sales_epoch）は数値型のUNIX秒でデータを保有している。これを日付型（dateやdatetime）に変換し、レシート番号(receipt_no)、レシートサブ番号（receipt_sub_no）とともに抽出せよ。データは10件を抽出すれば良い。 UNIX秒とは、協定世界時（UTC）での1970年1月1日午前0時0分0秒からの秒数です。 処理としては問47問目とほぼ同じ処理になりますが、UNIX秒を日付型に変換する方法が異なります。 本問を解きながら、UNIX秒を日付型に変換する方法を学びましょう。 to_datetime関数を使用し、引数unitをunit = 's'とすることで日付型に変換できます。 12tmp = pd.to_datetime(df_receipt['sales_epoch'], unit='s')tmp 出力1234567891011120 2018-11-031 2018-11-182 2017-07-123 2019-02-054 2018-08-21 ... 104676 2018-02-21104677 2019-09-11104678 2017-03-11104679 2017-03-31104680 2019-04-23Name: sales_epoch, Length: 104681, dtype: datetime64[ns] あとは、これまで同様にconcatで結合すればOKです。 1pd.concat([df_receipt[['receipt_no', 'receipt_sub_no']], tmp], axis=1).head(10) 出力123456789101112receipt_no receipt_sub_no sales_epoch0 112 1 2018-11-031 1132 2 2018-11-182 1102 1 2017-07-123 1132 1 2019-02-054 1102 2 2018-08-215 1112 1 2019-06-056 1102 2 2018-12-057 1102 1 2019-09-228 1112 2 2017-05-049 1102 1 2019-10-10 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"gIjS7\",\"s\":\"s\"}); リンク まとめ: 日付型のデータ変換の方法を学びました。本記事は、「【Python】日付データの変換方法を学ぶ | データサイエンス100本ノック【問45〜問48 回答】」というテーマでまとめました。 本記事で紹介した方法を元に、日付型のデータの取り扱いを深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-45-48/"},{"title":"【解説】2値化の方法を学ぶ | データサイエンス100本ノック【問52〜問53 回答】","text":"目次 この記事の対象者 第52問目: サブクエリによるデータ抽出と2値化 第53問目: データ型変換(str→int)と2値化 まとめ: 2値化の方法を学びました この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで2値化の方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、2値化の方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第52問目: サブクエリによるデータ抽出と2値化 P-052: レシート明細データフレーム（df_receipt）の売上金額（amount）を顧客ID（customer_id）ごとに合計の上、売上金額合計に対して2000円以下を0、2000円超を1に2値化し、顧客ID、売上金額合計とともに10件表示せよ。ただし、顧客IDが”Z”から始まるのものは非会員を表すため、除外して計算すること。 流れとしては以下のように進めたいと思います。 顧客IDが”Z”から始まるもの以外を抽出する。 customer_idでグループ化し、各合計を算出する。 ２値化を行い、新たなカラムに追加。 10件表示する。 まずはZから始まるもの以外の顧客IDがを抽出します。この方法は第34問目でやりましたね。 &gt;&gt; queryメソッドでデータを抽出する方法を復習する Zから始まる顧客IDが以外のデータを抽出12df_sales_amount = df_receipt.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python')df_sales_amount 出力12345678910111213 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1704 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 138... ... ... ... ... ... ... ... ... ...104671 20180131 1517356800 S14010 1102 1 CS010414000008 P060103003 1 150104673 20181217 1545004800 S13004 1142 2 CS004515000066 P059001016 1 308104674 20190911 1568160000 S14046 1182 1 CS046415000017 P070703003 1 98104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 14865682 rows × 9 columns 合計値の出し方はsumメソッドを使うやり方と、aggメソッドを使いやり方２通りあります。 &gt;&gt; sumメソッドとaggメソッドの使い方を復習する 今回は、sumメソッドを使ったやり方で進めます。 customer_idでグループ化しsumメソッドで合計を算出123# customer_idでグループ化し、各合計を算出します。df_sales_amount = df_sales_amount[['customer_id', 'amount']].groupby('customer_id').sum().reset_index()df_sales_amount 出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8301 CS051212000001 3368302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 rows × 2 columns ２値化の処理を行います。 データフレームの列に対して何らかの関数を適用した処理をするメソッドとしてapplyメソッドがありました。 データ分析ではlambda式と併用して、df.apply(lambda 引数: 返り値)という形式で使いましたね。 忘れてしまった方は、以下で復習しましょう。 &gt;&gt; applyメソッドとlambda式を復習する 2値化処理12df_sales_amount['sales_flag'] = df_sales_amount['amount'].apply(lambda x: 1 if x &gt; 2000 else 0)df_sales_amount.head(10) 出力123456789101112customer_id amount sales_flag0 CS001113000004 1298 01 CS001114000005 626 02 CS001115000010 3044 13 CS001205000004 1988 04 CS001205000006 3337 15 CS001211000025 456 06 CS001212000027 448 07 CS001212000031 296 08 CS001212000046 228 09 CS001212000070 456 0 本問はこれで完了です。 第53問目: データ型変換(str→int)と2値化 P-053: 顧客データフレーム（df_customer）の郵便番号（postal_cd）に対し、東京（先頭3桁が100〜209のもの）を1、それ以外のものを0に２値化せよ。さらにレシート明細データフレーム（df_receipt）と結合し、全期間において買い物実績のある顧客数を、作成した2値ごとにカウントせよ。 まずはdf_customerの構造を確認します。 df_customerの構造を確認1df_customer.head(20) 出力123456789101112131415161718192021 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-510 CS007403000016 依田 満 0 男性 1975-08-18 43 276-0022 千葉県八千代市上高野********** S12007 20150914 0-00000000-011 CS035614000014 板倉 菜々美 1 女性 1954-07-16 64 154-0015 東京都世田谷区桜新町********** S13035 20150804 0-00000000-012 CS011215000048 芦田 沙耶 1 女性 1992-02-01 27 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150228 C-20100421-913 CS009413000079 市川 コウ 1 女性 1975-12-28 43 158-0093 東京都世田谷区上野毛********** S13009 20151209 0-00000000-014 CS040412000191 川井 郁恵 1 女性 1977-01-05 42 226-0021 神奈川県横浜市緑区北八朔町********** S14040 20151101 1-20091025-415 CS029415000023 梅田 里穂 1 女性 1976-01-17 43 279-0043 千葉県浦安市富士見********** S12029 20150610 D-20100918-E16 CS009315000023 皆川 文世 1 女性 1980-04-15 38 154-0012 東京都世田谷区駒沢********** S13009 20150319 5-20080322-117 CS040702000012 根本 六郎 0 男性 1939-07-02 79 226-0018 神奈川県横浜市緑区長津田みなみ台********** S14040 20150112 0-00000000-018 CS046615000013 河野 花 1 女性 1953-04-06 65 224-0026 神奈川県横浜市都筑区南山田町********** S14046 20181207 0-00000000-019 CS025412000147 堀口 陽子 1 女性 1974-10-22 44 242-0015 神奈川県大和市下和田********** S14025 20150417 0-00000000-0 そしてレシート明細データフレーム（df_receipt）も確認しましょう。 df_receiptの構造を確認1df_receipt.head(5) 出力1234567sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 顧客データフレームの郵便番号に対して2値化した後、顧客数をカウントすることを踏まえ、customer_idカラムとpostal_cdカラムを抽出します。 customer_idカラムとpostal_cdカラムを抽出12df_tmp = df_customer[['customer_id', 'postal_cd']]df_tmp 出力1234567891011121314customer_id postal_cd0 CS021313000114 259-11131 CS037613000071 136-00762 CS031415000172 151-00533 CS028811000001 245-00164 CS001215000145 144-0055... ... ...21966 CS002512000474 185-003421967 CS029414000065 279-004321968 CS012403000043 231-082521969 CS033512000184 245-001621970 CS009213000022 154-001221971 rows × 2 columns ここで、新たなカラムとしてpostal_flgというものを用意します。その上で、postal_cdの先頭3桁が100〜209となっているものは1とし、それ以外のものは0とする処理を施そうと思います。 ``postal_cd``の先頭3桁が100〜209となっているものは1とし、それ以外のものは0とする処理ってどうやるの？ このように悩んだときは、具体的なデータを使って実験してみると良いです。 ここでは擬似的なpostal_cdとして&quot;123-4567&quot;というのを用いて実験してみます。 &quot;123-4567&quot;という文字列から先頭の3桁を抽出するにはどうすればよいか考えましょう。 これは結構シンプルで、pythonのスライスを使えば抽出できます。 1&quot;123-4567&quot;[0:3] 出力1'123' しかし、このままでは、100〜209の範囲なのかどうかの判定はできません。 その理由は、”123”がint型ではなくstr型になっているからです。 1type(&quot;123-4567&quot;[0:3]) 出力1str なのでこのデータをint型に変換する必要があります。 int型への変換は以下のようにすればOKです。 1int(&quot;123-4567&quot;[0:3]) 出力1123 ここまでの実験結果を踏まえて、applyメソッドを用いて以下のようなコードを書けば、postal_cdの先頭3桁が100〜209なのか、そうではないのかが判定できることが理解できると思います。 1df_tmp['postal_cd'].apply(lambda x: 1 if 100 &lt;= int(x[0:3]) &lt;= 209 else 0) 出力1234567891011120 01 12 13 04 1 ..21966 121967 021968 021969 021970 1Name: postal_cd, Length: 21971, dtype: int64 この結果については、のちのちdf_receiptと結合することになるので、postal_flgという新たなカラムに格納します。 12df_tmp['postal_flg'] = df_tmp['postal_cd'].apply(lambda x: 1 if 100 &lt;= int(x[0:3]) &lt;= 209 else 0)df_tmp 出力12345678910111213141516171819&lt;ipython-input-49-61507ef2b9a0&gt;:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy df_tmp['postal_flg'] = df_tmp['postal_cd'].apply(lambda x: 1 if 100 &lt;= int(x[0:3]) &lt;= 209 else 0)customer_id postal_cd postal_flg0 CS021313000114 259-1113 01 CS037613000071 136-0076 12 CS031415000172 151-0053 13 CS028811000001 245-0016 04 CS001215000145 144-0055 1... ... ... ...21966 CS002512000474 185-0034 121967 CS029414000065 279-0043 021968 CS012403000043 231-0825 021969 CS033512000184 245-0016 021970 CS009213000022 154-0012 121971 rows × 3 columns おっと、なにやらwarningが出てきました。 warningの内容123&lt;ipython-input-49-61507ef2b9a0&gt;:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value instead warningの内容は、 warningの内容の日本語訳12DataFrameのスライスのコピーに値を設定しようとしています。.loc[row_indexer,col_indexer] = valueを使用してください。 というわけで.locを使用してみます。 .locを適用12df_tmp.loc['postal_flg'] = df_tmp['postal_cd'].apply(lambda x: 1 if 100 &lt;= int(x[0:3]) &lt;= 209 else 0)df_tmp 出力123456789101112131415161718/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrameSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy iloc._setitem_with_indexer(indexer, value, self.name)customer_id postal_cd0 CS021313000114 259-11131 CS037613000071 136-00762 CS031415000172 151-00533 CS028811000001 245-00164 CS001215000145 144-0055... ... ...21967 CS029414000065 279-004321968 CS012403000043 231-082521969 CS033512000184 245-001621970 CS009213000022 154-0012postal_flg NaN NaN21972 rows × 2 columns .locを用いてもだめでした。 こういうときはググりましょう。 すると以下の記事が見つかります。 https://qiita.com/HEM_SP/items/56cd62a1c000d342bd70 どうやら.copyを用いてdf_tmpを最初にセットしなければいけなかったようです。改めて以下のコードを実施することで。warningが発生しないことが確認されました。 最初に.copyを用いて明示的にdf_customerのコピーであることを宣言123df_tmp = df_customer[['customer_id', 'postal_cd']].copy()df_tmp['postal_flg'] = df_tmp['postal_cd'].apply(lambda x: 1 if 100 &lt;= int(x[0:3]) &lt;= 209 else 0)df_tmp 出力12345678910111213 customer_id postal_cd postal_flg0 CS021313000114 259-1113 01 CS037613000071 136-0076 12 CS031415000172 151-0053 13 CS028811000001 245-0016 04 CS001215000145 144-0055 1... ... ... ...21966 CS002512000474 185-0034 121967 CS029414000065 279-0043 021968 CS012403000043 231-0825 021969 CS033512000184 245-0016 021970 CS009213000022 154-0012 121971 rows × 3 columns 次にdf_tmpとdf_receiptを結合します。 両者のデータフレームには共通するカラムとしてcustomer_idが存在するので、merge関数を用いて内部結合を行います。 mergeを用いて内部結合12df_merge = pd.merge(df_tmp, df_receipt, how='inner', on='customer_id')df_merge 出力12345678910111213 customer_id postal_cd postal_flg sales_ymd sales_epoch store_cd receipt_no receipt_sub_no product_cd quantity amount0 CS031415000172 151-0053 1 20170507 1494115200 S13031 1102 1 P060103001 1 1001 CS031415000172 151-0053 1 20171026 1508976000 S13031 1182 1 P090203004 1 3202 CS031415000172 151-0053 1 20190325 1553472000 S13031 1192 1 P071401025 1 24003 CS031415000172 151-0053 1 20170111 1484092800 S13031 1132 2 P071203007 1 4484 CS031415000172 151-0053 1 20190325 1553472000 S13031 1192 2 P070805011 1 258... ... ... ... ... ... ... ... ... ... ... ...65677 CS029414000065 279-0043 0 20191028 1572220800 S12029 1182 1 P060102002 1 8865678 CS029414000065 279-0043 0 20190806 1565049600 S12029 1132 2 P060101007 1 18065679 CS029414000065 279-0043 0 20180611 1528675200 S12029 1162 2 P090204049 1 39065680 CS029414000065 279-0043 0 20180305 1520208000 S12029 1132 2 P050602001 1 8865681 CS029414000065 279-0043 0 20170306 1488758400 S12029 1112 2 P071401020 1 220065682 rows × 11 columns また全期間において買い物実績のある顧客数を作成した2値ごとにカウントする必要があります。 まずはgroupbyメソッドを用いてpostal_flgでグルーピングし、customer_idの数を集計します。 集計方法はaggメソッドを使う方法と、nuniqueメソッドを使う方法がありますので両方紹介します。 パタン1:nunique()のパタン1df_merge.groupby('postal_flg')['customer_id'].nunique() 出力1234postal_flg0 39061 4400Name: customer_id, dtype: int64 パタン2:aggメソッドのパタン1df_merge.groupby('postal_flg').agg({'customer_id':'nunique'}) 出力1234 customer_idpostal_flg 0 39061 4400 まとめ: 2値化の方法を学びました本記事は、「【Python】2値化の方法を学ぶ | データサイエンス100本ノック【問52〜問53 回答】」というテーマでまとめました。 今回は、過去に学んだ事項の復習にもなったかと思います。 本記事で紹介した方法を元に、データサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-52-53/"},{"title":"【解説】データサイエンス100本ノック【問79〜83 回答】","text":"目次 第79〜83問目を解くために必要な基礎知識 欠損の確認方法 欠損レコードの削除方法 欠損の補完方法 平均値で補完する方法 中央値で補完する方法 （応用）applyを用いた細かい数値処理と補完 第80問目: 欠損レコードの削除 第81問目: 数値補完(平均値) 第82問目:数値補完(中央値) 第83問目: 数値補完(カテゴリごとの中央値) まとめ:データサイエンス100本ノック【問79〜83 回答】で欠陥値の扱いを学びました データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第79〜83問目を解くために必要な基礎知識問題を解く前に欠損値が存在する場合の補完方法に関する基礎をまとめておきます。 データフレームの中に欠損値が含まれるかもしれないとき、「確認」と「補完」または「削除」を行います。 「補完」には、様々な補完方法が存在します。 例えば、「平均値で補完」だったり「中央値で補完」といったものがあります。 繰り返しになりますが、問題を解いていく前に代表的な手法を簡単なデータフレームを用いて紹介したいと思います。 以下のような欠損値を含むデータフレームを用いて解説します。 123456import pandas as pdimport numpy as npcolumns = ['product', 'price']data = [['apple', np.nan], ['banana', 200], ['peach', 120], ['tomato', np.nan], [np.nan, 700]]df = pd.DataFrame(data, columns=columns)df 出力123456 product price0 apple NaN1 banana 200.02 peach 120.03 tomato NaN4 NaN 700.0 欠損の確認方法DataFrame, Seriesにおいて、各要素に対して欠損値を確認するには、isnullメソッドを使用します。 1df.isnull() 出力1234567product price0 False True1 False False2 False False3 False True4 True False 上記出力のように、欠損値が存在する箇所がTrueとなります。 欠損レコードの削除方法欠損がある行や列を全部削除する場合は、dropnaメソッドを使用します。 1df.dropna() 出力123 product price1 banana 200.02 peach 120.0 上記の出力の用にprice列において欠損があった行は、まるごと削除されていることがわかります。 これを、リストワイズ削除といいます。 欠損の補完方法続いて補完の方法です。 欠損値にデータを補完する際はfillnaメソッドと主に使用します。 fillnaメソッドは、辞書型で引数を指定することで、カラムごとにデータを補完することができます。 ここでは「平均値」、「中央値」で補完する方法を紹介します。 平均値で補完する方法欠損値が含まれている箇所を平均値で補完するには、numpy.nanmean関数を使用します。 ここでは、fillnaメソッドを用いてproductカラムにはmelon、priceには今のprice列に存在する価格である200, 120, 700の平均値を補完したいと思います 1df.fillna({'product':'melon', 'price':np.nanmean(df['price'])}) 出力1234567product price0 apple 340.01 banana 200.02 peach 120.03 tomato 340.04 melon 700.0 上記のように、productにはmelon、そしてpriceには200, 120, 700の平均値である340が補完されています。 中央値で補完する方法欠損値が含まれている箇所を中央値で補完するには、numpy.nanmedian関数を使用します。 こちらも同様にfillnaメソッドを用いてproductカラムにはmelon, priceには今のprice列に存在する価格である200, 120, 700の中央値を補完したいと思います 1df 出力123456 product price0 apple NaN1 banana 200.02 peach 120.03 tomato NaN4 NaN 700.0 1df.fillna({'product':'melon', 'price':np.nanmedian(df['price'])}) 出力123456 product price0 apple 200.01 banana 200.02 peach 120.03 tomato 200.04 melon 700.0 上記のように、productにはmelon、そしてpriceには200, 120, 700の中央値である200が補完されています。 （応用）applyを用いた細かい数値処理と補完本データフレームにおいて、たとえば欠損値であれば中央値を代入し、それ以外は30%値上げさせる処理をしたい場合を考えましょう。 やり方としては、applyメソッドとnumpy.isnan関数をを活用することで補完が可能です。 12345df_tmp = df.fillna({'product':'melon'})df_tmp['price'] = df_tmp['price'].apply(lambda x : np.nanmedian(df['price']) if np.isnan(x) else x*1.3)df_tmp 出力123456 product price0 apple 200.01 banana 260.02 peach 156.03 tomato 200.04 melon 910.0 上記のように、productにはmelonが補完されています。その上でpriceカラムの欠損値には中央値、既に価格が設定されていた値段は3割増しになっています。 欠損値の確認と補完方法の基礎については以上です。 ここまでの知識をもとに問題を解いていきましょう。 第79問目: 欠損列状況の確認 P-079: 商品データフレーム（df_product）の各項目に対し、欠損数を確認せよ。 DataFrame, Seriesでは、各要素に対して欠損値を確認するためには、isnullメソッドを使用します。 実際に本問を解きながら使い方を確認しましょう。 1df_product.isnull().sum() 出力1234567product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 7unit_cost 7dtype: int64 このように、欠損値を確認するためにはisnullメソッドを使用します。 その上で、各カラムに対して、合計を出す場合sumメソッドを使用することで、欠損値の判定とともに各項目ごとの数を出力できます。 第80問目: 欠損レコードの削除 P-080: 商品データフレーム（df_product）のいずれかの項目に欠損が発生しているレコードを全て削除した新たなdf_product_1を作成せよ。なお、削除前後の件数を表示させ、前設問で確認した件数だけ減少していることも確認すること。 データ欠損のある行や列を全て削除することを、「リストワイズ削除」といいます。 dropnaメソッドを用いることでNaNを含む全ての行を全て取り除けます。 本問を解きながらdropnaメソッドの使い方を学びましょう。 まずは、削除前の件数を出力します。 12df_product_1 = df_product.copy()print(&quot;削除前：&quot;, len(df_product_1)) 1削除前： 10030 欠損値を削除しデータの件数を出力します。 12df_product_1.dropna(inplace=True)print('削除語：', len(df_product_1)) 出力1削除語： 10023 削除前が10030であるのに対して削除後は10023と件数が減少していることが確認できました。 第81問目: 数値補完(平均値) P-081: 単価（unit_price）と原価（unit_cost）の欠損値について、それぞれの平均値で補完した新たなdf_product_2を作成せよ。なお、平均値について1円未満は四捨五入とし、0.5については偶数寄せでかまわない。補完実施後、各項目について欠損が生じていないことも確認すること。 欠損値NaNにデータを保管するにはfillnaメソッドを使用します。 引数は辞書型で指定し、カラムごとに代替データを変更することも可能です。 問題を解きながら使い方を学んでいきましょう。 早速平均値で欠損値を補完します。 なお、欠損値が含まれている状態で平均値を求める場合は、numpy.nenmean関数を使用します。 参考: https://note.nkmk.me/python-numpy-nansum/ 四捨五入はnumpy.round関数で行います。SeriesデータにNaNが存在する場合、通常のround関数を用いるとエラーになるので注意しましょう。 参考: https://omathin.com/100knock-66-68/ 1df_product.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.05 P040101006 04 0401 040101 298.0 224.06 P040101007 04 0401 040101 338.0 254.07 P040101008 04 0401 040101 420.0 315.08 P040101009 04 0401 040101 498.0 374.09 P040101010 04 0401 040101 580.0 435.0 12df_product_2 = df_product.fillna({'unit_price':np.round(np.nanmean(df_product['unit_price'])), 'unit_cost':np.round(np.nanmean(df_product['unit_cost']))})df_product_2.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.05 P040101006 04 0401 040101 298.0 224.06 P040101007 04 0401 040101 338.0 254.07 P040101008 04 0401 040101 420.0 315.08 P040101009 04 0401 040101 498.0 374.09 P040101010 04 0401 040101 580.0 435.0 各項目について欠損が生じていないことを確認します。 1df_product_2.isnull().sum() 出力1234567product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 0unit_cost 0dtype: int64 欠損値が存在していないのでOKです。 第82問目:数値補完(中央値) P-082: 単価（unit_price）と原価（unit_cost）の欠損値について、それぞれの中央値で補完した新たなdf_product_3を作成せよ。なお、中央値について1円未満は四捨五入とし、0.5については偶数寄せでかまわない。補完実施後、各項目について欠損が生じていないことも確認すること。 この問題も同様に、欠損値の補完なのでfillnaメソッドを使用します。 今回の問題では中央値を使用します。 データに欠損値が含まれた状態で中央値を求める場合は、numpy.nanmedian関数を使用します。 中央値で欠損値を補完します。 12df_product_3 = df_product.fillna({'unit_price': np.round(np.nanmedian(df_product['unit_price'])), 'unit_cost': np.round(np.nanmedian(df_product['unit_cost']))})df_product_3.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.05 P040101006 04 0401 040101 298.0 224.06 P040101007 04 0401 040101 338.0 254.07 P040101008 04 0401 040101 420.0 315.08 P040101009 04 0401 040101 498.0 374.09 P040101010 04 0401 040101 580.0 435.0 補完が完了したので、各項目について欠損が生じていないことを確認します。 1df_product_3.isnull().sum() 出力1234567product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 0unit_cost 0dtype: int64 欠損値が存在していないことが確認できたのでOKです。 第83問目: 数値補完(カテゴリごとの中央値) P-083: 単価（unit_price）と原価（unit_cost）の欠損値について、各商品の小区分（category_small_cd）ごとに算出した中央値で補完した新たなdf_product_4を作成せよ。なお、中央値について1円未満は四捨五入とし、0.5については偶数寄せでかまわない。補完実施後、各項目について欠損が生じていないことも確認すること。 まずは、df_productの構造を確認します。 1df_product.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.05 P040101006 04 0401 040101 298.0 224.06 P040101007 04 0401 040101 338.0 254.07 P040101008 04 0401 040101 420.0 315.08 P040101009 04 0401 040101 498.0 374.09 P040101010 04 0401 040101 580.0 435.0 欠損値の有無を確認します。 1df_product.isnull().sum() 出力1234567product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 7unit_cost 7dtype: int64 unit_priceとunit_costに欠損があることがわかりました。 まずは問題文の通り各商品の小区分(category_cd)ごとにunit_priceとunit_costの中央値を算出した磯思います。 12df_tmp = df_product.groupby('category_small_cd').agg({'unit_price':'median', 'unit_cost':'median'}).reset_index()df_tmp.head(10) 出力1234567891011 category_small_cd unit_price unit_cost0 040101 283.0 212.51 040102 378.0 284.02 040201 223.0 167.53 040202 178.0 134.04 040203 308.0 231.05 040204 198.0 149.06 040301 278.0 209.07 040401 288.0 216.58 040402 228.0 171.09 040403 248.0 186.0 各商品の小区分ごとにunit_priceとunit_costの中央値を算出することができました。 カラム名ががunit_price, unit_costとなっていますが、これでは各商品の小区分ごとの中央値であることが分か理にくいので、カラム名を変更します。 12df_tmp.columns = ['category_small_cd', 'median_price', 'median_cost']df_tmp.head(10) 出力1234567891011 category_small_cd median_price median_cost0 040101 283.0 212.51 040102 378.0 284.02 040201 223.0 167.53 040202 178.0 134.04 040203 308.0 231.05 040204 198.0 149.06 040301 278.0 209.07 040401 288.0 216.58 040402 228.0 171.09 040403 248.0 186.0 それではdf_productとdf_tmpを内部結合していきます。 内部結合はmergeメソッドで可能です。 12df_product_4 = pd.merge(df_product, df_tmp, how='inner', on='category_small_cd')df_product_4.head(10) 出力1234567891011 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost median_price median_cost0 P040101001 04 0401 040101 198.0 149.0 283.0 212.51 P040101002 04 0401 040101 218.0 164.0 283.0 212.52 P040101003 04 0401 040101 230.0 173.0 283.0 212.53 P040101004 04 0401 040101 248.0 186.0 283.0 212.54 P040101005 04 0401 040101 268.0 201.0 283.0 212.55 P040101006 04 0401 040101 298.0 224.0 283.0 212.56 P040101007 04 0401 040101 338.0 254.0 283.0 212.57 P040101008 04 0401 040101 420.0 315.0 283.0 212.58 P040101009 04 0401 040101 498.0 374.0 283.0 212.59 P040101010 04 0401 040101 580.0 435.0 283.0 212.5 df_product_4の欠損値の有無を確認します。 1df_product_4.isnull().sum() 出力123456789product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 7unit_cost 7median_price 0median_cost 0dtype: int64 unit_priceとunit_costに欠損値があることが確認できます。 この欠損値に対して各商品の小区分ごとに算出した中央値で補完をします。 欠損値がある場合のみ中央値を適用したいので、applyメソッドとlambda式を用いて補完していきます。 12345678# unit_price(下記コードではx[0]がunit_price)に欠損値があった場合は、median_price(下記コードではx[1]がmedian_price)を適用し、そうでない場合は。unit_priceそのまま# axis=1にすることで行方向への処理にさせる。df_product_4['unit_price'] = df_product_4[['unit_price', 'median_price']].apply(lambda x: np.round(x[1]) if np.isnan(x[0]) else x[0], axis=1)# unit_cost(下記コードではx[0]がunit_cost)に欠損値があった場合は、median_cost(下記コードではx[1]がmedian_cost)を適用し、そうでない場合は。unit_costそのまま# axis=1にすることで行方向への処理にさせる。df_product_4['unit_cost'] = df_product_4[['unit_cost', 'median_cost']].apply(lambda x : np.round(x[1]) if np.isnan(x[0]) else x[0], axis=1)df_product_4.isnull().sum() 出力123456789product_cd 0category_major_cd 0category_medium_cd 0category_small_cd 0unit_price 0unit_cost 0median_price 0median_cost 0dtype: int64 まとめ:データサイエンス100本ノック【問79〜83 回答】で欠陥値の扱いを学びました本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-79-83/"},{"title":"【解説】データサイエンス100本ノック【問84 回答】","text":"目次 第84問目: 除算エラー対応 まとめ: データサイエンス100本ノック【問84 回答】で除算エラー対応を学びました データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第84問目: 除算エラー対応 P-084: 顧客データフレーム（df_customer）の全顧客に対し、全期間の売上金額に占める2019年売上金額の割合を計算せよ。ただし、販売実績のない場合は0として扱うこと。そして計算した割合が0超のものを抽出せよ。 結果は10件表示させれば良い。また、作成したデータにNAやNANが存在しないことを確認せよ。 本問の回答の大まかな流れを図とともにまとめます。 まずdf_receiptからqueryメソッドを用いて2019年のデータを抽出しdf_tmp_1とします。 df_tmp_1をdf_customerに左外部結合を行うことで全顧客毎の2019年の売上金額のデータフレームが作成されます。 その一方で全顧客毎の全期間の売上金額のデータフレームをdf_tmp_2としてまとめ、df_tmp_1と内部結合を行い、最後に「2019年の売÷全期間の売上」を計算し割合を抽出します。 ポイントは、割合を算出する際にNaNデータがあることでエラーとなってしまいます。そのため最終的に欠損値がない状態で割合を計算する必要があるので、その点に気をつけましょう。 それでは早速回答していきます。 まずはdf_customerの構造を確認します。 1df_customer.head(10) 出力1234567891011customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 続いてレシート明細データフレーム(df_receipt)の構造を確認します 1df_receipt.head(10) 出力123456789101112sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 まずはdf_receiptから2019年1月1日から2019年12月31日までの期間のデータを抽出したいと思います。 12df_tmp_1 = df_receipt.query('20190101 &lt;= sales_ymd &lt;= 20191231')df_tmp_1.head(10) 出力123456789101112sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount3 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 255 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1387 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1289 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 68010 20190918 1568764800 S14025 1182 2 CS025415000134 P070401002 1 13813 20190326 1553558400 S13016 112 1 CS016215000032 P091401190 1 78016 20190621 1561075200 S13044 1142 2 ZZ000000000000 P040102001 1 26818 20190603 1559520000 S14026 1182 1 CS026515000042 P070504016 1 18819 20190606 1559779200 S13044 1122 1 ZZ000000000000 P071102002 1 19026 20190810 1565395200 S14034 1122 1 CS034414000034 P071302003 1 318 df_tmp_1をdf_customerに左外部結合させていきます。共通カラムはcustomer_idになります。 【解説】外部結合の方法を学ぶ | データサイエンス100本ノック【問38〜問40 回答】 - omathin blog 123# 2. &quot;１&quot;で抽出したデータを顧客データフレーム（df_customer）のcustomer_idに左外部結合するdf_tmp_1 = pd.merge(df_customer['customer_id'], df_tmp_1[['customer_id', 'amount']], how='left', on='customer_id')df_tmp_1.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount0 CS021313000114 NaN1 CS037613000071 NaN2 CS031415000172 2400.03 CS031415000172 258.04 CS031415000172 215.05 CS031415000172 98.06 CS028811000001 NaN7 CS001215000145 NaN8 CS020401000016 NaN9 CS015414000103 208.010 CS015414000103 102.011 CS015414000103 138.012 CS015414000103 118.013 CS015414000103 138.014 CS015414000103 170.015 CS029403000008 NaN16 CS015804000004 NaN17 CS033513000180 NaN18 CS007403000016 NaN19 CS035614000014 NaN20 CS011215000048 160.021 CS011215000048 88.022 CS009413000079 NaN23 CS040412000191 NaN24 CS029415000023 130.025 CS029415000023 2400.026 CS029415000023 60.027 CS029415000023 278.028 CS029415000023 190.029 CS029415000023 178.0 df_tmp_1で顧客ID(customer_id)をみると、同じIDが複数のレコードに分かれていることがわかります。例えば、CS031415000172というデータは、3行目〜6行目の間に含まれています。 そのためcustomer_idごとにamountの合計値を取る必要があるのでgroupbyとsumメソッドを用いて処理していきます。※aggメソッドを用いてもOKです またamountというカラム名もamount_2019というカラム名に変更しておきます。 &gt;&gt; groupby()メソッドとsum()またはagg()を用いて、各顧客ごとの売上金額の合計を算出する方法を復習する。 12df_tmp_1 = df_tmp_1.groupby('customer_id').sum().reset_index().rename(columns={'amount':'amount_2019'})df_tmp_1.head(30) 出力1234567891011121314151617181920212223242526272829303132customer_id amount_20190 CS001105000001 0.01 CS001112000009 0.02 CS001112000019 0.03 CS001112000021 0.04 CS001112000023 0.05 CS001112000024 0.06 CS001112000029 0.07 CS001112000030 0.08 CS001113000004 1298.09 CS001113000010 0.010 CS001114000005 188.011 CS001115000006 0.012 CS001115000010 578.013 CS001202000023 0.014 CS001202000024 0.015 CS001202000026 0.016 CS001203000021 0.017 CS001205000004 702.018 CS001205000006 486.019 CS001211000003 0.020 CS001211000007 0.021 CS001211000018 0.022 CS001211000024 0.023 CS001211000025 456.024 CS001212000018 0.025 CS001212000027 0.026 CS001212000031 0.027 CS001212000042 0.028 CS001212000045 0.029 CS001212000046 0.0 レシート明細データフレーム(df_receipt)を顧客データフレーム(df_customer)に左外部結合させます。 12df_tmp_2 = pd.merge(df_customer['customer_id'], df_receipt[['customer_id', 'amount']], how='left', on='customer_id')df_tmp_2.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount0 CS021313000114 NaN1 CS037613000071 NaN2 CS031415000172 100.03 CS031415000172 320.04 CS031415000172 2400.05 CS031415000172 448.06 CS031415000172 258.07 CS031415000172 215.08 CS031415000172 88.09 CS031415000172 102.010 CS031415000172 98.011 CS031415000172 278.012 CS031415000172 110.013 CS031415000172 218.014 CS031415000172 268.015 CS031415000172 185.016 CS028811000001 NaN17 CS001215000145 680.018 CS001215000145 195.019 CS020401000016 NaN20 CS015414000103 130.021 CS015414000103 118.022 CS015414000103 208.023 CS015414000103 102.024 CS015414000103 900.025 CS015414000103 1100.026 CS015414000103 138.027 CS015414000103 118.028 CS015414000103 138.029 CS015414000103 170.0 12df_tmp_2 = df_tmp_2.groupby('customer_id').sum().reset_index()df_tmp_2.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount0 CS001105000001 0.01 CS001112000009 0.02 CS001112000019 0.03 CS001112000021 0.04 CS001112000023 0.05 CS001112000024 0.06 CS001112000029 0.07 CS001112000030 0.08 CS001113000004 1298.09 CS001113000010 0.010 CS001114000005 626.011 CS001115000006 0.012 CS001115000010 3044.013 CS001202000023 0.014 CS001202000024 0.015 CS001202000026 0.016 CS001203000021 0.017 CS001205000004 1988.018 CS001205000006 3337.019 CS001211000003 0.020 CS001211000007 0.021 CS001211000018 0.022 CS001211000024 0.023 CS001211000025 456.024 CS001212000018 0.025 CS001212000027 448.026 CS001212000031 296.027 CS001212000042 0.028 CS001212000045 0.029 CS001212000046 228.0 df_tmp_1とdf_tmp_2を内部結合します。 12df_tmp = pd.merge(df_tmp_1, df_tmp_2, how='inner', on='customer_id')df_tmp.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount_2019 amount0 CS001105000001 0.0 0.01 CS001112000009 0.0 0.02 CS001112000019 0.0 0.03 CS001112000021 0.0 0.04 CS001112000023 0.0 0.05 CS001112000024 0.0 0.06 CS001112000029 0.0 0.07 CS001112000030 0.0 0.08 CS001113000004 1298.0 1298.09 CS001113000010 0.0 0.010 CS001114000005 188.0 626.011 CS001115000006 0.0 0.012 CS001115000010 578.0 3044.013 CS001202000023 0.0 0.014 CS001202000024 0.0 0.015 CS001202000026 0.0 0.016 CS001203000021 0.0 0.017 CS001205000004 702.0 1988.018 CS001205000006 486.0 3337.019 CS001211000003 0.0 0.020 CS001211000007 0.0 0.021 CS001211000018 0.0 0.022 CS001211000024 0.0 0.023 CS001211000025 456.0 456.024 CS001212000018 0.0 0.025 CS001212000027 0.0 448.026 CS001212000031 0.0 296.027 CS001212000042 0.0 0.028 CS001212000045 0.0 0.029 CS001212000046 0.0 228.0 ここで欠損値の有無を確認します。 1df_tmp.isnull().sum() 出力1234customer_id 0amount_2019 0amount 0dtype: int64 欠損値は無いようなので、2019年の売上金額/全期間の売上金額を算出し、amount_rateカラムに格納します。 12df_tmp['amount_rate'] = df_tmp['amount_2019']/df_tmp['amount']df_tmp.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount_2019 amount amount_rate0 CS001105000001 0.0 0.0 NaN1 CS001112000009 0.0 0.0 NaN2 CS001112000019 0.0 0.0 NaN3 CS001112000021 0.0 0.0 NaN4 CS001112000023 0.0 0.0 NaN5 CS001112000024 0.0 0.0 NaN6 CS001112000029 0.0 0.0 NaN7 CS001112000030 0.0 0.0 NaN8 CS001113000004 1298.0 1298.0 1.0000009 CS001113000010 0.0 0.0 NaN10 CS001114000005 188.0 626.0 0.30031911 CS001115000006 0.0 0.0 NaN12 CS001115000010 578.0 3044.0 0.18988213 CS001202000023 0.0 0.0 NaN14 CS001202000024 0.0 0.0 NaN15 CS001202000026 0.0 0.0 NaN16 CS001203000021 0.0 0.0 NaN17 CS001205000004 702.0 1988.0 0.35311918 CS001205000006 486.0 3337.0 0.14564019 CS001211000003 0.0 0.0 NaN20 CS001211000007 0.0 0.0 NaN21 CS001211000018 0.0 0.0 NaN22 CS001211000024 0.0 0.0 NaN23 CS001211000025 456.0 456.0 1.00000024 CS001212000018 0.0 0.0 NaN25 CS001212000027 0.0 448.0 0.00000026 CS001212000031 0.0 296.0 0.00000027 CS001212000042 0.0 0.0 NaN28 CS001212000045 0.0 0.0 NaN29 CS001212000046 0.0 228.0 0.000000 改めて欠損値を確認します。 1df_tmp.isnull().sum() 出力12345customer_id 0amount_2019 0amount 0amount_rate 13665dtype: int64 amount_rateに欠損値が存在しているので保管します。 欠損値の補完はfillnaメソッドを使用します。今回は全て0で補完します。 12df_tmp['amount_rate'] = df_tmp['amount_rate'].fillna(0)df_tmp.head(30) 出力12345678910111213141516171819202122232425262728293031 customer_id amount_2019 amount amount_rate0 CS001105000001 0.0 0.0 0.0000001 CS001112000009 0.0 0.0 0.0000002 CS001112000019 0.0 0.0 0.0000003 CS001112000021 0.0 0.0 0.0000004 CS001112000023 0.0 0.0 0.0000005 CS001112000024 0.0 0.0 0.0000006 CS001112000029 0.0 0.0 0.0000007 CS001112000030 0.0 0.0 0.0000008 CS001113000004 1298.0 1298.0 1.0000009 CS001113000010 0.0 0.0 0.00000010 CS001114000005 188.0 626.0 0.30031911 CS001115000006 0.0 0.0 0.00000012 CS001115000010 578.0 3044.0 0.18988213 CS001202000023 0.0 0.0 0.00000014 CS001202000024 0.0 0.0 0.00000015 CS001202000026 0.0 0.0 0.00000016 CS001203000021 0.0 0.0 0.00000017 CS001205000004 702.0 1988.0 0.35311918 CS001205000006 486.0 3337.0 0.14564019 CS001211000003 0.0 0.0 0.00000020 CS001211000007 0.0 0.0 0.00000021 CS001211000018 0.0 0.0 0.00000022 CS001211000024 0.0 0.0 0.00000023 CS001211000025 456.0 456.0 1.00000024 CS001212000018 0.0 0.0 0.00000025 CS001212000027 0.0 448.0 0.00000026 CS001212000031 0.0 296.0 0.00000027 CS001212000042 0.0 0.0 0.00000028 CS001212000045 0.0 0.0 0.00000029 CS001212000046 0.0 228.0 0.000000 最後に計算した割合が0以上となっているデータのみを抽出し10件出力されば完了です。 1df_tmp.query('amount_rate &gt; 0').head(10) 出力1234567891011 customer_id amount_2019 amount amount_rate8 CS001113000004 1298.0 1298.0 1.00000010 CS001114000005 188.0 626.0 0.30031912 CS001115000010 578.0 3044.0 0.18988217 CS001205000004 702.0 1988.0 0.35311918 CS001205000006 486.0 3337.0 0.14564023 CS001211000025 456.0 456.0 1.00000030 CS001212000070 456.0 456.0 1.00000057 CS001214000009 664.0 4685.0 0.14172959 CS001214000017 2962.0 4132.0 0.71684461 CS001214000048 1889.0 2374.0 0.795703 まとめ: データサイエンス100本ノック【問84 回答】で除算エラー対応を学びました本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-84/"},{"title":"【解説】データサイエンス100本ノック【問87〜88回答】","text":"目次 第87問目：名寄せ（完全一致） 第88問目: 名寄せ（変換データ作成） まとめ: 名寄せについて学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第87問目：名寄せ（完全一致） P-087: 顧客データフレーム（df_customer）では、異なる店舗での申込みなどにより同一顧客が複数登録されている。名前（customer_name）と郵便番号（postal_cd）が同じ顧客は同一顧客とみなし、1顧客1レコードとなるように名寄せした名寄顧客データフレーム（df_customer_u）を作成せよ。ただし、同一顧客に対しては売上金額合計が最も高いものを残すものとし、売上金額合計が同一もしくは売上実績の無い顧客については顧客ID（customer_id）の番号が小さいものを残すこととする。 名寄せとは、重複したデータを除く作業のことを言います。 まずはdf_customerの構造を確認してみましょう。 1df_customer.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 問題文より、顧客ごとの売上金額の合計を算出する必要があるため、df_receiptデータフレームの構造も確認します。 1df_receipt.head(10) 出力1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 今回の問題では、同一顧客に関しては売上金額の合計が最も高い売上合計額を残し、売上金額の合計が同一もしくは売上実績の無い顧客については顧客IDの番号が小さいものを残す処理をしなければなりません。 これを以下のような流れで処理します。 顧客ごとの売上金額合計を算出する 売上金額合計を、顧客データフレーム(df_customer)に追加し、売上金額合計を降順にソートする。ソートの際は顧客IDを照準にする。 降順にソートしたデータフレームに対して、最初の行を残し超副業を削除する。 まずは。1. 顧客ごとの売上金額合計を算出していきます。 12df_tmp = df_receipt.groupby('customer_id').agg({'amount':'sum'}).reset_index()df_tmp.head(10) 出力1234567891011 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 33375 CS001211000025 4566 CS001212000027 4487 CS001212000031 2968 CS001212000046 2289 CS001212000070 456 顧客データフレーム(df_customer)に売上金額の合計を追加し、売上金額の合計を降順にソートします。 ソートはsort_valuesメソッドを使用します。 sort_valuesについては、【解説】手を動かしながらソートと表連結を学ぶ | データサイエンス100本ノック【問17〜問20 回答】 - omathin blogを参照ください。 sort_valuesメソッドでは、ソートの基準にしたいカラム名をリストで指定します。 リストで複数のカラム名をした場合、最初に指定されたカラムが優先的にソートされます。 また、ascending=[True, False]のように指定すると、Trueは昇順、Falseは降順にすることができます。 少しわかりにくいかと思うので、簡単なデータフレームでを作成して上記の動作例を示します。 サンプルコード12345import pandas as pdcolumns = ['product', 'price']data = [['pen', 300], ['apple', 150], ['apple', 170], ['pen', 320], ['book', 500], ['bag', 1200]]df = pd.DataFrame(data, columns=columns)df.sort_values(columns, ascending=[True, False]) 出力1234567 product price2 apple 1701 apple 1505 bag 12004 book 5003 pen 3200 pen 300 このように、productカラムのデータはアルファベット順（昇順）、priceはproduct毎に価格が高い順（降順）になっていることがわかります。 本問では、amountを降順にし、顧客IDは昇順でソートしたいと思います。 12df_customer_u = pd.merge(df_customer, df_tmp, how='left', on='customer_id').sort_values(['amount', 'customer_id'], ascending=[False, True])df_customer_u.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd amount16905 CS017415000097 福士 千夏 1 女性 1973-04-03 45 166-0014 東京都杉並区松ノ木********** S13017 20151209 F-20101006-F 23086.012692 CS015415000185 岩淵 はるみ 1 女性 1973-09-19 45 135-0043 東京都江東区塩浜********** S13015 20150322 F-20101014-F 20153.013550 CS031414000051 長澤 沙知絵 1 女性 1973-04-25 45 151-0064 東京都渋谷区上原********** S13031 20150823 F-20101009-F 19202.04808 CS028415000007 紺野 あい 1 女性 1969-07-28 49 246-0023 神奈川県横浜市瀬谷区阿久和東********** S14028 20151212 F-20100922-F 19127.014205 CS001605000009 安部 耕司 0 男性 1952-10-22 66 144-0035 東京都大田区南蒲田********** S13001 20160203 F-20101019-E 18925.014760 CS010214000010 高嶋 芽以 1 女性 1991-02-19 28 221-0004 神奈川県横浜市神奈川区西大口********** S14010 20141106 F-20100909-F 18585.015709 CS006515000023 竹村 はるみ 1 女性 1963-06-27 55 224-0032 神奈川県横浜市都筑区茅ケ崎中央********** S14006 20151217 F-20100831-F 18372.06353 CS016415000141 西谷 愛梨 1 女性 1974-05-06 44 184-0012 東京都小金井市中町********** S13016 20150117 F-20100611-F 18372.021458 CS011414000106 紺野 窈 1 女性 1972-11-11 46 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150921 F-20101028-F 18338.020336 CS038415000104 城戸 しほり 1 女性 1971-02-21 48 134-0084 東京都江戸川区東葛西********** S13038 20151119 F-20100922-F 17847.0 同一顧客に対しては売上金額合計が最も高いものを残すように削除します。 12df_customer_u.drop_duplicates(subset=['customer_name', 'postal_cd'], keep='first', inplace=True)df_customer_u.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd amount16905 CS017415000097 福士 千夏 1 女性 1973-04-03 45 166-0014 東京都杉並区松ノ木********** S13017 20151209 F-20101006-F 23086.012692 CS015415000185 岩淵 はるみ 1 女性 1973-09-19 45 135-0043 東京都江東区塩浜********** S13015 20150322 F-20101014-F 20153.013550 CS031414000051 長澤 沙知絵 1 女性 1973-04-25 45 151-0064 東京都渋谷区上原********** S13031 20150823 F-20101009-F 19202.04808 CS028415000007 紺野 あい 1 女性 1969-07-28 49 246-0023 神奈川県横浜市瀬谷区阿久和東********** S14028 20151212 F-20100922-F 19127.014205 CS001605000009 安部 耕司 0 男性 1952-10-22 66 144-0035 東京都大田区南蒲田********** S13001 20160203 F-20101019-E 18925.014760 CS010214000010 高嶋 芽以 1 女性 1991-02-19 28 221-0004 神奈川県横浜市神奈川区西大口********** S14010 20141106 F-20100909-F 18585.015709 CS006515000023 竹村 はるみ 1 女性 1963-06-27 55 224-0032 神奈川県横浜市都筑区茅ケ崎中央********** S14006 20151217 F-20100831-F 18372.06353 CS016415000141 西谷 愛梨 1 女性 1974-05-06 44 184-0012 東京都小金井市中町********** S13016 20150117 F-20100611-F 18372.021458 CS011414000106 紺野 窈 1 女性 1972-11-11 46 223-0062 神奈川県横浜市港北区日吉本町********** S14011 20150921 F-20101028-F 18338.020336 CS038415000104 城戸 しほり 1 女性 1971-02-21 48 134-0084 東京都江戸川区東葛西********** S13038 20151119 F-20100922-F 17847.0 コレで完了しましたが、重複を削除した数がどの程度かを確認します。 1print('減少数：', len(df_customer)-len(df_customer_u)) 出力1減少数： 30 第88問目: 名寄せ（変換データ作成） P-088: 前設問で作成したデータを元に、顧客データフレームに統合名寄IDを付与したデータフレーム（df_customer_n）を作成せよ。ただし、統合名寄IDは以下の仕様で付与するものとする。 ・重複していない顧客：顧客ID（customer_id）を設定・重複している顧客：前設問で抽出したレコードの顧客IDを設定 本問では、前の問題で作成した名寄顧客データフレーム(df_customer_u)を顧客データフレーム(df_customer)に反映させます。 まずは、df_customerとdf_customer_uを内部結合します。df_customerとdf_customer_uで共通のカラムをまずは確認します。 1234df_customer_columns = df_customer.columnsdf_customer_u_columns = df_customer_u.columnsdf_and = set(df_customer_columns) &amp; set(df_customer_u_columns)df_and 出力1234567891011{'address', 'age', 'application_date', 'application_store_cd', 'birth_day', 'customer_id', 'customer_name', 'gender', 'gender_cd', 'postal_cd', 'status_cd'} 共通するカラムが複数存在します。顧客情報に関連するデータを共通カラムとして指定して内部結合していきたいので、ここでは customer_name, postal_cdの２つを共通カラムとして指定し内部結合していきたいと思います。customer_idは問題文よりもともとのdf_customerに含まれているcustomer_idと、df_customer_uのcustomer_idを分けて結合し、df_customer_u側のcustomer_idがintegration_idにするため、共通カラムとして指定は行いません。 12df_customer_n = pd.merge(df_customer, df_customer_u[['customer_name', 'postal_cd', 'customer_id']], how='inner', on=['customer_name', 'postal_cd'])df_customer_n.head(10) 出力1234567891011 customer_id_x customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd customer_id_y0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-0 CS0213130001141 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-0 CS0376130000712 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C CS0314150001723 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-0 CS0288110000014 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 CS0012150001455 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-0 CS0204010000166 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B CS0154140001037 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-0 CS0294030000088 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-0 CS0158040000049 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 CS033513000180 df_customer_nの構造とみると、customer_idが2つ存在しています。customer_id_yのほうが、df_customer_uで所持していたcustomer_id、すなわちintegration_idになります。 renameメソッドを用いてカラム名を変更していきます。引数inplaceをTrueにすると、元のpandas.DataFrameが変更されます。 renameメソッドの基礎に関しては、【解説】データサイエンス100本ノック【第1問〜第10問】 - omathin blog を参照ください。 12df_customer_n.rename(columns={'customer_id_x':'customer_id', 'customer_id_y':'integration_id'}, inplace=True)df_customer_n.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd integration_id0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-0 CS0213130001141 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-0 CS0376130000712 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C CS0314150001723 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-0 CS0288110000014 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 CS0012150001455 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-0 CS0204010000166 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B CS0154140001037 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-0 CS0294030000088 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-0 CS0158040000049 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 CS033513000180 最後にdf_customer_nにおけるcustomer_idとintegration_idの数の差分を確認します。 uniqueメソッドの復習は、【解説】手を動かしながらカウント(len関数、uniqueメソッド)を学ぶ | データサイエンス100本ノック【問21〜問22 回答】 - omathin blog 1print('ID数の差：', len(df_customer_n['customer_id'].unique()) - len(df_customer_n['integration_id'].unique())) 出力1ID数の差： 30 P-閑話: df_customer_1, df_customer_nは使わないので削除する。 12del df_customer_1del df_customer_n まとめ: 名寄せについて学びました。本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-87-88/"},{"title":"【解説】データサイエンス100本ノック【問85〜86回答】","text":"目次 第85問目：軽度緯度変換用データフレームの紐付け 第86問目: 軽度緯度の算出 まとめ：ジオコードを学びました データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第85問目：軽度緯度変換用データフレームの紐付け P-085: 顧客データフレーム（df_customer）の全顧客に対し、郵便番号（postal_cd）を用いて経度緯度変換用データフレーム（df_geocode）を紐付け、新たなdf_customer_1を作成せよ。ただし、複数紐づく場合は経度（longitude）、緯度（latitude）それぞれ平均を算出すること。 本問は、「df_customerの全顧客に対して、郵便番号(postal_cd)を用いて経度緯度変換用データフレーム(df_geocode)を紐付ける」ということですが、シンプルに内部結合を行えばOKです。 内部結合は、mergeメソッドを使えばOKです。 mergeメソッドの復習は以下の記事を参照ください。 【解説】内部結合の方法を学ぶ | データサイエンス100本ノック【問36〜問37 回答】 - omathin blog まずは、df_customerとdf_geocodeの構造を確認します。 1df_customer.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-25 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-06 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B7 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-08 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-09 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 1df_geocode.head(10) 出力123456789101112postal_cd prefecture city town street address full_address longitude latitude0 060-0000 北海道 札幌市中央区 None None None 北海道札幌市中央区 141.34103 43.055131 064-0941 北海道 札幌市中央区 旭ケ丘 None None 北海道札幌市中央区旭ケ丘 141.31972 43.042232 060-0042 北海道 札幌市中央区 大通西 None １丁目 北海道札幌市中央区大通西１丁目 141.35637 43.061023 060-0042 北海道 札幌市中央区 大通西 None ２丁目 北海道札幌市中央区大通西２丁目 141.35445 43.060804 060-0042 北海道 札幌市中央区 大通西 None ３丁目 北海道札幌市中央区大通西３丁目 141.35275 43.060865 060-0042 北海道 札幌市中央区 大通西 None ４丁目 北海道札幌市中央区大通西４丁目 141.35126 43.060396 060-0042 北海道 札幌市中央区 大通西 None ５丁目 北海道札幌市中央区大通西５丁目 141.34975 43.060177 060-0042 北海道 札幌市中央区 大通西 None ６丁目 北海道札幌市中央区大通西６丁目 141.34821 43.059928 060-0042 北海道 札幌市中央区 大通西 None ７丁目 北海道札幌市中央区大通西７丁目 141.34663 43.059749 060-0042 北海道 札幌市中央区 大通西 None ８丁目 北海道札幌市中央区大通西８丁目 141.34506 43.05957 df_customerとdf_geocodeを内部結合していきます。共通するカラムは、postal_cdを指定します。 12df_customer_1 = pd.merge(df_customer[['customer_id', 'postal_cd']], df_geocode[['postal_cd', 'longitude', 'latitude']], how='inner', on='postal_cd')df_customer_1 出力12345678910111213 customer_id postal_cd longitude latitude0 CS021313000114 259-1113 139.31779 35.413581 CS021303000023 259-1113 139.31779 35.413582 CS021303000007 259-1113 139.31779 35.413583 CS021313000183 259-1113 139.31779 35.413584 CS021314000098 259-1113 139.31779 35.41358... ... ... ... ...22085 CS021612000057 259-1134 139.30992 35.3854422086 CS035401000016 155-0033 139.66281 35.6527122087 CS003612000043 182-0033 139.53539 35.6602022088 CS007612000095 276-0043 140.10959 35.7341922089 CS021411000017 243-0121 139.26601 35.4489622090 rows × 4 columns df_customer_1というデータフレームが作成できました。 ここでcustomer_idに対して複数の緯度経度が紐付いてしまったデータに関しては緯度経度それぞれの平均を算出しなければなりません。 つまりcustomer_idごとに緯度経度それぞれの平均を取れば良いと言い換えられるので、gtoupbyとaggを用いれば良いと考えられます。 groupbyとaggの使い方は以下の記事を参考にしてください。 【解説】手を動かしながら平均値と中央値の抽出方法を学ぶ | データサイエンス100本ノック【問27〜問28 回答】 - omathin blog 12df_customer_1 = df_customer_1.groupby('customer_id').agg({'longitude':'mean', 'latitude':'mean'}).reset_index()df_customer_1.head(10) 出力1234567891011 customer_id longitude latitude0 CS001105000001 139.70238 35.541371 CS001112000009 139.70386 35.586702 CS001112000019 139.74687 35.571533 CS001112000021 139.70238 35.541374 CS001112000023 139.74687 35.571535 CS001112000024 139.70238 35.541376 CS001112000029 139.70238 35.541377 CS001112000030 139.70238 35.541378 CS001113000004 139.70238 35.541379 CS001113000010 139.70238 35.54137 緯度、軽度の平均をとった値なので、カラムの名前そm_longitude, m_latitudeに変換します。 カラム名の変換はrenameメソッドを用います。 renameメソッドの詳しい使い方は以下の記事を参考にしてください。 【解説】データサイエンス100本ノック【第1問〜第10問】 - omathin blog 12df_customer_1.rename(columns={'longitude':'m_longitude', 'latitude':'m_latitude'}, inplace=True)df_customer_1.head(10) 出力1234567891011customer_id m_longitude m_latitude0 CS001105000001 139.70238 35.541371 CS001112000009 139.70386 35.586702 CS001112000019 139.74687 35.571533 CS001112000021 139.70238 35.541374 CS001112000023 139.74687 35.571535 CS001112000024 139.70238 35.541376 CS001112000029 139.70238 35.541377 CS001112000030 139.70238 35.541378 CS001113000004 139.70238 35.541379 CS001113000010 139.70238 35.54137 最後にdf_customerとdf_customer_1を内部結合を行い完了です。 12df_customer_1 = pd.merge(df_customer, df_customer_1, how='inner', on='customer_id')df_customer_1.head(10) 出力1234567891011 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd m_longitude m_latitude0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-0 139.31779 35.413581 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-0 139.83502 35.671932 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C 139.68965 35.673743 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-0 139.48360 35.391254 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 139.70775 35.540845 CS020401000016 宮下 達士 0 男性 1974-09-15 44 174-0065 東京都板橋区若木********** S13020 20150225 0-00000000-0 139.67245 35.770736 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B 139.83601 35.678187 CS029403000008 釈 人志 0 男性 1973-08-17 45 279-0003 千葉県浦安市海楽********** S12029 20150515 0-00000000-0 139.90469 35.654228 CS015804000004 松谷 米蔵 0 男性 1931-05-02 87 136-0073 東京都江東区北砂********** S13015 20150607 0-00000000-0 139.83601 35.678189 CS033513000180 安斎 遥 1 女性 1962-07-11 56 241-0823 神奈川県横浜市旭区善部町********** S14033 20150728 6-20080506-5 139.51463 35.45013 第86問目: 軽度緯度の算出 P-086: 前設問で作成した緯度経度つき顧客データフレーム（df_customer_1）に対し、申込み店舗コード（application_store_cd）をキーに店舗データフレーム（df_store）と結合せよ。そして申込み店舗の緯度（latitude）・経度情報（longitude)と顧客の緯度・経度を用いて距離（km）を求め、顧客ID（customer_id）、顧客住所（address）、店舗住所（address）とともに表示せよ。計算式は簡易式で良いものとするが、その他精度の高い方式を利用したライブラリを利用してもかまわない。結果は10件表示すれば良い。 緯度（ラジアン）：\\phi \\\\ 経度（ラジアン）：\\lambda \\\\ 距離L = 6371 * arccos(sin \\phi_1 * sin \\phi_2 + cos \\phi_1 * cos \\phi_2 * cos(\\lambda_1 − \\lambda_2)) まずは店舗データフレームの構造を確認します。 1df_store.head(10) 出力1234567891011 store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area0 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.01 S13002 国分寺店 13 東京都 東京都国分寺市本多二丁目 トウキョウトコクブンジシホンダニチョウメ 042-123-4008 139.4802 35.70566 1735.02 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.04 S14036 相模原中央店 14 神奈川県 神奈川県相模原市中央二丁目 カナガワケンサガミハラシチュウオウニチョウメ 042-123-4045 139.3716 35.57327 1679.05 S13051 板橋大原店 13 東京都 東京都板橋区大原町 トウキョウトイタバシクオオハラチョウ 03-0123-4029 139.6980 35.76788 1045.06 S13015 南砂店 13 東京都 東京都江東区南砂二丁目 トウキョウトコウトウクミナミスナニチョウメ 03-0123-4014 139.8229 35.67066 1337.07 S14040 長津田店 14 神奈川県 神奈川県横浜市緑区長津田みなみ台五丁目 カナガワケンヨコハマシミドリクナガツタミナミダイゴチョウメ 045-123-4046 139.4994 35.52398 1548.08 S13044 南六郷店 13 東京都 東京都大田区南六郷二丁目 トウキョウトオオタクミナミロクゴウニチョウメ 03-0123-4028 139.7207 35.54604 1379.09 S14050 阿久和西店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4053 139.4961 35.45918 1830.0 問題文に従い、顧客データフレーム(df_customer_1)に対して、application_store_cdをキーに店舗データフレームを内部結合します。ここで注意ですが、df_storeには、application_store_cdという名前のカラムが存在しません。application_store_cdではなくstore_cdという名前のカラムになっています。このような場合の対処としては2パタンあります。 renameを用いてカラム名を揃える mergeメソッドの引数としてleft_onとright_onを用いて左側と右側それぞれにおけるキーカラムを指定する ここでは、後者の方法で進めたいと思います。 12df_tmp = pd.merge(df_customer_1, df_store, how='inner', left_on='application_store_cd', right_on='store_cd')df_tmp.head(10) 出力123456789101112 customer_id customer_name gender_cd gender birth_day age postal_cd address_x application_store_cd application_date ... store_cd store_name prefecture_cd prefecture address_y address_kana tel_no longitude latitude floor_area0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.01 CS021313000025 砂川 あさみ 1 女性 1981-10-05 37 259-1131 神奈川県伊勢原市伊勢原********** S14021 20150326 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.02 CS021411000096 布施 杏 1 女性 1971-10-30 47 259-1114 神奈川県伊勢原市高森********** S14021 20160621 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.03 CS021415000150 早美 紗季 1 女性 1969-11-26 49 259-1141 神奈川県伊勢原市上粕屋********** S14021 20150601 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.04 CS021313000046 会田 薫 9 不明 1983-01-19 36 259-1144 神奈川県伊勢原市池端********** S14021 20150722 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.05 CS021103000002 庄司 染五郎 0 男性 2006-11-24 12 259-1111 神奈川県伊勢原市西富岡********** S14021 20150317 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.06 CS021214000028 吉井 菜摘 1 女性 1991-07-12 27 259-1132 神奈川県伊勢原市桜台********** S14021 20151007 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.07 CS021512000095 佐々木 陽子 1 女性 1963-01-22 56 259-1126 神奈川県伊勢原市沼目********** S14021 20150820 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.08 CS021613000002 内村 貴美子 1 女性 1950-02-18 69 259-1132 神奈川県伊勢原市桜台********** S14021 20151125 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.09 CS021412000147 三輪 さやか 1 女性 1971-08-23 47 259-1103 神奈川県伊勢原市三ノ宮********** S14021 20150930 ... S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.010 rows × 23 columns 次に距離の計算を行います。まずは、2地点間の距離を算出する関数を定義しましょう。ここでは、問題文に記述されている距離Lを導く式を実装します。 123def calc_distance(x1, y1, x2, y2): distance = 6371 * math.acos(math.sin(math.radians(y1)) * math.sin(math.radians(y2)) + math.cos(math.radians(y1)) * math.cos(math.radians(y2)) * math.cos(math.radians(x1) - math.radians(x2))) return distance 定義したcalc_distance関数を用いてapplyメソッドとlambda式を用いて距離計算を行います。 123df_tmp['distance'] = df_tmp[['m_longitude', 'm_latitude','longitude', 'latitude']]. \\ apply(lambda x: calc_distance(x[0], x[1], x[2], x[3]), axis=1)df_tmp.head(10) 出力123456789101112 customer_id customer_name gender_cd gender birth_day age postal_cd address_x application_store_cd application_date ... store_name prefecture_cd prefecture address_y address_kana tel_no longitude latitude floor_area distance0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 1.3944091 CS021313000025 砂川 あさみ 1 女性 1981-10-05 37 259-1131 神奈川県伊勢原市伊勢原********** S14021 20150326 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 0.4742822 CS021411000096 布施 杏 1 女性 1971-10-30 47 259-1114 神奈川県伊勢原市高森********** S14021 20160621 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 2.4801553 CS021415000150 早美 紗季 1 女性 1969-11-26 49 259-1141 神奈川県伊勢原市上粕屋********** S14021 20150601 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 2.7347234 CS021313000046 会田 薫 9 不明 1983-01-19 36 259-1144 神奈川県伊勢原市池端********** S14021 20150722 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 1.1119115 CS021103000002 庄司 染五郎 0 男性 2006-11-24 12 259-1111 神奈川県伊勢原市西富岡********** S14021 20150317 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 2.3849416 CS021214000028 吉井 菜摘 1 女性 1991-07-12 27 259-1132 神奈川県伊勢原市桜台********** S14021 20151007 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 1.3993447 CS021512000095 佐々木 陽子 1 女性 1963-01-22 56 259-1126 神奈川県伊勢原市沼目********** S14021 20150820 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 1.9939918 CS021613000002 内村 貴美子 1 女性 1950-02-18 69 259-1132 神奈川県伊勢原市桜台********** S14021 20151125 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 1.3993449 CS021412000147 三輪 さやか 1 女性 1971-08-23 47 259-1103 神奈川県伊勢原市三ノ宮********** S14021 20150930 ... 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.0 3.50768010 rows × 24 columns 最後に顧客ID、顧客獣wy尾、店舗住所、距離を表示して完了です。 1df_tmp[['customer_id', 'address_x', 'address_y', 'distance']].head(10) 出力1234567891011 customer_id address_x address_y distance0 CS021313000114 神奈川県伊勢原市粟窪********** 神奈川県伊勢原市伊勢原四丁目 1.3944091 CS021313000025 神奈川県伊勢原市伊勢原********** 神奈川県伊勢原市伊勢原四丁目 0.4742822 CS021411000096 神奈川県伊勢原市高森********** 神奈川県伊勢原市伊勢原四丁目 2.4801553 CS021415000150 神奈川県伊勢原市上粕屋********** 神奈川県伊勢原市伊勢原四丁目 2.7347234 CS021313000046 神奈川県伊勢原市池端********** 神奈川県伊勢原市伊勢原四丁目 1.1119115 CS021103000002 神奈川県伊勢原市西富岡********** 神奈川県伊勢原市伊勢原四丁目 2.3849416 CS021214000028 神奈川県伊勢原市桜台********** 神奈川県伊勢原市伊勢原四丁目 1.3993447 CS021512000095 神奈川県伊勢原市沼目********** 神奈川県伊勢原市伊勢原四丁目 1.9939918 CS021613000002 神奈川県伊勢原市桜台********** 神奈川県伊勢原市伊勢原四丁目 1.3993449 CS021412000147 神奈川県伊勢原市三ノ宮********** 神奈川県伊勢原市伊勢原四丁目 3.507680 まとめ：ジオコードを学びました本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 データサイエンティストに必要な知識は、TechAcademyのデータサイエンスコースでの学習がおすすめです。 無料体験可能なのでご確認ください。","link":"/100knock-85-86/"},{"title":"【解説】データサイエンス100本ノック【第1問〜第10問】","text":"本記事では一般社団法人データサイエンティスト協会がGitHubに公開している「データサイエンス100本ノック」の問題解説をまとめていきます。 No.1〜No.10までの問題解説をまとめていきますが、最初にNo.1〜No.10の範囲において抑えておくべきポイントをまとめます。 抑えておくべきポイントというのは、Pythonの書き方や考え方のことです。 なお、データサイエンス100本ノックの環境構築方法については、以下の記事にまとめております。 抑えておくPythonのポイント データ表示する先頭行の指定: .head()メソッド。先頭から数えて()に指定した数の件数だけデータを表示させるメソッド。 df.head(10)とすると先頭10行が表示される。何も数字を指定しないと5行が表示される。 列指定: df[[&quot;列名&quot;, &quot;列名&quot;, ・・・]]と書くと特定の列(カラム)のみを抽出したデータフレームを取得することができる。 列名変更: .rename()メソッド。df[[&quot;列名&quot;, &quot;列名&quot;, ・・・]].rename(columns={'変更するカラム名': '変更後のカラム名'})とすることで、列名を変更できる。 特定の条件を満たした行の取り出し: .query()メソッド。()内に条件を記載すると、条件を満たしたレコードを抽出できる。例えば、列名Aという列に含まれる特定の顧客ID（”CS018205000001”）のみを取り出したいときは、df[['列名A', '列名B', ・・・]].query('列名A == &quot;CS018205000001&quot;')という記載になる。 文字列の前方一致: カラム名.str.startswith('文字列')とすることで特定の文字列で始まる行のみを抽出できる。 pythonで読み込み指定: .query()メソッド内部で、先述の文字列の前方一致条件指定すると、TypeError: 'Series' objects are mutable, thus they cannot be hashedというエラーが発生するときがある。.query()メソッドで文字列メソッドを使う場合、第２引数にengine='python'を指定しないといけません。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"東京大学のデータサイエンティスト育成講座 ~Pythonで手を動かして学ぶデ―タ分析~\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51qa-jgfYTL._SL500_.jpg\",\"\\/41BNybG2C4L._SL500_.jpg\",\"\\/41ABLFDSyfL._SL500_.jpg\",\"\\/41VfPraX1BL._SL500_.jpg\",\"\\/41iBWza6SXL._SL500_.jpg\",\"\\/412X2tUMUvL._SL500_.jpg\",\"\\/41o1c-4YyHL._SL500_.jpg\",\"\\/41jsiJ2-IWL._SL500_.jpg\",\"\\/41Kv-yarjrL._SL500_.jpg\",\"\\/41eWqTGQQ2L._SL500_.jpg\",\"\\/41VHUgCcr4L._SL500_.jpg\",\"\\/41D+AqTqBFL._SL500_.jpg\",\"\\/4192xkUg7SL._SL500_.jpg\",\"\\/41t6OVz-wrL._SL500_.jpg\",\"\\/41hntvWrjsL._SL500_.jpg\",\"\\/41rJ8t1OuxL._SL500_.jpg\",\"\\/41xvQYCknWL._SL500_.jpg\",\"\\/51pZKvZoKtL._SL500_.jpg\",\"\\/41eziZ1Ky3L._SL500_.jpg\",\"\\/41qgQojywWL._SL500_.jpg\",\"\\/41VO0XBaNkL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839965250\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4839965250\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%9D%B1%E4%BA%AC%E5%A4%A7%E5%AD%A6%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E8%82%B2%E6%88%90%E8%AC%9B%E5%BA%A7%20~Python%E3%81%A7%E6%89%8B%E3%82%92%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E5%AD%A6%E3%81%B6%E3%83%87%E2%80%95%E3%82%BF%E5%88%86%E6%9E%90~\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%9D%B1%E4%BA%AC%E5%A4%A7%E5%AD%A6%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E8%82%B2%E6%88%90%E8%AC%9B%E5%BA%A7%20~Python%E3%81%A7%E6%89%8B%E3%82%92%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E5%AD%A6%E3%81%B6%E3%83%87%E2%80%95%E3%82%BF%E5%88%86%E6%9E%90~\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"Glc6d\",\"s\":\"s\"}); リンク 回答と解説【第1問〜第10問】 以降、問題[第１問（P-001）〜第10問(P-010)]と解説をまとめていきます。 第１問 P-001: レシート明細のデータフレーム（df_receipt）から全項目の先頭10件を表示し、どのようなデータを保有しているか目視で確認せよ。 「全項目の先頭10件を表示」だから``head``メソッドを使おう！ 問１回答1df_receipt.head(10) 出力1234567891011 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 905 20190605 1559692800 S13003 1112 1 CS003515000195 P050102002 1 1386 20181205 1543968000 S14024 1102 2 CS024514000042 P080101005 1 307 20190922 1569110400 S14040 1102 1 CS040415000178 P070501004 1 1288 20170504 1493856000 S13020 1112 2 ZZ000000000000 P071302010 1 7709 20191010 1570665600 S14027 1102 1 CS027514000015 P071101003 1 680 これでOKです。 第2問 P-002: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、10件表示させよ。 列指定は``df[[\"列名\", \"列名\", ・・・]]``だね。10件のみ表示だから``head``メソッドも使おう！ 問２回答1df_receipt[[&quot;sales_ymd&quot;, &quot;customer_id&quot;, &quot;product_cd&quot;, &quot;amount&quot;]].head(10) 出力1234567891011 sales_ymd customer_id product_cd amount0 20181103 CS006214000001 P070305012 1581 20181118 CS008415000097 P070701017 812 20170712 CS028414000014 P060101005 1703 20190205 ZZ000000000000 P050301001 254 20180821 CS025415000050 P060102007 905 20190605 CS003515000195 P050102002 1386 20181205 CS024514000042 P080101005 307 20190922 CS040415000178 P070501004 1288 20170504 ZZ000000000000 P071302010 7709 20191010 CS027514000015 P071101003 680 これでOKです。 第３問 P-003: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、10件表示させよ。ただし、sales_ymdはsales_dateに項目名を変更しながら抽出すること。 次は``.rename()``メソッドだ！ 問３回答1df_receipt[[&quot;sales_ymd&quot;, &quot;customer_id&quot;, &quot;product_cd&quot;, &quot;amount&quot;]].head(10).rename(columns={'sales_ymd': 'sales_date'}) 出力123456789101112sales_date customer_id product_cd amount0 20181103 CS006214000001 P070305012 1581 20181118 CS008415000097 P070701017 812 20170712 CS028414000014 P060101005 1703 20190205 ZZ000000000000 P050301001 254 20180821 CS025415000050 P060102007 905 20190605 CS003515000195 P050102002 1386 20181205 CS024514000042 P080101005 307 20190922 CS040415000178 P070501004 1288 20170504 ZZ000000000000 P071302010 7709 20191010 CS027514000015 P071101003 680 これでOKです。だいぶ要領が分かってきたのではないでしょうか？ 第４問 P-004: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、以下の条件を満たすデータを抽出せよ。 顧客ID（customer_id）が”CS018205000001” 特定の条件を満たした行の取り出しは、``query``メソッドでしたね！ 問４回答1df_receipt[['sales_ymd', 'customer_id', 'product_cd', 'amount']].query('customer_id == &quot;CS018205000001&quot;') 出力12345678910111213 sales_ymd customer_id product_cd amount36 20180911 CS018205000001 P071401012 22009843 20180414 CS018205000001 P060104007 60021110 20170614 CS018205000001 P050206001 99027673 20170614 CS018205000001 P060702015 10827840 20190216 CS018205000001 P071005024 10228757 20180414 CS018205000001 P071101002 27839256 20190226 CS018205000001 P070902035 16858121 20190924 CS018205000001 P060805001 49568117 20190226 CS018205000001 P071401020 220072254 20180911 CS018205000001 P071401005 110088508 20190216 CS018205000001 P040101002 21891525 20190924 CS018205000001 P091503001 280 第５問 P-005: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、以下の条件を満たすデータを抽出せよ。 顧客ID（customer_id）が”CS018205000001”売上金額（amount）が1,000以上 この問題も``query``メソッド！２つの条件を両方満たすことを示すには``&``を使用します。 問５回答1df_receipt[['sales_ymd', 'customer_id', 'product_cd', 'amount']].query('customer_id == &quot;CS018205000001&quot; &amp; amount &gt;= 1000') 出力1234sales_ymd customer_id product_cd amount36 20180911 CS018205000001 P071401012 220068117 20190226 CS018205000001 P071401020 220072254 20180911 CS018205000001 P071401005 1100 第６問 P-006: レシート明細データフレーム「df_receipt」から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上数量（quantity）、売上金額（amount）の順に列を指定し、以下の条件を満たすデータを抽出せよ。 顧客ID（customer_id）が”CS018205000001”売上金額（amount）が1,000以上または売上数量（quantity）が5以上 この問題も``query``メソッド！or条件をは``|``を使用します。 問６回答1df_receipt[['sales_ymd', 'customer_id', 'product_cd', 'quantity', 'amount']].query('customer_id == &quot;CS018205000001&quot; &amp; (amount &gt;= 1000 | quantity &gt;= 5)') 出力123456 sales_ymd customer_id product_cd quantity amount36 20180911 CS018205000001 P071401012 1 22009843 20180414 CS018205000001 P060104007 6 60021110 20170614 CS018205000001 P050206001 5 99068117 20190226 CS018205000001 P071401020 1 220072254 20180911 CS018205000001 P071401005 1 1100 「xまたはy」とか「xかつy」という条件を意味する記述は、「論理演算子」といいます。 論理演算子は、100本ノックの問題を通じて手を動かしながら慣れていけば大丈夫です。 第7問 P-007: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、以下の条件を満たすデータを抽出せよ。 顧客ID（customer_id）が”CS018205000001”売上金額（amount）が1,000以上2,000以下 問7回答1df_receipt[['sales_ymd', 'customer_id', 'product_cd', 'quantity', 'amount']].query('customer_id == &quot;CS018205000001&quot; &amp; (amount &gt;= 1000 &amp; amount &lt;= 2000)') 出力12 sales_ymd customer_id product_cd quantity amount72254 20180911 CS018205000001 P071401005 1 1100 第８問 P-008: レシート明細のデータフレーム（df_receipt）から売上日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、以下の条件を満たすデータを抽出せよ。 顧客ID（customer_id）が”CS018205000001”商品コード（product_cd）が”P071401019”以外 問８回答1df_receipt[['sales_ymd', 'customer_id', 'product_cd', 'quantity', 'amount']].query('customer_id == &quot;CS018205000001&quot; &amp; product_cd != &quot;P071401019&quot;') 出力12345678910111213 sales_ymd customer_id product_cd quantity amount36 20180911 CS018205000001 P071401012 1 22009843 20180414 CS018205000001 P060104007 6 60021110 20170614 CS018205000001 P050206001 5 99027673 20170614 CS018205000001 P060702015 1 10827840 20190216 CS018205000001 P071005024 1 10228757 20180414 CS018205000001 P071101002 1 27839256 20190226 CS018205000001 P070902035 1 16858121 20190924 CS018205000001 P060805001 1 49568117 20190226 CS018205000001 P071401020 1 220072254 20180911 CS018205000001 P071401005 1 110088508 20190216 CS018205000001 P040101002 1 21891525 20190924 CS018205000001 P091503001 1 280 第9問 P-009: 以下の処理において、出力結果を変えずにORをANDに書き換えよ。 df_store.query('not(prefecture_cd == &quot;13&quot; | floor_area &gt; 900)') 問９回答1df_store.query('prefecture_cd != &quot;13&quot; &amp; floor_area &lt;= 900') 出力1234store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area18 S14046 北山田店 14 神奈川県 神奈川県横浜市都筑区北山田一丁目 カナガワケンヨコハマシツヅキクキタヤマタイッチョウメ 045-123-4049 139.5916 35.56189 831.020 S14011 日吉本町店 14 神奈川県 神奈川県横浜市港北区日吉本町四丁目 カナガワケンヨコハマシコウホククヒヨシホンチョウヨンチョウメ 045-123-4033 139.6316 35.54655 890.038 S12013 習志野店 12 千葉県 千葉県習志野市芝園一丁目 チバケンナラシノシシバゾノイッチョウメ 047-123-4002 140.0220 35.66122 808.0 第10問 P-010: 店舗データフレーム（df_store）から、店舗コード（store_cd）が”S14”で始まるものだけ全項目抽出し、10件だけ表示せよ。 文字列の前方一致は「カラム名.str.startswith('文字列')」。``query``メソッドで文字列メソッドを使う場合、第２引数に「engine='python'」を指定しないとエラーになるので注意！ 問10回答1df_store.query('store_cd.str.startswith(&quot;S14&quot;)', engine='python').head(10) 出力1234567891011 store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area2 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.04 S14036 相模原中央店 14 神奈川県 神奈川県相模原市中央二丁目 カナガワケンサガミハラシチュウオウニチョウメ 042-123-4045 139.3716 35.57327 1679.07 S14040 長津田店 14 神奈川県 神奈川県横浜市緑区長津田みなみ台五丁目 カナガワケンヨコハマシミドリクナガツタミナミダイゴチョウメ 045-123-4046 139.4994 35.52398 1548.09 S14050 阿久和西店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4053 139.4961 35.45918 1830.012 S14028 二ツ橋店 14 神奈川県 神奈川県横浜市瀬谷区二ツ橋町 カナガワケンヨコハマシセヤクフタツバシチョウ 045-123-4042 139.4963 35.46304 1574.016 S14012 本牧和田店 14 神奈川県 神奈川県横浜市中区本牧和田 カナガワケンヨコハマシナカクホンモクワダ 045-123-4034 139.6582 35.42156 1341.018 S14046 北山田店 14 神奈川県 神奈川県横浜市都筑区北山田一丁目 カナガワケンヨコハマシツヅキクキタヤマタイッチョウメ 045-123-4049 139.5916 35.56189 831.019 S14022 逗子店 14 神奈川県 神奈川県逗子市逗子一丁目 カナガワケンズシシズシイッチョウメ 046-123-4036 139.5789 35.29642 1838.020 S14011 日吉本町店 14 神奈川県 神奈川県横浜市港北区日吉本町四丁目 カナガワケンヨコハマシコウホククヒヨシホンチョウヨンチョウメ 045-123-4033 139.6316 35.54655 890.0 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 100本ノックをスタートすることができました。まずは10本のノックを受けきりました。お疲れさまでした。 正直な話、プログラミングを学習する際の一番のハードルは「スタート」です。 学習を始めることが出来た時点で周りと差をつけることができたと思っていいと思います。 今回学んだことのポイントを改めて以下にまとめます。 データ表示する先頭行の指定: .head()メソッド。先頭から数えて()に指定した数の件数だけデータを表示させるメソッド。 df.head(10)とすると先頭10行が表示される。何も数字を指定しないと5行が表示される。 列指定: df[[&quot;列名&quot;, &quot;列名&quot;, ・・・]]と書くと特定の列(カラム)のみを抽出したデータフレームを取得することができる。 列名変更: .rename()メソッド。df[[&quot;列名&quot;, &quot;列名&quot;, ・・・]].rename(columns={'変更するカラム名': '変更後のカラム名'})とすることで、列名を変更できる。 特定の条件を満たした行の取り出し: .query()メソッド。()内に条件を記載すると、条件を満たしたレコードを抽出できる。例えば、列名Aという列に含まれる特定の顧客ID（”CS018205000001”）のみを取り出したいときは、df[['列名A', '列名B', ・・・]].query('列名A == &quot;CS018205000001&quot;')という記載になる。 文字列の前方一致: カラム名.str.startswith('文字列')とすることで特定の文字列で始まる行のみを抽出できる。 pythonで読み込み指定: .query()メソッド内部で、先述の文字列の前方一致条件指定すると、TypeError: 'Series' objects are mutable, thus they cannot be hashedというエラーが発生するときがある。.query()メソッドで文字列メソッドを使う場合、第２引数にengine='python'を指定しないといけません。 この調子でどんどん学習を進めていきましょう。 &gt;&gt; 続きはこちら 参考記事などpandas Python Series objects are mutable, thus they cannot be hashed in query method - Stack Overflow pandas.DataFrameの行を条件で抽出するquery | note.nkmk.me","link":"/100knocks-1-10/"},{"title":"【ダイエットメニュー】プロテイン＋冷凍ブルーベリーが脂肪燃焼に最適だった","text":"脂肪燃焼したいなら、プロテインとブルーベリーが最適であることが分かったので記事にまとめていきます！ 在宅勤務でありながら、私はこの方法＋ハーフスクワットを朝にやったことで2ヶ月で5キロのダイエットに成功しました！ ✓目次 ブルーベリーで血管と脂質代謝の改善 [最強]早朝にプロテインと冷凍ブルーベリーのスムージーを飲んで筋トレする プロテイン＋冷凍ブルーベリースムージーの作り方 まとめ ブルーベリーで血管と脂質代謝の改善 本記事の内容は、アメリカの研究論文[1]による報告です。 ブルーベリーを1日当たり1カップ摂取すると、インスリン抵抗性の変化を伴わずに血管機能、脂質代謝の改善がもたらされることがわかりました。 また、その効果が持続することが示されました。 115名の男女の被験者を用意し、プラセボ郡を設けた上で6か月間の摂取により体に及ぼす影響を調査した研究になります。 「プラセボ郡」というのは、被験薬に似せかつ薬効成分を含まない「偽薬」を摂取する人たちのこと。要するに「病は気から」っていうのをなるべく排除する取り組みですね。 ブルーベリーを一日あたり1カップ摂取した郡において、血管の拡張率が1.45%の改善、2.24%の動脈硬化指数の改善が見られたようです。 在宅勤務等で、体重の増加が心配な方は、ブルーベリーを積極的に摂取するのはいかがでしょうか。 報告論文 [1]Peter J Curtis, Vera van der Velpen, Lindsey Berends, Amy Jennings, Martin Feelisch, A Margot Umpleby, Mark Evans, Bernadette O Fernandez, Mia S Meiss, Magdalena Minnion, John Potter, Anne-Marie Minihane, Colin D Kay, Eric B Rimm, Aedin Cassidy. \"Blueberries improve biomarkers of cardiometabolic function in participants with metabolic syndrome—results from a 6-month, double-blind, randomized controlled trial\". The American Journal of Clinical Nutrition, Volume 109, Issue 6, June 2019, Pages 1535–1545, [最強]早朝にプロテインと冷凍ブルーベリーのスムージーを飲んで筋トレする なんで朝なんだろう？？ 朝は、体の中からすべての栄養素がなくなっている状態だからです。 これは、人間の体が活動するうえで必要とされるエネルギー源からひも解くと理解いただけると思います。 所説ありますが、人間の活動エネルギー源は主に以下3つにわけられ、1→2→3の順番で使われます。 1. 炭水化物（糖質） ↓ 2. 筋肉 ↓ 3. 体についた脂肪 これら1～3のエネルギーは、最初に「1.炭水化物」が使われます。 炭水化物からのエネルギーを使い切った後は、「2.筋肉」を分解して発生されるエネルギーを活用します。 「もうこれ以上筋肉の分解エネルギーは使えませんよ。」という信号が脳に届いたときに、やっと「3.体についた脂肪」をエネルギー源にするのです。 要するにおなかがペコペコで、筋肉を使った運動した状態でやっと体の脂肪がエネルギー源になるということか。これって結構しんどいなぁ。 そこで、朝食で炭水化物を取らずにプロテイン＋ブルーベリーのスムージーを飲むのが最適なのです。 加えてスクワットなどの筋トレをするとどうなるでしょうか。 寝起きは栄養枯渇状態なので炭水化物はないですよね。 そして、筋トレをして筋肉にダメージをあたえると、人間の脳では「筋肉を分解させてはいけない」という信号が送られます。 その結果、体についた脂肪で活動する状態になるのです。 なるほど！寝起きは栄養枯渇状態。そこに脂質分解を促進するブルーベリーと、筋肉分解を抑えるプロテインを摂取しつつ筋トレすれば、脂肪が効率的に燃やせるんだね！ プロテイン＋冷凍ブルーベリースムージーの作り方 以下の有名Youtuberのkatochan33さんの動画の3:10当たりで紹介されているように、ミキサーにプロテインと冷凍のブルーベリーを入れて混ぜるだけです。 甘さすっきりで、かつ冷凍のフルーツの冷たさで朝飲むと目覚めが良いです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Angma ジューサー ミキサー 野菜 果物 ジュース 離乳食用 栄養補充 氷 一台多役 2つコップ 350ML\\/500ML 4000mAh 22000回転バッテリー 持ち運び 磁気誘導型安全機能 USB充電式 USB出力 アウトドア 旅行 出張 オフィス 日本語取扱説明書\",\"b\":\"Angma\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41HlUhSQfsS._SL500_.jpg\",\"\\/518fwXnYjMS._SL500_.jpg\",\"\\/51xYrdwDETS._SL500_.jpg\",\"\\/51c327lK64S._SL500_.jpg\",\"\\/51Dkx-VdH+S._SL500_.jpg\",\"\\/41Yz3c4aOeS._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B092ZKQ7QF\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B092ZKQ7QF\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Angma%20%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B5%E3%83%BC%20%E3%83%9F%E3%82%AD%E3%82%B5%E3%83%BC%20%E9%87%8E%E8%8F%9C%20%E6%9E%9C%E7%89%A9%20%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B9%20%E9%9B%A2%E4%B9%B3%E9%A3%9F%E7%94%A8%20%E6%A0%84%E9%A4%8A%E8%A3%9C%E5%85%85%20%E6%B0%B7%20%E4%B8%80%E5%8F%B0%E5%A4%9A%E5%BD%B9%202%E3%81%A4%E3%82%B3%E3%83%83%E3%83%97%20350ML%2F500ML%204000mAh%2022000%E5%9B%9E%E8%BB%A2%E3%83%90%E3%83%83%E3%83%86%E3%83%AA%E3%83%BC%20%E6%8C%81%E3%81%A1%E9%81%8B%E3%81%B3%20%E7%A3%81%E6%B0%97%E8%AA%98%E5%B0%8E%E5%9E%8B%E5%AE%89%E5%85%A8%E6%A9%9F%E8%83%BD%20USB%E5%85%85%E9%9B%BB%E5%BC%8F%20USB%E5%87%BA%E5%8A%9B%20%E3%82%A2%E3%82%A6%E3%83%88%E3%83%89%E3%82%A2%20%E6%97%85%E8%A1%8C%20%E5%87%BA%E5%BC%B5%20%E3%82%AA%E3%83%95%E3%82%A3%E3%82%B9%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E6%89%B1%E8%AA%AC%E6%98%8E%E6%9B%B8\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Angma%20%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B5%E3%83%BC%20%E3%83%9F%E3%82%AD%E3%82%B5%E3%83%BC%20%E9%87%8E%E8%8F%9C%20%E6%9E%9C%E7%89%A9%20%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B9%20%E9%9B%A2%E4%B9%B3%E9%A3%9F%E7%94%A8%20%E6%A0%84%E9%A4%8A%E8%A3%9C%E5%85%85%20%E6%B0%B7%20%E4%B8%80%E5%8F%B0%E5%A4%9A%E5%BD%B9%202%E3%81%A4%E3%82%B3%E3%83%83%E3%83%97%20350ML%2F500ML%204000mAh%2022000%E5%9B%9E%E8%BB%A2%E3%83%90%E3%83%83%E3%83%86%E3%83%AA%E3%83%BC%20%E6%8C%81%E3%81%A1%E9%81%8B%E3%81%B3%20%E7%A3%81%E6%B0%97%E8%AA%98%E5%B0%8E%E5%9E%8B%E5%AE%89%E5%85%A8%E6%A9%9F%E8%83%BD%20USB%E5%85%85%E9%9B%BB%E5%BC%8F%20USB%E5%87%BA%E5%8A%9B%20%E3%82%A2%E3%82%A6%E3%83%88%E3%83%89%E3%82%A2%20%E6%97%85%E8%A1%8C%20%E5%87%BA%E5%BC%B5%20%E3%82%AA%E3%83%95%E3%82%A3%E3%82%B9%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E6%89%B1%E8%AA%AC%E6%98%8E%E6%9B%B8\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"WukKA\",\"s\":\"s\"}); リンク プロテインは、正直好きなもので良いですが、ブルーべリーと相性がよく安価なプレーン味で良いのかなと思います。 参考ですが、プロテインの比較記事を作成したので興味があればこちらを参考にして最適なプロテインを探してみてください。 &gt;&gt;【徹底比較】毎日飲みたいホエイプロテイン 国産のもので一番安い江崎グリコさんのプロテインあたりが良いかもしれません。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"グリコ パワープロダクション ホエイプロテイン高たんぱく低糖質 プレーン味 800g【使用目安 40食分】WPI たんぱく質含有率95%(無水物換算値)カルシウム 鉄 ビタミン マグネシウム\",\"b\":\"パワープロダクション\",\"t\":\"G76035\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51-ZX8DumLL._SL500_.jpg\",\"\\/51hZqRwPMgL._SL500_.jpg\",\"\\/51OtX+MeH3L._SL500_.jpg\",\"\\/41noZnqe-GL._SL500_.jpg\",\"\\/513TtTLNghL._SL500_.jpg\",\"\\/517zjGEa9BL._SL500_.jpg\",\"\\/61dIzXjOXmL._SL500_.jpg\",\"\\/61akI-UMigL._SL500_.jpg\",\"\\/61dtD5eh6qL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0792SZGFQ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0792SZGFQ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%B0%E3%83%AA%E3%82%B3%20%E3%83%91%E3%83%AF%E3%83%BC%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E4%BD%8E%E7%B3%96%E8%B3%AA%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%E5%91%B3%20800g%E3%80%90%E4%BD%BF%E7%94%A8%E7%9B%AE%E5%AE%89%2040%E9%A3%9F%E5%88%86%E3%80%91WPI%20%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%E5%90%AB%E6%9C%89%E7%8E%8795%25(%E7%84%A1%E6%B0%B4%E7%89%A9%E6%8F%9B%E7%AE%97%E5%80%A4)%E3%82%AB%E3%83%AB%E3%82%B7%E3%82%A6%E3%83%A0%20%E9%89%84%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%9E%E3%82%B0%E3%83%8D%E3%82%B7%E3%82%A6%E3%83%A0\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%B0%E3%83%AA%E3%82%B3%20%E3%83%91%E3%83%AF%E3%83%BC%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E4%BD%8E%E7%B3%96%E8%B3%AA%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%E5%91%B3%20800g%E3%80%90%E4%BD%BF%E7%94%A8%E7%9B%AE%E5%AE%89%2040%E9%A3%9F%E5%88%86%E3%80%91WPI%20%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%E5%90%AB%E6%9C%89%E7%8E%8795%25(%E7%84%A1%E6%B0%B4%E7%89%A9%E6%8F%9B%E7%AE%97%E5%80%A4)%E3%82%AB%E3%83%AB%E3%82%B7%E3%82%A6%E3%83%A0%20%E9%89%84%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%9E%E3%82%B0%E3%83%8D%E3%82%B7%E3%82%A6%E3%83%A0\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"y6Hia\",\"s\":\"s\"}); リンク ブルーベリーは以下の国産の冷凍ブルーベリーが美味です！ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"南信州ここだに 長野県産 ブルーベリー 冷凍 国産 加工用 家庭用 (700g)\",\"b\":\"南信州ここだに\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51hFDz1SSnL._SL500_.jpg\",\"\\/41iSpMMFM3L._SL500_.jpg\",\"\\/51FIwAdk1vL._SL500_.jpg\",\"\\/61bhKMo1ZOL._SL500_.jpg\",\"\\/51PRqZLdI9L._SL500_.jpg\",\"\\/51jm9D2UGwL._SL500_.jpg\",\"\\/5111ymcjAQL._SL500_.jpg\",\"\\/51NH-2MdEYL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07MM5TQ87\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07MM5TQ87\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E5%8D%97%E4%BF%A1%E5%B7%9E%E3%81%93%E3%81%93%E3%81%A0%E3%81%AB%20%E9%95%B7%E9%87%8E%E7%9C%8C%E7%94%A3%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%99%E3%83%AA%E3%83%BC%20%E5%86%B7%E5%87%8D%20%E5%9B%BD%E7%94%A3%20%E5%8A%A0%E5%B7%A5%E7%94%A8%20%E5%AE%B6%E5%BA%AD%E7%94%A8%20(700g)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E5%8D%97%E4%BF%A1%E5%B7%9E%E3%81%93%E3%81%93%E3%81%A0%E3%81%AB%20%E9%95%B7%E9%87%8E%E7%9C%8C%E7%94%A3%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%99%E3%83%AA%E3%83%BC%20%E5%86%B7%E5%87%8D%20%E5%9B%BD%E7%94%A3%20%E5%8A%A0%E5%B7%A5%E7%94%A8%20%E5%AE%B6%E5%BA%AD%E7%94%A8%20(700g)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"58c4t\",\"s\":\"s\"}); リンク まとめ 脂肪燃焼したいなら、朝起きて炭水化物を食べずにプロテインとブルーベリーのスムージを飲むが最適であることが分かりました！ よく読まれている記事 2020-01-11風邪予防はビタミンCとグルタミンのサプリメントが最強Health 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/blueberries-improve/"},{"title":"オブジェクト指向のクラスをシンプルに理解する","text":"プログラミングを学習すると、高い確率で「オブジェクト指向」という言葉に誰しもが悩まされると思います。 本記事では、とてもシンプルにオブジェクト指向のClassの使い方をまとめます。 実際にご自身のプログラミング環境で手を動かしながら勉強してみてください。 ✓目次 この記事の対象者 プログラミングの環境を用意しよう。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態 クラス(設計書)を作成する。 クラス(設計書)の項目にパラメータを設定する。 クラス(設計書)をインスタンス化(実態化)する。 インスタンスに名前と国と年齢を聞いてみる。 クラス（設計書）の設計項目を変数にする。 【発展】インスタンスが挨拶する関数を作ってみる。 【発展】call関数の使い方 最後に この記事の対象者 プログラミングを勉強し始めたがオブジェクト指向、クラス、インスタンスというのが良くわからない人 回りくどい説明が嫌な人 シンプルなコードで、ざっくりと理解したい人 プログラミングの環境を用意しよう。Jupyter Notebookという環境で説明します。 以下、この記事を読まれている方の思考に応じて、2パターンのプログラミング環境の用意の仕方を紹介します。 その1:自分のPCにプログラミング環境を用意したい人 以下の記事を参考に、ご自身のPCに環境構築してみてください。 その2：環境構築とか面倒、という人 Google Colaboratoryがおすすめです。 Google Chromeとgoogleのアカウントを持っていれば、ブラウザ(Google Chrome)のみでプログラミング環境が用意できます。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態様々な本で同じような説明がされていると思います。 ここからは実際に簡単なソースコードを活用しながらクラスとはどのようなものなのかを理解していただければと思います。 クラス(設計書)を作成する。設計書には、最低限以下の2つを定義しなければいけません。 設計書の名前 設計項目 具体的な例として、人間(Person)という設計書を作っていきましょう。 今回は以下のような設計書を作ろうと思います。 設計書の名前: Person 設計項目 名前: name 国: nationality 年齢: age 早速、Personという設計書として名前, 国, 年齢という3つの設計項目を用意してみます。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"\" # 名前 self.nationality = \"\" # 国 self.age = \"\" # 年齢 このコードをJupyter Notebookのセルに記載して、実行してください。 SHIFTを押しながらEnterキーで実行できます。 これで、「人間」というクラス（設計書）ができました。 クラス(設計書)の項目にパラメータを設定する。次に、この設計書の各項目に値を設定します。 設定する値は、以下のようにしたいと思います 名前：鈴木 国：日本 年齢：10 早速、先ほどの設計書の設計項目に設定していきましょう。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"鈴木\" # 名前 self.nationality = \"日本\" # 国 self.age = \"10\" # 年齢 これでOKです。 クラス(設計書)をインスタンス化(実態化)する。ここまで作ってきた人間クラス（人間の設計書）を実体化します。 これも簡単です。 1suzuki = Person() これで、「suzuki」というインスタンス(実体)が作られました。 これまで作ってきたPersonという設計書からsuzukiという名前の人間を作ったのです。 もちろん、suzukiという名前のインスタンスではなく、satoという名前でインスタンス化しても問題ありません。 1sato = Person() ただし、Personという設計書には、”佐藤”ではなく”鈴木”という名前が設定されていました。 それにもかかわらずsatoという名前でインスタンス化してしまうと、外見は佐藤なのに、名前が鈴木という変な人間が作られてしまいます。 これを解決する方法についても後述しますので、読んでみてください。 インスタンスに名前と国と年齢を聞いてみる。suzukiという人間と、satoという人間が作られました。 まずはsuzukiさんに名前を聞いてみましょう。以下のコードで名前を聞くことができます。 1suzuki.name Jupyter notebook環境だと、以下のようになります。 名前と国と年齢をまとめて聞く場合は以下のようにすればOKです。 123print(suzuki.name)print(suzuki.nationality)print(suzuki.age) すると、以下のように出力されるはずです。 satoというインスタンスにも名前を聞いてみます。 想定通り、satoさんにもかかわらず”鈴木”と返ってきました。 でもこれ不便だと思いませんか？ クラス(設計書)の各設計項目に、鈴木、日本、10(歳)、という風に設定しまうと、suzukiというインスタンスしか作れなくなってしまいます。 できるなら、satoの中には、”佐藤”という名前を設定したいし、katoの中には”加藤”という名前を設定してほしくないですか？ これを解決する手段として、クラス(設計書)の設計項目を変数にするというのがあります。 クラス（設計書）の設計項目を変数にする。ここまで作成してきたPersonクラスの各設計項目(名前、国、年齢)には、”鈴木”、”日本”、10と設定していたいましたが、これをnamae, kuni, toshiという変数を設定します。※変数名は何でもOKです。 以下のようになります。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = namae # namaeという変数を設定 self.nationality = kuni # kuniという変数を設定 self.age = toshi # toshiという変数を設定 もう少し改造が必要です。 def __init__(self):の部分に、先ほど設定した3つの変数を追記して、def __init__(self, namae, kuni, toshi):とします。 1234567class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi インスタンス化してみます。 今回は、katoでインスタンス化してみたいと思います。 1kato = Person() すると、以下のようにエラーになると思います。※安心してください、想定通りです。 なぜエラーになったのかというと、インスタンス化する際に、クラス（設計書）の設計項目に設定した変数に代入する値を設定していなかったからです。 つまり、インスタンス化する時は、クラスで規定したnamae, kuni, toshiに代入する値を()に記載しなければいけないということです。 今回は、katoというインスタンスを作成するので、各設計項目に設定する値は以下とします。 名前(namae): 加藤 国(kuni): 日本 年齢(toshi): 30 以下のようにしてkatoというインスタンスを作成しましょう。 1kato = Person(\"加藤\", \"日本\", 30) ついでに、mikeというインスタンスも作成します。 1mike = Person(\"mike\", \"アメリカ\", 20) こうすることで、kato.nameと実行すれば”加藤”というのが出力されますし、mike.nameと実行すれば”mike”というのが出力されます。 【発展】インスタンスが挨拶する関数を作ってみる。発展と言っても難しくないのでご安心ください。 作成したインスタンスに、「こんにちは井上さん。私は鈴木です。」という風な感じで、挨拶をする関数を実装してみます。 以下の通り、9行目と10行目を追記してください。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self): print('こんにちは井上さん。私は鈴木です。') 早速インスタンス化しましょう。 まずはsuzukiさんというインスタンスを作成します。各変数に代入する値の設定を忘れずに！ 1suzuki = Person(&quot;鈴木&quot;, &quot;日本&quot;, 1) 早速、suzukiに挨拶をさせてみましょう。 1suzuki.say_hello() 以下のようにちゃんと挨拶ができました。 では次にbobさんというインスタンスを作成しましょう。この際も、各変数のに代入する値の設定を忘れずに! 1bob = Person(\"ボブ\", \"アメリカ\", 70) bobに挨拶をさせてみましょう。 1bob.say_hello() 以下のように出力されます。 ここまで来たらある程度予測できたのではないでしょうか。 そうです、ボブなのに、「私は鈴木です。」と言ってますね。 理想としては、ボブだったら、「私はボブです。」と挨拶できるようにしたいですよね？ あと、「こんにちは井上さん。」の”井上”の部分も、設定に応じて柔軟に変化できるようにしたいです。 順序が逆になってしまいますが、まずは、「こんにちは井上さん。」の”井上”の部分を柔軟に設定できるように変数化してみたいと思います。 これを解決する方法は、以下のように、say_hello(self, namae):という風に、namaeという変数を追加し、print('こんにちは{}さん。私は鈴木です。'.format(namae))という風に変更/追記すればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は鈴木です。'.format(namae)) 改めて、bobさんというインスタンスを作成し、近藤さんに挨拶をさせてみましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)bob.say_hello(\"近藤\") 以下の通り、「こんにちは近藤さん。私は鈴木です。」という風に、井上さんが近藤さんに代わりました。 最後に、bobというインスタンスの場合は、「私はbobです。」に変換し、tomというインスタンスの場合は「私はtomです。」という風に出力させるように改造します。 まず、”鈴木”の部分を{}に変更しします。 そして、この中括弧に当てはまる変数ですが、ここはインスタンス化する際に設定する名前なので、5行目のself.nameを指定すれば良いです。 selfは”自分自身の”と言い換えればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行したら、早速bobインスタンスとtomインスタンスを作成しましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)tom = Person(\"トム\", \"アメリカ\", 120) bobとtomに挨拶をさせてみます。 1bob.say_hello('近藤') 1tom.say_hello('山本') 以下の通り、ちゃんと期待通りに挨拶する相手を呼び、自分の名前を言えるようになりました。 【発展】call関数の使い方ここからはさらに発展になるので、「もう限界です。」という方は、ここまででも大丈夫です。 call関数というのは簡単に言うと、関数名を呼び出さずに処理を実行させることができる関数です。 言葉で説明するよりか、実際の動作を見たほうが分かるので、早速使い方を見ていきましょう。 以下のように、__call__という関数名で、say_hello()関数と同様の処理を定義してみます。 12345678910111213class Person: def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi # call関数でsay_hello()を定義 def __call__(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行し、yamadaというインスタンス作成します。 1yamada = Person(\"山田\", \"日本\", 200) そして、yamada.sayhello('大和田')というコードと、yamada.__call__('大和田')というコードを実行してみると、共に、「こんにちは大和田さん。私は山田です。」という出力が得られます。 では次に、yamada('大和田')という風に、関数名を宣言せずに実行してみてください。 すると、同様に、「こんにちは大和田さん。私は山田です。」と出力されます。 つまり、yamada.__call__('大和田')という風にわざわざ書かなくても、yamada('大和田')とするだけで、同様の処理が実行されるのです。 以下の通りです。 便利な関数なので、積極的に使ってみましょう。 最後に 本記事では、クラス、インスタンスの関係に加えて、関数の定義方法やcall関数についてもまとめました。 プログラミング学習については、以下の記事でおすすめの教材や勉強方法をまとめていますので、興味のある方は読んでみてください。","link":"/class-practice/"},{"title":"【5分で分かる】データモデルとデータベースの設計方法と関係性","text":"本記事では、「【5分で分かる】データモデルとデータベースの設計方法と関係性」というテーマでまとめていきます。 目次 本記事の対象者 データ/データベースとは何か データベースを作成する一連の過程：「データモデリング」 データベース構築の工程その１: 企業の業務の全体像を把握する データベース構築の工程その２: データベースで管理すべき項目を洗い出す 論理データモデルの種類: ①階層型データモデル(木構造) 論理データモデルの種類: ②ネットワーク型データモデル 論理データモデルの種類: ③リレーショナルデータモデル データベース構築の工程その３: 各データベースに合わせて設計する データベースの設計ポイント リレーショナルデータベースの弱点と「NoSQL」 まとめ：データべースの設計はデータモデリングが大事 本記事の対象者 「データモデル」って何？という人 データモデリングってどのような手順で考えればいいの？という人 データベースを設計する際に気をつけるポイントを知りたい人 データ/データベースとは何か「データ」とは、実際に存在するものを文字や数字や画像など、コンピュータ上で表現したものです。 例えば、「住所」、「氏名」、「年齢」などがデータに相当します。 そして、データの集合体のことを「データベース」と言います。ITの業界では、「DB」と略されることが多いです。 データベースを作成する一連の過程：「データモデリング」 データベースを作成するまでの一連の過程を「データモデリング」といいます。 データモデリングでは、実際の業務をシステム化するために、必要なデータ項目を整理して可視化します。 データベース構築の流れ、すなわちデータモデリングは、以下のとおりです。 １. 企業の業務の全体像を把握する 2. データベースで管理すべき項目を洗い出す 3. 各データベースに合わせて設計する そして、1~3の各工程で作成した情報が、「データモデル」です。 以降では、データモデリング工程である1~3の内容と、作成されるデータモデルについてまとめていきます。 データベース構築の工程その１: 企業の業務の全体像を把握するデータベースを設計するためには、対象となる業務の流れを調査・分析し、理解する必要があります。 例えば、お客様の注文情報管理システムを作成するといった要望があった場合、お客様の注文情報をデータ化するだけではシステムは作れません。 お客様の注文を管理するためには、注文を受けた商品の在庫を確認する業務や、発送する業務といった業務の流れが存在します。 このように業務の流れを調査し、全体像を理解することがデータベースを作成するためには必要です。 この際、細かい業務までを把握する必要はありません。 その業務において重要な業務を抽出すれば良いのです。 例えば、「営業」、「オーダー受付」、「商品」、「在庫」、、という具合です。 このように、「営業」、「オーダー受付」など、企業にとって重要な一つ一つの業務のことを「エンティティ」と言います。 そしてエンティティを抽出したものを「概念データモデル」といいます。 データベース構築の工程その２: データベースで管理すべき項目を洗い出す概念データモデルにより業務の全体を把握できたら、データ化する業務や項目をまとめていきます。 具体的には、「エンティティ」、「属性」、「各テーブルのリレーションシップ」を決定していきます。 例えば、「オーダー受付」と「商品」というエンティティをデータ化する場合で説明します。 まず「オーダー受付」という業務を行う上で、どのようなデータが必要なのかを整理します。 必要なデータを、ここでは仮に、「オーダーID」、「オーダー日時」、「顧客ID」だとします。 この「オーダーID」、「オーダー日時」、「顧客ID」それぞれを、「属性」と言います。 次に、各属性間の関係を整理します。 各属性間の関係は、特定の属性が他のエンティティにどれだけ紐付いているのかを線で結ぶことで整理します。 例えば以下のように、「オーダーID」という属性が商品というエンティティにも紐付いていることを示すことで、各エンティティ間の関係性を可視化します。 この関係性を「リレーションシップ」と言います。 以上のように、各エンティティにおける属性、リレーションシップが定義されたものを、「論理データモデル」と言い、論理データモデルによって、データ化する業務や項目を可視化することができるのです。 論理データモデルをまとめていく際の注意点としては、データ型などの細かい定義を行わないことです。 この段階では、まずは、MySQLといったデータベース管理システムに依存しないレベルで項目を洗い出していくことを前提にしましょう。 また、論理データモデルには、いくつか種類があります。 それぞれの特徴を簡単に紹介したいと思います。 論理データモデルの種類: ①階層型データモデル(木構造)階層型データモデルとは、データを親子関係で管理するモデルです。 階層構造の特徴は、1対多の関係にしか対応できない制約があります。 階層構造を満たすデータしか対応できませんが、階層構造のデータであれば高速で検索することが可能になります。 論理データモデルの種類: ②ネットワーク型データモデルネットワーク型データモデルとは、子データが複数の親データを持っているデータモデルのことです。 ネットワーク型データモデルは、多対多を表現することができます。 階層型データモデルに比べて、より複雑なデータモデル作成することが可能ですが、構造が複雑になりすぎる点がデメリットになります。 論理データモデルの種類: ③リレーショナルデータモデルリレーショナルデータモデルは、行と列によって構成された表のようなモデルのことです。 現在最も利用されているデータモデルであり、見やすく扱いやすいことに加え、複雑なデータ構成にも対応することができます。 データベース構築の工程その３: 各データベースに合わせて設計する実装フェーズに向けた詳細設計を進めていきます。 定義することは、各属性のデータ型、テーブル構成が主になります。 最も一般的に使われているデータベースは「リレーショナルデータベース」というデータベースです。 リレーショナルデータベースとは、データを表（テーブル）で管理するデータベースであり、行と列の組み合わせによってデータを管理しています。 このリレーショナルデータベースを管理するのが、RDBMSと呼ばれる「リレーショナル型データベース管理システム」というものです。 データの型やデータの構造の設計は、使用するRDBMSが定義するデータの型やデータ構造を前提に設計しなければなりません。 RDBMSにはいくつか種類があります。 Oracle DataBase米国のIT企業「Oracle」が開発しているデータベース。オンプレミスでもクラウドでも利用することができ、リレーショナル、グラフ、構造化および非構造化リレーショナルなどの全てのデータ型をサポートします。企業など、大規模システム開発で利用されることが多いデータベースです。 MySQL米国のIT企業「Oracle」が開発したRDBMSです。MySQLは、無料のオープンソースのデータベースです。無料でありながらも大規模なWebシステムにも対応することができます。 SQLServerSQLServerは、MicroSoftが提供するRDBMSです。Windowsとの相性が良く、UIもわかりやすいのが特徴です。GUI上の操作でデータベースを管理することができます。小規模な開発から大規模な開発まで対応できます。 データベースの設計ポイント ここではリレーショナルデータモデルを例に、基本的な設計の考え方や設計方法をまとめていきます。 リレーショナルデータモデルは、二次元の表であり、この二次元の表を「テーブル」と呼びます。 テーブルは、「カラム」、「レコード」、「フィールド」で構成されています。 こちらのテーブルを例に、テーブルのリレーションの考え方・ポイントについて解説します。 仮にこのテーブルに、「部署」という情報も加えたいとなった場合、どうすればよいでしょうか？ まず考えられるのは、新たに「部署」というカラムを作るというやり方が考えられます。 このように「部署」というカラムを作った後、例えば「HR」という部署名を変えたいとなった場合、どうなるでしょうか。 「HR」という文字列を、「Planning」に変更するとき、2箇所のフィールドを変更しなければなりません。 2つくらいであれば良いですが、これが100とか。1000とかになったらどうなるでしょうか？ 多くの処理が必要になり大変です。 これを防ぐためには、「部署テーブル」という新たなテーブルを作成し、「部署ID」をもたせれば良いのです。 こうすることによって、「HR」という部署名を変えたいとなった場合、部署テーブルの「HR」というフィールド１つだけを変えれば良いことになります。 以上のように、１つの表のカラムの中に、重複するデータが存在する場合は、別のテーブルを用意し、そのテーブルの１ヶ所を変更するだけで全て変更できるようにするのがポイントになります。 このように、データの重複をなくし、データの整合性を保てるようなデータベースを設計する方法のことを「正規化」と言います。 データベースを設計する際は、正規化を行い、データの重複を無くし整合性を保てるようなデータベースを設計することが大切なのです。 リレーショナルデータベースの弱点と「NoSQL」これまで説明してきたリレーショナルデータベースにも弱点があります。 それは、複雑な業務のシステム化など大規模なシステム開発になればなるほど、データベースが複雑化していくということです。 複雑な業務になることで、データベース内のテーブル数や項目が増加していくことになります。 これはプログラムが複雑化し、処理のスピードが低下する傾向があります。 複雑なデータを管理することができる一方で、大規模なデータになると処理速度が追いつかなくなるというデメリットがあります。 近年のIoTやAIにおいては、大量のデータを管理する必要があります。 今後、膨大なデータを扱うことが想定される将来を見据えた場合、必ずしもリレーショナル型データベースが望ましいとは言い切れません。 また、管理するデータの種類も、従来のような文字列、数値といったデータではなく、画像や音声といったデータ（非構造化データ）も対象となります。 そこで注目されているのが「NoSQL」と呼ばれるデータベースです。 NoSQLとは、SQL言語を使用せずに利用できるデータベースのことです。 NoSQLは、非構造化データの管理において、リレーショナルデータベースよりもコストやパフォーマンスに優れています。 今後は、NoSQL型のデータベースを使用する機械は増えてくるでしょう。 注意点としては、リレーショナル型データベースとNoSQLは、どちらが優れているということではありません。 複雑な業務でない限りは、リレーショナル型データベースが良いのは変わりありません。 扱うデータや状況によって、どちらを使うべきかを考える必要があるということを理解しておきましょう。 まとめ：データべースの設計はデータモデリングが大事本記事では、「【5分で分かる】データモデルとデータベースの設計方法と関係性」というテーマでまとめました。 データベースを作成する一連の過程のことを「データモデリング」と良い、各過程で作成される成果物がデータモデルでした。 データモデリングは、大きく3つの工程でしたね。 1. 企業の業務の全体像を把握する 2. データベースで管理すべき項目を洗い出す 3. 各データベースに合わせて設計する 実装を想定したデータベースの設計は、データの重複を無くし整合性を保つことを意識するのが大切です。 本記事ではリレーショナル型データベースにフォーカスして設計のポイントを纏めましたが、リレーショナルデータベースにもデメリットがあることも触れました。 将来を見据えた業務、そして扱うデータの種類によってNoSQLを選択するべきかどうかを考えるのが重要です。 データベースの設計の基本的なエッセンスをまとめましたが、本記事でまとめたこと以外にも多くの注意点や学ぶべきポイントが多くあります。 実際にデータベースの設計を問題形式で解いてみると、より知識を深められるかと思います。 データベースをより詳しく学びたい方 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"データベースリライアビリティエンジニアリング ―回復力のあるデータベースシステムの設計と運用\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/511NdH-fR9L._SL500_.jpg\",\"\\/41p4V-I7lzL._SL500_.jpg\",\"\\/31QkYUMsDRL._SL500_.jpg\",\"\\/41VDGYlyTYL._SL500_.jpg\",\"\\/31rMRlIj1sL._SL500_.jpg\",\"\\/51pmyCes+NL._SL500_.jpg\",\"\\/5141mFyXFhL._SL500_.jpg\",\"\\/512I0dUahCL._SL500_.jpg\",\"\\/51ncbMUsaJL._SL500_.jpg\",\"\\/41vlQPR9cfL._SL500_.jpg\",\"\\/41MnRuKQ47L._SL500_.jpg\",\"\\/51gMbNtVHDL._SL500_.jpg\",\"\\/51dMZIddw3L._SL500_.jpg\",\"\\/51vBi9vEO8L._SL500_.jpg\",\"\\/51qFOc5i8bL._SL500_.jpg\",\"\\/51XjoPMkDlL._SL500_.jpg\",\"\\/51OMf+duZ0L._SL500_.jpg\",\"\\/31pVILqY1RL._SL500_.jpg\",\"\\/51caNyR-PgL._SL500_.jpg\",\"\\/51yxnjoBbeL._SL500_.jpg\",\"\\/515vDGEw2FL._SL500_.jpg\",\"\\/51s5yUGUtnL._SL500_.jpg\",\"\\/51rHKf8yBdL._SL500_.jpg\",\"\\/51K1Oeh2pHL._SL500_.jpg\",\"\\/51zmVGFdK0L._SL500_.jpg\",\"\\/51-+M12sGpL._SL500_.jpg\",\"\\/51aCm8L5Z2L._SL500_.jpg\",\"\\/51-JojgOctL._SL500_.jpg\",\"\\/51ZRJ-nfCML._SL500_.jpg\",\"\\/51Ky5LlSiHL._SL500_.jpg\",\"\\/31EYupAmmqL._SL500_.jpg\",\"\\/516tgz77DsL._SL500_.jpg\",\"\\/51rWfDFX5uL._SL500_.jpg\",\"\\/51eJW5tscGL._SL500_.jpg\",\"\\/41ZjlkA9SjL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873119405\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873119405\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E3%83%AA%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%93%E3%83%AA%E3%83%86%E3%82%A3%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%20%E2%80%95%E5%9B%9E%E5%BE%A9%E5%8A%9B%E3%81%AE%E3%81%82%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E8%A8%AD%E8%A8%88%E3%81%A8%E9%81%8B%E7%94%A8\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"cMWvB\",\"s\":\"s\"}); リンク 【視聴期限無し】Udemyを使って動画でデータベース設計を学ぶ【30日間返金保証付き】 参考文献 DB設計におけるデータモデル - Ren’s blog","link":"/datamodel/"},{"title":"【Windows】DockerでRuby on Rails開発環境構築方法","text":"✓目次 この記事の対象者 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Dockerfile GemfileとGemfile.lock docker-compose.yml Rails開発環境の構築 まとめ この記事の対象者 ・ Windows10のPC(Windows10 Pro 64bit)でDockerを用いてRuby on Railsの環境を作りたい人 ・ Rails version: 5.0.0.1, Ruby version: 2.4.5, MySQL 5.7系の環境構築方法を知りたい人 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Windows10のPCにDockerを導入し、Ruby on Rails環境を構築する大まかな流れは以下のとおりです。 Docker for Windowsのインストールと再起動→再起動後、Dockerが起動しているかタスクバーのアイコンを確認 PowerShellを起動しdocker run hello-worldを実行してDockerが正常に動作するかを確認 任意の場所にフォルダを作成し、以下のファイルを用意する Dockerfile Gemfile Gemfile.lock docker-compose.yml 上記4つのファイルを用いてコンテナ起動 以降は主に、3. と4. の工程を中心にまとめています。 Dockerfile 所定のフォルダに以下のようなDockerfileを用意します。 Dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app Dockerfileには、Railsを実行するためのファイルやパッケージを、イメージに含めるための定義が書かれています。 このDockerfileがビルドされることで、Docker Imageというコンテナ仮想環境の雛形が作成されるのです。 ruby:2.4.5のコロンの前の部分を、リポジトリと言い、コロンの後ろを、タグといいます。 この場合、2.4.5のタグを書いています。 リポジトリには様々なバージョンがあります。詳細は、以下のDocker Hubを参照してみてくださいhttps://hub.docker.com/_/ruby?tab=tags&amp;page=1&amp;ordering=last_updated COPY . /appはDockerファイルの置いてあるフォルダの内容をすべてコンテナ内の/appディレクトリにコピーをしています。これは、Railsのアプリケーション実行に必要なファイルを、全てコンテナの中に含めるために記載しています。そのため、余計なファイルを含めてしまうと、コンテナに含まれてしまうので関係ないファイルは置かないようにしましょう。 GemfileとGemfile.lock Gemfile12source 'https://rubygems.org'gem 'rails', '5.0.0.1' GemfileはインストールするGemを定義しておくためのファイルです。 sourceには、GemのダウンロードもとのURLを記載しておきます。 そしてインストールするGemにはRailsのバージョンである5.0.0.1を指定しています。 このファイルが配置されているディレクトリで、$ bundle installコマンドを実行することで、RailsのGemをダウンロードして、インストールが実行されます。 Gemfile.lockは、最初の時点では空のファイルとなります。これは、通常直接編集するものではなく、$ bundle installを行った場合に、実際にインストールしたGemのリストとバージョンが自動的にGemfile.lockに配置されます。 Gemfile.lock1(空のファイル) Gemfile.lockの用途は、サーバや他の開発者のPCなど、別の環境で同じRailsアプリを動かす場合に、同じGemをインストールするために仕様されます。 Gemのインストールの際にはインストールするGemを動かすために必要な別のGemも一緒にインストールされます。 こういったあるライブラリーが別のファイブラリを必要としていることを依存関係といいます。 Gemのインストール時には、この依存関係の解決が行われ、関係する様々なGemがまとめてインストールされます。 依存関係も含めて何がインストールされたのかが、すべてGemfile.lockに記載されます。 そして、このGemfile.lockを別のPCやサーバに持って行って、bundle installコマンドを実行すると、Gemfile.lockに記載された内容にしたがって、Gemのインストールが実行される、というわけです。 docker-compose.ymlDocker-compose.ymlは、Dockerで複数のコンテナを、設定に従ってまとめて起動するために使用します。 Docker-compose.ymlは、Dockerで複数のコンテナを、設定に従ってまとめて起動するために使用します。 Railsを実行するコンテナとMySQLサーバを実行するコンテナの二つを起動する定義を記載してあります。 以下のようなコードが書かれたファイルを用意します。 docker-compose.yml123456789101112131415161718192021version: '3' # docker-compose.ymlのフォーマットバージョンservices: web: # Railsのコンテナ設定 build: . # docker-compose.ymlと同じディレクトリにあるdockerファイルを元にイメージを作成して使用することを意味している。 command: bundle exec rails s -p 3000 -b '0.0.0.0' # コンテナを起動した時にデフォルトで実行されるコマンド。TailsのWebサーバを起動するコマンドを記載。 volumes: # PC上のディレクトリをコンテナの/appディレクトリにマウント - .:/app ports: - 3000:3000 # コンテナの外部に3000番ポートを公開。コロンの左側がコンテナ外に公開するポート番号で、コロンから右側が、コンテナ内で転送されるポート番号になります。 depends_on: - db # Railsが起動する前にdbサービス、すなわちMySQLサーバが先に起動するように設定 tty: true # Railsでplyを使用してデバッグする際に必要な為、設定しています stdin_open: true # Railsでplyを使用してデバッグする際に必要な為、設定しています db: # MySQLサーバのコンテナ設定 image: mysql:5. # MySQLの5.7を使用 volumes: - db-volume:/var/lib/mysql # db-volumeという名前でPC上に作成した領域をコンテナの/var/lib/mysqlディレクトリにマウント。これを設定しない場合、データベースのデータは、直にコンテナ上に保存されますが、コンテナが削除された場合には、データも一緒に消えてしまいます。 environment: # コンテナに設定する環境変数を定義しています。環境変数とはOS上で保持される変数のことで、ここで設定しているMYSQL_ROOT_PASSWORDは、MySQLのrootユーザのパスワードを設定するために使用しています。 MYSQL_ROOT_PASSWORD: passwordvolumes: db-volume: Rails開発環境の構築 ここまで解説した設定ファイルを使用して、Railsの開発環境を動かしてみます。 まずは、解説したファイルを配置したフォルダでターミナルを開きます。Windowsを使用している方は、PowerShellを使用しましょう。 terminal123456$ cd documents/rails$ ls -l-rw-r--r-- 1 omashi 197121 365 2月 13 2018 docker-compose.yml-rw-r--r-- 1 omashi 197121 205 8月 22 19:16 Dockerfile-rw-r--r-- 1 omashi 197121 1748 8月 22 19:17 Gemfile-rw-r--r-- 1 omashi 197121 4404 8月 22 19:17 Gemfile.lock 以下のコマンドを実行します。 terminal1$ docker-compose run web rails new . --force --database=mysql docker-compose run webの部分は、docker-composeファイルに定義したweb:のRailsコンテナ設定を指しており、Railsのコンテナ上で、後ろに続くコマンドを実行することを意味しています。 --forceは既存ファイルを上書きするオプション。--database=mysqlはMySQLを使用する設定を明示的に示すオプションです。 実行が完了すると、Railsのファイルが作成されます。 terminal12345678910111213141516171819$ ls -ltotal 33drwxr-xr-x 1 user 197121 0 8月 22 19:17 appdrwxr-xr-x 1 user 197121 0 8月 22 19:17 bindrwxr-xr-x 1 user 197121 0 8月 22 19:17 config-rw-r--r-- 1 user 197121 130 8月 22 19:17 config.rudrwxr-xr-x 1 user 197121 0 8月 22 19:17 db-rw-r--r-- 1 user 197121 365 2月 13 2018 docker-compose.yml-rw-r--r-- 1 user 197121 205 8月 22 19:16 Dockerfile-rw-r--r-- 1 user 197121 1748 8月 22 19:17 Gemfile-rw-r--r-- 1 user 197121 4404 8月 22 19:17 Gemfile.lockdrwxr-xr-x 1 user 197121 0 8月 22 19:17 libdrwxr-xr-x 1 user 197121 0 8月 22 19:17 logdrwxr-xr-x 1 user 197121 0 8月 22 19:17 public-rw-r--r-- 1 user 197121 227 8月 22 19:17 Rakefile-rw-r--r-- 1 user 197121 374 8月 22 19:17 README.mddrwxr-xr-x 1 user 197121 0 8月 22 19:17 testdrwxr-xr-x 1 user 197121 0 8月 22 19:17 tmpdrwxr-xr-x 1 user 197121 0 8月 22 19:17 vendor ここでGemファイルに追記されたGemのインストールや作成されたファイルをコンテナ内に取り込むために、以下のコマンドで、もう一度ビルドを実行します。 terminal1$ docker-compose build ビルドが完了したらRailsで使用するデータベースの設定ファイルを編集します。ファイルはConfigディレクトリ内にあるdatabase.ymlになります。default:の項目にある、パスワードとホストを変更します。 パスワードは、docker-compose.ymlに記載したMySQL_ROOT_PASSWORD環境変数のpasswordに合わせる必要があります。ホスト名もdocker-compose.ymlに記載したMySQLサーバのサービス名であるdbに合わせます。 /Config/database.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# MySQL. Versions 5.0 and up are supported.## Install the MySQL driver# gem install mysql2## Ensure the MySQL gem is defined in your Gemfile# gem 'mysql2'## And be sure to use new-style password hashing:# http://dev.mysql.com/doc/refman/5.7/en/old-client.html#default: &amp;default adapter: mysql2 encoding: utf8 pool: 5 username: root password: password # この部分を変更 host: db # この部分を変更development: &lt;&lt;: *default database: app_development# Warning: The database defined as \"test\" will be erased and# re-generated from your development database when you run \"rake\".# Do not set this db to the same as development or production.test: &lt;&lt;: *default database: app_test# As with config/secrets.yml, you never want to store sensitive information,# like your database password, in your source code. If your source code is# ever seen by anyone, they now have access to your database.## Instead, provide the password as a unix environment variable when you boot# the app. Read http://guides.rubyonrails.org/configuring.html#configuring-a-database# for a full rundown on how to provide these environment variables in a# production deployment.## On Heroku and other platform providers, you may have a full connection URL# available as an environment variable. For example:## DATABASE_URL=\"mysql2://myuser:mypass@localhost/somedatabase\"## You can use this database configuration with:## production:# url: &lt;%= ENV['DATABASE_URL'] %&gt;#production: &lt;&lt;: *default database: app_production username: app password: &lt;%= ENV['APP_DATABASE_PASSWORD'] %&gt; 設定が完了したら、以下のコマンドを実行。のコマンドにより、RailsサーバーのコンテナとMySQLサーバのコンテナが起動します。 terminal1$ docker-compose up -d コンテナが起動しているか確認します。 terminal123456$ docker-compose ps指定されたパスが見つかりません。 Name Command State Ports--------------------------------------------------------------------------------rails_db_1 docker-entrypoint.sh mysqld Up 3306/tcp, 33060/tcprails_web_1 bundle exec rails s -p 300 ... Up 0.0.0.0:3000-&gt;3000/tcp 起動はしましたが、まだ開発環境用のデータベースが作成されていない状態なので、次のコマンドでデータベースを作成します。 terminal123456$ docker-compose run web bundle exec rake db:createStarting rails_db_1 ... done/usr/local/bundle/gems/activesupport-5.0.0.1/lib/active_support/xml_mini.rb:51: warning: constant ::Fixnum is deprecated/usr/local/bundle/gems/activesupport-5.0.0.1/lib/active_support/xml_mini.rb:52: warning: constant ::Bignum is deprecatedCreated database 'app_development'Created database 'app_test' これも先ほどと同様に、bundle exec以降がRailsのコンテナ内で実行されるコマンドです。 bundle exec rakeはRails環境にインストールされているrakeコマンドの実行を表しており、後ろにはdb:createと書いてあります。 rakeコマンドは、Railsで様々なタスクを実行する際に使用されるもので、rake db:createとした場合は、dbがまだ存在しない場合に新規に作成してくれます。 つまり、bundle exec rakeの部分は、Rails環境にインストールされているrakeコマンドを実行し、rake db:createでRailsで使用するデータベースをMySQLサーバ上に作成してくれます。 これで、Railsサーバにアクセス可能な状態になっているはずですので、ブラウザのURL欄にlocalhost:3000と打って開いてみましょう。 まとめ 4つのファイル(Dockerfile, Gemfile, Gemfile.lock, docker-compose.yml)を用意する Dockerfile: Gemfile: Gemfile.lock docker-compose.yml 以下のコマンド、設定ファイルを編集して環境構築 $ docker-compose run web rails new . --force --database=mysql $ docker-compose build /Config/database.ymlを編集 $ docker-compose up -d $ docker-compose run web bundle exec rake db:create localhost:3000にブラウザでアクセス。 あとはコードを書きながら学習するだけです。 忙しい毎日を過ごしながらも効率的にプログラミングを学びたい方に最適なプログラミングスクール・教材を記事にまとめてますので、よろしければ以下の記事も見ていってください。 &gt;&gt; 【厳選4つ】未経験におすすめのプログラミングスクール・教材！ - omathin blog 「1万円以上お金が出せない」「低コストでRailsの基礎を学びたい」という方はUdemyを活用した学習も検討してみてください。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームなので安心です。 &gt;&gt; 【Udemy】フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座","link":"/docker-ruby-on-rails/"},{"title":"【Keras】ニューラルネットワーク(NN)をPythonで作成する方法","text":"ニューラルネットワークとはどのようなものかをkerasという機械学習を簡単に使うためのライブラリを使ってまとめました。高校の数学でならったsin(サイン)関数をつかって、学習→予測をしてみたいと思います。 目次 本記事の対象者: ニューラルネットワーク(NN)をPythonで実装する方法を知りたい人 Pythonの環境 Kerasで作成するニューラルネットワーク(NN)の学習データの準備 入力データxの作成 正解データ（sin関数）の作成とグラフ描画 Kerasでニューラルネットワーク(NN)の構築、学習、予測 ニューラルネットワークの設定 ニューラルネットワークの構築 1セット目(入力層と中間層)の追加 2セット目(中間層と出力層)の追加 コンパイル ニューラルネットワークを用いて学習 学習の推移をグラフで確認 学習済ニューラルネットワークを使用して予測 Kerasでニューラルネットワーク(NN)を構築し学習/訓練、予測させる方法をまとめました。 本記事の対象者: ニューラルネットワーク(NN)をPythonで実装する方法を知りたい人 ニューラルネットワーク、というものがなんとなくわかっているが、細かい言葉の定義とかを忘れてしまった人。（順伝播、逆伝播とかを知っている。） 高校の数学（特に三角関数）を理解している。 pythonのプログラミングを、それなりに理解している。（progate等でpythonの使い方を雰囲気程度で理解している） これから本格的に、ニューラルネットワークを学ぶために基本的なことを復習したい人。 Pythonの環境以下の記事で紹介しているように、Anaconda NavigatorでJupyter notebookの環境を整えてください。 もしくは、Google Colaboratoryという、Google chromeというブラウザのみでプログラミングができる環境を使ってもいいと思います。 https://colab.research.google.com/?hl=ja Kerasで作成するニューラルネットワーク(NN)の学習データの準備本記事では、データの例としてサイン関数を用意したいと思います。 入力データをx, 正解データをtとします。 入力データxの作成まずは入力データとなるxを作成します。 ソースコードは以下の通り。 123456import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1)print(x) numpyとmatplotlibというライブラリをインポート。 入力xとしてnp.linspace(-np.pi, np.pi).reshape(-1, 1)と記載していますが、これは、-πからπまでの値を50行、1列の行列データを作成しています。 linspace()というのは、値の範囲を指定するメソッドです。ここで、-np.pi, np.piとすることで、-π(-3.1415・・・)からπ(3.1415・・・)までの範囲の値を扱うことを宣言しています。 reshape()は、行数と列数を指定して、行列の形を指定したり変更したりするメソッドです。 このコードでは、reshape(-1, 1)、すなわち行数を-1, 列数を1としています。行数が-1ってどのような意味なのかというと、-1を指定することで、「良い具合に自動で列数決めてくださいね。」というメッセージを送っていることになります。 良い具合に、というのは、reshapeの大本であるlinspaceにおけるデフォルト設定のことを指しており、具体的な数値でいうと50が設定されます。 すなわち、-πからπまでの値を50等分した配列データを作成しています。 作成したxをプリントすると以下のようになります。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[[-3.14159265] [-3.01336438] [-2.88513611] [-2.75690784] [-2.62867957] [-2.5004513 ] [-2.37222302] [-2.24399475] [-2.11576648] [-1.98753821] [-1.85930994] [-1.73108167] [-1.60285339] [-1.47462512] [-1.34639685] [-1.21816858] [-1.08994031] [-0.96171204] [-0.83348377] [-0.70525549] [-0.57702722] [-0.44879895] [-0.32057068] [-0.19234241] [-0.06411414] [ 0.06411414] [ 0.19234241] [ 0.32057068] [ 0.44879895] [ 0.57702722] [ 0.70525549] [ 0.83348377] [ 0.96171204] [ 1.08994031] [ 1.21816858] [ 1.34639685] [ 1.47462512] [ 1.60285339] [ 1.73108167] [ 1.85930994] [ 1.98753821] [ 2.11576648] [ 2.24399475] [ 2.37222302] [ 2.5004513 ] [ 2.62867957] [ 2.75690784] [ 2.88513611] [ 3.01336438] [ 3.14159265]] これで入力データは完成です。 正解データ（sin関数）の作成とグラフ描画続いて、正解データであるtを用意します。 ソースコードは以下です。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1) print(x)t = np.sin(x) # sin関数plt.plot(x, t)plt.show() 1行目の、%matplotlib inlineですが、実はこれが記載されていないとJupyter Notebook環境でグラフが表示されません。おまじないのように記載しておきましょう。 3行目から7行目は、先ほどの入力データxで説明した箇所なので、説明は省きます。 9行目のt = np.sin(x)で、先ほどの入力データxをサイン関数にいれて、これを正解データtとしています。 そして、plt.plot(x, t)で、横軸をx、縦軸をtとし、plt.show()とすることで、描画したグラフを出力させます。※plt.show()の記述が無くてもグラフが描画されたりしますが、そこは気にしない。 コードを実行すると以下のようにサイン関数のグラフが出力されます。 Kerasでニューラルネットワーク(NN)の構築、学習、予測ここから、Kerasを使ってニューラルネットワークの構築し、sin関数を学習し、入力データを用いて予測を行います。 ここで構築するのは、入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1の3層のニューラルネットワークです。 ニューラルネットワークの設定ソースコードは以下の通りです。 12345678910111213141516from keras.models import Sequentialfrom keras.layers import Dense# ニューラルネットワークの設定n_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数batch_size = 8 # バッチサイズ# 入力層、中間層、出力層の３層のニューラルネットワークを構築model = Sequential()model.add(Dense(n_mid, input_shape=(n_in,), activation=\"sigmoid\")) # 活性化関数にシグモイド関数model.add(Dense(n_out, activation=\"linear\")) # 活性化関数に恒等関数model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 損失関数に二乗誤差、最適化アルゴリズムにSGDを使用してコンパイルprint(model.summary()) 少し複雑に思うかもしれませんが、一つ一つ説明していきます。 入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1、なのでニューラルネットワークの設定として、 入力層のニューロン数をn_in = 1 中間層のニューロン数をn_mid = 20 出力層のニューロン数をn_out = 1 という風に記載します。 続いて、バッチサイズを8と設定しています。 バッチサイズとは、膨大なデータを細かく分割する単位の数です。 例えば、100万個のサンプルがあったとします。 これに対してバッチサイズを100と設定した場合、100万のサンプルを100個ずつ細かく分割し、1万個の小さい100個入りの箱に分けるということです。 この箱の一つ一つをミニバッチといい、ミニバッチに分けて計算することをミニバッチ学習と言います。 ミニバッチ学習をすると何が嬉しいのでしょうか。 100万個のサンプルの計算というのは基本的に多くの時間がかかり、1回の更新を終えるだけで膨大な時間を要します。 しかし、ミニバッチ学習を採用することで、誤差を修正する更新を終える頻度を増やすことができます。 そのため、どのように値が更新されたのかを観察しやすく、かつ、更新頻度を増やすことで、サンプル全体として最適な値を導くことができ、局所解を防ぐことができます。 なお、100万個のサンプル全体の計算を終えて、パラメータの更新が1回終わることを、1epoc(エポック)と言います。 そして、ミニバッチのパラメータを更新することを1 iteration(イテレーション)と言います。 今回の例でいうと、100万サンプルを100ずつ細かく分割し1万の小さい箱に分けているので、1epoch = 1万iterationとなります。 これで、「バッチサイズ」、「ミニバッチ」、「ミニバッチ学習」、「エポック」、「イテレーション」というものの概要が理解できたかと思います。 ニューラルネットワークの構築続いて、入力層、中間層、出力層の３層のニューラルネットワークを構築していきます。 3層のニューラルネットワークを構築する前に、ニューラルネットワークを構築する際の考え方として大事なのは、2層を1セットで考えるということです。 つまり、下図に示すように「入力層と中間層」で1セット、「中間層と出力層」で1セット、合計2セットとして扱うということです。 それぞれの1セットは、Dence()を用いて追加します。 1セット目(入力層と中間層)の追加Denseは、Sequential()を用いてmodelを作成し、addメソッドによって活用されます。 コードでいうと、1セット目(入力層と中間層)の部分はmodel.add(Dense(n_mid, input_shape=(n_in,), activation=&quot;sigmoid&quot;))という風にして追加しています。 Dense({中間層のニューロン数}, {入力の形状}, {活性化関数})という記述になっています。 活性化関数というのは、中間層の各ノード(ニューロン)内で適用されるアルゴリズムで、下図における\\( u \\)から\\( z \\)を求める関数です。 活性化関数は、様々あり、自然言語処理の世界では、シグモイド関数、tanh(ハイパボリックタンジェント)、恒等関数が主となるようです。 今回は、シグモイド関数を使っていますが、他の活性化関数を適用して実験してみてもいいと思います。 また、こちらの\\( u \\)から\\( z \\)への変換を、非線形変換といったります。 線形でない曲線的な関数である、非線形の関数を用いて\\( u \\)から\\( z \\)を変換しているので、非線形変換といいます。 なぜ非線形なのでしょうか。線形変換でもよいのでは？と思うかもしれません。 理由は、ものすごく簡単に言ってしまうと、実際のビジネスでは、非線形なデータの方が多く、非線形変換を行わなければ、実際のビジネスの現場では使えないためです。 2セット目(中間層と出力層)の追加続いて2セット目の層を追加します。 こちらもDenseを用います。 出力層のニューロン数と活性化関数を指定すればOKです。 コードとしては、model.add(Dense(n_out, activation=&quot;linear&quot;))となります。 コンパイルコンパイルというのは、人間が分かる言葉で書いたプログラムのコードを、コンピュータが分かる言葉に変換/翻訳することです。コンピュータが分かる言葉というのは、いわゆる0と1の列です。 コンパイルの際は、損失関数と、最適化アルゴリズム、というのを指定します。コードでいうと、model.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;sgd&quot;)と記載しているところです。 損失関数とは、ニューラルネットワークが予想した値が静価値にどれだけ近いかを評価する関数のことです。 別名、評価関数とも呼びます。 損失関数は２つに分類されます。 回帰(数値を予測) → 二乗誤差 分類(カテゴリを予測) → クロスエントロピー（交差エントロピー） 今回は、数値を予測するので、二乗誤差を指定しています。 最適化アルゴリズムとは、重み\\( w \\)をどのようなルールで変換して正解値に近づけるかを数式化(モデル化)したものです。 SGDとは、確率的勾配降下法というもので、数式としては、以下のようなものになります。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}}以下のページに詳しい説明がまとめられているので、興味のある方は参考にしてください。https://mathwords.net/sgd 先ほどのコードを実行して、構築したモデルのsummary()を表示すると以下の通りとなります。 12345678910111213Model: \"sequential_1\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================dense_1 (Dense) (None, 20) 40 _________________________________________________________________dense_2 (Dense) (None, 1) 21 =================================================================Total params: 61Trainable params: 61Non-trainable params: 0_________________________________________________________________None Output Shapeというのは、各Denseの出力側の形状を示しています。 1セット目(入力層から中間層の部分)のOutput Shapeは、(None, 20)となっているため、中間層のニューロン数が20であることを意味しています。 2セット目(中間層から出力層の部分)のOutput Shapeは、(None, 1)となっているため、出力層のニューロン数が1であることを示しています。 Paramというのは、各層のパラメータ数を示しています。 1セット目のパラメータ数が40(重みの数が20, バイアスの数が20の合計40)で、2セット目のパラメータ数が21(重みの数が20, バイアスの数が1の合計21)であることを示しています。 ニューラルネットワークを用いて学習ここから、構築したニューラルネットワークを用いて学習を行います。 学習は、fit()メソッドを使います。 1history = model.fit(x, t, batch_size=batch_size, epochs=2000, validation_split=0.1) # 10%のデータを検証用に使う modelのfitメソッドに、先ほどの入力xと正解t、バッチサイズ、エポック数、バリデーションスプリットを設定しています。 バリデーションスプリットとは、全データの何%を検証用のデータとして扱うかを指定することができます。今回は10%のデータを検証用に使うので、0.1を設定しています。 こちらのコードを実行すると以下のような出力が得られます。 1234567891011121314151617Train on 45 samples, validate on 5 samplesEpoch 1/200045/45 [==============================] - 0s 5ms/step - loss: 0.5445 - val_loss: 0.0813Epoch 2/200045/45 [==============================] - 0s 295us/step - loss: 0.3997 - val_loss: 0.0355Epoch 3/200045/45 [==============================] - 0s 502us/step - loss: 0.3446 - val_loss: 0.0444Epoch 4/2000(略)45/45 [==============================] - 0s 301us/step - loss: 0.0093 - val_loss: 0.1108Epoch 1999/200045/45 [==============================] - 0s 265us/step - loss: 0.0093 - val_loss: 0.1142Epoch 2000/200045/45 [==============================] - 0s 323us/step - loss: 0.0095 - val_loss: 0.1142 loss: となっている部分は、訓練用データの誤差になります。 10%の検証用データを用いた結果の誤差が、val_loss:として出力されています。 学習の推移をグラフで確認matplotlibを用いて、先ほどのlossとval_lossをグラフとして描画してみます。 123456loss = history.history['loss'] # 訓練用データの誤差vloss = history.history['val_loss'] # 検証用データの誤差plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 以下のようなグラフが表示されます。 検証用のデータは青いラインで、訓練用のデータがオレンジのラインです。 両者ともに、エポック数を重ねると順調に下がっています。 学習済ニューラルネットワークを使用して予測predict()メソッドを用いることで、学習済みのニューラルネットワークを使用して予測を行うことができます。 123plt.plot(x, model.predict(x)) # 予測を行うplt.plot(x, t)plt.show() 最初に、入力xと入力xをpredictメソッドに入れた結果をプロットします。 predictメソッドに入力値を渡すだけで、予測データの出力を得ることができます。 比較のために、入力xと正解値tをプロットしたものを同時に出力したいと思います。 コードを実行すると以下のようなグラフが描画されます。 正解値はオレンジのラインで、学習済みのモデルに入力値を入れて予測したデータが青いラインになります。 正解のオレンジのラインをまねるように、青いラインが描かれていることから、ニューラルネットワークがサイン関数を学習していることが分かります。 Kerasでニューラルネットワーク(NN)を構築し学習/訓練、予測させる方法をまとめました。本記事ではKerasでニューラルネットワーク(NN)を構築し学習/訓練、予測させる方法をまとめました。 ニューラルネットワークをちゃんと学びたい！という方はキカガクでの学習がおすすめです。 ＼ 無料説明会受付中！ ／ キカガクを確認する 参考にしたページや文献など 確率的勾配降下法の大雑把な意味 - 具体例で学ぶ数学 Optimizer : 深層学習における勾配法について - Qiita","link":"/keras-nn-basic/"},{"title":"【M1 Mac】Railsの開発環境をdocker-composeで作成する","text":"M1 MacでもDockerでRails開発環境作れるの？という疑問に答えていきます！ 目次 この記事の対象者:M1 Macにdocker-composeでRailsの環境を作りたい方 M1 Macにdocker-composeを用いてRails環境をを構築する流れ docker Desktop for Macのインストール Dockerfileの作成 Gemfileの作成 Gemfile.lockの作成 docker-compose ymlの作成 MySQLの設定ファイルの作成 Rails開発環境の構築 まとめ：M1 Macにdocker-composeを用いてRailsの環境を構築する方法をまとめました。 この記事の対象者:M1 Macにdocker-composeでRailsの環境を作りたい方 ・ M1 MacでRails開発環境をDockerで構築したい方(Rails 6.0.3.4 / mySQL 8.0.22系) WindowsのPCを用いている方は、以下の記事を参照してください。 &gt;&gt; 【Windows】DockerでRuby on Rails開発環境構築方法 M1 Macにdocker-composeを用いてRails環境をを構築する流れ Docker Desktop for Macのインストール Dockerfileの作成 Gemfileの作成 Gemfile.lockの作成 docker-compose.ymlの作成 MySQLの設定ファイルの作成の設定 Rails開発環境の構築 docker Desktop for Macのインストール 以下の記事にまとめられているインストール方法で問題なく導入できます。Macbook Pro M1(Apple Silicon) で Dockerを動かす - Qiita インストールが完了したらバージョンと動作確認。 terminal12345$ docker --versionDocker version 20.10.1, build 831ebeae96$ docker-compose --versiondocker-compose version 1.27.4, build 40524192 Dockerfileの作成 まずは任意の空のディレクトリを用意して、Dockerfileを用意していきます。 この記事では``railsapp``という名前の空ディレクトリを作ります。 terminal123$ mkdir ~/railsapp$ cd ~/railsapp$ vim Dockerfile docker-composeを使う場合、docker-compose.ymlがおいてあるディレクトリ名が、コンテナ名やvolume名の接頭字として使用されます。 実際の開発においては、プロジェクトの名前など、意味のあるディレクトリ名にしておいたほうが望ましいです。 また、作成したディレクトリをビルドコンテキストとするので、不要なファイルは含めないようにしましょう。 railsapp/Dockerfile12345678910111213FROM ruby:3.0.0RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /appRUN curl https://deb.nodesource.com/setup_12.x | bashRUN curl https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -RUN echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | tee /etc/apt/sources.list.d/yarn.listRUN apt-get update &amp;&amp; apt-get install -y nodejs yarn postgresql-client Dockerfileは、Railsを実行するためのファイルサーバやパッケージをイメージに含めるための定義が書かれています。ポイントだけ説明します。 FROM ruby:3.0.0: 現時点で最新バージョンであるruby 3.0.0を指定しています。 COPY . /appはDockerファイルの置いてあるフォルダの内容をすべてコンテナ内の/appディレクトリにコピーしています。これはrailsのアプリケーション実行に必要なファイルをすべてコンテナの中に含めるために記載している。そのため余計なファイルを含めてしまうと、コンテナに含まれてしまうので、本記事で述べるファイル以外の関係のないファイルはおかないように注意しましょう。 10行目〜13行目は、yarnというjsのパッケージ管理ツールをDockerコンテナ内部にインストールするためのコードです。後々、Webpackを導入するために必要となります。 Gemfileの作成 GemfileはインストールするGemを定義しておくためのファイルです。 railsapp/Gemfile12source 'https://rubygems.org'gem 'rails', '6.0.3.4' sourceには、Gemのダウンロード元のURLを記載しています。 インストールするGemには現時点で最新バージョンであるRailsの6.0.3.4を指定しています。 このGemfileが配置されたディレクトリで、「bundle install」コマンドを実行すると、インストールが実行されるよ！ Gemfile.lockの作成 terminal1$ vim Gemfile.lock Gemfile.lockでは空のファイルになります。通常Gemfile.lockは、直接編集するものではありません。Gemfile.lockはbundle installを行った際に、実際にインストールしたGemのリストとバージョンが自動的に記載されるファイルです。 つまり、1. Gemfileでinstallしたいgemを定義2. bundle installコマンドを実行3. gemがインストールされる4. installしたgemがGemfile.lockに記載されるということだね！ Gemfile.lockの用途は、別のサーバーや他の開発者のPCといった別環境で同じRailsアプリを動かす際、同じGemをインストールするために使用されます。 Gemをインストールする際は、インストールするGemを動かすために必要な別のGemも一緒にインストールしてくれます。 あるライブラリが別のライブラリを必要とすることを「依存関係」っていうんだ！ 依存関係も含めて何がインストールされたのかが、全てGemfile.lockに記載されます。 このGemfile.lockを別の環境に持っていき、そこでbundle installコマンドを実行すると、Gemfile.lockに記載された内容に従って、Gemのインストールが実行される、というわけです。 docker-compose ymlの作成 docker-compose.ymlは、Dockerで複数のコンテナを設定に従ってまとめて起動するためのファイルです。ここでは、Railsを実行するコンテナとMySQLを実行するコンテナを起動する定義を記載します。 railsapp/docker-compose.yml12345678910111213141516171819202122version: '3'services: web: build: . command: bundle exec rails s -p 3000 -b '0.0.0.0' volumes: - .:/app ports: - 3000:3000 depends_on: - db tty: true stdin_open: true db: image: mysql@sha256:dce31fcdd15aaedb5591aa89f19ec37cb79981af46511781fa41287d88ed0abd volumes: - db-volume:/var/lib/mysql - ./mysql-confd:/etc/mysql/conf.d environment: MYSQL_ROOT_PASSWORD: passwordvolumes: db-volume: 注目する点は、MySQLのimages指定です。2021年1月時点ではタグではなくDIGESTの欄のIDを指定しないとエラーが出ます。 そして./mysql-confd:/etc/mysql/conf.dは、MySQLのデフォルトの認証形式であるcaching_sha2_passwordからmysql_native_passwordに変更するファイルになります。 この設定ファイルは次のセクションで作成します。 MySQLの設定ファイルの作成 MySQLのデフォルトの認証形式をデフォルトのcaching_sha2_passwordからmysql_native_passwordに変更するファイルは以下のとおりです。 railsapp/mysql-confd/default_authentication.cnf12[db]default_authentication_plugin= mysql_native_password [db]と書かれている部分は、docker-compose.ymlファイルに記載されたデータベースのservice名に対応しています。 Rails開発環境の構築 ここまで作成した設定ファイルを使用して、Railsの開発環境を動かしていきます。 フォルダとファイルは以下のとおりです。 tree123456789.├── Dockerfile├── Gemfile├── Gemfile.lock├── docker-compose.yml└── mysql-confd └── default_authentication.cnf1 directory, 5 files 以下のコマンドを実行します。 terminal1$ docker-compose run web rails new . --force --database=mysql ここでERROR: Service 'web' failed to build : The command '/bin/sh -c curl https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -' returned a non-zero code: 2というエラーが発生しましたら、本記事の末尾のコメント欄に対応例が紹介されていますので、お手数ですがそちらをご確認ください。 処理が完了するとRailsプロジェクトのファイルが自動生成されます。 terminal12345/railsapp $ lsDockerfile Rakefile config lib package.json testGemfile app config.ru log postcss.config.js tmpGemfile.lock babel.config.js db mysql-confd public vendorREADME.md bin docker-compose.yml node_modules storage yarn.lock ここでGemfileに追記されたGemのインストールや作成されたファイルをコンテナ内に取り込むために、もう一度ビルドを実行します。 terminal1$ docker-compose build ビルドが完了したら、Railsで使用するデータベースの設定ファイルを編集します。ファイルはconfigディレクトリ内にあるdatabase.ymlです。 変更箇所は17行目と18行目です。 database.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# MySQL. Versions 5.5.8 and up are supported.## Install the MySQL driver# gem install mysql2## Ensure the MySQL gem is defined in your Gemfile# gem 'mysql2'## And be sure to use new-style password hashing:# https://dev.mysql.com/doc/refman/5.7/en/password-hashing.html#default: &amp;default adapter: mysql2 encoding: utf8mb4 pool: &lt;%= ENV.fetch(&quot;RAILS_MAX_THREADS&quot;) { 5 } %&gt; username: root password: password # 変更 host: db # 変更development: &lt;&lt;: *default database: app_development# Warning: The database defined as &quot;test&quot; will be erased and# re-generated from your development database when you run &quot;rake&quot;.# Do not set this db to the same as development or production.test: &lt;&lt;: *default database: app_test# As with config/credentials.yml, you never want to store sensitive information,# like your database password, in your source code. If your source code is# ever seen by anyone, they now have access to your database.## Instead, provide the password as a unix environment variable when you boot# the app. Read https://guides.rubyonrails.org/configuring.html#configuring-a-database# for a full rundown on how to provide these environment variables in a# production deployment.## On Heroku and other platform providers, you may have a full connection URL# available as an environment variable. For example:## DATABASE_URL=&quot;mysql2://myuser:mypass@localhost/somedatabase&quot;## You can use this database configuration with:## production:# url: &lt;%= ENV['DATABASE_URL'] %&gt;#production: &lt;&lt;: *default database: app_production username: app password: &lt;%= ENV['APP_DATABASE_PASSWORD'] %&gt; ファイルを保存して、以下のコマンドを実行します。 terminal1$ docker-compose up -d webとdbの２つのコンテナが起動状態になっていることを確認します。両方ともStateがUPになっていればOKです。 terminal12345$ docker-compose ps Name Command State Ports --------------------------------------------------------------------------------railsapp_db_1 docker-entrypoint.sh mysqld Up 3306/tcp, 33060/tcp railsapp_web_1 bundle exec rails s -p 300 ... Up 0.0.0.0:3000-&gt;3000/tcp 起動は完了しましたが、まだ開発環境用のデータベースが作成されていない状態なので、次のコマンドでデータベースを作成します。 terminal1$ docker-compose run web bundle exec rake db:create これでうまく行けば良いですが、まれに以下のようなエラーが出てくるかと思います。 エラー1Mysql2::Error::ConnectionError: Plugin caching_sha2_password could not be loaded: /usr/lib/aarch64-linux-gnu/mariadb19/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory これは、MySQL 8.0系の認証形式がcaching_sha2_passwordのままになっているためです。 本来ならdefault_authentication.cnfが変えてくれるはずなんですけどね。。。 以下のように、MySQLにログインして2つのrootの認証方式をmysql_native_passwordに変更します。 terminal12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152$ docker exec -it ror_db_1 bashroot@a503c7951a1f:/# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10Server version: 8.0.22 MySQL Community Server - GPLCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; SELECT User, Host, Plugin FROM mysql.user; +------------------+-----------+-----------------------+| User | Host | Plugin |+------------------+-----------+-----------------------+| root | % | caching_sha2_password || mysql.infoschema | localhost | caching_sha2_password || mysql.session | localhost | caching_sha2_password || mysql.sys | localhost | caching_sha2_password || root | localhost | caching_sha2_password |+------------------+-----------+-----------------------+5 rows in set (0.04 sec)mysql&gt; select @@version;+-----------+| @@version |+-----------+| 8.0.22 |+-----------+1 row in set (0.02 sec)mysql&gt; alter user 'root'@'%' identified WITH mysql_native_password by 'password';Query OK, 0 rows affected (0.22 sec)mysql&gt; alter user 'root'@'localhost' identified WITH mysql_native_password by 'password';Query OK, 0 rows affected (0.13 sec)mysql&gt; SELECT User, Host, Plugin FROM mysql.user;+------------------+-----------+-----------------------+| User | Host | Plugin |+------------------+-----------+-----------------------+| root | % | mysql_native_password || mysql.infoschema | localhost | caching_sha2_password || mysql.session | localhost | caching_sha2_password || mysql.sys | localhost | caching_sha2_password || root | localhost | mysql_native_password |+------------------+-----------+-----------------------+5 rows in set (0.01 sec) これで再び以下のコマンドを実行してください。 terminal1234$ docker-compose run web bundle exec rake db:createCreating ror_web_run ... doneCreated database 'app_development'Created database 'app_test' localhost:3000にブラウザでアクセスするとRailsの画面が現れます。 まとめ：M1 Macにdocker-composeを用いてRailsの環境を構築する方法をまとめました。お疲れさまでした。これでRailsの環境構築は完了です。 これからRailsの知識を着けたい方は、デイトラのRailsコースがおすすめですので、合わせてご確認ください。 教材を元に作成したサンプルアプリを改造しながらオリジナルアプリを作るのが、プログラミングスキルを向上させるコツです。 頑張ってください。 もしよろしければ、以下の記事もご確認ください。 &gt;&gt; 【厳選4つ】未経験におすすめのプログラミングスクール・教材！ - omathin blog 参考記事 Rails6 Webpackerでエラーが出た - Qiita yarnをインストールする - Qiita docker for macでrails × yarn × webpackerのfront環境を整える - Qiita dockerイメージ内にyarnをインストールする - Qiita MySQLの認証プラグインを変更する方法(caching_sha2_password) - Qiita Docker Compose と Rails(+MySQL) で開発環境作成したときに気になったポイント - Qiita Docker で MySQL 8.0.4 を使う - Qiita MySQL8.0におけるデフォルトの認証プラグインの変更 – variable.jp [データベース,パフォーマンス,運用]","link":"/m1-mac-dockercompose-rails/"},{"title":"【2021年最新】ITエンジニアが高級マウスを徹底比較(5製品)して購入した話","text":"本記事では、「【2021年最新】ITエンジニアが高級マウスを徹底比較(4製品)して購入した話」というテーマでまとめていきます。 目次 本記事の対象者 購入する高級マウスの要件を整理 要件を満たしそうな高級マウスの候補を選定 1. ロジクール MX MASTER 2S 2. ロジクール MX MASTER 3 3. ロジクール MX ANYWHERE 3 4. Raser Pro Click 5. ‎SteelSeries Aerox 3 Wireless 62604 5種の高級マウスを比較評価 [結論]MX Anywhereを購入！ 実際にMX Anywhereを使ってみた感想 まとめ: 高級マウス5つを比較評価しMX Anywhereを購入しました！ 本記事の対象者 ちょっと高級なマウスを購入したい人 機能や利便性の観点で最適なマウスは何かを知りたい人 完全フルリモートワークのエンジニアが使っているマウスは何かを知りたい人 購入する高級マウスの要件を整理まずは、購入するマウスの要件を整理します。 2021年8月現在、私は完全フルリモートワークでIT系エンジニアです。 ドキュメント作成やプログラミング、Slackでのコミュニケーションなど、普段は一日中タイピングとマウス操作をしています。 仕事のロケーションは主に自宅やカフェ、コワーキングスペースが中心です。 そんな私がマウスに求める要件は以下とします。 要件 1. 持ち運びするためなるべく軽いマウス2. コード類でデスクを専有させたくないのでワイヤレスマウス3. サイドボタンが着いている※操作性を意識して2つ程度でOK4. USB-Cで充電式のマウス5.複数のPCに接続切り替えできる 要件を満たしそうな高級マウスの候補を選定ここからは、先程整理した要件を満たしそうなマウスの候補を並べていきます。 Amazon検索でランキング上位に位置づけられているマウスを選定します。 なお、予算は10,000円とします。 正直マウス含めガジェットは、安かろう悪かろうの世界であることは変わりないです。 10,000円近くのマウスに絞って候補を選定していきます。 1. ロジクール MX MASTER 2S (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール MX MASTER 2S ワイヤレス マウス MX2100CR Bluetooth 無線 ワイヤレスマウス windows mac グラファイト 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"910-005970\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31jLZc7z4SL._SL500_.jpg\",\"\\/41mKvU+RLiL._SL500_.jpg\",\"\\/41Icr5FeQ8L._SL500_.jpg\",\"\\/515hrRFA+WL._SL500_.jpg\",\"\\/41tPwvOKltS._SL500_.jpg\",\"\\/41SEJesNSML._SL500_.jpg\",\"\\/51+EAgRW1CL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08K8PH9G3\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08K8PH9G3\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20MX%20MASTER%202S%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E3%83%9E%E3%82%A6%E3%82%B9%20MX2100CR%20Bluetooth%20%E7%84%A1%E7%B7%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%83%9E%E3%82%A6%E3%82%B9%20windows%20mac%20%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"JnkZr\",\"s\":\"s\"}); リンク Amazonで検索すると必ず現れるマウスです。 パッと見た感じ、少し大きめで重量感がありそうなマウスですが、要件を満たしそうなのでピックアップしました。 2. ロジクール MX MASTER 3 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール アドバンスド ワイヤレスマウス MX Master 3 MX2200sGR Unifying Bluetooth 高速スクロールホイール 充電式 FLOW 7ボタン windows Mac iPad OS 対応 無線 マウス MX2200 グラファイト 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"910-005707\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41tqA-o-QHL._SL500_.jpg\",\"\\/41u6aqeRB3L._SL500_.jpg\",\"\\/41F2q4WlNvL._SL500_.jpg\",\"\\/51GbSgpIFwL._SL500_.jpg\",\"\\/41QmsK0GnEL._SL500_.jpg\",\"\\/419pewYjeuL._SL500_.jpg\",\"\\/41ZBpteUBkL._SL500_.jpg\",\"\\/41sPHyjQXrL._SL500_.jpg\",\"\\/51psOaUW6xL._SL500_.jpg\",\"\\/41YFuG+iVJL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07XQ6XD8J\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07XQ6XD8J\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20%E3%82%A2%E3%83%89%E3%83%90%E3%83%B3%E3%82%B9%E3%83%89%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%83%9E%E3%82%A6%E3%82%B9%20MX%20Master%203%20MX2200sGR%20Unifying%20Bluetooth%20%E9%AB%98%E9%80%9F%E3%82%B9%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%AB%E3%83%9B%E3%82%A4%E3%83%BC%E3%83%AB%20%E5%85%85%E9%9B%BB%E5%BC%8F%20FLOW%207%E3%83%9C%E3%82%BF%E3%83%B3%20windows%20Mac%20iPad%20OS%20%E5%AF%BE%E5%BF%9C%20%E7%84%A1%E7%B7%9A%20%E3%83%9E%E3%82%A6%E3%82%B9%20MX2200%20%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"zSVKn\",\"s\":\"s\"}); リンク MX MASTER 2Sの次世代マウスですね。 MASTER 2Sよりも更にサイズが大きくなった印象を持ちますが、デザインとしてはこちらのほうがカッコいいのでピックアップしました。 3. ロジクール MX ANYWHERE 3 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール MX ANYWHERE 3 ワイヤレス モバイルマウス MX1700GR Unifying Bluetooth 高速スクロールホイール 充電式 ワイヤレスマウス 無線 マウス windows mac chrome iPad OS MX1700 グラファイト 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"910-006004\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31MBk3oBQmL._SL500_.jpg\",\"\\/419gQRozI3L._SL500_.jpg\",\"\\/41hkwCTR29L._SL500_.jpg\",\"\\/41Ksz7RHD5L._SL500_.jpg\",\"\\/41fxRcW+oWL._SL500_.jpg\",\"\\/51tD1KWpSgL._SL500_.jpg\",\"\\/41a1T9FeK2L._SL500_.jpg\",\"\\/51qxbb1z-EL._SL500_.jpg\",\"\\/51e1BeYLmNL._SL500_.jpg\",\"\\/41snOlXND-L._SL500_.jpg\",\"\\/21AGq1-zBpS._SL500_.jpg\",\"\\/31c5+2+jQWL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HRQRVPJ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HRQRVPJ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20MX%20ANYWHERE%203%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E3%83%A2%E3%83%90%E3%82%A4%E3%83%AB%E3%83%9E%E3%82%A6%E3%82%B9%20MX1700GR%20Unifying%20Bluetooth%20%E9%AB%98%E9%80%9F%E3%82%B9%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%AB%E3%83%9B%E3%82%A4%E3%83%BC%E3%83%AB%20%E5%85%85%E9%9B%BB%E5%BC%8F%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%83%9E%E3%82%A6%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%83%9E%E3%82%A6%E3%82%B9%20windows%20mac%20chrome%20iPad%20OS%20MX1700%20%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"m4syU\",\"s\":\"s\"}); リンク MXシリーズの中でもシンプルなマウス。 「ANYWHERE」と書いてあることからも、在宅・カフェなどでも使えそうな高機能マウスかと思い、ピックアップしました。 4. Raser Pro Click (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Razer Pro Click ワイヤレス マウス 2.4GHz Bluetooth 最大400時間バッテリー持続 疲労軽減 人間工学 無線 有線 両対応 Humanscale 16,000DPI Razer 5G光学センサー 8ボタン 【日本正規代理店保証品】 RZ01-02990100-R3M1\",\"b\":\"Razer(レイザー)\",\"t\":\"RZ01-02990100-R3M1\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41nf9EetrhL._SL500_.jpg\",\"\\/41XU1zYWurL._SL500_.jpg\",\"\\/41c8fmv5WnL._SL500_.jpg\",\"\\/41D8BgRP33L._SL500_.jpg\",\"\\/41gS3RGbpTL._SL500_.jpg\",\"\\/41X95fk59qL._SL500_.jpg\",\"\\/41bOqOzJvEL._SL500_.jpg\",\"\\/41hR6dSsPaL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08MZVWHPR\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08MZVWHPR\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Razer%20Pro%20Click%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E3%83%9E%E3%82%A6%E3%82%B9%202.4GHz%20Bluetooth%20%E6%9C%80%E5%A4%A7400%E6%99%82%E9%96%93%E3%83%90%E3%83%83%E3%83%86%E3%83%AA%E3%83%BC%E6%8C%81%E7%B6%9A%20%E7%96%B2%E5%8A%B4%E8%BB%BD%E6%B8%9B%20%E4%BA%BA%E9%96%93%E5%B7%A5%E5%AD%A6%20%E7%84%A1%E7%B7%9A%20%E6%9C%89%E7%B7%9A%20%E4%B8%A1%E5%AF%BE%E5%BF%9C%20Humanscale%2016%2C000DPI%20Razer%205G%E5%85%89%E5%AD%A6%E3%82%BB%E3%83%B3%E3%82%B5%E3%83%BC%208%E3%83%9C%E3%82%BF%E3%83%B3%20%E3%80%90%E6%97%A5%E6%9C%AC%E6%AD%A3%E8%A6%8F%E4%BB%A3%E7%90%86%E5%BA%97%E4%BF%9D%E8%A8%BC%E5%93%81%E3%80%91%20RZ01-02990100-R3M1\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"XEYEu\",\"s\":\"s\"}); リンク 人間工学に基づいて設計されたと思われる無線マウス。 こちらも先述した要件を満たしてそうなのでピックアップしました。 5. ‎SteelSeries Aerox 3 Wireless 62604 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"SteelSeries ゲーミングマウス 無線 ワイヤレス 2.4Ghz\\/Bluetooth USB-C高速充電対応 超軽量 IP54規格 防水 防塵 3ゾーンRGBイルミネーション Aerox 3 Wireless 62604\",\"b\":\"SteelSeries\",\"t\":\"62604\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41cCgR-nG6L._SL500_.jpg\",\"\\/51q3GKdRdOL._SL500_.jpg\",\"\\/4130TPrQhbL._SL500_.jpg\",\"\\/41C227YUxPL._SL500_.jpg\",\"\\/51vN5q-lvmL._SL500_.jpg\",\"\\/412J-uprqML._SL500_.jpg\",\"\\/41FSaqgP-fL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08KWKDRFF\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08KWKDRFF\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/SteelSeries%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%9E%E3%82%A6%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%202.4Ghz%2FBluetooth%20USB-C%E9%AB%98%E9%80%9F%E5%85%85%E9%9B%BB%E5%AF%BE%E5%BF%9C%20%E8%B6%85%E8%BB%BD%E9%87%8F%20IP54%E8%A6%8F%E6%A0%BC%20%E9%98%B2%E6%B0%B4%20%E9%98%B2%E5%A1%B5%203%E3%82%BE%E3%83%BC%E3%83%B3RGB%E3%82%A4%E3%83%AB%E3%83%9F%E3%83%8D%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%20Aerox%203%20Wireless%2062604\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=SteelSeries%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%9E%E3%82%A6%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%202.4Ghz%2FBluetooth%20USB-C%E9%AB%98%E9%80%9F%E5%85%85%E9%9B%BB%E5%AF%BE%E5%BF%9C%20%E8%B6%85%E8%BB%BD%E9%87%8F%20IP54%E8%A6%8F%E6%A0%BC%20%E9%98%B2%E6%B0%B4%20%E9%98%B2%E5%A1%B5%203%E3%82%BE%E3%83%BC%E3%83%B3RGB%E3%82%A4%E3%83%AB%E3%83%9F%E3%83%8D%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%20Aerox%203%20Wireless%2062604\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"KVZ8w\",\"s\":\"s\"}); リンク 外側に独特な穴が空いている外側のケースが特徴的なゲーミングマウス。 超軽量で操作性に優れたマウスが売りのようなのでピックアップしました。 5種の高級マウスを比較評価 MX Master2S MX Master3 MX Anywhere Raser Pro Click Aerox 3 Wireless 62604 重量 145g 141g 99g 150g 66g 接続形式 Bluetooth/Unifying(USB) Bluetooth/Unifying(USB) Bluetooth/Unifying(USB) Bluetooth/Unifying(USB) Bluetooth/有線 サイドボタン 3つ(全体7つ) 3つ(全体7つ) 2つ(全体6つ) 2つ（全体8つ） 2つ 蓄電方式 充電(USB-Cではない) 充電(USB-C) 充電(USB-C) 充電(USB-Cではない) 充電(USB-C) 連続使用時間 70日 70日 70日 400時間(Bluetooth使用時) 最長200時間 接続切り替え 3台(ボタン切り替え) 3台(ボタン切り替え) 3台(ボタン切り替え) 4台(ボタン切り替え) なし 保証 2年 2年 2年 保証なし(?) 1年 評判(主に悪い評判) USB-Cではない スクロール速度が遅いor不安定親指と薬指を使ってマウスを持ち上げるのが困難（重い） クリック音が大きい。ホイールが静音ではない。 ミニUSBの差込口が奥まっていて刺しにくい。クリック音大きめ。 サイドボタンが細すぎ＆硬すぎで押しにくい。macOS Big Sur環境において一部ショートカットが機能しない。 その他機能 Flow機能 Flow機能 Flow機能 - 2.4GHzワイヤレス 価格2021年8月9日時点 ￥9,520 ￥13,365 ￥9,702 ￥12,980 ¥11.864 [結論]MX Anywhereを購入！ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール MX ANYWHERE 3 ワイヤレス モバイルマウス MX1700GR Unifying Bluetooth 高速スクロールホイール 充電式 ワイヤレスマウス 無線 マウス windows mac chrome iPad OS MX1700 グラファイト 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"910-006004\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31MBk3oBQmL._SL500_.jpg\",\"\\/419gQRozI3L._SL500_.jpg\",\"\\/41hkwCTR29L._SL500_.jpg\",\"\\/41Ksz7RHD5L._SL500_.jpg\",\"\\/41fxRcW+oWL._SL500_.jpg\",\"\\/51tD1KWpSgL._SL500_.jpg\",\"\\/41a1T9FeK2L._SL500_.jpg\",\"\\/51qxbb1z-EL._SL500_.jpg\",\"\\/51e1BeYLmNL._SL500_.jpg\",\"\\/41snOlXND-L._SL500_.jpg\",\"\\/21AGq1-zBpS._SL500_.jpg\",\"\\/31c5+2+jQWL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HRQRVPJ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08HRQRVPJ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20MX%20ANYWHERE%203%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E3%83%A2%E3%83%90%E3%82%A4%E3%83%AB%E3%83%9E%E3%82%A6%E3%82%B9%20MX1700GR%20Unifying%20Bluetooth%20%E9%AB%98%E9%80%9F%E3%82%B9%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%AB%E3%83%9B%E3%82%A4%E3%83%BC%E3%83%AB%20%E5%85%85%E9%9B%BB%E5%BC%8F%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%83%9E%E3%82%A6%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%83%9E%E3%82%A6%E3%82%B9%20windows%20mac%20chrome%20iPad%20OS%20MX1700%20%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"m4syU\",\"s\":\"s\"}); リンク 決めてはなんと言っても重量です。 「99g」と圧倒的に軽い。 カフェやコワーキングスペースに持参することも考えると、持ち運びしやすいと考えました。 充電式で70日間連続使用可能で、サイドボタンも着いており、予算の範囲内だったのも決め手です。 横スクロールが可能なMX Master3も考えましたが、重量がネック。 それに、「横スクロールってそんなに使うかな？」とも思いました。 ほか２つは、充電の端子がminiUSBでありUSB-Cではないので、残念ながら外れました。 実際にMX Anywhereを使ってみた感想実際に使ってみた感想ですが、「軽い！」の一言。 Bluetooth接続や、logicool optionのインストールも特に難しい点は無く、簡単にペアリングできました。 なお、悪い評判で書かれていた「ホイール音が静音ではない。（カリカリする）」というのは、logicool optionのホイール設定で静音にできました。 以下の通り、SmartShiftを無効にし、固定スクロールホイールモードをフリースピンにすれば静音になります。 マウスのカチカチ音はたしかに大きい気がしますが、カフェとかで周りに迷惑になるレベルかというと、そうでもない気がします。 結果としては満足です。 まとめ: 高級マウス5つを比較評価しMX Anywhereを購入しました！本記事は、「【2021年最新】ITエンジニアが高級マウスを徹底比較(4製品)して購入した話」というテーマでまとめました。 筆者独自の要件に基づいた比較評価になりますが、購入を検討されている方の参考になればと思います。 合わせて読みたい記事","link":"/mouse-mxanywhere3/"},{"title":"【実録】レアジョブ英会話の予約〜予習〜本番〜レビューの流れを公開","text":"レアジョブ英会話ってどうやってレッスンを予約して受講すれば良いのか知りたいなぁ。。。 実際に毎日レアジョブ英会話を受講している筆者が、レッスンの予約方法から受講までの流れを公開します。 ✓目次 予約 レアジョブ英会話にログイン 【重要】カリキュラムの設定 講師の検索と予約 環境チェック 予習 【重要】教材の予習は1つ先の教材までやっておく 【重要】英語を使った自己紹介の準備 レッスン本番 [重要]カメラの確認 レッスン開始 レッスン終了 次回のレッスン予約 予約 まずはレアジョブ英会話のポータルにログインし、予約を行います。 難しくないので安心してください。 レアジョブ英会話にログイン まずは、レアジョブ英会話のログイン画面にいきましょう。 &gt;&gt; レアジョブ英会話ログイン画面 画面右上の「ログイン」をクリックし、登録したメールアドレスとパスワードを入力します。 以下のような画面に遷移したらOKです。 【重要】カリキュラムの設定 レアジョブ英会話を始める際に気をつけることは、カリキュラムを設定しておくことです。 カリキュラムを設定しておかないと、講師の方が何のレッスンをやればよいのか分からない状態になります。そのため、レッスン開始時に慌ててカリキュラムを設定してアタフタするなんてことになります。 ログイン後の画面の右側にある「カリキュラムを設定する」をという青いボタンをクリックし、カリキュラムを設定しましょう。 各カリキュラムの「詳細をみる」というボタンを押すと、どのくらいのレベルの教材かを確認できます。 オススメは、自分が思っている英会話レベルよりも優しいレベルです。英語にあまり自身のない方は、基本的にはスターターレベルを選択するのが無難です。 レアジョブ英会話が提供しているカウンセリングやスピーキングテストを受講して判断しても良いと思いますが、基本的には不要かなと思います。 私はレアジョブ英会話が提供している「PROGOS」というスピーキングテストを受講しましたが、受験しても２週間ほど結果待ち状態になりました。 時間がもったいないので、ひとまずスターターレベルで、さっさと始めてしまいましょう。 &gt;&gt;無料体験レッスンの内容を確認する 講師の検索と予約 カリキュラムを選択したら、最初のログイン後の画面に戻り、「講師検索から予約」を押しましょう。 すると、講師の検索画面が表示されます。 レアジョブ英会話レッスンに慣れていない方は、特徴という項目で「初心者・初心者向き」を選択しておきましょう。 また本当に英語を話すのが苦手な方は、日本語が話せる先生を選択しましょう。 「さらに詳しい条件を指定する」の「＋」の部分を押すと、「日本語」という項目があります。 「日常会話が可能」を選択して検索すればOKです。 環境チェック 予約が完了したら、ログイン後のトップ画面に戻ります。 すると、レッスンの予約欄に「環境チェック」というボタンがあるので、これをクリックしましょう。 すると、以下のようにルーム環境チェックの画面が立ち上がるので、一つ一つの項目をチェックしましょう。 パソコンにカメラが付いていない場合は、外付けのWebカメラを装着することをおすすめします。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ウェブカメラ フルHD 1080P 30FPS USB Webカメラ\",\"b\":\"MESEVEN\",\"t\":\"M-MC65\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41+UJNziMbL.jpg\",\"\\/51qKys-TNzL.jpg\",\"\\/41f-3NSe1cL.jpg\",\"\\/51csX2+tuLL.jpg\",\"\\/51EWLA29OZL.jpg\",\"\\/51shwbk+6fL.jpg\",\"\\/51W-kVgnYML.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08BJQFBSJ\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08BJQFBSJ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":0},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%A6%E3%82%A7%E3%83%96%E3%82%AB%E3%83%A1%E3%83%A9%20%E3%83%95%E3%83%ABHD%201080P%2030FPS%20USB%20Web%E3%82%AB%E3%83%A1%E3%83%A9\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":1}],\"eid\":\"1yHgn\",\"s\":\"xs\"}); リンク マイクは、Webカメラ内臓のマイクではなく、マイク付きのイヤホンを使用したほうが、スピーカー音をマイクが拾って回り込みしないのでおすすめです。※回り込み：相手の声を自分のマイクが拾ってしまい声が二重になってしまうこと (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"マイク付きイヤホン 有線 インナーイヤー型イヤフォン\",\"b\":\"Linklike\",\"t\":\"Linklike_Classic 2\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41r1XUPIPhL.jpg\",\"\\/5144Rk5SIlL.jpg\",\"\\/41ETlAyP2rL.jpg\",\"\\/41X7OCJZdpL.jpg\",\"\\/41020VkF7sL.jpg\",\"\\/41iEgOuclqL.jpg\",\"\\/41k-5LGqMnL.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B086GPTFD4\",\"t\":\"amazon\",\"r_v\":\"\"},\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B086GPTFD4\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":0},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%9E%E3%82%A4%E3%82%AF%E4%BB%98%E3%81%8D%E3%82%A4%E3%83%A4%E3%83%9B%E3%83%B3%20%E6%9C%89%E7%B7%9A%20%E3%82%A4%E3%83%B3%E3%83%8A%E3%83%BC%E3%82%A4%E3%83%A4%E3%83%BC%E5%9E%8B%E3%82%A4%E3%83%A4%E3%83%95%E3%82%A9%E3%83%B3\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":1}],\"eid\":\"MfEWG\",\"s\":\"xs\"}); リンク すべてのチェックが終わったら、デモ画面を確認しましょう。 この時、まれにカメラをONにしても自分の画像が現れない場合があります。 自分の顔が映らない場合は、ブラウザを更新すると大体直ります。 これで、受講の準備はほぼ完了です。 予習 受講開始前に、レッスンで使用する教材の予習をしましょう。 使用する教材は、設定したカリキュラムの欄の「Now:」となっている教材のリンクから参照できます。 【重要】教材の予習は1つ先の教材までやっておく レッスンが順調に進むと先生から「次のレッスンに進みましょう！」という提案を受けます。 これに備えて、使用予定の教材だけでなくその次の教材も予習しておきましょう。 教材の最後に、「NEXT LESSON」というリンクがあるので、これをクリックすれば1つ先の教材を参照することができます。 【重要】英語を使った自己紹介の準備 レッスンが開始すると自己紹介が始まります。 この時、「My name is xxx」だけで終わってしまうのは寂しいものです。 事前に英語で自己紹介をする準備をしておきましょう。 以下に自己紹介のスクリプト例を載せておきますので活用してください。 Nice to meet you. (はじめまして。) My name is Taro Yamada. （私の名前は、やまだたろうです。） Please call me Taro. （「たろう」と呼んでください。） I work for xxx company as a system engeneer. （xxxという会社でシステムエンジニアをしています。） I realy like playing with my kids. (私は子どもたちと遊ぶのが好きです。) I also like driving. (ドライブも好きです。) My family is composed of my husband and two kids. (夫と２人の子供がいます。) We live in Osaka. (大阪に住んでいます。) I hope to enjoy today's lessons with you. Thank you very much. (今日のレッスンを楽しみたいと思います。よろしくおねがいします。) レッスン本番 レッスン前は緊張するかもしれません。でも、大丈夫！少しずつ慣れていきましょう。 レッスン開始3分前になると、レッスンルームに入ることができます。 レッスンルームに入ってみましょう。 [重要]カメラの確認 レッスンルームに入った際に、カメラが起動し自分の顔が写っているかどうかを確認しましょう。 私の場合、カメラONで入室すると、カメラの画面が真っ白な状態になっていることがあります。 写ってない場合は、カメラの電源の確認、カメラのON/OFF、ブラウザのリロードをしましょう。 大体はブラウザのリロードで解決します。 レッスン開始 レッスン開始時間になると講師の方がルームに入ってきます。 元気よく「Hello！」と挨拶しましょう。 「Please introduce yourself.」といった感じで自己紹介を求められたら、準備したとおり自己紹介をしてみましょう。 簡単なお話が済んだらレッスン開始です！ レッスン終了 レッスンが終盤になると、講師の方からレッスンのレビューがチャットボックスに投稿されます。 Greatであれば、問題なく次のレッスンにすすめることができます。 発音や文法に間違いがあった場合は以下のように練習すべき内容を教えてくれます。 例えば以下のようなレビューをくれたりします。この例はGreatではなくGoodです。 Overall score: 3 GOOD ※評価 - You were able to use the expressions correctly. - You completed all the exercises and challenges accordingly. *Vocabulary* You understood all the words in this lesson. *Grammar* Just keep practicing! *Pronunciation* sore throat [ sawr throht ] レビューを元に復習をしましょう。 次回のレッスン予約 これまで紹介した流れと同じ方法で講師を予約すればOKをです。 レッスンがどこまで完了したのかは、システム側で次の講師に引き継がれているので、リクエスト欄などに記載などしなくて大丈夫です。 教材のどこから始めればよいか等、細かい内容も引き継がれています。ご安心ください。 最後に 現在レアジョブでは無料体験レッスンが2つ受講できるので、まずはこちらを試してみると良いと思います。 &gt;&gt;レアジョブの無料体験レッスンの内容を確認する","link":"/reajob-eikaiwa-1/"},{"title":"【初心者レベル別】Web系エンジニアを目指すためのUdemyオススメ講座","text":"・Web系エンジニアにオススメのUdemy講座が知りたい。 ・なるべく低コストで即戦力スキルを身に着けたい。 ・エンジニアになってリモートワークしたい。 ・そもそも何の言語から学習すべきか分からない。 こんな疑問に対して回答していきます。 この記事を読めば、 ・パソコン初心者でも即戦力のWeb系エンジニアになる学習ルートが分かる。 ・実践すればWeb系エンジニアへの転職、またはフリーランスで案件獲得も十分可能なレベルになる。※実際に知人がこの方法でWeb系エンジニアに転職した。 ✓目次 本記事の対象者:初心者レベルの確認 学ぶべきWeb系言語 【Web言語別】オススメUdemy講座 PHP/LaravelのオススメUdemy講座 Ruby/RailsのオススメUdemy講座 Python/DjangoのオススメUdemy講座 まとめ：学習計画を踏まえUdemyを活用しよう！ 本記事の対象者:初心者レベルの確認 Udemyは、普段PCを触ってなかったり、プログラミングに全く触れたことがない人にとっては少々難しいと思います。そんな方は、以下の記事を参照ください。 本記事で述べる”初心者”の定義は以下です。 ・PCの操作に慣れている。(ブラウザのダウンロード、キーボード操作で\"~\"とか入力できる) ・Windows10またはMacbookなど、それなりのパソコンを持っている。 ・Progateでプログラミングを少し学んだ。 ・Linuxのコマンドが少し分かる。(cd, ls, mkdir, など) 以降は学ぶべきプログラミング言語を決めるための参考情報も踏まえつつ、オススメのUdemy講座を紹介します。 学ぶべきWeb系言語 コロナウィルスの影響でリモートワークが主流になりつつあります。 IT業界には常駐での仕事とリモートワーク可能な業務があります。どうせなら、リモートワークで働きたいですよね？ リモートワーク可能な業界は大半がWeb系業界になります。 Web系業界で活用されるプログラミング言語は主に以下になります。なおWeb系エンジニアとしては、Laravel, Raisl, Djangoといったフレームワークの知識はほぼ必須です。プログラミング言語とフレームワークをセットでまとめていきます。 ・ PHP/Laravel ・ Ruby/Rails ・ Python/Django 求人サイトで各言語の求人数を調べてみました。※2021年1月17日時点 プログラミング言語 Midworks Indeed PHP 214件 16648件 Ruby 116件 5065件 Python 82件 7555件 国内のWeb系エンジニアの求人は、PHPが頭一つ抜けていることがわかりました。Rubyも多いですね。 ただし、今後この構図は大きく変わる可能性が高いです。 理由は、IT技術の最先端であるシリコンバレーではPythonとGoが主流だからです。PythonはAIやFintechそして自動化関連のライブラリが豊富に用意されていることが主な要因です。GoはPythonに比べて処理速度が早く、バックエンドの言語として主流になりつつあります。中国の人気Webサイトは、（人口が多いので）Goでつくられています。 海外で主流となっている技術や流行は、5年後に日本の流行となる傾向があります。 そのため学ぶべき言語は、数年後を見据えた学習なのか、直近のジョブチェンジを見据えた学習なのか等で変わってくると思います。 つまり、、、・3〜5年後を見据えた学習→Python・直近のニーズに適した学習→PHP or Rubyということだね！ ただし、PHPやRubyを学んでおけば、Pythonへの学習も楽になるので決して無駄にはなりません。 以上を踏まえ、自分が何の言語を学ぶべきかを決めた上で、Udemyで学んでいきましょう。以降はWeb系プログラミング言語別のUdemy講座を紹介します。 【Web言語別】オススメUdemy講座 以降は私がおすすめする各言語別のオススメ講座を紹介します。 その前に、オススメする根拠として評価観点を整理します。 コスパの良し悪し 「作って終わり」ではなく外部に公開するためのレクチャーも含まれるかどうか 初心者ファーストに開発環境のインストールも丁寧に説明しているかどうか 評価観点 1. 講義のボリューム2. 外部公開レクチャーの有無3. 環境構築レクチャーの有無 繰り返しになりますが、全くのプログラミング初心者の場合、Udemyは難しいと感じる可能性が高いです 全くの初心者の方は以下の記事を参照してください。 PHP/LaravelのオススメUdemy講座 PHPからLaravelまで サーバーサイドをとことんやってみよう【初心者から脱初心者へ】【わかりやすさ最重視】 講義のボリューム 12.5時間 レクチャ数：132 外部公開レクチャーの有無 ○ Xサーバーへのアップロード 環境構築レクチャーの有無 ○ Win・Mac両方有り 講義内容 ・ PHP基礎 ・ お問合せフォーム ・ データベース接続 ・ セッションや高度な関数 ・ オブジェクト指向やモダンPHP ・ Laravel入門 ・ 簡易Webアプリ（CRUGFD/RESTful） ・ Webアプリを開発するために ・ 補足(XAMPPインストール, MAMPインストール, Visual Studio Codeインストール, コマンドプロンプトの使い方, composerのインストール, Laravelのインストール, Node.jsのインストール) PHPの基礎、フォームの作成、DB接続、Laravelと内容が盛りだくさんです。講師の方は、わかりやすさをモットーに講義を作成しておられることもあり、レビューの評価も高くUdemyベストセラーの講座となっています。 作成したアプリケーションをサーバーへアップロードする方法もレクチャーに含まれているので、この講義をベースに自分なりのアプリケーションを作成し外部公開/アピールが可能となります。 受講の際ですが講師の方から以下のようなお知らせが記載されています。 わかりやすさをモットーに解説しておりますが、まったくのプログラミング初心者の場合は少し内容が難しいかもしれません。全くの初心者の場合はプロゲートやドットインストールなどでプログラミングってこんなもの、と体験いただいてからご受講いただいた方がいいかもしれません。 Ruby/RailsのオススメUdemy講座はじめてのRuby on Rails入門-RubyとRailsを基礎から学びWebアプリケーションをネットに公開しよう 講義のボリューム 9時間 レクチャ数：166 外部公開レクチャーの有無 ○ Herokuへのアップロード 環境構築レクチャーの有無 ○ AWS Cloud9を使用 講義内容 ・ 開発環境構築 ・ はじめてのRuby入門 ・ 初めてのRuby on Rails入門 ・ ミニQ&Aサービスの開発 ・ インターネットにWebサービスを公開する Rubyの基礎からHerokuというPaaS環境にアプリを公開するレクチャーまで一気通貫で学べる構成になっています。 Herokuは、無料で自分のWebアプリケーションを外部公開できるクラウドサービスであり、私も重宝しているサービスです。 本講座の特徴は、AWS Cloud9というクラウド環境の開発環境を使用している点です。Cloud9を利用する場合はメールアドレス、クレジットカード、電話番号が必要です。 クレジットカードなど用意できないという方は、本ブログでDockerというコンテナ型仮想環境を使った開発環境構築方法を整理しているので参照いただければと思います。 受講の際の注意点など、講師の方から以下のようなお知らせが記載されています。Progateなどで要件を満たしてからの受講が望ましいと思います。 受講者対象プログラミング入門サイトを1周したくらいのWeb開発初心者プログラミングの基礎は学習したが、Webサービスの実際の作り方と公開の仕方がわからないポートフォリオサイトを作ってWeb系の企業に転職したい要件HTMLの基礎知識CSSの基礎知識JavaScriptの基礎知識データベース・SQLの基礎知識Linuxコマンドによるファイル操作の基礎知識（cd, ls, mv, sudoが使えるレベル） Python/DjangoのオススメUdemy講座【徹底的に解説！】Djangoの基礎をマスターして、3つのアプリを作ろう！（Django2版 / 3版を同時公開中です） 講義のボリューム 19時間 (Django2/3両方のため実質9.5時間) レクチャ数：165 (Django2/3両方のため実質82) 外部公開レクチャーの有無 ○ VPSへのアップロード 環境構築レクチャーの有無 ○ Win/Mac両方対応 講義内容 ・ はじめに ・ フレームワークとは ・ 開発環境の構築 ・ Hello Worldアプリ ・ Todoアプリ ・ 社内SNSアプリ ・ 作成したアプリの公開 Djangoは2019年12月にバージョン3が公開されました。 Django3に対応したUdemyの日本語講座は3つほどしか存在しません。 その中でもこの講座は、Django単体では本講座が最もわかりやすく丁寧に解説されています。 ただし、HTML、CSS、Pythonの基礎は本講座では触れてないので、Progateで学んでおく方が理解は早いと思います。 受講の際の注意点など、講師の方から以下のようなお知らせが記載されています。Progateなどで要件を満たしてからの受講が望ましいと思います。 受講者対象フレームワークについてこれから学ぼうと考えている方Djangoの基礎的な内容を学びたい方要件Pythonの基礎的な文法を学んでいると、より理解を深めることができます。フレームワークやDjangoの知識は必要ありません。使われるマシンにもよりますが、Linuxの基本的なコマンド（ls、mkdir、touch、cd）を理解しているとスムーズに進めることができるかと思います。 まとめ：学習計画を踏まえUdemyを活用しよう！ 今回は、「パソコン初心者がエンジニアになるためのオススメUdemy講座」というテーマでお話しました。 まず大事なのは、Udemyは全くのプログラミング初心者には少し難しいということです。 そんな方向けの記事もまとめているので参考になればと思います。私自身は以下の記事で紹介している流れで学習を進めて土台を作り、Udemyで新たな知識を吸収しています。 最後に、Web系エンジニアに必要なスキルは、まだまだ多くことが必要になります。例えばGit/Gtihubやデータベースの知識も必要になります。でも大丈夫です。ここまで頑張ったなら、自らGoogle検索やドキュメンなどを調べて自ら学ぶための自走力はついているはずです。 なお、Udemyには無料でGit/Githubを学べるレクチャがあります。Udemyがどんなものなのかを試しに見てみる程度でも良いので、ご確認いただければと思います。 無料でGitを学ぶ！ 以上です！ Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。","link":"/road-to-web-engineer/"},{"title":"【プログラミング】SkillHacks受講後にオススメのUdemy講座","text":"SkillHacksを受講した後の学習スケジュールは決まってますか？ SkillHacks同様、オンラインで学習を進めたいという方は、Udemyがおすすめです。 Udemy 不定期に開催されるセール時は、1000円台で講座を購入できるのでお財布にも優しいです。 SkillHacksを受講し終わった方を対象に、数あるUdemyの講座の中で、おすすめの講座をまとめました。 ✓目次 本記事の信頼性について オススメの講座一覧(タイプ別) 1.Ruby/Ruby on Railsの知識を深めたい方 1.1. Rubyで作る! ビットコイン自動売買システム 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 3. インフラの知識を深めたい方 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 3.2. Amazon Web Service マスターコース EC2編 4. 他の言語等を学び知識の幅を広げたい方 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） 4.2. 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 4.3. 【JavaScript】：実例でわかる JavaScript 初心者講座 まとめ 本記事の信頼性について こちらで紹介している講座は、筆者が実際に受講した講座の中から選定しております。※筆者が受講済の講座数は、2020年5月時点で、約30講座です。 網羅性という観点で心配されるかと思いますが、Udemyは30日間の返金保証があります。 「受講してみたけど、やっぱり違うな」と感じたら、お金は返ってきますのでご安心ください。 オススメの講座一覧(タイプ別) これから学習したい方向性や考え方別にまとめたいと思います。 SkillHackの講師が「学んだほうが良い」と述べているもの ＋ 今のIT業界の流行という観点で分類しました。 Ruby/Ruby on Railsの知識を深めたい方 現場で絶対に使うGit/Githubの知識を深めたい方 インフラの知識を深めたい方 他の言語等を学び知識の幅を広げたい方 早速、以下にまとめたいと思います。 1.Ruby/Ruby on Railsの知識を深めたい方 SkillHacksで、Ruby/Ruby on Railsを学ばれたかと思いますが、Ruby/Ruby on Railsには、まだまだ深い技術が存在します。 SkillHacksでは扱わなかった技術を補完する or 深めるということにフォーカスして、２つの講座を紹介します。 1.1. Rubyで作る! ビットコイン自動売買システム a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYnOIbA\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム SkillHacksの講師である迫さんが講師を務める講座です。 開発環境がSkillHacksと同じAmazonCloud9であり、かつ、講師が同じなのでスムーズに講義に入れると思います。 講義の中身ですが、SkillHacksでは扱っていないRubyのライブラリやREST APIを用いたアプリケーション開発手法が学べます。 Railsの講義はありませんが、Webアプリケーションを作成する際、外部のAPIを活用して作成する機会は多いです。 API keyの扱い方やJsonの知識もRubyと合わせて学んでおくべきだと思います。 講座の概要欄に「現在，bitFlyerにて新規アカウントの作成が停止されています。」と記載がありますが、2019年7月3日から、bitflyerの新規アカウントの受付が再開されているのでご安心ください。 あわよくば仮想通貨で一攫千金が狙えるかも？ 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoetKL\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rails-kj/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1497262_1c92.jpg\"}}); フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 即戦力のRailsエンジニアになることを目的とした講座です。 基本的なRubyの基礎から応用まで網羅的にまとめられているので復習もかねて学習が進められると思います。 ”即戦力”というだけあり、コードを綺麗に書く際の考え方に加え、Dockerというコンテナ型仮想化技術や、プログラムが想定した動作をすることをテストするためのプログラムであるテストコード(RSpec)のレクチャもあります。 またSkillHacksでは扱っていない、ログイン、ログアウト機能の実装についても、本講義で扱っています。 かなりのボリュームなので、全部をマスターするには時間がかかると思いますが、この講座の内容を習熟できれば十分即戦力のRuby/Ruby on Railsのエンジニアになれると思います。 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 Web関連の開発現場では、ソースコード管理ツールGitは必須の知識となります。 開発メンバーにいち早く加わるためにも、GitとGitHubを学びましょう。 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYolLK2\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 正直この講座だけでGit/GitHubは問題ありません。 Gitとはなにか、GitHubとはなにか、等、綺麗な図で説明されており、ハンズオンで手を動かしながら学ぶことができます。 GitHub Flowと呼ばれるチーム開発でコードの管理をするための概念を理解したうえで、Gitを扱えるようになっておけば、開発現場のメンバーとしてすぐに加われると思います。 また、自分が作成したアプリのコードをGithubにアップロードしておいて技術をアピールしてもいいかもしれません。 余談ですが、このブログはGithubの機能の一つであるGitHub PagesとHexoという静的ブログジェネレータを用いて作成されています。 3. インフラの知識を深めたい方 インフラ技術は多岐にわたりますが、その中でもAWSを扱う企業が多い印象を受けます。 ここではSkillHacksを学んだRuby on Railsと関わり高いAWS関連の講座を中心にまとめました。 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYozwYi\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/aws-and-infra/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2361020_edcc.jpg\"}}); AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 Linuxのコマンドの少々不安がある方は、こちらの講座で基礎から学ぶのが良いと思います。 先ほど紹介した「Git： もう怖くないGit！チーム開発で必要なGitを完全マスター」と同じ講師の方になります。 分かりやすさの観点では断トツに良いです。 AWSの基本的な機能であるEC2, Route53, RDS, S3周辺は、この講座で問題ないかと思います 3.2. Amazon Web Service マスターコース EC2編 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYouKOH\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/amazon-web-service-ec2/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1949062_f23f_2.jpg\"}}); Amazon Web Service マスターコース EC2編 Webサーバの構築やそれなりにAWSを知っている方は、こちらの講座が良いと思います。 EC2を中心にしっかりと学ぶ、という意味では、おそらくこの講座が筆頭であり、詳細な領域まで学ぶことができます。 「フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座」と同じ講師の方の講座になります。 EC2編となっておりますが、VPC編もありますので、余力があればそちらも受講すると良いかと思います。 4. 他の言語等を学び知識の幅を広げたい方 Ruby/Ruby on Rails以外の言語も学びたいという方向けにオススメの講座をまとめました。 特に人気の高いPython, JavaScriptに分けて記載しています。 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoFMhf\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/django-beginner/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1213286_dfba_2.jpg\"}}); 【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） ”3日でできる”とタイトルにありますが、たぶん3日で終わらないくらい充実した講座です。 Djangoとは、Ruby on Railsによく似たPythonのWebフレームワークです。 UdemyのプラットフォームもPythonとDjangoで開発されています、 昨今のAIブームから、ニューラルネットワーク用のライブラリが豊富なPythonベースであるDjangoを使う企業も多くなると想定します。 この講座ではブログサービスを構築しており、SkillHacksでも学んだ内容がそのまま活かせる内容になっていておすすめです。 AWSへの公開方法もレクチャーの中で学べます。 SkillHacksで作成した掲示板を、Python on Djangoで作成するとより理解が深まります。※私もやりました。 4.2. 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） 数あるUdemyの講座の中でも、「【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論」はオススメです。 理由は、以下です。※ほぼSkill Hacksと同じですが、、、 ・ コードを書く前の設計方法をレクチャーしてくれる ・ コードを書く際の思考の流れもレクチャーしてくれる。 最初に述べたSkill Hacksと同様、プログラミングを書く際の思考が学べる講座だからです。 この講座を実際に受講して、私個人が「いいな」と思ったのは、いきなりコードを書かずに日本語の文章でどのような処理をどうすればよいのかという考え方から入る点です。 これは、実際に仕事でプログラミングをする際にも行うことなのですが、この工程をせずにいきなりコードを書き始める講座がホントに多いんですよね。。。。 「どのような設計や構造にすれば、目的のシステムが作れるのか」というのを、頭に思い浮かべながらコードを書くことができる人はごく少数です。 大抵は、まず日本語のテキストや絵をつかって、どのようなアルゴリズムで組み立てればよいのかを整理する「設計」から入るのです。 また、この講座の中でも講師の方が何度も言うのですが、「最初から完璧で美しいコードを作ろうとせず、まず動かすことを目指しましょう」という考え方が、とてもGoodだと思いました。 本当にそのとおりで、最初は汚いコードでも動けばOKで、動いてから綺麗なものに成形(リファクタリング)すればよいと思います。 正直、コードの書き方自体は、様々なオンライン講座で学んだ知見＋Google検索を駆使すれば問題ありません。 4.3. 【JavaScript】：実例でわかる JavaScript 初心者講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoLbht\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/javascript-kouza/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/654658_4489_3.jpg\"}}); 実例でわかる JavaScript 初心者講座 2019年の人気プログラミング言語ランキング1位のJavaScriptを基本的な文法を学びつつ実際に動くアプリを作成して理解を深められる講座です。 作成するアプリは多岐にわたります。その数なんと15個！ 税込み計算アプリ（入力欄から数値を得て計算結果を表示） アウトライン メモ（アウトライン エディタ風に、ネストしたリストを追加） 三択問題アプリ（ユーザーの解答に応じて、結果表示を分岐） 字典アプリ（マウスオーバーで、説明表示を切り替え） テーブル ソート（テーブルを、名前順や数値順で、自在にソート） 連続計算アプリ（複数行入力欄の数式を、行ごとに計算して結果表示） メモ アプリ（Webブラウザに情報を記録したり、取り出したり） HTML自動リンク アプリ（文字列からURLを探し出して、自動でタグを付加） 角丸四角画像生成アプリ（角丸四角のパスを作り、画像を動的に生成） 画像切り抜きアプリ（画像を丸く切り抜いたPNG画像を生成） セピア調アプリ（画像の画素を処理して、セピア調に変換） 音声再生アプリ（音声を読み込み、再生） 動画再生アプリ（動画を読み込み、再生） ストップウォッチ（経過時間を取得して、定期的に表示を更新） 人気Webページ表示（Web APIを利用して情報を得て、リンクボタンを自動生成 どのアプリも普段から使えそうなものばかりですよね。 私は画像の切り抜きアプリは資料作成の際に使ってます。 まとめSkillHacks終了後の学習計画の参考になればと思いUdemyのおすすめ講座をまとめました。 私自身、Udemyで現在進学習中ですので、「これは良い！」と思ったものは積極的に紹介していきたいと思います。 UdemyにはATやIoT、ブロックチェーン、動画編集、ビジネスモデル等を学べる領域は多岐にわたります。 様々な学習を通じて、興味の幅や適応領域を広げ、人生を豊かにしていきましょう。 あわせて読みたい記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/skill-hacks-next-step-udemy/"},{"title":"【Win&#x2F;Mac両対応】おすすめキーボード【2021年最新】","text":"本記事では、「WindowsとMacの両方に対応したキーボードの紹介」というテーマでまとめていきます。 本記事の対象者 [結論]Logicool MX KeysかKeychronがおすすめ Keychron K2 Logicool MX keys for Mac Keychron K1(JIS配列) Logicool MX keys 各キーボードの比較表 各キーボードのデメリット Keychronのデメリット 1. Zoom会議でキーボード音をマイクが拾う 2. パームレストが必須 3. WindowsとMacのキー配列をサイドのスイッチで切り替えなければならない Logicool MX keysのデメリット 1. メカニカルキーボードに比べると打鍵感が無い 2. キーボード幅が広くデスクスペースを専有する まとめ 記事の信頼性(自己紹介) omathin ・完全フルリモートワークのエンジニア. ・リモートワークの生産性向上に勤しむ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得 本記事の対象者 WindowsとMac、両方に対応したBluetoothキーボードが欲しい方 せっかくなら長く使える良いキーボードが欲しい方 とはいっても、3万円とかする最高級キーボードではなく、1万円くらいのコスパの良いキーボードが欲しい方 [結論]Logicool MX KeysかKeychronがおすすめ様々なキーボードを実際に使用した結果、これから紹介するlogicool MX KeysとKeychronのキーボードがコスパ的には最高かなと思いました。 HHKBやRealforceといった最高級キーボードも使ってみましたが、やっぱり値段が高い。 予算15,000円以下で高スパの良いキーボードを探し、機能性、耐久性、口コミや評判をもとに比較したところ、logicool MX KeysとKeychronのキーボードにたどり着きました。 キーボードにはUS配列、JIS配列という２種類のキー配列が存在します。 キー配列ごとにおすすめキーボードが異なりますので、以下にフローチャートを作成しました。 それぞれのキーボードの特徴をまとめていきます。 Keychron K2 Keychron K2に関しては、2021年4月26日時点でAmazonで取り扱っていないため、Keychron社のページからの購入になります。 以下のリンクから購入すれば10%OFFのクーポンを利用することができます。 &gt;&gt;10%OFFのクーポンを用いてKeychronのキーボードを購入する Keychron K2の特徴、なんと言ってもおしゃれなデザインが特徴です。 1万円程度で高級感があり、打鍵感も文句なしのキーボードです。 また似たような構成のキーボードとしてKeychron K6というキーボードも存在します。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Keychron K6 68キー Bluetooth ワイヤレス\\/USB有線ゲーミングメカニカルキーボード RGBバックライト\\/光学レッドスイッチ\\/Nキーロールオーバー Mac Windows用コンパクト65%レイアウトキーボード\",\"b\":\"Keychron\",\"t\":\"K6\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41edLECcqsL._SL500_.jpg\",\"\\/41vr12fvWaL._SL500_.jpg\",\"\\/415C13TSjAL._SL500_.jpg\",\"\\/51tbMKlPu7L._SL500_.jpg\",\"\\/41CF2Ybn2QL._SL500_.jpg\",\"\\/51hIkjKFOtL._SL500_.jpg\",\"\\/41Lb4bcErmL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07ZTC8JB5\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07ZTC8JB5\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Keychron%20K6%2068%E3%82%AD%E3%83%BC%20Bluetooth%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%2FUSB%E6%9C%89%E7%B7%9A%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%A1%E3%82%AB%E3%83%8B%E3%82%AB%E3%83%AB%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20RGB%E3%83%90%E3%83%83%E3%82%AF%E3%83%A9%E3%82%A4%E3%83%88%2F%E5%85%89%E5%AD%A6%E3%83%AC%E3%83%83%E3%83%89%E3%82%B9%E3%82%A4%E3%83%83%E3%83%81%2FN%E3%82%AD%E3%83%BC%E3%83%AD%E3%83%BC%E3%83%AB%E3%82%AA%E3%83%BC%E3%83%90%E3%83%BC%20Mac%20Windows%E7%94%A8%E3%82%B3%E3%83%B3%E3%83%91%E3%82%AF%E3%83%8865%25%E3%83%AC%E3%82%A4%E3%82%A2%E3%82%A6%E3%83%88%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"ECExP\",\"s\":\"s\"}); リンク もしこの記事を読んでいる方で。ファンクションキーを殆ど使わないという方でしたら、Keychron K6が良いと思います。 私はWeb制作などをする際、Google Chromeのデベロッパーツールを使うのですが、その際にF12キーを使います。また、ページの更新の際は、F5を使いますし、Windowsで文字入力の際に、カタカナ変換するときはF7を使ったりします。 こういったように、ファンクションキーをそれなりに使うという方はKeychron K2が適していると思います。 Bluetooth接続は、最大で３デバイスまで登録可能であり、Functionキー + 1 or 2 or 3でペアリング接続可能です。 Logicool MX keys for Mac “for Mac”と記載されていますが、Windows側のデバイス設定で、US配列を指定すれば、問題なく使えます。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール アドバンスド ワイヤレス イルミネイテッド キーボード KX800M MX KEYS for Mac 充電式 US配列 bluetooth Unifying iPad 無線 ワイヤレスキーボード 薄型 KX800 スペースグレー 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"920-009844\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41kJv60lbSL._SL500_.jpg\",\"\\/51J02p4tLzL._SL500_.jpg\",\"\\/41qfvi0CPzL._SL500_.jpg\",\"\\/51UdIo55hKL._SL500_.jpg\",\"\\/51Nhb6gtpaL._SL500_.jpg\",\"\\/51yxqSAtlnL._SL500_.jpg\",\"\\/41LG0IjX4JL._SL500_.jpg\",\"\\/510lKd2ITQL._SL500_.jpg\",\"\\/51kWjGcmVgL._SL500_.jpg\",\"\\/5116d9U8DBL._SL500_.jpg\",\"\\/51xDZfF81HL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08D3M4D9L\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08D3M4D9L\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20%E3%82%A2%E3%83%89%E3%83%90%E3%83%B3%E3%82%B9%E3%83%89%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E3%82%A4%E3%83%AB%E3%83%9F%E3%83%8D%E3%82%A4%E3%83%86%E3%83%83%E3%83%89%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20KX800M%20MX%20KEYS%20for%20Mac%20%E5%85%85%E9%9B%BB%E5%BC%8F%20US%E9%85%8D%E5%88%97%20bluetooth%20Unifying%20iPad%20%E7%84%A1%E7%B7%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E8%96%84%E5%9E%8B%20KX800%20%E3%82%B9%E3%83%9A%E3%83%BC%E3%82%B9%E3%82%B0%E3%83%AC%E3%83%BC%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"JMrKX\",\"s\":\"s\"}); リンク Logicool MX keysの良いところは、なんと言ってもFlow機能かと思います。 Flow機能とは、複数のパソコン間を、まるでひとつのデバイスかのようにドラックアンドドロップでファイルを移動させたりできる機能です。 Flow機能は、LogicoolのMX keysシリーズに加え、Flow機能に対応したLogicoolのマウスを使用することで利用できます。 持ち運び可能で必要最低限の機能を具備したLogicool Anywhereがおすすめです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール ワイヤレスマウス 無線 マウス ANYWHERE 2S MX1600sGR Unifying Bluetooth 高速充電式 FLOW対応 7ボタン windows mac iPad OS 対応 MX1600s グラファイト 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"910-005162\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/316SUL+A3rL._SL500_.jpg\",\"\\/41s2q86MQrL._SL500_.jpg\",\"\\/41KaFkNx48L._SL500_.jpg\",\"\\/415l-66NggL._SL500_.jpg\",\"\\/41s7i51FcEL._SL500_.jpg\",\"\\/414roS+tO0L._SL500_.jpg\",\"\\/41EkFOTRMSL._SL500_.jpg\",\"\\/419E9utJBhL._SL500_.jpg\",\"\\/51kXZiKB1iL._SL500_.jpg\",\"\\/41K+4t6xSkL._SL500_.jpg\",\"\\/41Be6cnVK9L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0722XWTFR\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0722XWTFR\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%83%9E%E3%82%A6%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%83%9E%E3%82%A6%E3%82%B9%20ANYWHERE%202S%20MX1600sGR%20Unifying%20Bluetooth%20%E9%AB%98%E9%80%9F%E5%85%85%E9%9B%BB%E5%BC%8F%20FLOW%E5%AF%BE%E5%BF%9C%207%E3%83%9C%E3%82%BF%E3%83%B3%20windows%20mac%20iPad%20OS%20%E5%AF%BE%E5%BF%9C%20MX1600s%20%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%88%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"Bm9Xb\",\"s\":\"s\"}); リンク Logicool製のキーボードを購入する場合は、Flow機能に対応したマウスも購入しておくと良いかと思います。。 Keychron K1(JIS配列) こちらも、以下のリンクから購入すれば10%割引になりますので、ご利用ください。 &gt;&gt;10%OFFのクーポンを用いてKeychronのキーボードを購入する USキーボードしか対応していなかったKeychronが、JIS配列に対応しました。 JIS配列に対応したKeychronのキーボードは、2021年4月26日時点で、Keychron K1しか存在しません。 Keychron K2と同様に3デバイスまで同時接続が可能で、Windows/Mac両方に対応したキーボードです。 Keychron K2と比べて薄型のキーボードですが、打鍵感もちゃんとメカニカルキーボード同様に打ち心地がよく、デザインもかっこいいです！ Logicool MX keys (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ロジクール アドバンスド ワイヤレスキーボード KX800 MX KEYS 充電式 bluetooth Unifying Windows Mac FLOW ワイヤレス 無線 キーボード 国内正規品 2年間無償保証\",\"b\":\"Logicool(ロジクール)\",\"t\":\"920-009299\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41rNbCxiY8L._SL500_.jpg\",\"\\/515K3FLwHLL._SL500_.jpg\",\"\\/51J2ZE4-heL._SL500_.jpg\",\"\\/516LLl7STBL._SL500_.jpg\",\"\\/51psOaUW6xL._SL500_.jpg\",\"\\/51IuR1By8OL._SL500_.jpg\",\"\\/510jyfBDu6L._SL500_.jpg\",\"\\/51NJNRizUKL._SL500_.jpg\",\"\\/516Qu0VIOAL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07XQ7G6BH\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07XQ7G6BH\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB%20%E3%82%A2%E3%83%89%E3%83%90%E3%83%B3%E3%82%B9%E3%83%89%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20KX800%20MX%20KEYS%20%E5%85%85%E9%9B%BB%E5%BC%8F%20bluetooth%20Unifying%20Windows%20Mac%20FLOW%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E7%84%A1%E7%B7%9A%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E5%9B%BD%E5%86%85%E6%AD%A3%E8%A6%8F%E5%93%81%202%E5%B9%B4%E9%96%93%E7%84%A1%E5%84%9F%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"kSOxx\",\"s\":\"s\"}); リンク JIS配列キーボードで、メカニカルではないキーボードであれば、こちらのキーボード一択だと思います。 このキーボードもFlow機能を具備しており、Flow機能に対応したLogicllのマウスと組み合わせることで、作業効率を飛躍的にUPさせることができます。 各キーボードの比較表 Keychron K2 Logicool MX keys for Mac Keychron K1(JIS配列) Logicool MX keys キー配列 US US JIS JIS キー構造 メカニカル構造 パンタグラフ構造 メカニカル構造 パンタグラフ構造 同時接続数 3 3 3 3 バックライト RGB or ホワイト ホワイト RGB or ホワイト ホワイト その他機能 - Flow機能 - Flow機能 各キーボードのデメリットおすすめのキーボードをまとめてきましたが、いずれのキーボードも良い点/悪い点があります。 私個人の主観も含まれますが、購入の際の参考にしていただければと思います。 Keychronのデメリット1. Zoom会議でキーボード音をマイクが拾うリモートワークをされている方で、WebEXやZoomなどを用いてビデオ会議をする機会があると思います。 その際、Keychronのメカニカルキーボードを利用すると、キーボード音をマイクが拾います。 会議の参加者から、「すごい音ですね。」なんて言われたりします。 もしリモートワークをしながらクライアントとビデオ会議される方は、注意したほうが良いかと思います。 2. パームレストが必須特にKeychron K2を購入する場合は、パームレストが必須です。 パームレストが無いと手首の負担が大きく、ブログ記事の執筆も進みません。 Keychron製のパームレストも販売されていますが、Amazonでもおしゃれなパームレストが販売されています。 パームレストの素材は、木製のものが良いです。汚れが着いても拭き取れますし、木独特の良い匂いが最高です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Side3 天然木 ウッドリストレスト 木製パームレスト (Mサイズ:30cm, ウォールナット材)\",\"b\":\"Side3\",\"t\":\"FGWR\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31Iru6F7ZvL._SL500_.jpg\",\"\\/41YEFDVYgnL._SL500_.jpg\",\"\\/41v+uumyWQL._SL500_.jpg\",\"\\/41hWPmCcRXL._SL500_.jpg\",\"\\/41TgdehIGbL._SL500_.jpg\",\"\\/410oz7++MQL._SL500_.jpg\",\"\\/51RB3Wey1tL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08C5KXW8G\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08C5KXW8G\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Side3%20%E5%A4%A9%E7%84%B6%E6%9C%A8%20%E3%82%A6%E3%83%83%E3%83%89%E3%83%AA%E3%82%B9%E3%83%88%E3%83%AC%E3%82%B9%E3%83%88%20%E6%9C%A8%E8%A3%BD%E3%83%91%E3%83%BC%E3%83%A0%E3%83%AC%E3%82%B9%E3%83%88%20(M%E3%82%B5%E3%82%A4%E3%82%BA%3A30cm%2C%20%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB%E3%83%8A%E3%83%83%E3%83%88%E6%9D%90)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"0aalG\",\"s\":\"s\"}); リンク 3. WindowsとMacのキー配列をサイドのスイッチで切り替えなければならないWindowsとMacのPC間を切り替える場合、Logicool MXシリーズのキーボードは、ボタン一つで接続先のPCを切り替えるだけでなく、OSに最適化されたキー配列の設定に自動で切り替えてくれます。 しかし、KeychronでWindowsからMac（その逆パタン含む）に接続を切り替える場合、Fn + 1 or 2 or3 で接続先を切り替えるだけでは、キー配列の切り替えができません。 Keychronのキーボードのサイドにある「Windows/Mac」のキー配列を切り替える物理ボタンを操作しなければなりません。 これが以外と面倒です。 Logicool MX keysのデメリット1. メカニカルキーボードに比べると打鍵感が無いLogicool MX Keysのキー構造は、パンタグラフ構造であり、メカニカル構造に比べると、タイピング時の心地よさが物足りません。 メカニカルキーボードのタイピングの心地よさを覚えた後、パンタグラフに戻ると、タイピングしている感覚が弱く、爽快感がありません。 2. キーボード幅が広くデスクスペースを専有するKeychronと比較すると、Logicool MX keysは、横幅が広くデスクのスペースを専有してしまいます。 上の画像を見ていただくと分かる通り、Keychronのほうがかなりコンパクトですよね。 机を広く使いたい、という方に取っては、少しデメリットポイントかと思います。 まとめ本記事では、「【Win/Mac両対応】おすすめキーボード【2021年最新】」というテーマでまとめました。 「キーボードにお金をかけるなんて。。。」と思う方もいらっしゃるかと思いますが、中途半端に安いものを買うよりかは、少し背伸びをして良いものを買った方が、長持ちしますし作業効率も高まります。 「かといって最高級のキーボードを買うのもちょっとなぁ」という方は、本記事の内容が参考になると思っています。 皆様のワークスタイルに合ったキーボードを導入し、素晴らしいタイピングライフを送っていただけることを願っております。","link":"/win-mac-keyboard/"},{"title":"【自然言語処理】Google Colaboratoryでword2vecを実装してみよう！","text":"本記事では、word2vecを実装していきます。 word2vecとはなにか？については、以下の記事でまとめています。 実装の全体像 1. word2vecを実装する環境を用意する 2. Livedoorニュースのファイルをダウンロードしカテゴリ数と内容を確認する 3. 記事を2つ抽出し、記事の全文と記事のラベル（カテゴリ）を表示してみる 4. Word2Vecの実装 1. word2vecを実装する環境を用意する本記事では、Google Colaboratoryを使用します。 Google Colaboratoryとは、ブラウザ上でPythonを記述し実行できる環境です。 Googleのアカウントを持っていればすぐに利用できます。 GPUも無料で利用できるなど、嬉しい機能がたくさん備わっています。 詳しい使い方は、こちらで紹介されています。 もし、ローカルの環境に、Google Colaboratoryと似たような開発環境を用意したい場合は、以下の記事を参照いただければと思います。Anaconda Navigatorを用いてjupyter notebookを利用する方法です。 2. Livedoorニュースのファイルをダウンロードしカテゴリ数と内容を確認する本記事では、livedoor newsコーパスというテキストコーパスを使用します。 Google colabで以下のコードを入力し実行してみましょう。 Livedoorコーパスのダウンロード1! wget &quot;https://www.rondhuit.com/download/ldcc-20140209.tar.gz&quot; 以下のような出力がされたら、ダウンロード成功です。 出力12345678910--2021-04-29 08:42:51-- https://www.rondhuit.com/download/ldcc-20140209.tar.gzResolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 8855190 (8.4M) [application/x-gzip]Saving to: ‘ldcc-20140209.tar.gz’ldcc-20140209.tar.g 100%[===================&gt;] 8.44M 2.00MB/s in 4.2s 2021-04-29 08:42:56 (2.00 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190] また、Google colabの画面左側に表示されるフォルダに、Livedoorコーパスのファイルがダウンロードされていることを確認しましょう。Ldcc-20140209.tar.gzというファイルが、Livedoorコーパスファイルです。 次に、ダウンロードしたファイルを解凍し、カテゴリーの数と内容を確認します。 以下のコードを実行します。 ファイルの解凍とカテゴリー数の確認12345678910111213141516171819# ファイルを解凍し、カテゴリー数と内容を確認import tarfileimport os# 解凍tar = tarfile.open(&quot;ldcc-20140209.tar.gz&quot;, &quot;r:gz&quot;)tar.extractall(&quot;./data/livedoor/&quot;)tar.close()# フォルダのファイルとディレクトリを確認files_folders = [name for name in os.listdir(&quot;./data/livedoor/text/&quot;)]print(files_folders)# カテゴリーのフォルダのみを抽出categories = [name for name in os.listdir( &quot;./data/livedoor/text/&quot;) if os.path.isdir(&quot;./data/livedoor/text/&quot;+name)]print(&quot;カテゴリー数:&quot;, len(categories))print(categories) こちらのコードを実行すると、以下のような出力が得られます。 出力123['topic-news', 'kaden-channel', 'README.txt', 'sports-watch', 'CHANGES.txt', 'it-life-hack', 'movie-enter', 'dokujo-tsushin', 'smax', 'livedoor-homme', 'peachy']カテゴリー数: 9['topic-news', 'kaden-channel', 'sports-watch', 'it-life-hack', 'movie-enter', 'dokujo-tsushin', 'smax', 'livedoor-homme', 'peachy'] カテゴリーの数は9つ存在することが分かります。 9つのカテゴリは、['topic-news', 'kaden-channel', 'sports-watch', 'it-life-hack', 'movie-enter', 'dokujo-tsushin', 'smax', 'livedoor-homme', 'peachy']です。 3. 記事を2つ抽出し、記事の全文と記事のラベル（カテゴリ）を表示してみるまずは、word2vecを実装するために必要なライブラリを導入します。以下のコードを実行して、janomeをインストールします。 1!pip install janome 以下のような出力が得られたら成功です。 出力12345Collecting janome Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB) |████████████████████████████████| 19.7MB 1.2MB/s Installing collected packages: janomeSuccessfully installed janome-0.4.1 その上で、以下のコードを実行すれば、2つの記事のラベルと全文が確認できます。 123456789101112131415161718192021222324252627282930313233343536373839import globfrom janome.tokenizer import Tokenizerfrom gensim.models import word2vecdef load_livedoor_news_corpus(): category = { &quot;dokujo-tsushin&quot;: 1, &quot;it-life-hack&quot;:2, &quot;kaden-channel&quot;: 3, &quot;livedoor-homme&quot;: 4, &quot;movie-enter&quot;: 5, &quot;peachy&quot;: 6, &quot;smax&quot;: 7, &quot;sports-watch&quot;: 8, &quot;topic-news&quot;:9 } docs = [] labels = [] for c_name, c_id in category.items(): files = glob.glob(&quot;./data/livedoor/text/{c_name}/{c_name}*.txt&quot;.format(c_name=c_name)) for file in files: with open(file, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f: lines = f.read().splitlines() url = lines[0] datetime = lines[1] subject = lines[2] body = &quot;&quot;.join(lines[3:]) text = subject + body docs.append(text) labels.append(c_id) return docs, labelsdocs, labels = load_livedoor_news_corpus()print(&quot;\\nlabel: &quot;, labels[0], &quot;\\ndocs:\\n&quot;, docs[0])print(&quot;\\nlabel: &quot;, labels[1000], &quot;\\ndocs:\\n&quot;, docs[1000]) 簡単にコードの内容を説明します。合わせて、pythonのコードも学んでおきましょう。 import globは、globというモジュールを導入しています。globモジュールは、ファイルやディレクトリを操作するときに便利なモジュールであり、正規表現を用いてパスを指定できます。 def load_livedoor_news_corpus()関数では、全ての記事の文章データとそのラベル（カテゴリー）を取得しています。 辞書型のループ処理をする際、items()というメソッドを使うことで、キーとバリューの両方を変数に格納することができます。このコードでは、キーはc_nameという変数に、バリューはc_idという変数に格納されています。 ファイルを読み込む際は以下のメソッドを使用します。 open(): ファイルを開く read(): ファイルを読み込む close(): ファイルを閉じる 本コードで用いているopen()の第二引数に&quot;r&quot;と記述されています。これはファイルを開くときのモードを指定するもので、この場合だとreadの意味になり、読み込み専用であることを表しています。 通常、ファイルを読み込み、処理を行った後は、close()を用いてファイルを閉じる必要があるのですが、このclose()を書き忘れてしまったり、途中でエラーが発生し、ファイルが閉じることができず、無駄にメモリを専有するといったことが起こります。 それを防ぐために、with文を使用します。 with文を用いると、ファイルが自動的にclose()されるため、明示的にclose()を記述する必要がありません。また、ファイルを開いている間にエラーが発生しても、適切な例外処理が自動的に行われるため、メモリを専有することも防げます。 本コードのポイントとしては以上です。 このコードを実行すると、以下のような出力が得られるかと思います。 1234567label: 1 docs: ムダな抵抗！？ 加齢の現実 ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「そげる→たわむ→外に流れる」という。バストの変化はすでに20代から始まり、20代にして「たわむ」になっている人もいる。そして、元に戻った人は一人もいない。さらに、体の各部位の20代〜50代までの変化をみると、ウエストとお腹の変化が最も大きく、お腹はバストと同じ大きさになっている。 これは、４月に開催されたワコール人間科学研究所の記者発表「からだのエイジング（加齢による体型変化）について一定の法則を発見」での内容の一部。延べ4万人分の経年変化の数値を集計・分析したデータとともに、写真や映像で説明させるので説得力は抜群だ。 現実を直視させられた後に、体型変化の少ない人達の身体的特徴や日常の行動・意識を紹介。その主な内容は、日頃から体を動かし、姿勢をチェック、下着は必ず試着してフィット感を確かめるというもの。そして、パネルディスカッションでは、歩幅の広い歩き方を１年間続ける実験に参加した人が、背筋が伸び、脂肪が落ちたという結果などが紹介されていた。 興味は尽きず、知人たちに内容を伝えるとさまざまな意見や経験が聞けた。 「ずっと計測されているから、体型変化の少ない人はスポーツをしてたのでは？」という疑問もあったが、この回答は、「運動を一生懸命しているというより日常生活を気をつけている印象が強い。そして、ダイエットはあまりしたことがない」とのこと。 「叔母もそんなことを言っていた」と言うのはＹ子。60歳代の叔母さんが友人たちと温泉旅行に行ったとき、「バストの変化が少ないとほめられた」と喜んでいたので、バストのケア方法を尋ねたそうだ。「叔母はブラジャーを常に着用し、購入時は必ず計測して試着している。一方、友人達は『苦しい』からと家ではブラジャーをしないこともあるらしい」。それを聞いて以来、Ｙ子は下着を買うときには試着はもちろん、計ってもらうようにしている。 「私も歩いてやせた」と話すのは、腰痛に悩まされていたＫ子。医師に筋力の低下を指摘されて、駅までの自転車を止めて、片道30分の道のりを毎日往復歩くことに。筋力をつけるために始めたことで体全体が引き締まり、結果として減量にも成功した。 「でも、スポーツすればしまるよね」と言うＡ子は、不摂生がたたって気になり始めたウエスト回りをスポーツクラブに通って改善。ジーンズがワンサイズ小さくなったと喜んでいる。 パネルディスカッションでは、「加齢は一方通行だが、現状維持は可能」「アンチエイジングは医学界でも注目だが、身体的な美しさの維持と健康維持の関係性は表裏一体のはず」とも言われていた。それならば、体型変化という加齢への抵抗はあきらめないほうが得策だ。杉本彩が言っていたっけ、「若いころに戻りたいとか、若く見られたい、とは思わない。今の自分がどう美しくあるかを追求したい」って。（オフィスエムツー／オオノマキ）詳細はコチラlabel: 2 docs: Excel表のデータの合計値を計算式を使わず表示する方法【知っ得・虎の巻】Excelでいくつかのセルの合計値を知りたい場合、どうしているだろう？ 合計値を入力するセルがあるのなら、合計の計算式を入力しておけばいいわけだが、表内のある一部分の合計値を知りたい場合などだ。実は計算式など利用しなくても、合計値を知る方法がある。■知っ得No.287 ステータスバーの情報を利用する複数のセルの合計値は、実は特に設定しなくても、初期設定で画面上に表示されるようになっている。その場所がステータスバーだ。合計の他にも、平均もわかるようになっている。●複数のファイルを選択して、合計を確認する合計を知りたいセルを選択状態にし、画面下部のステータスバーの右側部分を見てほしい。［平均：●● データの個数：●● 合計：●●］と表示されているはずだ（画面1）。 画面1 セルを選択すると、ステータスバーの右側に合計値が表示される。 なんと、セルを選択するだけで、そのセルに入力されている数値の合計だけでなく、平均や、選択しているセルの個数までわかるのである。計算機を取り出して計算したり、仮にどこかのセルに計算式を入力して計算させてみたりといった手間は全然必要ない。ステータスバーに表示する内容は、ステータスバーを右クリックすると表示される［ステータスバーのユーザー設定］で選択することで変更することもできる（画面2）。 画面2 ［ステータスバーのユーザー設定］で表示する内容を指定できる。 その時々で、必要とする情報が表示されるよう、設定を変更するといいだろう。編集部：池田利夫＋岡本奈知子（ジャムハウス）制作編集：エヌプラスCopyright 2012 livedoor. All rights reserved.■PC便利技が満載！「知っ得！虎の巻」ブログ■の記事をもっとみる・最近使ったファイルを素早くスタートメニューから開く・先頭行を固定したままスクロールするには？−−今さら聞けないExcelワザ・WordやExcelでよく使うコマンドをワンクリックで実行する・ウィンドウを閉じることなくデスクトップのアイコンを操作するマル秘ワザ・今さら聞けないExcelワザ 入力後のカーソルを右方向に動かすには？ 4. Word2Vecの実装Word2Vecを実装するには、gensimというモジュールを使用します。 Word2Vecは、引数として学習に使用する文章を指定するのですが、その文章は、分かち書きされている必要があります。 分かち書きは、janome.tokenizerを使って行います。 分かち書きを行う際、日本語では、「名詞、動詞、形容詞、形容動詞」以外は単語の関連性の分析に使用できません。 そのため、「名詞、動詞、形容詞、形容動詞」のみの分かち書きリストを作成します。 123456789def tokenize(text): tokens = t.tokenize(&quot;,&quot;.join(text)) word = [] for token in tokens: part_of_speech = token.part_of_speech.split(&quot;,&quot;)[0] if part_of_speech in [&quot;名詞&quot;, &quot;動詞&quot;, &quot;形容詞&quot;, &quot;形容動詞&quot;]: word.append(token.surface) return word Word2Vecは以下のようにして実装できます。 model = word2vec.Word2Vec(リスト, sg=1, size=a, min_count=b, window=c) 各パラメータは以下のとおりです。 リスト: 分かち書きされたリスト sg: 1ならskip-gram。0ならCBOWで学習する size: ベクトルの自演数 window: この数の前後の単語を、関連性のある単語とみなして学習を行う min_count: n回未満登場する単語を破棄 作成したmodelに対して、.most_similar(positive=[&quot;単語&quot;])のようにmost_similar()メソッドを用いるとその単語との類似度が高いものが出力されます。 ここでは、「家族」という単語の類似度を算出してみます。 Word2Vecの実装123456# ラベルと文章に分類docs, labels = load_livedoor_news_corpus()t = Tokenizer() # 最初にTokenizerインスタンスを作成sentences = tokenize(docs[0:100]) # データ量が多いため制限model = word2vec.Word2Vec([sentences], sg=1, size=100, min_count=20, window=15)print(model.most_similar(positive=[&quot;家族&quot;])) 出力123[('意味', 0.9859291315078735), ('必要', 0.9851418137550354), ('お互い', 0.9839500188827515), ('親', 0.9809558987617493), ('思い', 0.9803527593612671), ('生活', 0.9785477519035339), ('母', 0.9776737689971924), ('32', 0.9745824337005615), ('あっ', 0.9723453521728516), ('みたい', 0.9685757756233215)]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead). import sys 「家族」という単語と類似度が高い単語として、「意味」や「必要」、「お互い」、「親」といった関連性の高い単語が出力されていることが分かります。 いろいろな単語で試してみましょう。 1print(model.most_similar(positive=[&quot;恋&quot;])) 出力123[('夏', 0.9577336311340332), ('アイテム', 0.9559974670410156), ('できる', 0.9532942771911621), ('カフェ', 0.9497220516204834), ('映画', 0.9485588073730469), ('中', 0.943411111831665), ('今回', 0.9432932138442993), ('魅力', 0.9406061172485352), ('行動', 0.9401353001594543), ('感', 0.9322444200515747)]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead). &quot;&quot;&quot;Entry point for launching an IPython kernel. 「恋」という単語と類似度が高い単語として「夏」、「アイテム」、「カフェ」といった単語が抽出されました。 まとめ: word2vecの実装方法を学びました 改めて全体を振り返りましょう。本記事では、以下のような流れでWord2Vecを実装してみました。 word2vecを実装する環境を用意する Livedoorニュースのファイルをダウンロードしカテゴリ数と内容を確認する 記事を2つ抽出し、記事の全文と記事のラベル（カテゴリ）を表示してみる Word2Vecの実装 本記事で紹介したコードをベースに、他の単語で試してみたり、skip-gramとCBOWの比較や、処理速度の違いを試してみてください。 また、より専門的な自然言語処理技術は、Udemyで学ぶことが出来ます。 なかでも、自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発が特におすすめですので、ご確認ください。 参考記事 https://qiita.com/g-k/items/69afa87c73654af49d36","link":"/word2vec-python/"},{"title":"【解説】データサイエンス100本ノック【問70〜74 回答】","text":"目次 第70問目: 経過日数の計算 第71問目: 経過月数の算出 第72問目: 経過年数の算出 第73問目: 経過時間の算出 第74問目: 月曜日からの経過日数の計算 まとめ: 年月日、月曜からの経過時間の算出方法を学びました。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第70問目: 経過日数の計算 P-070: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）に対し、顧客データフレーム（df_customer）の会員申込日（application_date）からの経過日数を計算し、顧客ID（customer_id）、売上日、会員申込日とともに表示せよ。結果は10件表示させれば良い（なお、sales_ymdは数値、application_dateは文字列でデータを保持している点に注意）。 本問は時間の計算について問われています。 時間の計算は、データを日付型に変換する必要があります。 日付型への変換は、pandas.to_datetime関数を使用すれば良いです。 変換を行った日付型同士では、引き算などの計算が行なえます。 変換元のデータ型毎に、日付型に変換する方法を以下の記事で紹介しているので、こちらも参照してください。 &gt;&gt; 【解説】日付データの変換方法を学ぶ | データサイエンス100本ノック【問45〜問48 回答】 本問を解きながら、使い方を学んでいきましょう。 まずはdf_receiptとdf_customerの構造を確認します。 1df_receipt.head(5) 出力1234567sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 本問を解くために、両者のデータフレームから必要なデータのみを抽出します。 まずは本問を解くために必要なデータであるdf_receiptの売上日とdf_customerの会員申込日を内部結合を行うことで抽出します。 12df_tmp = pd.merge(df_receipt[['customer_id', 'sales_ymd']], df_customer[['customer_id', 'application_date']], how='inner', on='customer_id')df_tmp.head(20) 出力123456789101112131415161718192021 customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502013 CS006214000001 20170608 201502014 CS006214000001 20181028 201502015 CS006214000001 20181028 201502016 CS006214000001 20170509 201502017 CS006214000001 20190908 201502018 CS006214000001 20180131 201502019 CS006214000001 20170705 2015020110 CS006214000001 20181110 2015020111 CS006214000001 20170705 2015020112 CS006214000001 20190410 2015020113 CS006214000001 20180131 2015020114 CS006214000001 20181103 2015020115 CS006214000001 20190601 2015020116 CS006214000001 20190908 2015020117 CS006214000001 20190507 2015020118 CS006214000001 20181110 2015020119 CS006214000001 20190507 20150201 出力した結果を見ると、重複している行が確認されますので、重複した行を削除します。 重複した行の削除は以下のコードで削除可能です。 12df_tmp = df_tmp.drop_duplicates()df_tmp.head(20) 出力12345678910111213141516171819202122customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502014 CS006214000001 20181028 201502017 CS006214000001 20190908 201502018 CS006214000001 20180131 201502019 CS006214000001 20170705 2015020110 CS006214000001 20181110 2015020112 CS006214000001 20190410 2015020115 CS006214000001 20190601 2015020117 CS006214000001 20190507 2015020122 CS008415000097 20181118 2015032223 CS008415000097 20170328 2015032224 CS008415000097 20180325 2015032228 CS008415000097 20190417 2015032230 CS028414000014 20170712 2015071131 CS028414000014 20180408 2015071132 CS028414000014 20180527 2015071133 CS028414000014 20180811 2015071134 CS028414000014 20191023 20150711 次にsales_ymdとapplication_dateを日付型に変換します。 日付型への変更方法は以下の記事にまとめているので参照してください。 &gt;&gt; 【解説】日付データの変換方法を学ぶ | データサイエンス100本ノック【問45〜問48 回答】 12df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'], format='%Y%m%d')df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 2018-11-03 201502011 CS006214000001 2017-05-09 201502012 CS006214000001 2017-06-08 201502014 CS006214000001 2018-10-28 201502017 CS006214000001 2019-09-08 20150201... ... ... ...65672 CS004411000027 2017-06-01 2015051765674 CS040513000029 2018-06-07 2015091565676 CS004613000146 2017-12-02 2016081365678 CS002314000037 2018-04-21 2015120265680 CS040311000022 2019-04-16 2015041932411 rows × 3 columns 同様にapplication_dateを日付型に変換します。 12df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'], format='%Y%m%d')df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 2018-11-03 2015-02-011 CS006214000001 2017-05-09 2015-02-012 CS006214000001 2017-06-08 2015-02-014 CS006214000001 2018-10-28 2015-02-017 CS006214000001 2019-09-08 2015-02-01... ... ... ...65672 CS004411000027 2017-06-01 2015-05-1765674 CS040513000029 2018-06-07 2015-09-1565676 CS004613000146 2017-12-02 2016-08-1365678 CS002314000037 2018-04-21 2015-12-0265680 CS040311000022 2019-04-16 2015-04-1932411 rows × 3 columns sales_ymdとapplication_dateの両者を日付型に変換できたので、あとは両データの差分をとり経過日数を計算し、新たなカラムであるelapsed_dateに格納します。 12df_tmp['elapsed_date'] = df_tmp['sales_ymd'] - df_tmp['application_date']df_tmp.head(10) 出力1234567891011 customer_id sales_ymd application_date elapsed_date0 CS006214000001 2018-11-03 2015-02-01 1371 days1 CS006214000001 2017-05-09 2015-02-01 828 days2 CS006214000001 2017-06-08 2015-02-01 858 days4 CS006214000001 2018-10-28 2015-02-01 1365 days7 CS006214000001 2019-09-08 2015-02-01 1680 days8 CS006214000001 2018-01-31 2015-02-01 1095 days9 CS006214000001 2017-07-05 2015-02-01 885 days10 CS006214000001 2018-11-10 2015-02-01 1378 days12 CS006214000001 2019-04-10 2015-02-01 1529 days15 CS006214000001 2019-06-01 2015-02-01 1581 days これで完成です。 第71問目: 経過月数の算出 P-071: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）に対し、顧客データフレーム（df_customer）の会員申込日（application_date）からの経過月数を計算し、顧客ID（customer_id）、売上日、会員申込日とともに表示せよ。結果は10件表示させれば良い（なお、sales_ymdは数値、application_dateは文字列でデータを保持している点に注意）。1ヶ月未満は切り捨てること。 前の問題と異なり「経過月数」の計算を求められています。 月単位の演算を行う場合は、dateutil.relativedeltaモジュールを使用します。 以下に簡単な使い方の例を示します。 12345from datetime import datetimefrom dateutil.relativedelta import relativedeltaresult = datetime(2020, 12, 1) + relativedelta(months=3)result 出力1datetime.datetime(2021, 3, 1, 0, 0) また、以下のようにrelativedelta(datetime1, datetime2)とすると、datetime1からdatetime2への経過時間を取得することが出来ます。 1234567from datetime import datetimefrom dateutil.relativedelta import relativedeltadatetime1 = datetime(2020, 12,1 ) datetime2 = datetime(2019, 2, 1) relativedelta(datetime1, datetime2) 出力1relativedelta(years=+1, months=+10) 上記の出力では、1年と10ヶ月が経過していることが示されています。 「1年と10ヶ月」ではなく「22ヶ月」という形式で出力させる場合は、以下のようにすればOKです。 12months = relativedelta(datetime1, datetime2).years * 12 + relativedelta(datetime1, datetime2).monthsprint(&quot;経過月数: {}&quot;.format(months)) 出力1経過月数: 22 これらのノウハウを用いて本問を解いていきましょう。 前問と同様に、df_receiptとdf_customerの必要なカラムのみで内部結合させていきます。 12df_tmp = pd.merge(df_receipt[['customer_id', 'sales_ymd']], df_customer[['customer_id', 'application_date']], how='inner', on='customer_id')df_tmp.head(10) 出力1234567891011 customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502013 CS006214000001 20170608 201502014 CS006214000001 20181028 201502015 CS006214000001 20181028 201502016 CS006214000001 20170509 201502017 CS006214000001 20190908 201502018 CS006214000001 20180131 201502019 CS006214000001 20170705 20150201 重複している行が存在しているようなので、drop_duplicates()で重複している行を削除します。 1df_tmp = df_tmp.drop_duplicates() sales_ymdとapplication_dateそれぞれを、日付型に変換します。 変換方法は、以下を参照してください。 &gt;&gt; 【解説】日付データの変換方法を学ぶ | データサイエンス100本ノック【問45〜問48 回答】 123df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'], format='%Y%m%d')df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'], format='%Y%m%d')df_tmp.head(10) 出力1234567891011 customer_id sales_ymd application_date0 CS006214000001 2018-11-03 2015-02-011 CS006214000001 2017-05-09 2015-02-012 CS006214000001 2017-06-08 2015-02-014 CS006214000001 2018-10-28 2015-02-017 CS006214000001 2019-09-08 2015-02-018 CS006214000001 2018-01-31 2015-02-019 CS006214000001 2017-07-05 2015-02-0110 CS006214000001 2018-11-10 2015-02-0112 CS006214000001 2019-04-10 2015-02-0115 CS006214000001 2019-06-01 2015-02-01 冒頭に紹介した例の用を参考に、経過月数を求めていきます。 ここでは復習も兼ねてapplyとlambda式を使って算出します。 &gt;&gt; 【lambda式とapplyを復習】【データサイエンス】Pythonで最頻値を表示する方法 | データサイエンス100本ノック【問29 回答】 12df_tmp['elapsed_date'] = df_tmp[['sales_ymd', 'application_date']].apply(lambda x: relativedelta(x[0], x[1]).years * 12 + relativedelta(x[0], x[1]).months)df_tmp 出力1234567891011121314customer_id sales_ymd application_date elapsed_date0 CS006214000001 2018-11-03 2015-02-01 NaN1 CS006214000001 2017-05-09 2015-02-01 NaN2 CS006214000001 2017-06-08 2015-02-01 NaN4 CS006214000001 2018-10-28 2015-02-01 NaN7 CS006214000001 2019-09-08 2015-02-01 NaN... ... ... ... ...65672 CS004411000027 2017-06-01 2015-05-17 NaN65674 CS040513000029 2018-06-07 2015-09-15 NaN65676 CS004613000146 2017-12-02 2016-08-13 NaN65678 CS002314000037 2018-04-21 2015-12-02 NaN65680 CS040311000022 2019-04-16 2015-04-19 NaN32411 rows × 4 columns elapsed_dateがすべてNaNになってしまいました。 原因を探っていきます。 relativedeltaで経過年数を算出する部分だけ抜き取ってコードを実行してみます。 1df_tmp[['sales_ymd', 'application_date']].apply(lambda x: relativedelta(x[0], x[1]).years) 出力123sales_ymd 1application_date 0dtype: int64 本来であれば、6万ほどあるsales_ymdとapplication_dateの経過年数を出してくれるはずなのですが、一つしか出力されませんでした。 これは、applyメソッドがデフォルトで縦方向のデータ間のrelativedeltaの計算をしているためです。言い換えるとapplyメソッドはデフォルトでaxis=0を指定しており、sales_ymd列間の経過年数の計算をしてしまっているのです。 上記のコードの場合x[0]がsales_ymdの0番目である2018-11-03というデータを抽出し、x[1]がsales_ymdの1番目である2017-05-09というデータを取得して経過年数を算出してしまうのです。 以下のようにaxis=1を指定すれば、各レコードにおけるsales_ymdとapplication_date間の経過年数を算出することが出来ます。 1df_tmp[['sales_ymd', 'application_date']].apply(lambda x: relativedelta(x[0], x[1]).years, axis=1) 出力1234567891011120 31 22 24 37 4 ..65672 265674 265676 165678 265680 3Length: 32411, dtype: int64 これを踏まえ、コードを修正します。 修正は簡単でaxis=1を指定するだけです。 12df_tmp['elapsed_date'] = df_tmp[['sales_ymd', 'application_date']].apply(lambda x: relativedelta(x[0], x[1]).years * 12 + relativedelta(x[0], x[1]).months, axis=1)df_tmp.head(10) 出力1234567891011 customer_id sales_ymd application_date elapsed_date0 CS006214000001 2018-11-03 2015-02-01 451 CS006214000001 2017-05-09 2015-02-01 272 CS006214000001 2017-06-08 2015-02-01 284 CS006214000001 2018-10-28 2015-02-01 447 CS006214000001 2019-09-08 2015-02-01 558 CS006214000001 2018-01-31 2015-02-01 359 CS006214000001 2017-07-05 2015-02-01 2910 CS006214000001 2018-11-10 2015-02-01 4512 CS006214000001 2019-04-10 2015-02-01 5015 CS006214000001 2019-06-01 2015-02-01 52 第72問目: 経過年数の算出 P-072: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）に対し、顧客データフレーム（df_customer）の会員申込日（application_date）からの経過年数を計算し、顧客ID（customer_id）、売上日、会員申込日とともに表示せよ。結果は10件表示させれば良い。（なお、sales_ymdは数値、application_dateは文字列でデータを保持している点に注意）。1年未満は切り捨てること。 経過年数を求める場合経過月数を求める場合と同様に、dateutil.relativedeltaモジュールを使用します。 早速問題を解きながら使い方を学んでいきましょう。 まずはdf_receiptの構造を確認します。 1df_receipt.head(5) 出力123456 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90 df_customerの構造も確認します。 1df_customer.head(5) 出力1234567customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-01 CS037613000071 六角 雅彦 9 不明 1952-04-01 66 136-0076 東京都江東区南砂********** S13037 20150414 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-2 まずは、df_receiptとdf_customerという２つのデータフレームから、今回の問題を解く上で必要となるカラムだけを抽出したいと思います。 今回の問題を解く上で、必要となるカラムは、customer_id, sales_ymd, application_dateですね。 df_receiptとdf_customerの間で共通的なカラムとしてcustomer_idが存在しますので、mergeを用いて内部結合で新たなデータフレームdf_tmpを作成します。 12df_tmp = pd.merge(df_receipt[['customer_id', 'sales_ymd']], df_customer[['customer_id', 'application_date']], how='inner', on='customer_id')df_tmp 出力1234567891011121314customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502013 CS006214000001 20170608 201502014 CS006214000001 20181028 20150201... ... ... ...65677 CS004613000146 20171202 2016081365678 CS002314000037 20180421 2015120265679 CS002314000037 20180421 2015120265680 CS040311000022 20190416 2015041965681 CS040311000022 20190416 2015041965682 rows × 3 columns 重複した行を削除します。 12df_tmp = df_tmp.drop_duplicates()df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502014 CS006214000001 20181028 201502017 CS006214000001 20190908 20150201... ... ... ...65672 CS004411000027 20170601 2015051765674 CS040513000029 20180607 2015091565676 CS004613000146 20171202 2016081365678 CS002314000037 20180421 2015120265680 CS040311000022 20190416 2015041932411 rows × 3 columns 経過年数を算出するためには、それぞれのデータを日付型に変換する必要があります。 sales_ymdとapplication_dateをpandas.to_datetimeを用いて日付型に変換します。 123df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'], format='%Y%m%d')df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'], format='%Y%m%d')df_tmp 出力12345678910111213141516171819202122232425&lt;ipython-input-24-755911942cfb&gt;:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'], format='%Y%m%d')&lt;ipython-input-24-755911942cfb&gt;:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'], format='%Y%m%d')customer_id sales_ymd application_date0 CS006214000001 2018-11-03 2015-02-011 CS006214000001 2017-05-09 2015-02-012 CS006214000001 2017-06-08 2015-02-014 CS006214000001 2018-10-28 2015-02-017 CS006214000001 2019-09-08 2015-02-01... ... ... ...65672 CS004411000027 2017-06-01 2015-05-1765674 CS040513000029 2018-06-07 2015-09-1565676 CS004613000146 2017-12-02 2016-08-1365678 CS002314000037 2018-04-21 2015-12-0265680 CS040311000022 2019-04-16 2015-04-1932411 rows × 3 columns この時、Warningが出力されます。 これはデータサイエンス100本ノックの52問目〜53問目 を解いていく際に出力されたWarningと同様のものです。 今回は本コードを実行した直前のコードを、df_tmp = df_tmp.drop_duplicates().copy()とすればWarningは出力されなくなります。 1234df_tmp = df_tmp.drop_duplicates().copy()df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'], format='%Y%m%d')df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'], format='%Y%m%d')df_tmp 出力1234567891011121314customer_id sales_ymd application_date0 CS006214000001 2018-11-03 2015-02-011 CS006214000001 2017-05-09 2015-02-012 CS006214000001 2017-06-08 2015-02-014 CS006214000001 2018-10-28 2015-02-017 CS006214000001 2019-09-08 2015-02-01... ... ... ...65672 CS004411000027 2017-06-01 2015-05-1765674 CS040513000029 2018-06-07 2015-09-1565676 CS004613000146 2017-12-02 2016-08-1365678 CS002314000037 2018-04-21 2015-12-0265680 CS040311000022 2019-04-16 2015-04-1932411 rows × 3 columns このようにWarningが出力されなくなりました。 続いて、elapsed_dateという新しいカラムに、経過年数の結果を格納します。 経過年数の計算は、lambda式でateutil.relativedeltaモジュールを活用して算出します。 12df_tmp['elapsed_date'] = df_tmp[['sales_ymd', 'application_date']].apply(lambda x: relativedelta(x[0], x[1]).years, axis=1)df_tmp.head(10) 出力123456789101112customer_id sales_ymd application_date elapsed_date0 CS006214000001 2018-11-03 2015-02-01 31 CS006214000001 2017-05-09 2015-02-01 22 CS006214000001 2017-06-08 2015-02-01 24 CS006214000001 2018-10-28 2015-02-01 37 CS006214000001 2019-09-08 2015-02-01 48 CS006214000001 2018-01-31 2015-02-01 29 CS006214000001 2017-07-05 2015-02-01 210 CS006214000001 2018-11-10 2015-02-01 312 CS006214000001 2019-04-10 2015-02-01 415 CS006214000001 2019-06-01 2015-02-01 4 これで完成です。 第73問目: 経過時間の算出 P-073: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）に対し、顧客データフレーム（df_customer）の会員申込日（application_date）からのエポック秒による経過時間を計算し、顧客ID（customer_id）、売上日、会員申込日とともに表示せよ。結果は10件表示させれば良い（なお、sales_ymdは数値、application_dateは文字列でデータを保持している点に注意）。なお、時間情報は保有していないため各日付は0時0分0秒を表すものとする。 日付型(datetime)をエポック秒にする場合、timestampメソッドを使用します。 12345from datetime import datetimedatetime_test = datetime(2021, 8, 10)datetime_test.timestamp() 出力11628553600.0 本問では、&quot;2018-11-03&quot;11&quot;というデータ形式で格納されています。 Seriesでの方法としてデータの型変換をastypeを使用し、変換後の方としてint64型に変換するとナノ秒単位の値が得られます。 ナノ秒を秒に変換するには$10^{9}$で割ればOKです。 123456import pandas as pdimport numpy as npdata = pd.Series([&quot;2021-8-10&quot;])pd.to_datetime(data).astype(np.int64)/ 10**9 出力120 1.628554e+09dtype: float64 ここまでの前提知識も踏まえて本問を解いていきたいと思います。 まずはdf_receiptとdf_customerにおいて必要なカラムのみを抽出して内部結合させます。 12df_tmp = pd.merge(df_receipt[['customer_id', 'sales_ymd']], df_customer[['customer_id', 'application_date']], how='inner', on='customer_id')df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502013 CS006214000001 20170608 201502014 CS006214000001 20181028 20150201... ... ... ...65677 CS004613000146 20171202 2016081365678 CS002314000037 20180421 2015120265679 CS002314000037 20180421 2015120265680 CS040311000022 20190416 2015041965681 CS040311000022 20190416 2015041965682 rows × 3 columns 重複した行を削除します。ここでcopy()を使用しないと、後々warningが出ます。 12df_tmp = df_tmp.drop_duplicates().copy()df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 20181103 201502011 CS006214000001 20170509 201502012 CS006214000001 20170608 201502014 CS006214000001 20181028 201502017 CS006214000001 20190908 20150201... ... ... ...65672 CS004411000027 20170601 2015051765674 CS040513000029 20180607 2015091565676 CS004613000146 20171202 2016081365678 CS002314000037 20180421 2015120265680 CS040311000022 20190416 2015041932411 rows × 3 columns それぞれ日付型に変換をします。 123df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'].astype('str'))df_tmp['application_date'] = pd.to_datetime(df_tmp['application_date'].astype('str'))df_tmp 出力12345678910111213 customer_id sales_ymd application_date0 CS006214000001 2018-11-03 2015-02-011 CS006214000001 2017-05-09 2015-02-012 CS006214000001 2017-06-08 2015-02-014 CS006214000001 2018-10-28 2015-02-017 CS006214000001 2019-09-08 2015-02-01... ... ... ...65672 CS004411000027 2017-06-01 2015-05-1765674 CS040513000029 2018-06-07 2015-09-1565676 CS004613000146 2017-12-02 2016-08-1365678 CS002314000037 2018-04-21 2015-12-0265680 CS040311000022 2019-04-16 2015-04-1932411 rows × 3 columns エポック秒での経過時間を求めます。 12df_tmp['elapsed_date'] = (df_tmp['sales_ymd'].astype(np.int64)/10**9) - (df_tmp['application_date'].astype(np.int64)/10**9)df_tmp.head(10) 123456789101112customer_id sales_ymd application_date elapsed_date0 CS006214000001 2018-11-03 2015-02-01 118454400.01 CS006214000001 2017-05-09 2015-02-01 71539200.02 CS006214000001 2017-06-08 2015-02-01 74131200.04 CS006214000001 2018-10-28 2015-02-01 117936000.07 CS006214000001 2019-09-08 2015-02-01 145152000.08 CS006214000001 2018-01-31 2015-02-01 94608000.09 CS006214000001 2017-07-05 2015-02-01 76464000.010 CS006214000001 2018-11-10 2015-02-01 119059200.012 CS006214000001 2019-04-10 2015-02-01 132105600.015 CS006214000001 2019-06-01 2015-02-01 136598400.0 これで完成です。 第74問目: 月曜日からの経過日数の計算 P-074: レシート明細データフレーム（df_receipt）の売上日（sales_ymd）に対し、当該週の月曜日からの経過日数を計算し、売上日、当該週の月曜日付とともに表示せよ。結果は10件表示させれば良い（なお、sales_ymdは数値でデータを保持している点に注意）。 日付型(datetime)のweekdayメソッドは曜日を0-6の数字として得ることができます。 また、このweekdayメソッドを使用することで、月曜日の日付を取得することができます。 以下にサンプルコードとともに方法を紹介します。 12345678from datetime import datetimefrom dateutil.relativedelta import relativedeltadatetime_test = datetime(2021, 8, 10)date = datetime_test.weekday()result = datetime_test - relativedelta(days=date)result 出力1datetime.datetime(2021, 8, 9, 0, 0) すなわち、2021年8月9日が月曜日であることがわかります。 これらの前提知識をもとに、本問を解いていきましょう。 まずは、必要なカラムのみを抽出します。本問における必要なカラムは、customer_idとsales_ymdとなります。 12df_tmp = df_receipt[['customer_id', 'sales_ymd']]df_tmp.head(5) 出力123456 customer_id sales_ymd0 CS006214000001 201811031 CS008415000097 201811182 CS028414000014 201707123 ZZ000000000000 201902054 CS025415000050 20180821 重複している行は削除します。 1df_tmp = df_tmp.drop_duplicates() sales_ymdカラムのデータを日付型に変換します。 12df_tmp['sales_ymd'] = pd.to_datetime(df_tmp['sales_ymd'].astype('str'))df_tmp.head(5) 出力123456 customer_id sales_ymd0 CS006214000001 2018-11-031 CS008415000097 2018-11-182 CS028414000014 2017-07-123 ZZ000000000000 2019-02-054 CS025415000050 2018-08-21 mondayカラムに各々のsales_ymdの日付における月曜日の日付を格納します各日付における月曜日を算出し、経過日数をelapsed_weekdayカラムに格納して出力します。 12df_tmp['monday'] = df_tmp['sales_ymd'].apply(lambda x: x - relativedelta(days=x.weekday()))df_tmp.head(5) 出力123456customer_id sales_ymd monday0 CS006214000001 2018-11-03 2018-10-291 CS008415000097 2018-11-18 2018-11-122 CS028414000014 2017-07-12 2017-07-103 ZZ000000000000 2019-02-05 2019-02-044 CS025415000050 2018-08-21 2018-08-20 sales_ymdからmondayを引き算することで経過日数を算出し、elapsed_weekdayというカラムに代入して出力します 12df_tmp['elapsed_weekday'] = df_tmp['sales_ymd'] - df_tmp['monday']df_tmp.head(10) 出力1234567891011 customer_id sales_ymd monday elapsed_weekday0 CS006214000001 2018-11-03 2018-10-29 5 days1 CS008415000097 2018-11-18 2018-11-12 6 days2 CS028414000014 2017-07-12 2017-07-10 2 days3 ZZ000000000000 2019-02-05 2019-02-04 1 days4 CS025415000050 2018-08-21 2018-08-20 1 days5 CS003515000195 2019-06-05 2019-06-03 2 days6 CS024514000042 2018-12-05 2018-12-03 2 days7 CS040415000178 2019-09-22 2019-09-16 6 days8 ZZ000000000000 2017-05-04 2017-05-01 3 days9 CS027514000015 2019-10-10 2019-10-07 3 days これで完成です。 まとめ: 年月日、月曜からの経過時間の算出方法を学びました。本記事は、「【解説】データサイエンス100本ノック【問70〜74 回答】」というテーマでまとめました。 本記事で紹介した方法を元にデータサイエンティストとしての知見を深めていただければと思います。 なお、データサイエンティストに必要な知識は、Udemyを活用した学習が効率的です。30日間の返金保証、および一流講師へのQ&amp;Aシステムが整ったオンライン学習プラットフォームです。 不定期で90%以上の割引セールも行っているので無料会員登録だけでも実施しておくといいと思います。 世界で34万人が受講した以下の講座をご確認ください。 【世界で34万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜","link":"/100knock-70-74/"},{"title":"【厳選4つ】30代未経験におすすめの買い切り型プログラミングスクール・教材！","text":"本記事では「【厳選4つ】30代未経験におすすめのプログラミングスクール・教材！」というテーマでまとめていきます！ 記事の信頼性(自己紹介) omathin ・IT企業のアーキテクト|研究者 ・Udemyを中心に100以上のオンライン講座を受講・30歳からプログラミングを本格的に学び始め、ハッカソンで入賞、研究で賞を獲得 目次 【30代向け】プログラミングスクール選びのポイント 【忙しい30代向け】おすすめプログラミングスクール一覧表【4選】 【おすすめスクール①】デイトラ デイトラの口コミ: 場所を選ばず学べる高品質なカリキュラムが高評価! 【おすすめスクール②】キカガク キカガクの口コミ: 充実したサポートと育成体制が高評価！転職・就職支援も有り！ 【おすすめスクール③】SkillHacks SkillHacksの口コミ: Web系ではコスパ最強！近々更新されて最強の教材に進化！？ 【おすすめスクール④】RailsHack RailsHackの口コミ 筆者の選択: 私はSkillHacksを受講しました。 最後に: 無料オンライン相談会を活用しましょう。 【30代向け】プログラミングスクール選びのポイント まず30代というと様々なライフスタイルの変化が起きる年代です。 結婚、出産、昇進・・・という風に大変忙しい時期だと思います。 そこで、30代の忙しいビジネスパーソンがプログラミングスクールを選ぶポイントを以下と設定しました。 【30代】プログラミングスクールに求める要件 【要件1】. スクールに行く時間なんて無い！オンライン完結型スクール！【要件2】. 忙しい日々の時間を割いて期限内にカリキュラムを終わらせられるか不安！教材・動画は無期限で見放題！【要件3】. プログラミングでエラーが出たら何も出来ない！講師への質問が無制限！ こちらの要件にマッチするプログラミングスクールを独自に調査したので、自分に最適なスクールを選んでください。 参考ですが私個人的には、【要件2】が最も重要かと思います。 理由は、プログラミング言語の仕様は常に変化しているからです。 「最近まで動いていたプログラムがUpdateされて動かなくなった」なんてことは良くあることです。 ということで本記事では【要件2】に重きをおいてプログラミングスクールを厳選しました。 では早速まとめていきます。 【忙しい30代向け】おすすめプログラミングスクール一覧表【4選】設定した要件に基づいて下表におすすめプログラミングスクールを表でまとめました。 デイトラ キカガク SkillHacks RailsHack 受講スタイル 動画でプログラミング学習 動画でプログラミング学習 動画でプログラミング学習 動画でプログラミング学習 教材・動画の視聴期限 一度受講したらその後もカリキュラムを見放題 すべてのコースで視聴制限なし（一生観られる！） 永久にカリキュラムを閲覧可能 受講期間に制限はなく、一度受講すれば、ずっとカリキュラムを閲覧することが可能 サポート チャットツール”Slack”で質問 月４回の講師が参加するメンタリング日（質問や学習進捗管理、雑談など）やslackでの質問対応や受講生通しのコミュニケーションができる 質問対応に関してもカリキュラム内のことであれば無制限、無期限 質問に対しても専門のITエンジニアが回答 価格 一年間のサポート付きで99,800円(例:Web制作コース) （給付金を活用して）237,600円 69,800円 通常価格 69,800円(割引特典を活用して29,800 円) 以降は、表形式で紹介した各々のプログラミングスクールについて詳しく観ていきましょう。 【おすすめスクール①】デイトラ おすすめプログラミングスクール1つめは、デイトラです。 デイトラは年間受講者数8,000人超の国内最大規模のオンラインプログラミングスクールです。 デイトラの最大の特長は、フリーランスや副業を意識したコースを中心としていること。 それもそのはず、デイトラの運営人は、全員元フリーランスだからです。 目指すキャリアの方向性として、フリーランスを目指している人は、経験豊富の元フリーランスから案件獲得のノウハウも学ぶことができるでしょう。 提供しているコースも以下の通り非常に豊富です。 デイトラが提供しているコース一覧 ・Web制作コース・Webデザインコース・Shopifyコース・Ruby/Railsコース・広告運用コース・動画編集コース・Pythonコース ＼ 豊富なカリキュラム！ ／ デイトラを確認する デイトラの口コミ: 場所を選ばず学べる高品質なカリキュラムが高評価! 着実に知識を定着させるための仕組み・工夫がなされています。 初級で見栄えの良いLPを作成するスキルが身につきます。 入浴中も学べる！？ 未経験が半年で高待遇のフリーランス契約を獲得した例も！ ＼ 半年で一流のエンジニアに！ ／ デイトラを確認する 【おすすめスクール②】キカガク おすすめのプログラミングスクール2つめは、キカガクです。 受講者数45,000人以上、研修提供企業数500社以上の実績を有する、AI学習プラットフォームです。 キカガクが提供するAI動画学習プラットフォームは、ikus.ai（イクサイ）というサービス名で提供されています。 私はUdemyでキカガクが提供する講座を受講しましたが、とにかく分かりやすいの一言につきます。 また、月４回の講師が参加するメンタリング日（質問や学習進捗管理、雑談など）やslackでの質問対応や受講生通しのコミュニケーションができるのも嬉しい点です。 独学でプログラミングを学ぶ上で、悩みや不明点をシェアできるコミュニティはモチベーション維持に繋がり貴重です。 キカガクで学べる内容は以下のとおりです。 キカガクで学べる内容一覧（随時拡大中！） ・Pythonの基礎・統計学・データサイエンス・人工知能・深層学習・機械学習の数学・画像・自然言語処理・Web開発 ご覧の通り、Pythonを中心としたAI・機械学習エンジニア、データサイエンティストにフォーカスしたカリキュラムになっていますね。 受講料は、給付金を活用して237,600円（2021年7月時点）です。 「ちょっと高いな。」という思われるかもですが、Midworksで「Python」と検索すると、以下の通り月収100万〜30万円の案件が200件近くあります。 Pythonのエンジニアになれば、30万ほどの金額はすぐに回収できるかと思うので、自分への投資だと思ってチャレンジしてみてはいかがでしょうか？ まずはキカガクさんが主催する、無料オンライン説明会に参加し、具体的な学習イメージを掴んでみると良いと思います。 ＼ まずは無料相談！ ／ キカガクの無料オンライン説明会を確認する キカガクの口コミ: 充実したサポートと育成体制が高評価！転職・就職支援も有り！ なんと「doda」から転職・就職支援を得ることができる！ しっかりとした育成をするため、人数を制限しているようです。 オンラインでもサポートは手厚いようです。 卒業後も大量の教材を活用できる！ キカガクの口コミを調べた結果、ほぼ悪評と言えるようなものは見つかりませんでした。 まずは、無料オンライン説明会に参加してみると良いでしょう。 ＼ まずは無料相談！ ／ キカガクの無料オンライン説明会を確認する 【おすすめスクール③】SkillHacks おすすめのプログラミングスクール3つめは、SkillHacksです。 まず最初に、大きく広告に写っている男性は、迫 佑樹(さこ ゆうき)さんという方です。 3000名以上にプログラミングを指導した実績がある方で、エンジニアとしてもハッカソンやソフトウェア開発のイベントで優勝しているようです。また、Udemyでもベストセラー講座を公開するなど、その実績は確かなものだと思います。 以下に、SkillHacksの講義の一部を体験できる動画を用意しました。 動画をご覧になれば分かると思いますが、例え話を交えながら丁寧な解説で分かりやすいですよね。 このような動画が、合計で94本用意されています。しかも買い切りで一生何回でも観ることが出来ます。 SkillHacksで学べる内容を以下にまとめました。 SkillHacksで学べる内容一覧 ・HTML・CSS・Bootstrap・Ruby・Rails・メモアプリ開発・Herokuデプロイ（外部に公開）・サイト作成演習 一見あっさりしたコンテンツ内容に見えますが、中身はREST APIの概念やエラーへの対処方法まで含まれており、確かな実力を付けられる構造になっています。 また、SkillHacksは「絶対に挫折させない」とコンセプトにしており質問も無制限です。 価格も69,800円と他のプログラミングスクールに比べると、かなり手頃な値段となっているのも嬉しい点です。 ＼ 絶対に挫折しない！ ／ SkillHacksを確認する SkillHacksの口コミ: Web系ではコスパ最強！近々更新されて最強の教材に進化！？ 転職サポートも付きコースもある Skill Hacks×転職クエストコラボ 近々アップデートされて最強の教材になるかも！？ 「絶対に挫折させない」は本物 Web業界を目指す人には最高の教材 SkillHacksの口コミを調べた結果、コストパフォーマンスの高さに関する高評価が多い印象でした。 なお、迫さんはプログラミング以外にも動画編集やデザイン、Webマーケ等の講座も公開しています。 プログラミング以外のスキルにも興味がある方は、以下のボタンから講座のラインナップを確認してみてください。 ＼ 動画編集等の講座もあるよ！ ／ Hacksシリーズを確認する 【おすすめスクール④】RailsHack おすすめのプログラミングスクール4つめは、RailsHackです。 こちらも完全オンライン講座で一度受講すれば、ずっとカリキュラムを閲覧することが可能です。 質問に対しても専門のITエンジニアが回答してくれるため、サポートも問題なしかと思います。 そして注目すべきはなんといっても、価格の安さです。 2021年7月28日時点ですが、通常価格 69,800円が、割引特典を活用して29,800 円となっています。 カリキュラムの内容を見てみましょう。 SkillHacksで学べる内容一覧 ・HTML・CSS・Bootstrap・Ruby・Rails・Webアプリ開発(簡易メモアプリ、掲示板アプリ、お店アプリ) 割引後の値段でこれだけのコンテンツが揃っていれば、コスパも良いですね。 RailsHackの口コミを調査しました。 RailsHackの口コミ 就職支援が不要であれば良い。 他の講座との違いは、就職支援がない点です。 転職サイトを活用して自ら転職活動を進めていく考えを持っている方は、RailsHackが良いかと思います。 ＼ 割引特典を活用して29,800 円！ ／","link":"/30s-programming-school/"},{"title":"【AI】LSTMでサンドウィッチマンの漫才を学習して予測させてみた","text":"本記事では、LSTM(Long short-term memory)というRNNの拡張モデルを活用して、サンドウィッチマンさんの漫才ネタを学習させて、もっともらしい単語の予測をさせてみました。 目次 LSTMとは 入力データの準備 データの読み込み 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定 各文字のベクトル化 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 時系列データと予測する文字の抽出 入力と正解をone-hot表現で表す LSTMモデルの構築 文書を生成するための関数を記述し学習 まとめ LSTMとは以下の記事で詳細にまとめられています。 https://qiita.com/t_Signull/items/21b82be280b46f467d1b LSTM(Long short-term memory)は、RNN(Recurrent Neural Network)の拡張として1995年に登場した、時系列データ(sequential data)に対するモデル、あるいは構造(architecture)の1種です。その名は、Long term memory(長期記憶)とShort term memory(短期記憶)という神経科学における用語から取られています。LSTMはRNNの中間層のユニットをLSTM blockと呼ばれるメモリと3つのゲートを持つブロックに置き換えることで実現されています。 要するにRNNの中間層がLSTM層に置き換わったものであるということです。 LSTM層の内部には、記憶セル、入力ゲート、出力ゲート、忘却ゲートという内部要素を保持しており、複雑に絡み合っております。 しかしながらPythonのKerasを用いることでシンプルに実装することができます。 なお、RNNについては以下の記事でまとめているので参考にしてください 入力データの準備今回は、サンドイッチマンさんの漫才ネタをテキストデータとして用意したものを使います。 その中でも私個人的に好きな、ハンバーガー屋のネタ、弔事のネタ、旅行代理店のネタの3つを、テキストで書いたものです。 以下のような感じです・ sand_manzai.txt12345あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。(略)婚活パーティーか、お前。金取れ、女からも。バカたれ！さっ！というわけでねっ。そろそろお時間となってしまいました。何でラジオの終わりみたいになってんの。おかしい。DJみたいになってんじゃん、急に。ホントにねっ。まろやかに眠ってもらいたいです。いやいや。やすらかにだよ、やすらかに。まろやかにってお前、クリープかお前。それではまた、来週のこの時間まで！さようならぁ～！来週もやんのかよ。どういうことだよ、これお前。こんな感じでどうかな？全部書き直せ。もういいぜ。 ハンバーガー屋のネタから弔事のネタまでを、ただ単にテキストで書き連ねただけのデータです。 データの読み込みまずは、このテキストデータをJupyter Notebook環境に読み込みます。 読み込むテキストデータは、実行している.ipynbファイルと同じフォルダに配置しましょう。 12345678import rewith open(\"sand_manzai.txt\", mode=\"r\", encoding=\"utf-8\") as f: sand_original = f.read()sand = re.sub(\"[\\n]\", \"\", sand_original) # 改行の削除 print(sand) これで、テキストデータが表示されればOKです。 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定この辺りの値は、実験を繰り返しながら最適な値を設定しました。 以下は、何回か実験を繰り返した結果の最終的な値です。 1234n_rnn = 10 # 時系列の数batch_size = 128 # バッチサイズepochs = 60 # エポック数n_mid = 256 # 中間層のニューロン数の数 入力データに対する時系列の数やバッチサイズって、どのように設定するのがベストプラクティスなのかは、勉強中です。。。 以下の記事によると、少しばかりヒントがありました。https://www.st-hakky-blog.com/entry/2017/11/16/161805 よく論文で見るBatch sizeDeep Learningの論文を読んでいるとどうやって学習をさせたかみたいな話はほぼ乗っているので、そういうのを見ていてよく見かけるのは以下あたりではないかと思います(すみません、私の観測範囲ですが)。 1 32 128 256 512だいたい、1だと完全に確率的勾配降下法になりますし、512だと学習速度をあげたかったのかなという気持ちが見えます。このあたりについてどれにするべきかというところを考察してみたいと思います。 各文字のベクトル化各文字をone-hot表現にします。one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができます。 各文字をone-hot表現にするには、以下のように処理を行います。 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 入力と正解をone-hot表現に変更する 文字の重複を省きlist化まずは、setを使って文字の重複を省き、listにして、sortしたものをcharに格納したいと思います。 1234567import numpy as npchars = sorted(list(set(sand)))print(chars)print(\"文字数(重複なし)\", len(chars))# ['(', ')', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'D', 'J', 'M', 'h', 'i', 'k', 'o', 's', 'y', '…', '※', '♪', '、', '。', '々', '「', '」', 'ぁ', 'あ', 'ぃ', 'い', 'う', 'ぇ', 'え', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'っ', 'つ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ね', 'の', 'は', 'ば', 'ひ', 'び', 'ふ', 'ぶ', 'へ', 'べ', 'ほ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'を', 'ん', 'ァ', 'ア', 'ィ', 'イ', 'ウ', 'ェ', 'エ', 'オ', 'カ', 'ガ', 'キ', 'ク', 'グ', 'ケ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ソ', 'タ', 'ダ', 'チ', 'ッ', 'ツ', 'テ', 'ト', 'ド', 'ナ', 'ニ', 'ハ', 'バ', 'パ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ペ', 'ホ', 'ボ', 'ポ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ュ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ヴ', '・', 'ー', '一', '万', '丈', '三', '上', '下', '不', '世', '両', '中', '予', '事', '二', '京', '人', '今', '仕', '他', '付', '仙', '代', '以', '伊', '休', '会', '何', '作', '使', '修', '俺', '個', '健', '偽', '僕', '優', '兄', '入', '全', '内', '円', '冬', '出', '分', '刺', '削', '前', '加', '助', '勝', '化', '北', '千', '印', '原', '厨', '参', '取', '受', '古', '叩', '召', '台', '各', '合', '同', '名', '向', '周', '品', '員', '商', '喋', '回', '因', '図', '国', '土', '地', '場', '壁', '士', '売', '変', '夏', '外', '多', '夜', '大', '太', '夫', '奇', '奮', '女', '奴', '好', '婚', '季', '安', '定', '客', '宴', '密', '富', '小', '少', '尿', '居', '屋', '山', '岡', '川', '差', '帰', '幌', '年', '康', '式', '弔', '当', '彷', '待', '徨', '念', '怖', '思', '急', '性', '感', '態', '慌', '懐', '房', '手', '払', '投', '担', '拶', '持', '指', '挨', '振', '故', '文', '料', '断', '新', '方', '旅', '日', '早', '昨', '時', '普', '暮', '曲', '書', '最', '月', '期', '本', '札', '来', '東', '根', '桶', '棺', '業', '極', '楽', '構', '様', '樹', '次', '欲', '正', '歩', '歴', '死', '残', '気', '永', '求', '江', '決', '泊', '注', '活', '流', '海', '淳', '渕', '渡', '湯', '澤', '無', '然', '物', '状', '球', '理', '生', '田', '由', '申', '男', '界', '発', '皆', '盛', '目', '直', '相', '真', '眠', '知', '砂', '確', '神', '福', '秘', '稲', '笑', '第', '等', '答', '算', '箸', '米', '粧', '糖', '紀', '約', '終', '結', '続', '綿', '総', '緒', '繰', '置', '考', '者', '耳', '聞', '膳', '自', '興', '若', '草', '菅', '葬', '行', '要', '見', '覚', '触', '言', '診', '詰', '話', '読', '誰', '談', '象', '買', '跡', '踏', '輪', '辞', '近', '返', '通', '造', '週', '過', '達', '遠', '適', '選', '還', '郎', '部', '金', '間', '閣', '阪', '集', '静', '面', '音', '頃', '願', '飛', '食', '飲', '高', '鳩', '鶏', '麗', '麻', '黙', '鼻', '！', '（', '）', '０', '１', '２', '５', '７', '？', 'Ａ', 'Ｌ', 'Ｍ', 'Ｓ', '～']# 文字列(重複なし) 477 文字がキーでインデックスが値の辞書を作成次にchar_indicesという空の辞書を作成し、そこにループでインデックスi, 各文字をcharに格納。 char_indicesのキーとしてcharを指定してiを格納することで、文字がキーでインデックスが値の辞書が完成します。これは後程使います 1234567891011121314151617181920212223242526char_indices = {}for i, char in enumerate(chars): char_indices[char] = ichar_indices# {'(': 0,# ')': 1,# '-': 2,# '0': 3,# '1': 4,# '2': 5,# '3': 6,# '4': 7,# '5': 8,# '6': 9,# '7': 10,# '8': 11,# '9': 12,# 'D': 13,# 'J': 14,# 'M': 15,# 'h': 16,# 'i': 17,# 'k': 18,# 'o': 19,# 's': 20,# 以降は省略 インデックスがキーで文字が値の辞書を作成次に、indices_charというインデックスがキーで文字が値の辞書を作成します。こちらも後程使います。 12345678910111213141516171819202122232425indices_char = {}for i, char in enumerate(chars): indices_char[i] = charindices_char# {0: '(',# 1: ')',# 2: '-',# 3: '0',# 4: '1',# 5: '2',# 6: '3',# 7: '4',# 8: '5',# 9: '6',# 10: '7',# 11: '8',# 12: '9',# 13: 'D',# 14: 'J',# 15: 'M',# 16: 'h',# 17: 'i',# 18: 'k',# 19: 'o',# 以降は省略 時系列データと予測する文字の抽出時系列データはtime_chars、予測する文字はnext_charsに格納します。 テキストの長さから時系列の長さをを引いた分だけループを実施。 time_charsにはテキストのi～i+n_rnn分の長さだけの文字を加えてあります。これで時系列の数の回数分だけ再帰処理する時系列データを用意できます。 next_charsにはtime_charsから予測すべき文字なので、i + n_rnn番目の文字をリストに格納しています。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849time_chars = []next_chars = []for i in range(0, len(sand) - n_rnn): time_chars.append(sand[i: i + n_rnn]) next_chars.append(sand[i + n_rnn]) time_chars# ['あら。昨日の夜まで何',# 'ら。昨日の夜まで何も',# '。昨日の夜まで何もな',# '昨日の夜まで何もなか',# '日の夜まで何もなかっ',# 'の夜まで何もなかった',# '夜まで何もなかったの',# 'まで何もなかったのに',# 'で何もなかったのに、',# '何もなかったのに、急',# 'もなかったのに、急に',# 'なかったのに、急にハ',# 'かったのに、急にハン',# 'ったのに、急にハンバ',# 'たのに、急にハンバー',# 'のに、急にハンバーガ',# 'に、急にハンバーガー',# '、急にハンバーガー屋',# 以降は省略next_chars# ['も',# 'な',# 'か',# 'っ',# 'た',# 'の',# 'に',# '、',# '急',# 'に',# 'ハ',# 'ン',# 'バ',# 'ー',# 'ガ',# 'ー',# '屋',# '出',# '来'# 以下省略 入力と正解をone-hot表現で表すここで、入力\\(x\\)と正解\\(t\\)を作っています。最初はzerosすべての要素を0にします。 入力\\(x\\)の形状は、[time_charsの長さ、時系列データの長さ(n_rnn)、文字数]、となります。今回は、要素は0か1の二通りしかありませんので、データのタイプはbool型にしておきます。 また、正解\\(t\\)ですが、こちらは、[time_charsの長さ、文字数]、の形状にします。こちらも同様にデータのタイプはbool型にしておきます。 time_charsの数だけまずループを行います。 まず、正解に対して値を設定。 indexがiで各要素がt_csになるわけですが、正解な文字が入っているnext_charsから文字を取り出し、char_indicesによりindexに変換します。そして、その要素を1に設定します。 これにより、この要素のみ1で、あとは0になるone-hot表現に変換されることになります。 また、入力の方は、さらにループの入れ子構造を使って設定します。 t_csを使ってループを行っており、この際のインデックスはj, 要素はcharとします。 \\(x\\)のiとjを設定して、そのうえでchar_indicesを使って文字をインデックスに変換します。 この要素を1にします。 こうすることで、入力も同様にone-hot表現で表すことが可能です。 試しに、xを出力してみます。 1234567891011121314151617181920212223242526x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)for i, t_cs in enumerate(time_chars): t[i, char_indices[next_chars[i]]] = 1 # 正解をone-hot表現で表す for j, char in enumerate(t_cs): x[i, j, char_indices[char]] = 1 # 入力をone-hot表現で表す x# array([[[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]],t# Out[9]:# array([[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]]) xとtの形状も確認してみます。 1234print(\"xの形状\", x.shape)print(\"tの形状\", t.shape)# xの形状 (5408, 10, 477)# tの形状 (5408, 477) これでone-hot表現化は完了です。 LSTMモデルの構築Kerasを使ってLSTMを構築していきます。 SimpleRNN層と同じ方法で構築できます。 損失関数は、複数の分類に適したcategorical_crossentropyを指定し、最適化アルゴリズムは収束しやすいadamを指定したいと思います。 1234567891011121314151617181920212223242526272829303132333435from keras.models import Sequentialfrom keras.layers import Dense, LSTMmodel_lstm = Sequential()model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))model_lstm.add(Dense(len(chars), activation=\"softmax\"))model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")print(model_lstm.summary())# Model: \"sequential_1\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# simple_rnn_1 (SimpleRNN) (None, 20) 440 # _________________________________________________________________# dense_1 (Dense) (None, 1) 21 # =================================================================# Total params: 461# Trainable params: 461# Non-trainable params: 0# _________________________________________________________________# None# Model: \"sequential_2\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# lstm_1 (LSTM) (None, 20) 1760 # _________________________________________________________________# dense_2 (Dense) (None, 1) 21 # =================================================================# Total params: 1,781# Trainable params: 1,781# Non-trainable params: 0# _________________________________________________________________# None 文書を生成するための関数を記述し学習各エポックが終了した際に、文章を生成するための関数を作成します。 12345678910111213141516171819202122232425262728293031323334353637from keras.callbacks import LambdaCallback def on_epoch_end(epoch, logs): print(\"エポック: \", epoch) beta = 5 # 確率分布を調整する定数 prev_text = sand[0:n_rnn] # 入力に使う文字。「'あら。昨日の夜まで何'」という文字列 created_text = prev_text # 生成されるテキスト print(\"シード: \", created_text) for i in range(400): # 入力をone-hot表現に x_pred = np.zeros((1, n_rnn, len(chars))) for j, char in enumerate(prev_text): x_pred[0, j, char_indices[char]] = 1 # 予測を行い、次の文字を得る y = model.predict(x_pred) # (1, 479)のarray。array([[0.00203636, 0.0020888 , ・・・・・ p_power = y[0] ** beta # 確率分布の調整。y[0]は(479,)のarray。array([0.00203636, 0.0020888 , 0.00209593, ・・・・ next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) # next_indexには、len(p_power)の数値である0～479間のintがランダムで代入される。 next_char = indices_char[next_index] # 'あ'とか'～'とか文字列を得る。 created_text += next_char prev_text = prev_text[1:] + next_char print(created_text) print()# エポック終了後に実行される関数を設定epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)model = model_lstmhistory_lstm = model_lstm.fit(x, t, batch_size=batch_size, epochs=epochs, callbacks=[epock_end_callback]) LambdaCallbackは、エポック終了時等のタイミングで、特定の処理を行うための関数として使用します。 betaという定数が設定されています。これは確率分布を調整する定数です。 確率分布を使用する意図は、最も確率が高い文字だけではなく、それ以外の文字からも確率に従いサンプリングをするためです。結果的に、高い確率の文字が選ばれる頻度が高くなります。これは、入力データに対して、次の文字として最も確率の高い文字を予測する代わりに、確率分布を推定する、ということになります。 prev_textには、テキストの最初から時系列分だけを取り出したサンドウィッチマンのネタの文字列が入ります。これが、モデルに入力される文字列になり、常に直近の時系列データが入るようにします。 created_textは、生成されるテキストです。文章は必ず、prev_textから始まるようにするので、prev_textを入れておきます。そして、created_textがシードになります。これがベースとなって次々と次の文字を予測していくことになります。 今回は400文字の文章を生成する。 入力をone-hot表現に変換するために、入力x_predには、まずnp.zerosで初期化したものを含める。サンプル数が1, 時系列データ, charsの数の形状をしています。 次に予測を行っていきます。model.predictに、x_predを入れて出力のyを得ることができます。 y[0]で各文字に対応する確率分布のリストが得られる。これにbetaを累乗。betaの値は、1より大きいと高い確率がより高くなるように確率分布が調整されます。 次の文字として、next_indexに、特定の確率分布の中からサンプリングされた値(文字のインデックス)が代入される。確率分布pは、p_powerに対して、P_powerを足し合わせたもので割っている。これは、確率分布pが、すべて足しあわされて1にならなければならないためです。確率分布については、以下のchainerチュートリアルのドキュメントが分かりやすいと思います。 https://tutorials.chainer.org/ja/06_Basics_of_Probability_Statistics.html そして、next_indexをキーとして、indices_charに入れることで、次の文字を取り出すことができる。 prev_textは、最初の文字を取り除き、next_charを加えることで、直近の時系列に更新される。 このようにして訓練済みのLSTMのモデルを使って、文章を自動生成することができる。 学習の推移を確認していくと徐々にサンドイッチマンのネタに近づいていきます。途中ずっと「いらっしゃいませこんにちは！」しか言わなったりしますが、、、 123456789101112131415161718192021222324252627282930313233343536373839Epoch 1/605408/5408 [==============================] - 14s 3ms/step - loss: 5.3819エポック: 0シード: あら。昨日の夜まで何あら。昨日の夜まで何ないかんんーんーんんいい。い。ないいいんい、ん、っいんかいんいなかいおいんっん。いかていい、っい、たんな、、いいだのいいいんんいてお、ない、いんーいーいいーーい、いんい。っい、で、ー、いいーー、いいな、。ん、いいなんんいー、ーーいいいんていっおんいいっなんんいーーあ、、ん。だーんんいんん、、んおんい、っない、ー、いっいい、いいいい、ら、んかんん。っないかいいー、。っん、いおおいて、っいっ、いいいー、かんおおーいていん、、んんいいいいすん、おーーー、いい、いい、いんっー、っっいいーーいってんいいいーんいい、ーんいのし、なんんい、、んっいすっんーてーんてーいっなのいーい、、いっ、い、、いんっー。、のなー、いんー、っ、いっ。んいておいいーよいん、んー、ーなー、い、、っんい、いんないんだっ、か、いーなん、、っっいんーてーんいおいんうでいで、んーの。い、、のんんい。ーおしっ、いんんんいんいーいいん。Epoch 10/605408/5408 [==============================] - 11s 2ms/step - loss: 4.1347エポック: 9シード: あら。昨日の夜まで何あら。昨日の夜まで何たたいたいんだよ。。あ、、ののののに・・のにいににいっててん。。。んのく、のののののにののすののですかか？。か？か、、。ちののにののしのの、、いすに。ののののーー、だ、よ。。、れののの方にののにしにいってん。。。ちちののののの、いのののにしにいてんだよ。。あちれしっての。。。あ、、ののにののの方になのたっててん。。。の、のののののの・・・・・で・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・、・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・Epoch 20/605408/5408 [==============================] - 12s 2ms/step - loss: 2.5751エポック: 19シード: あら。昨日の夜まで何あら。昨日の夜まで何ですかかもにりだよ。おっていいます。何や、ロオーー。そー、知れ。これ、お前。あー、ううらううう。あれ、あうです。やうやでしうから、お前。ないまですか？やや、だオー。ララララ見にてってるてよかな。でんですか？いいんだよ。お前、ちゃんだよ。いいいです。何やからだー、お前。何ですか？？いわ、、なん。持持ちてよ、お前。えってんでよ。どうううってんだよ。あン、これになんだよ。お前、あ、、お前。きやきうららいます。あ、ですも。ううーうう！！！れンンううううう！！ンンンンンンンン！ンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンEpoch 44/605408/5408 [==============================] - 12s 2ms/step - loss: 0.2862エポック: 43シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってよねうか。お前、あットババナナェイェイで…いやサイでです。こいなににこんらくくちゃいていのお前。なー、じゃあの、こンにに北おおかしなあ。バー。繰イ人人、お前。あ、で婚の人お前っなんか。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言Epoch 49/605408/5408 [==============================] - 12s 2ms/step - loss: 0.1811エポック: 48シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちEpoch 60/605408/5408 [==============================] - 12s 2ms/step - loss: 0.0870エポック: 59シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。上に置いとかな全然見えなかったわ、お前。あー、どうしようかな。じゃあ、ビッグバーガーセットはいかがですか？太るわ。普通なんかサイドメニューみたいな。サイドメニュー？ご一緒に(※ポテトの発音で)ホタテになります。(※ポテトの発音で)ホタテに！あ、いらっしゃちいま。あとち言ーにますらか。な一ににつらっていませま。。あもですぎ。１ぇの！ういいや！１１回！（※でも１をを指両両両のををンン指指を指を 誤差の収束具合をグラフで確認します。 12345678%matplotlib inlineimport matplotlib.pyplot as pltloss_lstm = history_lstm.history['loss']plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")plt.legend()plt.show() ちゃんと誤差が収束に向かっているのが分かります。 まとめLSTMの理解を深めるために、サンドウィッチマンのネタを学習し予測させてみました。 様々なデータに活用し、実験してみていただけると幸いです。 RNNやLSTMを構築して自然言語処理を学びたい方は、以下のUdemy講座がおすすめです。 本記事の作成においても、とても参考にさせていただきました。30日以内では返金保証が効くので無料で講座の内容を確認することが出来ます。 &gt;&gt;自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/lstm-sandwich/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで①[ケガ→手術→リハビリ開始まで]","text":"右膝前十字靭帯を断裂し、再建手術を受け、復帰に向けたリハビリに入る前までの体験談をまとめました。 以下のような関心事や分からないことがあれば読んでみても損はないと思います。 ・手術を決意した後、どのような流れで手術を迎えるのか、実体験を基にした具体的な流れが知りたい。 ・麻酔って、どんな感じなの？痛いの？ ・手術中や手術が終わった後って、どんな感じ？ ・細かいレベルで辛かったこと、痛かったことを知りたい。 私自身も、前十字靭帯の再建手術を受けました。 野球に復帰するまでは10か月くらいかかり、リハビリを卒業するまでは約1年3か月くらいかかりました。 ざっくりとした復帰までの流れは以下のとおりです。 ・2017年5月: 野球の守備で前十字靭帯を損傷 ・2017年5月～7月: リハビリ ・2017年7月: 再建手術・入院 ・2018年3月: 復帰※リハビリは続く ・2018年8月: リハビリ卒業 順調に回復し現在はケガする前よりも高いパフォーマンスが発揮できるくらいになりました。 復帰に向けたリハビリの際に自分なりに工夫したことなども、今後別記事にまとめたいと思います。 目次 手術を決意するまで 手術当日を迎えるまで 前十字靭帯再建手術 当日 翌朝 まとめ: 全身麻酔は怖くないが、手術後が大変でした。 手術を決意するまで ケガをしたときは「捻挫かな？」という感じでした。 それなりに歩けましたし、ケガした当日は車も運転しました。 しかし翌日になると、みるみる膝が腫れてきたため、急遽職場近くの病院に行きました。 医者にケガしたときの細かい動作や、ケガをしたときに感覚を伝えると、 前十字靭帯を切ってるかもね。 とのことでした。 「膝の関節に注射するから横になって」とすぐに言われたときは、心拍数はMAX。 注射の針は3cmくらいの長い針で、本当にビビりました。 注射自体はひどい痛みではありませんでした。口でゆっくり呼吸すると痛みが和らぐらしいです。 膝の中にたまった液体は、真っ赤な血液でした。 水ではなくて血だから、何らかの組織が損傷してるということだね。。。 注射1本分の血液量(たしか50ccくらい)だったと思います。 この時は絶望でした。 血液を抜いたあと、「痛み止めも膝に入れておくね。」と言われ、別の注射器で透明な液体を入れられました。痛み止めを入れてくれたはずなのに、気分が落ち込んだせいか、痛みが増した気がした。 膝の組織が損傷していると思うから、サポーターも着けておきますね。 とのことで、結構なお金を支払い、サポーターを着けた足を引きずりながらMRIを撮影する施設へ移動。。。。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"膝サポーター スポーツ 怪我防止 通気性伸縮性 前十字靭帯サポーター膝 痛み保温固定膝サポートランニング 男女 左右兼用 ２枚セット (Small)\",\"b\":\"JEJOYG\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41u5IEra2yL._SL500_.jpg\",\"\\/51PAqbdt6gL._SL500_.jpg\",\"\\/51Et6l2go9L._SL500_.jpg\",\"\\/5199uo4FJSL._SL500_.jpg\",\"\\/51RtjlkGP5L._SL500_.jpg\",\"\\/510LrSEEzwL._SL500_.jpg\",\"\\/61EIay0vxgL._SL500_.jpg\",\"\\/41u5IEra2yL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08BJ7XJ8Y\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08BJ7XJ8Y\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E8%86%9D%E3%82%B5%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%BC%20%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84%20%E6%80%AA%E6%88%91%E9%98%B2%E6%AD%A2%20%E9%80%9A%E6%B0%97%E6%80%A7%E4%BC%B8%E7%B8%AE%E6%80%A7%20%E5%89%8D%E5%8D%81%E5%AD%97%E9%9D%AD%E5%B8%AF%E3%82%B5%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%BC%E8%86%9D%20%E7%97%9B%E3%81%BF%E4%BF%9D%E6%B8%A9%E5%9B%BA%E5%AE%9A%E8%86%9D%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%88%E3%83%A9%E3%83%B3%E3%83%8B%E3%83%B3%E3%82%B0%20%E7%94%B7%E5%A5%B3%20%E5%B7%A6%E5%8F%B3%E5%85%BC%E7%94%A8%20%EF%BC%92%E6%9E%9A%E3%82%BB%E3%83%83%E3%83%88%20(Small)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E8%86%9D%E3%82%B5%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%BC%20%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84%20%E6%80%AA%E6%88%91%E9%98%B2%E6%AD%A2%20%E9%80%9A%E6%B0%97%E6%80%A7%E4%BC%B8%E7%B8%AE%E6%80%A7%20%E5%89%8D%E5%8D%81%E5%AD%97%E9%9D%AD%E5%B8%AF%E3%82%B5%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%BC%E8%86%9D%20%E7%97%9B%E3%81%BF%E4%BF%9D%E6%B8%A9%E5%9B%BA%E5%AE%9A%E8%86%9D%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%88%E3%83%A9%E3%83%B3%E3%83%8B%E3%83%B3%E3%82%B0%20%E7%94%B7%E5%A5%B3%20%E5%B7%A6%E5%8F%B3%E5%85%BC%E7%94%A8%20%EF%BC%92%E6%9E%9A%E3%82%BB%E3%83%83%E3%83%88%20(Small)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"kCO99\",\"s\":\"s\"}); リンク ケガした膝をMRIで撮影し確認したところ、本来ならあるはずの靭帯がありませんでした。orz ”手術しない”という選択肢はあるのでしょうか。。。？ 私の問いに対して医師は、 前十字靭帯は、自然に治ることはほぼ無いんだよ。手術せずに運動したら変形関節症になって人工関節にしないといけなくなったり、歩けなくなるかもしれないよ？ ・・・・・わかりました、手術受けます（泣） 手術当日を迎えるまで すぐに手術なのかと思ったら、そうではありませんでした。 ケガによって委縮してしまった筋肉を、なるべくケガする前の状態に戻す必要があるためです。 なぜ手術前にリハビリが必要なのかは、病院のHPや専門の方がまとめている記事を参照いただければと思います。 私の場合、1か月後の7月に手術をするスケジュールで週に1回、3時間ほどのリハビリをしました。 内容は膝のマッサージ、スクワット(両足・片足)、ゴムチューブを使ったレッグカール(前と後ろ)が中心でした。 手術を受ける1週間前になると、手術の説明を受けます。 全身麻酔での手術になります。入院は1週間でその後は自宅で1ヶ月間、絶対安静でお願いしますね。手術の同意書とかその他の注意点は書類で渡すのでよく読んでおいてくださいね。 あと今日は、採血と麻酔のアレルギーのチェックしますね！ 採血と麻酔アレルギー検査のために、別室に連れていかれました。 麻酔アレルギーの検査は、ちょっと痛いので我慢してくださいね！ （え！？痛いの！？）わ、、、わかりました。 麻酔アレルギーの検査は、腕の皮膚と筋肉の間に少量の麻酔を打ち、アレルギー反応が起こるかどうかを確認するのです。 この麻酔注射は、採血よりも全然痛かったです。 思わず「いててててて！」と声に出してしまいました。。。 特にアレルギーはでなかったので、そのまま帰宅しました。 その後は、保険関連で用意したほうが良い書類とかを確認し、当日を迎えることになります。 前十字靭帯再建手術 当日 手術当時の朝は、飲み物を含む食事は禁止でした。（というか気分が落ち込みすぎて食欲なかった汗） 病院に向かう道中は、本当に憂鬱です。 麻酔は痛くないだろうか。全身麻酔から冷めなかったらどうしよう。術後の痛みどうなんだろう。 などなど。 このような気持ちになるのは正直仕方ないかと思います。 病院に到着すると、まずは入院する部屋に案内されます。 そこで、血圧を図ったり、体重を図ったり、膝の状態の確認をされます。マジックでケガしたほうの足に色々書かれます。 そして、麻酔を体に入れるための点滴針も入れられます。これはそんなに痛くなかったです。 体重計に乗って体重を図ったり、膝はどのくらい曲がるのか、等のチェックもその際に行います。 しばらく待機。 すると、 痛み止めの座薬を入れましょうね。私が入れましょうか？自分で入れます？ （ざ、、、座薬。。）じ、、、自分で入れます。。。 人差し指の第一関節くらいまで押し込んでくださいね！ 手袋とカプセル型の座薬を渡され、自分でその場でいれました。 （なんとも言えない微妙な空気。。。） そしていよいよ手術室に案内されます。手術室には、自分の足で歩いて手術台に横たわります。 〇〇さーん、気分はどうですかー。リラックスしてくださいね〜。 左腕にバンド巻きますね〜。 とか色々言われながら処置が進み、 じゃあ、麻酔入れますね〜。ちょっとグラグラしますよ〜。 と言われた瞬間に、天井がぐにゃぐにゃになりました(笑)※みんな同じ感覚なのかな。 そして気が付いた時には手術が終わってました。 ！？手術終わったの！？ 手術の時間も含めて、5時間くらい寝ていたと思います。 本当に時間の感覚無く、どれだけ時間がたったのかも分からないくらいの一瞬の出来事で少し恐ろしかったです。 麻酔がまだ少し効いてるので、意識は朦朧してるとおもいます。時間がたてば意識がはっきりしてくるので安心してくださいねー。何かあったらナースコールしてください。あと、手術したほうの足の足首は、頻繁に動かしてくださいね。 手術後の右足は出血状態が続いており、頻繁に足首を動かして血を循環させたほうが良いそうです。 間もなく先生からも半月板の状態はどうだったか、とか、いろいろ説明があります。 そしてそこで初めて手術後の自分の体がどのような状態になっているのかが分かるのです。 私の場合、体には計5本の管が入っていました。 ・左腕に点滴の管 ・右側股関節に痛み止めの管 ・右ひざのお皿の近くに血抜きの管（その1） ・右ひざのお皿の近くに血抜きの管（その2） ・尿道に管 ← **これが最悪** 全体を振り返ると一番つらかった/痛かったのは、この5.尿道の管だったように思います。 常に残尿感がある状態のような感覚でとにかく気持ち悪いし、少し体を動かすだけでチクチク痛いのです。 (尿道の管、いつか抜くと思うんだけど、絶対に痛い！） 恐怖したのを今でも覚えています。 なお、膝は手術後の血が足にたまらないように少し高くされており、氷嚢でアイシングされた状態になっています。 この状態のときは全く身動きが取れないので、とにかく寝ることに徹したほうが良いです。（しかしながら、ときおり看護師さんが点滴の入れ替えや、尿の出具合を確認しに来るので、あまり眠れない。。。） ちなみに手術後の痛みは、股関節に入れられている管から入れられている痛み止めが効いているおかげでほとんどありませんでした。 翌朝 朝10:00くらいになると、医師と看護師が管を抜きに来ます。 まずは、膝の管。 人によっては痛いようですが、私の場合は痛み止めが効いていたからかわかりませんが、痛みはありませんでした。 次に、股関節の管。この辺も大丈夫。 点滴もこの時に抜かれた気がします。 そして最後の尿道の管。 てきぱきと抜こうとするのでおもわず、 ちょ、、、ちょっと待ってください。これ(尿道の管)絶対に痛いですよね？汗 と言いました(笑) 看護師さんが、 あー、男性の方は尿道が長いので痛いみたいですねぇ。口呼吸すると、幾分か痛みが和らぐみたいですよ？自分で管抜きますか？ い、、、いや、、、自分では絶対ムリなのでお願いします泣 というので思いっきり口呼吸しました。。。 でもやはり、、、、 いてててててててて！！！！！！ って感じです。 しかし、すべての管がなくなると、本当に身軽になります。 以降は普通に食事もできます。 少ししんどいですが、自ら松葉杖を使ってトイレに行くこともできます。 この経験をすると、”自分でトイレを済ませることができる”ということのありがたみが分かります。介護される側の立場からすると、トイレのお世話をしてもらうのが精神的につらいものがあるのではと思いました。 この経験を忘れないように、自らの健康管理を徹底したいと思っています。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"最新医学図解 詳しくわかるひざ・股関節の痛みの治療と安心生活\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51rU49OiycL._SL500_.jpg\",\"\\/41mnVV-9fmL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4391150239\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4391150239\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%9C%80%E6%96%B0%E5%8C%BB%E5%AD%A6%E5%9B%B3%E8%A7%A3%20%E8%A9%B3%E3%81%97%E3%81%8F%E3%82%8F%E3%81%8B%E3%82%8B%E3%81%B2%E3%81%96%E3%83%BB%E8%82%A1%E9%96%A2%E7%AF%80%E3%81%AE%E7%97%9B%E3%81%BF%E3%81%AE%E6%B2%BB%E7%99%82%E3%81%A8%E5%AE%89%E5%BF%83%E7%94%9F%E6%B4%BB\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%9C%80%E6%96%B0%E5%8C%BB%E5%AD%A6%E5%9B%B3%E8%A7%A3%20%E8%A9%B3%E3%81%97%E3%81%8F%E3%82%8F%E3%81%8B%E3%82%8B%E3%81%B2%E3%81%96%E3%83%BB%E8%82%A1%E9%96%A2%E7%AF%80%E3%81%AE%E7%97%9B%E3%81%BF%E3%81%AE%E6%B2%BB%E7%99%82%E3%81%A8%E5%AE%89%E5%BF%83%E7%94%9F%E6%B4%BB\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"7TY7p\",\"s\":\"s\"}); リンク まとめ: 全身麻酔は怖くないが、手術後が大変でした。 手術を決意した後、しばらくリハビリ期間があります。 手術の数週間前に麻酔のアレルギー検査があります。少し痛い。 全身麻酔は怖くない。ただし、手術後が辛い。 特に尿道の管は辛い ”自分でトイレを済ませることができる”というのは素晴らしいことです。 以上です。続きは以下の記事にまとめています。 &gt;&gt;[続き]手術後から退院までのエピソードはこちら オススメの記事 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです プログラミング学習に興味のある方はこちら","link":"/knee-surgery/"},{"title":"【未経験OK】プログラミング学習はProgate→SkillHacks→Udemyがおすすめ","text":"学生時代は情報系ではなく化学だった私は、社会人になってからプログラミングを学び始めました。 最初は本当に大変だった。。。 その経験を踏まえ、プログラミング学習方法をまとめたいと思います。 ✓目次 [高額なプログラミングスクール不要]オンライン学習がオススメ！ 本記事が述べる良い講座の定義 -設計や思考まで解説しているかどうか- まずはパソコンを用意しよう。 最初はProgateでプログラミングの全体像をつかもう 国内のWeb系エンジニアを目指すならRubyがオススメ Progateの後はSkill Hacksがオススメ SkillHacksの次はUdemyがオススメ オンライン学習の勉強方法：ちゃんとノートを取って復習する オンライン学習の効率化のために(Git, Github) まとめ [高額なプログラミングスクール不要]オンライン学習がオススメ！ 昨今のコロナウィルスのこともあり、プログラミングスクールに行くのは少し抵抗ありませんか？ そもそもプログラミング学習は、オンラインでの動画学習が最適です。 ・ スクールに向かう移動時間を学習時間にあてられる。 ・ お金を払えば、期限なしに動画見放題 ・ 好きな時間に好きなだけ勉強できる ・ 質問も、追加料金なしで、質問し放題 ・ 教材がアップデートされる ・ 単純に安い また、プログラミング学習においては書籍で勉強は正直お勧めしません。 プログラミング言語は、時期とともにバージョンアップが図られ、文法が変わったりします。 そのため、少し古い本だとコードの仕様が変わっていたりしてエラーで動かないなんてことが頻発して、高い確率で挫折します。 本だと質問できる人がいないから、挫折しちゃうんだよね。。。 一方、オンライン学習は、書籍とは違い、その時々に応じてコードや内容等がアップデートされるし、何よりも講師の人に質問ができるので、挫折しない仕組みが整っています。 好きな時間、自分の都合の良いタイミングで、好きなだけ学習できるので最高です。 本記事が述べる良い講座の定義 -設計や思考まで解説しているかどうか- プログラミングを始めた頃に、私含めて周りのプログラミング初心者の人が勘違いしていたことは、プログラマーは何らかのサービスを作る際、完成品に向けていきなりコードを書き始めているものだと思っている点です。 当然これはNoです。 何らかのサービスを作る際に重要なのは、「設計」です。 例えば掲示板のようなアプリであれば、 記事のタイトル一覧を表示する 記事を新規に作成する 記事を削除する 記事を編集する ・・・といった機能が考えられます。 これらの機能をどのようにプログラミングに落とし込めばよいのか、というのが大切です。 本記事では、プログラミングを行う際のサービス設計や思考を丁寧に解説している教材に限定して整理したいと思います。 まずはパソコンを用意しよう。 オンボロPCしかないのですが・・・・・ インターネットに繋がってYoutubeが見れるくらいのパソコンであれば基本問題ないと思います。 Windowsであれば最低限Windows7以上、Macであれば3世代くらい前のもので十分です。 まずは気楽に身近にあるパソコンでやり始めましょう。 最初はProgateでプログラミングの全体像をつかもう まったくの初心者の方は、まずは、Progate[プロゲート]でプログラミングというのがどんなもんなのか、感覚をつかむといいと思います。 無料プランでもいいので、まずはプログラミングがどんな感じのものなのか体感しましょう。 完璧にすべてのコードを覚えようとせず、穴埋め問題的にどんどんLessonを進めてしまってOKです。まずは、プログラミングを続けていけそうかどうか（嫌いじゃないかどうか）を判断するくらいで良いと思います。 最初は誰でも初心者！プログラミングをやってみて、「難しそうだけど頑張ればできそうだな。」という感じであれば、問題ないと思うよ。 国内のWeb系エンジニアを目指すならRubyがオススメ プログラミング言語は、「国内でエンジニアとして活躍したい！」、「エンジニアとして転職したい！」というのであれば、Rubyが良いと思います。 その理由は、日本国内のWeb系エンジニアの求人として、Ruby, Ruby on Railsの求人が多いからです。※2021年1月時点 米国シリコンバレーやAIブームもあり、Pythonの人気が高くなっていますが、フリーランスエンジニアのための求人・案件サイトである、Midworksで確認いただくと、Ruby, Ruby on Railsの求人はPythonよりも多く、比較的単価も高い案件が多くなっています。 特にこだわりがなく、エンジニアとしてスタートを切りたいのであれば、Ruby, Ruby on Railsを学ぶのが良いと思います。 Progateの後はSkill Hacksがオススメ Progateは、プログラミングの感覚をつかむのは良いですが、穴埋め問題的な形で学習が進むため、たぶん、学習を終えても満足にコードが書けるようになってないのではないかと思います。 「設計」を勉強してないからしょうがない。。。 Progateでプログラミングがどんなものかを体感したら、オンライン動画でプログラミング(Ruby, Ruby on Rails)が学べる、SkillHacksの受講をおすすめします。 私のおすすめ：Skill Hacks おすすめの理由を簡単にまとめます。 ✔受講生の評価もかなりよく，絶対に挫折させない仕組みがあること ✔プログラミングスクールの現役講師が作った講座だということ ✔著者はUdemyベストセラー動画の著者・書籍執筆経験があるということ ✔エンジニア経験がある人が作っているということ ✔LINE@による無制限質問サポートで挫折しない仕組みがあるということ ✔94本のしっかりした動画があるということ ✔他のプログラミングスクールよりも安くて手頃ということ ✔動画は無期限で見放題 ✔コードを書く前のサービス設計まで丁寧に解説していること 挫折させない仕組み、って何？？ まずプログラミングをするための環境がクラウド環境であるという点です。どういうことかというと、インターネットに接続可能なパソコンがあれば誰でも始められる、ということです。 また、LINE@による無制限質問サポートが非常に良いです。 エラーが出てもすぐに講師の方に質問して解決できるので「途中で学習が進められなくなった。」みたいなことはありません。 現在SkillHacksは、以下のコンテンツが用意されています。 第00章 事前準備をしよう (2本) 第01章 HTMLのサイト作成講座 (6本) 第02章 CSSでのWebデザイン基礎講座 (6本) 第03章 HTML/CSSワークショップ -自己紹介サイトを作ろう- (6本) 第04章 Bootstrap活用デザイン講座 (7本) 第05章 Rubyプログラミング学習講座 (12本) 第06章 Rubyワークショップ -メモアプリ開発- (7本) 第07章 Ruby on Rails コントローラ・ビュー編 (14本) 第08章 Rails基礎講座 モデル・データベース編 (10本) 第09章 Rails実践編 メモアプリ開発・デプロイ (11本) 第10章 Rails実践編 メモアプリに削除編集カテゴリを追加 (13本) 本記事の冒頭でも述べているように、SkillHacksは単純にアプリを作る方法をレクチャーするのではなく、アプリを作る際の設計についても丁寧に解説されています。 そのため、1つのアプリを作る知識が単純につくのではなく、自分の作りたいアプリを自分の力で形にする思考力も身につけることができます。これが私が最もおすすめする理由です。 Skill Hacksを詳しく見る 多くの教材は、この「設計」の考え方がなく、完成品がいきなり提示され、その完成品の作成に向けてプログラミングのレクチャが始まります。 しかしSkill Hacksは、そのようなスタイルではなく、「設計の考え方まで含まれている点が良いのです。」 また、設計後にコードを書く際も、単純にコードの書き方をレクチャーするのではなく、コードを書くに至るまでの思考も細かくレクチャーしてくれるので、一流のプログラマがどのように考えながらコードを書いているのかを理解することができます。 そして何よりも、エラーで躓いた際のサポートが的確で早い点です。 しかも無制限。聞き放題です。 とはいっても、私自身は2～3回くらいしか質問しなかったです。 それだけ講座の内容が分かりやすく、躓かないように工夫がなされている証拠だと思います。 では、肝心の価格ですが、69,800円（税込）です。※2021年1月時点 少々値は張ると思いますが、この値段で、94本の動画と無制限質問サポートつき。追加料金なしの買い切り価格です。 なので、教材としては一生ものになります。 ただし、価格は予告なく上がる可能性があるようです。 近年の、コロナウィルスの影響で、リモートワークが一気に普及しました。 そのため、リモートワークがしやすい、IT企業への就職または転職を目指す人が増えてくるでしょう。 そうなれば、おのずと本講座の受講生は増えるだろうし、それに伴い、受講料も上がる可能性が高いと思います。 7万という価格で一生もののスキルを身に着けられますし、7万なんて正直すぐに回収できる価格なので、個人にとってみればほぼ無料(むしろ得でしかない)価格に等しいと思います。 Skill Hacksを詳しく見る SkillHacksの次はUdemyがオススメ Udemyとは、世界最大級のオンライン学習プラットフォームです。 Udemyは米国Udemy,Inc.が運営するプラットフォームで日本では、しまじろうでおなじみの、ベネッセが事業パートナーとして協業をしています。 講師は、現役のシリコンバレーエンジニアなど、超一流の方々ばかりです。 価格は、通常価格は2万円くらいですが、不定期で開催されるセール中は最安値で1200円で購入することができます。 すべての講座には、30日間の返還保証もついているため、「ちょっとこの講座ちがうな。」と思ったら返金してくれます。 ちなみに、私はいつも不定期に開催されるセールの時期に、興味のある講座をまとめて購入しています。 Udemyをはじめる Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。 オンライン学習の勉強方法：ちゃんとノートを取って復習する skill hacksに限らず、オンラインの動画でプログラミングなどを勉強する際は、単純に動画の通りに手を動かして進めてもあまり定着しまぜん。 理由は単純に忘れてしまうからです。。。汗 忘れないためにどうすればよいでしょうか。 動画を何度も見返せばよいでしょうか。 それでは少し非効率なのではと考えています。 私の考えとしては、 どのような思考で1つ1つのコードを書いたのかを、何度も振り返られるようにノートを取る というのが、良いと思っています。 ノートの取り方は各々の環境に合わせてやりやすい方法で良いと思いますが、 私の場合は、Boostnoteというツールを使っています。(無料です) Boostnoteに、コードを書く際の思考の流れと、実際のソースコードを記述し、Githubというコードやテキストファイルなどを保存/管理するプラットフォームに置いて、隙間時間にスマホ等で復習を行うとよいでしょう。 GitHubの使い方は、別途学習が必要なので、最初はBoostnoteに講義内容を書き留めればOKです。 Boostnoteでノートを取る際は、マークダウンという記法を活用すると、コードを色付けしてくれたりして、読みやすくなるのでお勧めです。 最低限まずは、「見出し」と「コードブロック」の書き方を覚えておけば良いでしょう。 Googleで「マークダウン 書き方」と検索すれば、記述方法がまとまった記事が出てくるので、参照してみてください。 オンライン学習の効率化のために(Git, Github) 先ほど少し述べたGIt, GitHubも学習しましょう。 Web系の会社に勤めるとなると間違いなく必要です。 自分が作成したアプリを外部に公開する際も必要になります。 Gitというのは、ドキュメントやソースコードなどの記録を変更履歴とともに管理するシステムで、GitHubは、このGitの仕組みを利用して、プログラムコードやデザインデータなどを保存できるウェブサービスです。 skill hacksで学んだ内容をGitHubに記録すれば、通勤中、奥様のお買い物の付き添い中、（環境にもよりますが）職場でも自分の勉強した内容を復習することができます。 勉強は何よりも復習が大事です。 また、GitとGitHubはエンジニアを目指すのであれば必須の知識です。 学んでおいて全く損はない（むしろ得することばかり）なので、プログラミングの学習と並行して、GitとGitHubも勉強しましょう。 なお、GitHubは、プライベートモードにしておけば、他の人に閲覧されることはないのでご安心ください。 まずは以下の無料のGithubのUdemy講座を受講しましょう。個人で使うレベルであれば、こちらのUdemyの無料講座で十分です。 無料でGitを学ぶ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-sm2sCFi\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/intro_git/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/480x270/1081802_50f8_2.jpg?XV3MCps2tn22sb2zV5oDjnZGHjMMH__93M51-yhuKYWR7DxRtAuPdFt4nfjaPVHp8LglgLp1M5V9KBywz9TUWSAJt336gv1OjAmNjNVt9hQ8OLFmZ4T5linwaxMVIw\"}}); 中級レベルのGit, Githubを学ぶ必要があれば以下がおすすめです。上記の無料講座を受講いただければ、以下の講座は割引クーポンで1500円程度で安く購入できます。 Git中級編を学ぶ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rNlhfWh\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://i.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); まとめ プログラミング学習はオンライン動画がオススメ。IT技術の進化は早く、書籍での勉強は、コード仕様の変更でエラーになるなど挫折必須。 最初はProgateでプログラミングの感覚をつかむ。終わったら、Skill Hacksを受講して、エンジニアとして自走力をつけよう！ Skill Hacksが終わったらUdemyがオススメ！セール時は1200円で動画は無期限で見放題。30日間の返金保証付き！ 動画を見ながら手を動かすだけではなく、講師が口頭で述べている考え方もちゃんとノートを取ろう。 ノートはBoostnoteがおすすめ。 余力があればGit, GitHubの使い方も勉強し、作成したノートをいつでもどこでもスマホで復習できるようにしよう。 まずは無料のGit：はじめてのGitとGitHub 上記の無料講座が終わったら、Git： もう怖くないGit！チーム開発で必要なGitを完全マスターを学ぼう。 Skill Hacksを詳しく見る Udemyを詳しく見る 無料でGitを学ぶ Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。","link":"/programing-study-next-of-progate/"},{"title":"【ラズパイ入門】Raspberry Pi 3 Model B+の組み立てと初期設定の注意事項！","text":"本記事ではRaspberry Pi 3 Model B+の組み立てと初期設定の方法と注意点をまとめていきます。 この記事の対象者 ・ これからRaspberry Piを購入しようとしている人 ・ Raspberry Piの初期設定に不安を抱えている人 目次 購入/セットアップしたRaspberry Pi 1. 追加で必要なものがある 有線キーボードとマウス LANケーブル インターネット ディスプレイ 2. 最初にやることはヒートシンクを装着しケースに収納 3. 有線キーボードが悪さをしてマウスが操作できない場合がある 4. 初期アップデートはとんでもない時間がかかる まとめ: ラズパイの組み立てと初期設定をする上での注意点をまとめました。 購入/セットアップしたRaspberry Pi本記事はAmazonで購入した以下のラズベリーパイを用いてます。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Raspberry Pi 3 Model b+ ラズベリーパイ 3 b＋ MicroSDHCカード32G\\/NOOBSシステムプリインストール\\/カードリーダ \\/5V\\/3A スイッチ付電源\\/高品質HDMIケーブルライン\\/ヒートシンク\\/簡単に取り付けケース\\/日本語取扱説明書\\/12ヶ月保証\",\"b\":\"BosNano\",\"t\":\"RPi 3B+-JP-BosNano\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51VtEe-XkeS._SL500_.jpg\",\"\\/51LgOrBi9OS._SL500_.jpg\",\"\\/51sqNXoqbRS._SL500_.jpg\",\"\\/51Yt0Dn9KLS._SL500_.jpg\",\"\\/513UWGVZ-9S._SL500_.jpg\",\"\\/51BPloN1eWS._SL500_.jpg\",\"\\/41kUxpuiL6S._SL500_.jpg\",\"\\/51jXqAnYhRS._SL500_.jpg\",\"\\/51Kygi964xS._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B09826D3C1\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B09826D3C1\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Raspberry%20Pi%203%20Model%20b%2B%20%E3%83%A9%E3%82%BA%E3%83%99%E3%83%AA%E3%83%BC%E3%83%91%E3%82%A4%203%20b%EF%BC%8B%20MicroSDHC%E3%82%AB%E3%83%BC%E3%83%8932G%2FNOOBS%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%83%97%E3%83%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%2F%E3%82%AB%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%80%20%2F5V%2F3A%20%E3%82%B9%E3%82%A4%E3%83%83%E3%83%81%E4%BB%98%E9%9B%BB%E6%BA%90%2F%E9%AB%98%E5%93%81%E8%B3%AAHDMI%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%E3%83%A9%E3%82%A4%E3%83%B3%2F%E3%83%92%E3%83%BC%E3%83%88%E3%82%B7%E3%83%B3%E3%82%AF%2F%E7%B0%A1%E5%8D%98%E3%81%AB%E5%8F%96%E3%82%8A%E4%BB%98%E3%81%91%E3%82%B1%E3%83%BC%E3%82%B9%2F%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E6%89%B1%E8%AA%AC%E6%98%8E%E6%9B%B8%2F12%E3%83%B6%E6%9C%88%E4%BF%9D%E8%A8%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Raspberry%20Pi%203%20Model%20b%2B%20%E3%83%A9%E3%82%BA%E3%83%99%E3%83%AA%E3%83%BC%E3%83%91%E3%82%A4%203%20b%EF%BC%8B%20MicroSDHC%E3%82%AB%E3%83%BC%E3%83%8932G%2FNOOBS%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%83%97%E3%83%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%2F%E3%82%AB%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%80%20%2F5V%2F3A%20%E3%82%B9%E3%82%A4%E3%83%83%E3%83%81%E4%BB%98%E9%9B%BB%E6%BA%90%2F%E9%AB%98%E5%93%81%E8%B3%AAHDMI%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%E3%83%A9%E3%82%A4%E3%83%B3%2F%E3%83%92%E3%83%BC%E3%83%88%E3%82%B7%E3%83%B3%E3%82%AF%2F%E7%B0%A1%E5%8D%98%E3%81%AB%E5%8F%96%E3%82%8A%E4%BB%98%E3%81%91%E3%82%B1%E3%83%BC%E3%82%B9%2F%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E6%89%B1%E8%AA%AC%E6%98%8E%E6%9B%B8%2F12%E3%83%B6%E6%9C%88%E4%BF%9D%E8%A8%BC\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"ADkjL\",\"s\":\"s\"}); リンク Raspberry Piのスターターキットということで、以下の物品が同包されています。 MicroSDカード（NOOBSというシステムが入っており時間を欠けずに公式OSであるRaspbianの導入が可能） 専用ケース（基盤の保護と冷却効果がある） ヒートシンク（熱伝導性接着剤がデフォルトで着いている） カードリーダー(MicroSDとUSB-Cの変換ケーブル。パソコンから気になるシステムをカードに読み込み可能) 電源アダプタ HDMIケーブル 説明書（日本語） MicroSDカードにNOOBSがすでに入っているのは嬉しいですね。 こちらのラズパイを組み立てて初期設定する際の注意点をまとめていきます。 1. 追加で必要なものがあるラズパイの初期設定をすすめるためには以下の物品が別途必要です。 【注意】ラズパイのセットアップに追加で必要なもの 1. 有線マウス（BluetoothマウスはOSが起動してから利用可能となるため最初は有線マウスが必要）2. 有線キーボード(BluetoothキーボードはOSが起動してから利用可能となるため最初は有線キーボードが必要)3. LANケーブル（初期設定の際にラズパイをインターネットに接続するために必要。無線LANはセットアップが終わった後に設定したほうが安心）4. インターネット環境（当然ながらソフトウェアのアップデート等で必須） 5. ディスプレイ(ラズパイの設定画面を表示) 有線キーボードとマウス 有線キーボードとマウスは初期設定をする際、ラズパイへの文字入力と設定操作をする上で必須となります。 なおマウスとキーボードのBluetooth接続は、ラズパイにRasbianが導入された後に可能となります。 マウスとキーボードは有線に加えBluetooth接続可能なものが望ましいかと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"iClever キーボード bluetooth USB接続 ワイヤレス 薄型 折りたたみ式 ブルートゥース キーボード 無線 \\u0026 有線 デュアルモード接続 マルチペアリング対応 4台までのデバイス同時接続 バックライト機能なし IOS\\/Android\\/Windows iPhone iPad 対応 IC-BK20se\",\"b\":\"iClever\",\"t\":\"IC-BK20se\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41U8AnYRwJS._SL500_.jpg\",\"\\/51sU8uEQkiL._SL500_.jpg\",\"\\/41Juk+EEJbL._SL500_.jpg\",\"\\/51x4FBeTxTL._SL500_.jpg\",\"\\/41TCzMm7ARL._SL500_.jpg\",\"\\/51p8uj4uYJL._SL500_.jpg\",\"\\/41VPysq+b2L._SL500_.jpg\",\"\\/41xMPiR6YkL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B01DX74J6C\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B01DX74J6C\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/iClever%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20bluetooth%20USB%E6%8E%A5%E7%B6%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E8%96%84%E5%9E%8B%20%E6%8A%98%E3%82%8A%E3%81%9F%E3%81%9F%E3%81%BF%E5%BC%8F%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%88%E3%82%A5%E3%83%BC%E3%82%B9%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E7%84%A1%E7%B7%9A%20%26%20%E6%9C%89%E7%B7%9A%20%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%83%A2%E3%83%BC%E3%83%89%E6%8E%A5%E7%B6%9A%20%E3%83%9E%E3%83%AB%E3%83%81%E3%83%9A%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E5%AF%BE%E5%BF%9C%204%E5%8F%B0%E3%81%BE%E3%81%A7%E3%81%AE%E3%83%87%E3%83%90%E3%82%A4%E3%82%B9%E5%90%8C%E6%99%82%E6%8E%A5%E7%B6%9A%20%E3%83%90%E3%83%83%E3%82%AF%E3%83%A9%E3%82%A4%E3%83%88%E6%A9%9F%E8%83%BD%E3%81%AA%E3%81%97%20IOS%2FAndroid%2FWindows%20iPhone%20iPad%20%E5%AF%BE%E5%BF%9C%20IC-BK20se\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=iClever%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20bluetooth%20USB%E6%8E%A5%E7%B6%9A%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E8%96%84%E5%9E%8B%20%E6%8A%98%E3%82%8A%E3%81%9F%E3%81%9F%E3%81%BF%E5%BC%8F%20%E3%83%96%E3%83%AB%E3%83%BC%E3%83%88%E3%82%A5%E3%83%BC%E3%82%B9%20%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E7%84%A1%E7%B7%9A%20%26%20%E6%9C%89%E7%B7%9A%20%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%83%A2%E3%83%BC%E3%83%89%E6%8E%A5%E7%B6%9A%20%E3%83%9E%E3%83%AB%E3%83%81%E3%83%9A%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E5%AF%BE%E5%BF%9C%204%E5%8F%B0%E3%81%BE%E3%81%A7%E3%81%AE%E3%83%87%E3%83%90%E3%82%A4%E3%82%B9%E5%90%8C%E6%99%82%E6%8E%A5%E7%B6%9A%20%E3%83%90%E3%83%83%E3%82%AF%E3%83%A9%E3%82%A4%E3%83%88%E6%A9%9F%E8%83%BD%E3%81%AA%E3%81%97%20IOS%2FAndroid%2FWindows%20iPhone%20iPad%20%E5%AF%BE%E5%BF%9C%20IC-BK20se\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"z1Jis\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"JinSun 充電式 ラップトップ ワイヤレスゲーミングマウス 2 in 1 無線・有線 オプティカルマウス USBマウス 5ボタン 6色ブリーズライト PC・Mac用 6種類のDPI調節可能 ラップトップ・Mac Pro・コンピュータ用 (W200)\",\"b\":\"JinSun\",\"t\":\"Gaming mouse-01\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/412XqJoQzBL._SL500_.jpg\",\"\\/41axYPYPj-L._SL500_.jpg\",\"\\/51kfHiMw3ML._SL500_.jpg\",\"\\/514tNFShf0L._SL500_.jpg\",\"\\/41CjpaI6KQL._SL500_.jpg\",\"\\/61zkNXMzKjL._SL500_.jpg\",\"\\/41FL6QMwYHL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07BT8RHYM\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07BT8RHYM\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/JinSun%20%E5%85%85%E9%9B%BB%E5%BC%8F%20%E3%83%A9%E3%83%83%E3%83%97%E3%83%88%E3%83%83%E3%83%97%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%9E%E3%82%A6%E3%82%B9%202%20in%201%20%E7%84%A1%E7%B7%9A%E3%83%BB%E6%9C%89%E7%B7%9A%20%E3%82%AA%E3%83%97%E3%83%86%E3%82%A3%E3%82%AB%E3%83%AB%E3%83%9E%E3%82%A6%E3%82%B9%20USB%E3%83%9E%E3%82%A6%E3%82%B9%205%E3%83%9C%E3%82%BF%E3%83%B3%206%E8%89%B2%E3%83%96%E3%83%AA%E3%83%BC%E3%82%BA%E3%83%A9%E3%82%A4%E3%83%88%20PC%E3%83%BBMac%E7%94%A8%206%E7%A8%AE%E9%A1%9E%E3%81%AEDPI%E8%AA%BF%E7%AF%80%E5%8F%AF%E8%83%BD%20%E3%83%A9%E3%83%83%E3%83%97%E3%83%88%E3%83%83%E3%83%97%E3%83%BBMac%20Pro%E3%83%BB%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E7%94%A8%20(W200)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=JinSun%20%E5%85%85%E9%9B%BB%E5%BC%8F%20%E3%83%A9%E3%83%83%E3%83%97%E3%83%88%E3%83%83%E3%83%97%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%9E%E3%82%A6%E3%82%B9%202%20in%201%20%E7%84%A1%E7%B7%9A%E3%83%BB%E6%9C%89%E7%B7%9A%20%E3%82%AA%E3%83%97%E3%83%86%E3%82%A3%E3%82%AB%E3%83%AB%E3%83%9E%E3%82%A6%E3%82%B9%20USB%E3%83%9E%E3%82%A6%E3%82%B9%205%E3%83%9C%E3%82%BF%E3%83%B3%206%E8%89%B2%E3%83%96%E3%83%AA%E3%83%BC%E3%82%BA%E3%83%A9%E3%82%A4%E3%83%88%20PC%E3%83%BBMac%E7%94%A8%206%E7%A8%AE%E9%A1%9E%E3%81%AEDPI%E8%AA%BF%E7%AF%80%E5%8F%AF%E8%83%BD%20%E3%83%A9%E3%83%83%E3%83%97%E3%83%88%E3%83%83%E3%83%97%E3%83%BBMac%20Pro%E3%83%BB%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E7%94%A8%20(W200)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"qScV4\",\"s\":\"s\"}); リンク LANケーブル LANケーブルは、カテゴリ６系であれば大丈夫です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"UGREEN LANケーブル カテゴリー7 RJ45 コネクタ ギガビット10Gbps\\/600MHz CAT7準拠 イーサネットケーブル STP 爪折れ防止 シールド モデム ルータ PS3 PS4 Xbox等に対応 1M\",\"b\":\"UGREEN\",\"t\":\"11260JP\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41AbYsGv1rL._SL500_.jpg\",\"\\/51ypwEP5CpL._SL500_.jpg\",\"\\/41ektO5xT7L._SL500_.jpg\",\"\\/51s4l6p1gtL._SL500_.jpg\",\"\\/41g2DkViDBL._SL500_.jpg\",\"\\/41S7D9ml1lL._SL500_.jpg\",\"\\/41jB8v0e4lL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07C7PRCGY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07C7PRCGY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/UGREEN%20LAN%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%20%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E3%83%BC7%20RJ45%20%E3%82%B3%E3%83%8D%E3%82%AF%E3%82%BF%20%E3%82%AE%E3%82%AC%E3%83%93%E3%83%83%E3%83%8810Gbps%2F600MHz%20CAT7%E6%BA%96%E6%8B%A0%20%E3%82%A4%E3%83%BC%E3%82%B5%E3%83%8D%E3%83%83%E3%83%88%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%20STP%20%E7%88%AA%E6%8A%98%E3%82%8C%E9%98%B2%E6%AD%A2%20%E3%82%B7%E3%83%BC%E3%83%AB%E3%83%89%20%E3%83%A2%E3%83%87%E3%83%A0%20%E3%83%AB%E3%83%BC%E3%82%BF%20PS3%20PS4%20Xbox%E7%AD%89%E3%81%AB%E5%AF%BE%E5%BF%9C%201M\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=UGREEN%20LAN%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%20%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E3%83%BC7%20RJ45%20%E3%82%B3%E3%83%8D%E3%82%AF%E3%82%BF%20%E3%82%AE%E3%82%AC%E3%83%93%E3%83%83%E3%83%8810Gbps%2F600MHz%20CAT7%E6%BA%96%E6%8B%A0%20%E3%82%A4%E3%83%BC%E3%82%B5%E3%83%8D%E3%83%83%E3%83%88%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%20STP%20%E7%88%AA%E6%8A%98%E3%82%8C%E9%98%B2%E6%AD%A2%20%E3%82%B7%E3%83%BC%E3%83%AB%E3%83%89%20%E3%83%A2%E3%83%87%E3%83%A0%20%E3%83%AB%E3%83%BC%E3%82%BF%20PS3%20PS4%20Xbox%E7%AD%89%E3%81%AB%E5%AF%BE%E5%BF%9C%201M\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"90CGo\",\"s\":\"s\"}); リンク インターネット インターネットは、工事不要のインターネット会社を活用すると直ぐに使えます。 工事不要のインターネットは、利用者人気No.1のGMOインターネットのとくとくBBがキャッシュバックもありお得です。 GMOインターネットのとくとくBBの注意点は、オプションサービスを早めに解除しないと請求されてしまう点ですね。 ディスプレイ ディスプレイはテレビなどをお持ちの方はそれを活用すれば良いと思います。 もし購入する場合はモバイルディスプレイであれば、大きなスペースを必要としないのでおすすめです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ノースマイク(NORSMIC) 最新版 モバイルモニター 15.6インチ IPSパネル 液晶スクリーン 1920ｘ1080FHD高解像度 72%NTSC\\/100%sRGB広色域 PC\\/Switch\\/PS4\\/XBOX\\/MAC\\/スマホなど対応のゲームモニター ポータブルディスプレイ 9mm 薄型 790g 軽量 Type-C\\/USB\\/標準HDMI\\/miniDP入力 スタンドカバー付き 日本語対応 日本語取説付き NORS-Z1-3 [PSE認証ずみ]\",\"b\":\"NORSMIC\",\"t\":\"Z1-3\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41pd9yb0fDL._SL500_.jpg\",\"\\/51hSkucoINL._SL500_.jpg\",\"\\/41G1nONFdRL._SL500_.jpg\",\"\\/5139kaV1oKL._SL500_.jpg\",\"\\/51mQ7+ret3L._SL500_.jpg\",\"\\/511qOOeY2xL._SL500_.jpg\",\"\\/41UzoWQ9oGL._SL500_.jpg\",\"\\/41UckvE-fGL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08ML9WVC4\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08ML9WVC4\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%8E%E3%83%BC%E3%82%B9%E3%83%9E%E3%82%A4%E3%82%AF(NORSMIC)%20%E6%9C%80%E6%96%B0%E7%89%88%20%E3%83%A2%E3%83%90%E3%82%A4%E3%83%AB%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%2015.6%E3%82%A4%E3%83%B3%E3%83%81%20IPS%E3%83%91%E3%83%8D%E3%83%AB%20%E6%B6%B2%E6%99%B6%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%201920%EF%BD%981080FHD%E9%AB%98%E8%A7%A3%E5%83%8F%E5%BA%A6%2072%25NTSC%2F100%25sRGB%E5%BA%83%E8%89%B2%E5%9F%9F%20PC%2FSwitch%2FPS4%2FXBOX%2FMAC%2F%E3%82%B9%E3%83%9E%E3%83%9B%E3%81%AA%E3%81%A9%E5%AF%BE%E5%BF%9C%E3%81%AE%E3%82%B2%E3%83%BC%E3%83%A0%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%20%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%96%E3%83%AB%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4%209mm%20%E8%96%84%E5%9E%8B%20790g%20%E8%BB%BD%E9%87%8F%20Type-C%2FUSB%2F%E6%A8%99%E6%BA%96HDMI%2FminiDP%E5%85%A5%E5%8A%9B%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%89%E3%82%AB%E3%83%90%E3%83%BC%E4%BB%98%E3%81%8D%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%AF%BE%E5%BF%9C%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E8%AA%AC%E4%BB%98%E3%81%8D%20NORS-Z1-3%20%5BPSE%E8%AA%8D%E8%A8%BC%E3%81%9A%E3%81%BF%5D\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%8E%E3%83%BC%E3%82%B9%E3%83%9E%E3%82%A4%E3%82%AF(NORSMIC)%20%E6%9C%80%E6%96%B0%E7%89%88%20%E3%83%A2%E3%83%90%E3%82%A4%E3%83%AB%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%2015.6%E3%82%A4%E3%83%B3%E3%83%81%20IPS%E3%83%91%E3%83%8D%E3%83%AB%20%E6%B6%B2%E6%99%B6%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%201920%EF%BD%981080FHD%E9%AB%98%E8%A7%A3%E5%83%8F%E5%BA%A6%2072%25NTSC%2F100%25sRGB%E5%BA%83%E8%89%B2%E5%9F%9F%20PC%2FSwitch%2FPS4%2FXBOX%2FMAC%2F%E3%82%B9%E3%83%9E%E3%83%9B%E3%81%AA%E3%81%A9%E5%AF%BE%E5%BF%9C%E3%81%AE%E3%82%B2%E3%83%BC%E3%83%A0%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%20%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%96%E3%83%AB%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4%209mm%20%E8%96%84%E5%9E%8B%20790g%20%E8%BB%BD%E9%87%8F%20Type-C%2FUSB%2F%E6%A8%99%E6%BA%96HDMI%2FminiDP%E5%85%A5%E5%8A%9B%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%89%E3%82%AB%E3%83%90%E3%83%BC%E4%BB%98%E3%81%8D%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%AF%BE%E5%BF%9C%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%8F%96%E8%AA%AC%E4%BB%98%E3%81%8D%20NORS-Z1-3%20%5BPSE%E8%AA%8D%E8%A8%BC%E3%81%9A%E3%81%BF%5D\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"AmHqB\",\"s\":\"s\"}); リンク 2. 最初にやることはヒートシンクを装着しケースに収納付属の説明書に記載されている組み立て手順には、MicroSDカードの装着やヒートシンクの装着、そして各種ケーブルの装着が記載されていますが、正しい組立て手順は以下のとおりです。 ヒートシンクを付ける（表裏両方） ケースに収納する SDカードを装着 HDMIケーブルを装着。ケーブルはディスプレイにも装着 電源スイッチをON ポイントはSDカードの装着の前にケースに収納するということです。 SDカードを指した状態では、ケースに収納することが出来ません。（私はこれにハマりました） ヒートシンクを付けたら早々にケースに収納しましょう。 3. 有線キーボードが悪さをしてマウスが操作できない場合がある私が使用しているキーボードを有線で装着すると、なぜかマウスの操作ができなくなる事象が発生しました。 マウスの操作ができなくなった場合は、一旦キーボードの有線接続を外してみると良いかと思います。 私はラズパイの設定画面が表示された後、早々に画面右上のBluetooth設定で、キーボードをBluetooth接続させて解決させました。 4. 初期アップデートはとんでもない時間がかかるラズパイの設定を進めていくと、言語選択、画面周りに黒い縁があるかどうかを聞かれます。 最後に、ソフトウェアの総点検とUpdate Softwareが求められますが完了までに1日くらい時間がかかります。 私の場合前日の夜にUpdateを仕掛けて翌朝の時点でも完了しておらず、「なんかおかしくなってるのかな？」とおもいラズパイを再起動しました。 再起動実施後も、同様の設定チェックが求められるSoftware Updateを求められたため再度実行。 このときは1時間くらいでUpdateが完了しました。 何れにせよ、初期設定時のSoftware Updateは相当時間がかかることを念頭においておいたほうが良いかと思います。 まとめ: ラズパイの組み立てと初期設定をする上での注意点をまとめました。本記事は、「【ラズパイ入門】Raspberry Pi 3 Model B+の組み立てと初期設定の注意事項！」というテーマでまとめました。 本記事にまとめた注意事項と、付属の日本語解説書を元にセットアップすれば問題ないかと思います。 設定が完了すると以下のような画面になります。 特にハマる点としてはヒートシンクの装着を完了させたらケースに収納するという工程を飛ばしてしまう点です。説明書に書いてないので、これは結構ハマる人がいるのではないかと思います。 あとは初期設定最後のSoftware Updateですね。 Software Updateは下手したら1日で終わりません。そのくらいの気持ちでUpdateを仕掛けましょう。 なお、Raspberry Piを活用したIoTは、Udemyを活用した学習が効率的です。 以下のベストセラー講座で、pythonというプログラミングを用いてCO2、温湿度、照度、水深の測定、Google Spreadsheetへのデータ保存、自動水やり機能の実装方法が学べます。 &gt;&gt; Raspberry PiとPythonでIoTはじめの一歩～IoTキッチンガーデン講座～ &gt;&gt; Raspberry PiとPythonでIoTはじめの一歩～IoTキッチンガーデン講座～;","link":"/raspi-getstart/"},{"title":"【RNN基礎】RNNとはなにか？Pythonで実装しながらちゃんと理解してみる。","text":"✓目次 本記事の対象者 RNNとはなにか RNNは勾配爆発と勾配消失を起こしやすい RNNを実装してみる 訓練用データを作成する。 ①ノイズ付きサイン関数の作成 ②入力データと正解データの作成 ③入力データと正解データの形状をKerasのRNN仕様に変更する。 RNNの構築 バッチサイズとモデルの設定 モデルを作成し層を追加 構築したRNNのモデルを用いて学習 学習の推移を確認する。 学習済モデルを使ってサイン関数を予測 まとめ 本記事の対象者 ニューラルネットワークとは何かを理解している人。 pythonの基本を理解している人。 Kerasでニューラルネットワークを作ったことがある人 以下の記事で、Kerasを使ってニューラルネットワークとはどのようなものかをまとめているので、参考にしてみてください。 &gt;&gt; ニューラルネットワークとは何かを学ぶ RNNとはなにか RNNは「リカレントニューラルネットワーク」の略です。 RNNとは、過去のデータを基に、これからどのような処理をするのかを判断することが得意なニューラルネットワークです。 時系列データを扱うのが得意なニューラルネットワークとも言われ、具体的には以下のような時系列データをあつかったりします。 株価 音声データ 音楽 文書 気象 RNNではこの時系列データを入力および正解として扱います。 RNNの特徴は、以下の図に示すように、中間層がループする構造を取る点です。 中間層がループする構造とは、中間層の出力が入力層からの次の入力とセットで、中間層への入力になるということです。 このように、自ら出力したデータを再び入力データとしてループすることを再帰といいます。 そのためRNNは、「再帰型ニューラルネットワーク」と言い換えられたりもします。 このような特徴から、RNNは過去のデータを保持することになるため、過去のデータを用いて判断を行うことができるのです。 時間\\( t\\)の経過に沿った動作を図で表すと以下のようになります。 時間が経過すればするほど、中間層が何層にもつながり、ある意味深いニューラルネットワークになることが分かります。 順伝播で入力データに対する予測が行われ、逆伝播の際に学習が行われます。 重みの更新は、通常のニューラルネットワークと同様、以下の式で表される勾配に基づいて行われます。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}} RNNと通常のニューラルネットワークとの違いは、重みやバイアスのパラメータ更新に、過去のデータからさかのぼってきた情報を利用する点にあります。 つまり、全時刻を通じて誤差をさかのぼり、重みとバイアスを更新するということになります。 RNNは勾配爆発と勾配消失を起こしやすい RNNは時系列データを用いて深いニューラルネットワークになっています。 このような構造を取った場合、何層にもわたって誤差を伝搬させることにより、勾配が大きくなりすぎるという問題が発生します。 勾配が大きくなりすぎてしまうことを勾配爆発と一般的に言い、これが起きてしまうとコンピュータ側で処理できなくなってします。 また、その逆で勾配が小さくなりすぎてしまう、勾配消失（勾配が0になる）というのも起こることがあり、学習できなくなってしまいます。 RNNは、前の時刻からデータを引継ぎ、繰り返し同じ重みを掛け合わせるため、通常のニューラルネットワークと比べて、これらの問題が起こりやすいと考えられています。 勾配爆発の対策としては、勾配クリッピングが有効です。勾配クリッピングとは、勾配の大きさに制限をかけることにより、勾配爆発を抑制することです。 勾配消失の対策としては、活性化関数を変更するか、LSTMというRNNの発展形であるニューラルネットワークを用いるのが良いそうです。 RNNを実装してみる Jupyter NotebookでRNNの実装を行います。 Jupyter Notebookの環境構築方法は、こちらにまとめています。 ここでは、ノイズを含めたサイン関数を用意し、RNNを構築し、学習させたあと、学習済みモデルを使用して予測を行ってみたいと思います。 訓練用データを作成する。 まずは、RNNで用いる訓練用のデータを作成します。 ①ノイズ付きサイン関数の作成 サイン関数に代入する値として、\\( -2π\\)から\\( 2π\\)までの値を用意します。 123456%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまで値を50個 x_dataは以下のようになっています。 12345678910array([-6.28318531, -6.02672876, -5.77027222, -5.51381568, -5.25735913, -5.00090259, -4.74444605, -4.48798951, -4.23153296, -3.97507642, -3.71861988, -3.46216333, -3.20570679, -2.94925025, -2.6927937 , -2.43633716, -2.17988062, -1.92342407, -1.66696753, -1.41051099, -1.15405444, -0.8975979 , -0.64114136, -0.38468481, -0.12822827, 0.12822827, 0.38468481, 0.64114136, 0.8975979 , 1.15405444, 1.41051099, 1.66696753, 1.92342407, 2.17988062, 2.43633716, 2.6927937 , 2.94925025, 3.20570679, 3.46216333, 3.71861988, 3.97507642, 4.23153296, 4.48798951, 4.74444605, 5.00090259, 5.25735913, 5.51381568, 5.77027222, 6.02672876, 6.28318531]) このx_dataをサイン関数に代入し、np.random.randnにより、乱数でノイズを加えてsin_dataとします。 グラフとして描画も実施します。 1234sin_data = np.sin(x_data) + 0.3*np.random.randn(len(x_data)) # sin関数に乱数でノイズを加えるplt.plot(x_data, sin_data)plt.show() サイン関数にノイズが付いたプロットが表示されました。 ②入力データと正解データの作成 続いて入力データと正解データを作りたいと思います。 1234n_rnn = 15 # 時系列の数n_sample = len(x_data)-n_rnn # サンプル数i_data = np.zeros((n_sample, n_rnn)) # 入力c_data = np.zeros((n_sample, n_rnn)) # 正解 まず、時系列の数を設定します。 時系列の数というのは、要するに中間層がループする回数です。 今回は15回中間層がループする設定にします。 サンプル数は、len(x_data)-n_rnnとなり、今回の例でいうと、50 - 15 = 35となります。 これは、入力データと正解データを1セットで1サンプルとしてカウントするためです。 具体的に説明します。 x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、これを入力データとします。 そして、入力データから値を予想するモデルを作るために必要な正解データとして、入力データを1つずらした15個分のデータ1ブロックを正解データとします。 そして1サンプルというのは、先に述べた入力データおよび正解データの2つを1セットにしたものを指します。 図で表すと以下のようなイメージです。 入力データであるi_dataは、numpyのzerosメソッドで、すべて0とし初期化しておきます。 i_dataの行数は、サンプル数であるn_sampleとし、列数は時系列の数であるn_rnnにします。 正解データに関しても同様の配列にします。 i_data.shapeを実行すると(35, 15)、つまり、35行、15列になっていることが分かります。 もちろん配列データの中身は[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]となっています。 次に初期化したi_dataとc_dataに、sin関数にノイズを加えたsin_dataを設定していきます。 123for i in range(0, n_sample): i_data[i] = sin_data[i:i+n_rnn] c_data[i] = sin_data[i+1:i+n_rnn+1] # 時系列を入力よりも一つ後にずらす 入力データi_dataは、iからi+n_rnnまでを1ブロックとして加えたものになります。 正解データc_dataは時系列を入力データよりも1つ後にずらしたものになります。 未来のデータであればsin_data[i+n_rnn+1]の一つだけでも良さそうですが、これではエラーになります。 RNNには2つのタイプがあり、最後の時刻のみの出力を使うタイプと、全ての時刻の出力を使うタイプです。 前者に必要な正解は1つですが、後者は出力の数だけ正解が必要になります。 今回は後者にあたります。 上記のコードを実行し、i_dataの中身を見てみると、以下のようになっています。 12345678array([[-0.03454036, 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603], [ 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603, -0.52893013], (略) ③入力データと正解データの形状をKerasのRNN仕様に変更する。 入力と正解データを作成しましたが、Kerasでは、データの形状を(入力のサンプル数, 時系列の数, 入力層のニューロン数)にする必要があります。 現時点でのi_dataの形状は、(35, 15)になっているので、reshapeを用いて、形状を変更させます。 12i_data = i_data.reshape(n_sample, n_rnn, 1) # KerasにおけるRNNでは、入力を（サンプル数、時系列の数、入力層のニューロン数）にするc_data = c_data.reshape(n_sample, n_rnn, 1) # 今回は入力と同じ形状 i_dataの中身を見てみると以下のようになっており、形状は(35, 15, 1)となります。 それぞれサンプル数、時系列の数、入力層のニューロン数を表しています。 12345678910111213141516171819202122232425262728293031323334array([[[-0.03454036], [ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603]], [[ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603], [-0.52893013]], (略) これで、訓練用のデータを作成することができました。 RNNの構築 Kerasを使ってRNNを構築します。 Kerasで活用できるRNNは主に以下があります。 SimpleRNN: RNN。全結合の中間層が再帰的になる。 LSTM: RNNの発展版であるLSTMを活用できる。複雑な時系列データを扱えるが学習に時間がかかる。 GRU: LSTMの簡易版のようなもの。LSTMに比べパラメータが少ないので、LSTMに比べて学習に時間がかからない。 お好みに合わせて、何れかのニューラルネットワークを活用すればよいと思います。 バッチサイズとモデルの設定 本記事では、Kerasで活用できるRNNの中で一番シンプルな、SimpleRNN層を使います。 バッチサイズ、入力層のニューロン数、中間層のニューロン数、出力層のニューロン数を設定します。 1234567from keras.models import Sequentialfrom keras.layers import Dense, SimpleRNNbatch_size = 5 # バッチサイズn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数 これでOKです。 モデルを作成し層を追加 Sequential()でモデルを作成し、層を追加していきます。 1234567model = Sequential()# SimpleRNN層の追加。return_sequenceをTrueにすると、時系列の全てのRNN層が出力を返す。# return_sequenceをTrueをFalseにすると、最後のRNN層のみが出力を返す。model.add(SimpleRNN(n_mid, input_shape=(n_rnn, n_in), return_sequences=True))model.add(Dense(n_out, activation=\"linear\"))model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 誤差は二乗誤差、最適化アルゴリズムはSGDprint(model.summary()) まずはSimpleRNNの層を追加します。 SimpleRNN追加の際は、中間層のニューロン数を設定して、入力の形状を設定します。 RNNの場合、入力の形状は、(時系列の数(15), 入力層のニューロン数(1))となります。 return_sequencesはTrueに設定します。Trueにすることで、時系列のすべてのRNN層が出力を返すことになります。これをFalseに設定すると、最後のRNN層のみが、出力を返すことになります。なお、デフォルトでは、この値はFalseになっています。 SimpleRNNの後は、Denceを追加します。 Denceは通常のニューラルネットワークにおける、全結合層になります。 Denceには、出力層のニューロン数を設定し、活性化関数を、linearに設定します。linearは、恒等関数です。 SimpleRNNでは、活性化関数を設定していませんが、SimpleRNNの標準としてtanh(ハイパボリックタンジェント)が設定されます。 最後に、compileを行います。 損失関数は、回帰の場合は二乗誤差を適用し、分類の場合はクロスエントロピーを適用するのが一般的です。今回は、回帰になるので二乗誤差を設定します。 最適化アルゴリズムには、SDGを使用します。 こちらのコードを実行すると、model.summary()によって、以下のような出力を得ることが来ます。 1234567891011121314Model: \"sequential_2\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================simple_rnn_2 (SimpleRNN) (None, 15, 20) 440 _________________________________________________________________dense_2 (Dense) (None, 15, 1) 21 =================================================================Total params: 461Trainable params: 461Non-trainable params: 0_________________________________________________________________None SimpleRNNのOutput Shapeは(None, 15, 20)となっています。15は時系列の数、20は中間層のニューロン数を意味しています。 パラメータの数は、合計で461であることが分かります。 SimpleRNNのパラメータ数は440であることが分かります。440の内訳は以下の通りです。 入力に対しての重み入力の次元数ｘ隠れ状態の次元数 → 1*20 隠れ状態に対しての重み隠れ状態の次元数 x 隠れ状態の次元数→ 20*20 バイアス隠れ状態の次元数→ 20 その他のパタンのパラメータ数の数え方については、こちらの記事で分かりやすくまとめられてます。 DenseのOutput Shapeは(None, 15, 1)となっています。15は時系列の数、1は出力層のニューロン数を意味しています。 参考ですが、重みやバイアスを調べる方法を以下にまとめます。 123456789print(len(model.layers[0].get_weights()))# 3i_weight, h_weight, bias = model.layers[0].get_weights() # lenが3なので、3変数に代入print(i_weight.size)# 20print(h_weight.size)# 400print(bias.size)# 20 構築したRNNのモデルを用いて学習 学習は、fitメソッドを用いて行う。 入力データ(i_data)、正解データ(c_data)のほかにエポック数を指定する。 またバッチサイズとバリデーションスプリットも指定を行う。 1history = model.fit(i_data, c_data, epochs=100, batch_size=batch_size, validation_split=0.1) すると以下のように学習が走ります。 12345678910111213141516Train on 31 samples, validate on 4 samplesEpoch 1/10031/31 [==============================] - 0s 5ms/step - loss: 0.3232 - val_loss: 0.2373Epoch 2/10031/31 [==============================] - 0s 631us/step - loss: 0.2265 - val_loss: 0.2034Epoch 3/10031/31 [==============================] - 0s 551us/step - loss: 0.2003 - val_loss: 0.1930(略)Epoch 98/10031/31 [==============================] - 0s 500us/step - loss: 0.1233 - val_loss: 0.1471Epoch 99/10031/31 [==============================] - 0s 505us/step - loss: 0.1233 - val_loss: 0.1467Epoch 100/10031/31 [==============================] - 0s 490us/step - loss: 0.1230 - val_loss: 0.1468 学習の推移を確認する。 lossとval_lossを確認していきましょう。 123456loss = history.history['loss']vloss = history.history['val_loss']plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 訓練用のデータ、検証用のデータ、共に収束していることが分かります。 学習済モデルを使ってサイン関数を予測 入力データを用います。 入力データ(i_data)とは何なのかをおさらいすると、、x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、このブロックが合計で35個あるデータでした。 i_data.shapeを実行すると(35, 15, 1)と出力されることからも理解ができると思います。 入力データから最初の行列取り出し、reshape(-1)で1次元のベクトルにし、predictedという変数に格納します。 12predicted = i_data[0].reshape(-1) # 入力データの最初の行列データを取り出し、reshape(-1)で一次元のベクトルにする。predicted これを実行すると、以下のように出力されます。 123array([-0.29245656, 0.33761251, 0.73473534, 0.88417973, 0.8520399 , 0.91658402, 1.33572366, 0.84339794, 1.00440569, 0.45843943, 0.56022552, 0.23427566, 0.10704196, -0.65186734, -0.73755624]) 次に、この入力データ(predicted)を学習済みのモデルに入力し、値の予測をさせてみたいと思います。 以下のfor文になります。 123for i in range(0, n_sample): y = model.predict(predicted[-n_rnn:].reshape(1, n_rnn, 1)) # 直近のデータを使って予測を行う predicted = np.append(predicted, y[0][n_rnn-1][0]) # 出力の最後の結果をpredictedに追加する 最初のforループでは、predicted[0:]となるので、predictedに代入されているすべての15データを使って予測をしています。 その後、予測値yの末尾をpredictedに追加しています。 2回目以降のループでは、前回の予測値yの末尾を含んだ直近のデータ15個で予測をしています。 そのため、2回目のループでは、「predictの先頭のデータを除いた14個のデータ」 ＋ 「末尾に加えられた予測値yのデータ」の合計、15個のデータで予測を行っています。 そのため、ループの16回目からは、もともとのpredictのデータは全く使われず、すべて予測値yのデータで、追加予測をしていることになります。 予測結果を確認してみます。比較のために、sin_dataも同時にプロットします。 1234plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")plt.plot(np.arange(len(predicted)), predicted, label=\"Predicted\")plt.legend()plt.show() 青いラインが訓練用のデータで、オレンジのラインが学習済みのRNNのモデルで予測した結果です。 このように、直近の時系列データを使って、次の値を予測できるようになりました。 直近のデータを加えながら予測を行っているため、グラフが右に進めば進むほど、誤差の影響が積み重なるように受けてしまうため、訓練用データとのずれが大きくなっていることが確認できます。 まとめ 今回は、sin関数の予測を行いました。 cos関数の予測に挑戦してみたり、各設定値を変えたり、実際の時系列データ（株価等）に適用してみたりすれば、より理解を深められると思います。 本記事が役立ったらTwitterのフォローもよろしくおねがいします！ RNNについてさらなる応用を学びたい方は、以下のUdemyを参照してください。 &gt;&gt; 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - &gt;&gt; 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 参考記事 https://note.nkmk.me/python-tensorflow-keras-count-params/ https://note.nkmk.me/python-tensorflow-keras-get-weights-kernel-bias/ https://qiita.com/Phoeboooo/items/6c3ea770047c820046f4","link":"/rnn-basic/"},{"title":"【ふるさと納税でGET】東プレのREALFORCEがオススメ！良い点|悪い点も紹介！","text":"本記事では、【ふるさと納税でGET】東プレのREALFORCEがオススメ！良い点|悪い点も紹介！というテーマでまとめていきます。 目次 本記事の対象者 REALFORCEは「ふるさと納税」で手に入れろ！ REALFORCEの良い点 REALFORCEの良い点：①打鍵感が最高 REALFORCEの良い点：②手が疲れにくい REALFORCEの悪い点 REALFORCEの悪い点：①デザインがダサい REALFORCEの悪い点：②サイズが大きくデスクスペースを圧迫する まとめ 本記事の対象者 東プレのREALFORCEが気になっている人 他のキーボードと比べてREALFORCEの良い点/悪い点を知りたい人 税金を払っているサラリーマンエンジニア など REALFORCEは「ふるさと納税」で手に入れろ！ なんと、最高級キーボードのREALFORCEは、ふるさと納税で手に入れることができます。 「ふるさと納税はやりません。」という方は、以下にコスパの良いキーボードを紹介しているので、こちらも参照ください。 ふるさと納税って何？という方は以下のとおりです。 ふるさと納税とは、あなたが応援したい自治体に寄付ができる仕組みのことです。ふるさと納税の寄付金は税金の還付・控除が受けられます。手続きをすると、最終的な実質自己負担額は2,000円（※）のみ！さらにお礼品として、自治体から特産品や宿泊券などをもらえる、とてもうれしい制度です。※控除上限額の範囲内で寄付すると、2,000円を超える部分について税金が控除されます。※確定申告に関しては、所得税からの還付と住民税からの控除が受けられます。引用サイト：https://www.satofull.jp/static/instruction01.php ポイントは、最終的な実質自己負担額は2,000円（※）のみ！です。 例えば、控除を受けられる上限額が10万円だったとして、10万円ぴったりふるさと納税をすると、98,000円は所得税、住民税として収めなくても良いですよ、ということです。 REALFORCEは、楽天アフィリエイトから納税できるので、ご確認ください。 &gt;&gt; ふるさと納税でGetできるRealfoceキーボードを確認する。 【ふるさと納税】東プレ コンピューターキーボードC Realforce RGB (型式：R2A-JP4G-BK AEAZ05）価格：71000円（税込、送料無料) (2021/5/12時点)楽天で購入 【ふるさと納税】東プレ コンピューターキーボード J(型式：R2-USV-BK AGBZ01)※着日指定送不可価格：62000円（税込、送料無料) (2021/5/12時点)楽天で購入 実質2,000円の自己負担にするために、控除手続きは忘れずに実施してください。 控除手続きは、「ワンストップ特例制度」か「確定申告」の2パタンがあります。 申請する自治体が5つ以下であれば、「ワンストップ特例制度」を利用するのがお手軽かなと思います。マイナンバーカードのコピーと自治体指定の書類1枚を、納付先の指定の住所に送るだけで完了です。 REALFORCEの良い点 筆者の主観ですが、Realforceの良い点をまとめていきます。 REALFORCEの良い点：①打鍵感が最高皆さんは、コンビニのATMに備わっているキーボードを触ったことあるでしょうか？ コンビニのATMの物理キーボードは、Realforceと同じ構造のキーボードと言われています。 「どんな打鍵感なんだろう？」という方は、コンビニに行ってATMのキーボードを打ってみてください。 コンビニATMは、多くの人が利用します。 そのため、コンビニATMのキーボードの要件として「壊れにくく、打ちやすく、タイプミスが防げるようなキーボード」が求められる、ということは想像つきますよね。 これらの要件を満たしたキーボードが、Realforceと同じ構造のキーボード、ということかと思います。 打鍵感を文字で表すと、難しいですが「スコスコスコ」「サクサクサク」「タタタン」という感じ。 長く使うという意味では、購入して損することはまず無いかなと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"東プレ REALFORCE SA R2 日本語112キー 静電容量無接点方式 USBキーボード 静音\\/APC機能付き 荷重30g 昇華印刷(墨) かな表記なし ブラック R2SA-JP3-BK\",\"b\":\"東プレ(Topre Corporation)\",\"t\":\"R2SA-JP3-BK\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/315cUvExVlL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B077QH54KX\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B077QH54KX\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%9D%B1%E3%83%97%E3%83%AC%20REALFORCE%20SA%20R2%20%E6%97%A5%E6%9C%AC%E8%AA%9E112%E3%82%AD%E3%83%BC%20%E9%9D%99%E9%9B%BB%E5%AE%B9%E9%87%8F%E7%84%A1%E6%8E%A5%E7%82%B9%E6%96%B9%E5%BC%8F%20USB%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E9%9D%99%E9%9F%B3%2FAPC%E6%A9%9F%E8%83%BD%E4%BB%98%E3%81%8D%20%E8%8D%B7%E9%87%8D30g%20%E6%98%87%E8%8F%AF%E5%8D%B0%E5%88%B7(%E5%A2%A8)%20%E3%81%8B%E3%81%AA%E8%A1%A8%E8%A8%98%E3%81%AA%E3%81%97%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%20R2SA-JP3-BK\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"QfWLW\",\"s\":\"s\"}); リンク REALFORCEの良い点：②手が疲れにくい Realforceのキーボードは、不思議と手が疲れません。 その秘密は、「静電容量無接点方式」という構造にあるようです。 静電容量無接点方式というのは、平たく言えば、キーボードを完全に下まで押さなくても文字入力可能な構造のことをいいます。 私は完全フルリモートのIT系エンジニアであり、メンバーとSlack(ビジネスチャットアプリ)でのやり取り、プログラミング、ドキュメントづくりなど、１日中タイピングをしています。 ですがRealforceは、他のキーボードに比べて、不思議と手が疲れません。 むしろ、コピペで済むような文字入力を、わざわざタイピングで打ち込みたくなるくらい、タイピング楽であり楽しいものになります。 「プログラマー」、「ライター」、「ブロガー」といった、タイピング量がどうしても多くなりがちな方々にとっては、必須アイテムになると思います。 REALFORCEの悪い点最高級キーボードでも欠点はあります。 実際に使ってみた観点でデメリットをまとめていきます。 REALFORCEの悪い点：①デザインがダサい 完全に主観ですが、デザインが少しイマイチです。 私は、「REALFORCE RGB / R2A-JP4G-BK」というゲーミングキーボードを使っているのですが、右上の「REALFORCE」というロゴが余計だとおもいました。 理想のデザインは、Keychronのように、無駄のないシンプルでテンキーレスなデザインがオシャレでカッコいいと思います。 あくまで私の主観だと微妙なので、妻と娘にLogicool MXkeysとkeychronとRealforceの3つのキーボードの中で、どのキーボードがカッコいいかを聞いてみました。 ふたりともKeychronがカッコいい、という結果でした。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"【マラソンクーポン有り】 Keychron K1 日本語配列 テンキーレス メカニカルキーボード 有線 \\/ Bluetooth 5.1 ワイヤレス 両対応 91キー RGBライト Gateron 赤軸 # K1-91-RGB-Red-JP キークロン (キーボード)\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/thumbnail.image.rakuten.co.jp\",\"c_p\":\"\\/@0_mall\\/kitcut\\/cabinet\\/item\\/136\",\"p\":[\"\\/p-373180.jpg\",\"\\/r-373199.jpg\",\"\\/r-373192.jpg\"],\"u\":{\"u\":\"https:\\/\\/item.rakuten.co.jp\\/kitcut\\/493042\\/\",\"t\":\"rakuten\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/s\\/ref=nb_sb_noss_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A\\u0026url=search-alias%3Daps\\u0026field-keywords=%E3%80%90%E3%83%9E%E3%83%A9%E3%82%BD%E3%83%B3%E3%82%AF%E3%83%BC%E3%83%9D%E3%83%B3%E6%9C%89%E3%82%8A%E3%80%91%20Keychron%20K1%20%E6%97%A5%E6%9C%AC%E8%AA%9E%E9%85%8D%E5%88%97%20%E3%83%86%E3%83%B3%E3%82%AD%E3%83%BC%E3%83%AC%E3%82%B9%20%E3%83%A1%E3%82%AB%E3%83%8B%E3%82%AB%E3%83%AB%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%20%E6%9C%89%E7%B7%9A%20%2F%20Bluetooth%205.1%20%E3%83%AF%E3%82%A4%E3%83%A4%E3%83%AC%E3%82%B9%20%E4%B8%A1%E5%AF%BE%E5%BF%9C%2091%E3%82%AD%E3%83%BC%20RGB%E3%83%A9%E3%82%A4%E3%83%88%20Gateron%20%E8%B5%A4%E8%BB%B8%20%23%20K1-91-RGB-Red-JP%20%E3%82%AD%E3%83%BC%E3%82%AF%E3%83%AD%E3%83%B3%20(%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89)\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/item.rakuten.co.jp\\/kitcut\\/493042\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"pafla\",\"s\":\"s\"}); リンク 「見た目がカッコいいほうがテンションが上がる」という方は、Keychronが良いかな、と思います。 REALFORCEの悪い点：②サイズが大きくデスクスペースを圧迫するふるさと納税で購入したRealforceはテンキーレスではありません。 また、先述したロゴが存在することもあるためか、サイズが大きく、かなり机のスペースを圧迫します。 キーボードが大きいと、タイピングした後にマウスを操作する際、マウスがキーボードに当たったりします。 手書きのノートを開くスペースも、机の大きさによっては取れないかもしれません。 また重量感もあるため、持ち運びも難しいかなと思います。 まとめ 本記事は、【コスパ最強】東プレのREALFORCE | 実質2,000円で購入する方法も紹介！」というテーマでまとめました。 REALFORCEは、ふるさと納税で手に入れるのがおすすめです。 デメリットもまとめましたが、総論としてはそれを上回るメリットのほうが大きいと思います。 ちなみに私は以下のように使い分けています。 本業（自宅）：REALFORCE 本業（コワーキングスペース）：Logicool MXkeys ブログ：Keychron K2 3台を使い分ける必要性は無いと思いますが、参考になればと思います。 【ふるさと納税】東プレ コンピューターキーボードC Realforce RGB (型式：R2A-JP4G-BK AEAZ05）価格：71000円（税込、送料無料) (2021/5/12時点)楽天で購入 【ふるさと納税】東プレ コンピューターキーボード J(型式：R2-USV-BK AGBZ01)※着日指定送不可価格：62000円（税込、送料無料) (2021/5/12時点)楽天で購入 [合わせて読みたい記事]4Kモニターも導入しよう！","link":"/realforce-keyboard/"},{"title":"【翻訳技術】seq2seqを実装しながら理解してみた","text":"✓目次 本記事の対象者 seq2seqとはなにか 訓練用のデータを作成する。 seq2seqの構築 1. 学習用モデル構築（ライブラリのインポートとモデルの設定） 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 コサイン関数をサイン関数に翻訳 本記事の対象者 ・ RNNとLSTMを理解している人 ・ pythonの基本を理解している人。 ・ Kerasでニューラルネットワークを作ったことがある人 RNNの基礎については以下の記事でまとめているので参照してください。 RNNの基礎を学びたい方はこちら↓ また、実行環境としてはJupyter Notebookになります。以下の記事に従って環境構築していただければと思います。 環境構築はこちら↓ 今回は、Kerasを使ってseq2seqを構築し、コサイン関数をサイン関数に変換（翻訳）してみたいと思います。 seq2seqとはなにかseq2seqは、シーケンスを受け取り別のシーケンスに変換するモデルのことで、文章などの入力を圧縮するencoderと、出力を展開するdecoderからなります。 「私はペンを持っている」という文章を、「I have a pen」という英文に翻訳することが可能となります。 encoderとdecoderに、それぞれRNNの層が構築され、encoderとdecoderが接続させることによってseq2seqが作られます。 seq2seqの仕組みについては以下の記事が大変分かりやすいので、参考にしてください。こちらでまとめられている絵を見ながら、以降の記事を読んでいただくと、それぞれのコードがどの領域の実装なのかがイメージしやすくなると思います。https://sinyblog.com/deaplearning/seq2seq-001/#i 少々複雑に聞こえるかもしれませんが、今回は簡単な例としてcos関数をsin関数に翻訳する形で、その構造を理解したいと思います。 訓練用のデータを作成する。cos関数の値をencoderへの入力、sin関数の値をdecoderへの入力とします。 なお、正解は、sin関数になります。 decoderへの入力というのは正解から1つ後の時刻にずらした値になります。これは、ある時刻におけるdecoderの出力が、次の時刻における入力に近づくように学習をさせるためです。 このように、ある時刻における正解が次の時刻の入力となる手法を教師強制と言います。 まずは、cos関数とsin関数を作成してプロットしてみます。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_ax = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまでの50つの値cos_data = np.cos(x_ax)sin_data = np.sin(x_ax)plt.plot(x_ax, cos_data)plt.plot(x_ax, sin_data)plt.show() 次に、encoderへの入力、decoderへの入力、decoderの正解を作成します。 今回、時系列の数は10に設定しておきます。 zerosメソッドでエンコーダー、デコーダー、正解の形状を作成します。 今回はすべて同じ形状にする。 1234567891011n_rnn = 10 # 時系列の数n_sample = len(x_ax) - n_rnn # サンプル数x_encoder = np.zeros((n_sample, n_rnn)) # encoderの入力x_decoder = np.zeros((n_sample, n_rnn)) # decoderの入力t_decoder = np.zeros((n_sample, n_rnn)) # decoderの正解print(x_encoder.shape)print(x_decoder.shape)print(t_decoder.shape)# 全部(40, 10) x_encoderには、コサイン関数の値を入れていき、x_decoderにはサイン関数の値を入れていきます。 この時、x_decoderに入れるサイン関数は、1つ後の時刻にずらす必要があります。時系列で1以降の値に代入するので最初の値は0のままということになります。 123456789101112131415161718for i in range(0, n_sample): x_encoder[i] = cos_data[i:i+n_rnn] x_decoder[i, 1:] = sin_data[i:i+n_rnn-1]x_decoder# array([[ 0.00000000e+00, 2.44929360e-16, 2.53654584e-01,# 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01],# [ 0.00000000e+00, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 0.00000000e+00, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01], 続いて正解データであるt_decoderを作成します。 t_decoderには、サイン関数の値をそのまま入れます。 1234567891011121314151617for j in range(0, n_sample): t_decoder[j] = sin_data[j:j+n_rnn]t_decoder# array([[ 2.44929360e-16, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 2.53654584e-01, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01],# [ 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01, 7.40277997e-01, 5.45534901e-01,# 3.15108218e-01], KerasにおけるRNNの入力の形状にするために、x_encoder, x_decoder, t_decoderの形状を、サンプル数、時系列の数、入力層のニューロン数という形状に変更しておきます。 123x_encoder = x_encoder.reshape(n_sample, n_rnn, 1) # （サンプル数、時系列の数、入力層のニューロン数）x_decoder = x_decoder.reshape(n_sample, n_rnn, 1)t_decoder = t_decoder.reshape(n_sample, n_rnn, 1) これで、データの準備はOKです。 seq2seqの構築Kerasを使ってseq2seqを構築していきます。 seq2seqの特徴は、学習用のモデル構築と予測用のモデル構築の2つのモデル構築を別々で行う点にあります。 学習用のモデルと予測用のモデルの中に、それぞれencoderとdecoderが存在します。 この特徴を踏まえ、以下のような流れで作成を進めていきます。 1. 学習用モデル構築(ライブラリのインポートとモデルの設定) 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 それでは一つ一つ順を追ってseq2seqを構築していきたいと思います。 1. 学習用モデル構築（ライブラリのインポートとモデルの設定）これまで、RNNやLSTMを構築した際は、Sequentialクラスを使用してましたが、今回は、Modelクラスを使います。 Modelクラスを用いることで、複数の経路の入力を持つニューラルネットワークを構築することが可能だからです。 また状態を渡すことでRNN同士を接続することもできます。 今回のseq2seqのRNN部分にはLSTMを使おうと思います。 各種ライブラリをインポートしていますが、今回はInputというのも導入します。 Inputは、入力層を表すライブラリです。 モデルの設定をしていきます。入力層のニューロン数は1、中間層のニューロン数は20、出力層のニューロン数は入力層のニューロン数と同じにします。 123456from keras.models import Modelfrom keras.layers import Dense, LSTM, Inputn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = n_in # 出力層のニューロン数 こちらのコードで各種ライブラリのインポートと、モデルの設定は完了です。 2. 学習用モデル構築(encoderの構築)最初にInputを使ってencoderの入力層を設定します。 Inputを使用する際は、入力の形状を設定する必要があります。時系列数, 入力層のニューロン数を指定しますので、n_rnn, n_inとします。 1encoder_input = Input(shape=(n_rnn, n_in)) 続いてencoderにLSTMを設定します。中間層のニューロン数を設定し、return_stateをTrueに設定します。 return_stateをTrueに設定すると、その時刻における出力と共に状態を得ることができます。 LSTMにおける出力\\(h_{t}\\)と状態であるメモリセルを得ることができるということです。 1encoder_lstm = LSTM(n_mid, return_state=True) そして、このencoderのLSTMに、先ほどのencorderの入力を渡します。その結果得られるのは、encoderの出力とencoderの状態\\(h\\)とencoderの状態\\(c\\)になります。 LSTMの内部に\\(h\\)と\\(c\\)という2つの状態を持っている点については、以下の記事で詳しくまとめらていますので、詳細が知りたい方は参考にしてください。https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca 1encoder_output, encoder_state_h, encoder_state_c = encoder_lstm(encoder_input) この2つの状態\\(t\\)と\\(c\\)は、リストでまとめておき、encoder_stateとしておきます。 1encoder_state = [encoder_state_h, encoder_state_c] これでencoderは完成です。 3. 学習用モデル構築(decoderの構築)まずInputを用いて、decoderの入力層を作ります。 1decoder_input = Input(shape=(n_rnn, n_in)) encoderの時と同様、LSTMの層を作ります。こちらも先ほど同様に、return_stateをTrueにしておきますが、return_sequencesもTrueにしておきます。 このようにすることで、すべての時系列の出力を出力として得ることができます。 1decoder_lstm = LSTM(n_mid, return_sequences=True, return_state=True) decoderのLSTMには、先ほど作成したdecoder_inputを入れます。その際に初期状態であるinitial_stateに先ほどのencoder_stateに設定します。 その結果返ってくるのが、decoderの出力と2つの状態です。 この段階で、decoderから出力された状態は使わないので、とりあえず_をいれておきます。 1decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_state ) LSTM層の次に、全結合層であるDenseを入れます。 Denseには出力層のニューロン数を設定します。活性化関数は、ひとまずlinearとしておきます。linearは恒等関数を意味します。 1decoder_dense = Dense(n_out, activation='linear') そして、このdecoder_denseにdecoder_outputを入れることでdecoderの出力を得ることができます。 1decoder_output = decoder_dense(decoder_output) decoderの構築はこれで完了です。 4. 学習用モデル構築(モデルのコンパイル)まずはseq2seqにおける学習用のモデルを構築していきます。 Modelクラスを用いてモデル構築を行います。 Modelクラスは、全体の入力と出力のみ設定すればOK、という優れものです。 入力が複数存在する場合は、リストを使って設定すればOKです。 入力は、encoder_inputとdecoder_inputの2つになります。 そして全体の出力は、decoder_outputになるので、コードとしては以下となります。 1model = Model([encoder_input, decoder_input], decoder_output) 次にモデルのコンパイルを実施します。 コンパイルの際は、損失関数とと最適化アルゴリズムを指定する必要があります。 損失関数は回帰の場合は、二乗誤差で、分類の場合はクロスエントロピーが提供されるのが一般的です。 今回は、encoderの入力から、学習した結果に基づいて翻訳結果を予測するので、二乗誤差を適用します。 最適化アルゴリズムは、収束しやすいadamでもいいですが、sgdを適用してみたいと思います これでモデル構築は完了なので、print(model.summary())で、構築したモデルの概要を確認したいと思います。 1234567891011121314151617181920212223model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")print(model.summary())# Model: \"model_11\"# __________________________________________________________________________________________________# Layer (type) Output Shape Param # Connected to # ==================================================================================================# input_18 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# input_19 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# lstm_9 (LSTM) [(None, 20), (None, 1760 input_18[0][0] # __________________________________________________________________________________________________# lstm_10 (LSTM) [(None, 10, 20), (No 1760 input_19[0][0] # lstm_9[0][1] # lstm_9[0][2] # __________________________________________________________________________________________________# dense_5 (Dense) (None, 10, 1) 21 lstm_10[0][0] # ==================================================================================================# Total params: 3,541# Trainable params: 3,541# Non-trainable params: 0# __________________________________________________________________________________________________# None encoderの入力とdecoderの入力があります。 また、encoderのLSTMとdecoderのLSTMがあります。decoderの方は、全結合層であるDenseを1つ所持していることが確認できます。 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施)RNNの時と同様にfitメソッドを使用して学習を行います。 入力は、x_encoderとx_decoderとし、正解は、t_decoderを指定します。 バッチサイズを10とし、エポック数を30に設定します。 123history = model.fit([x_encoder, x_decoder], t_decoder, batch_size=8, epochs=30) 6. 学習用モデル構築(学習の推移を確認する。)以下のコードでグラフで誤差の収束具合を確認します。 123loss = history.history['loss']plt.plot(np.arange(len(loss)), loss)plt.show() んー、収束しきってない気がします。 7. 予測用モデル構築(encoderのモデルを構築)seq2seqでは、訓練用のモデルと、予測用のモデルを別々に構築する必要があります。 予測用モデルは、学習済みのオブジェクトから、encoder, decoderのモデルを構築します。 encoderは入力を受け取り状態を返し、decoderは入力と状態を受け取って出力と状態を返すようにします。 まずはModelクラスを用いてencoderのモデルを構築します。 入力としてencoder_input、出力としてencoder_stateを設定します。 encoder_inputとencoder_stateの間には、encoder_lstmが存在する構造をとっています。このencoder_lstmは先ほどの学習済みのLSTMになります。 これだけで、予測用モデルにおけるencoderは完成します。 1encoder_model = Model(encoder_input, encoder_state) 8. 予測用モデルの構築(decoderのモデルを構築)続いて予測用モデルのdecoderを構築します。 入力層は、新規にInputを使って作成します。形状は、時系列の長さ、入力層のニューロン数を設定します。 今回は、時系列の長さは1で入力層のニューロン数はn_inで設定しているので、以下のようになります。なお、時系列の長さが可変である場合は、Noneを設定します。 1decoder_input = Input(shape=(1, n_in)) LSTMには内部に2つの状態を持つので、状態の入力を2つ作ります。 この2つの状態は、decoder_state_in_hとdecoder_state_in_cとします。 それぞれの状態の数は、中間層のニューロンの数と同じになります。 これらは、1つのリストにまとめて、decoder_state_inとしておきます。 123decoder_state_in_h = Input(shape=(n_mid,))decoder_state_in_c = Input(shape=(n_mid,))decoder_state_in = [decoder_state_in_h, decoder_state_in_c] 次に先ほどのdecoder_lstmにdecoder_inputとdecoder_state_inを設定します。decoder_state_inは、初期状態として設定するので、initial_stateとしておきます。 decoder_lstmも同様、既存の学習済みのLSTMになります。 1decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_input, initial_state=decoder_state_in) 得られたdecoder_state_hとdecoder_state_cは、以下のようにリストにし、そのうえで、decoder_denseにdecoder_outputを入れて、decoderの出力を得ることができます。こちらも、すでに学習済みのDenseになります。 12decoder_state = [decoder_state_h, decoder_state_c]decoder_output = decoder_dense(decoder_output) いよいよ、decoderのモデルを構築します。 モデル化の際に、入力として渡すのは、decoder_inputとdecoder_state_inです。 出力は、decoder_outputとdecoder_stateになります。 それぞれ、リストとして値を保持しており、入力として渡す際は、各リストを結合して渡すので、+でリストを結合しています。 1decoder_model = Model([decoder_input] + decoder_state_in, [decoder_output] + decoder_state) 9. 翻訳用の関数を定義コサイン関数を翻訳して、サイン関数に変換するための関数を定義します。 encoderへの入力値であるinput_dataを渡し、予測用モデルに適用した翻訳結果を返す処理を定義します。 12345678910111213def translate(input_data): translated = [] state_value = encoder_model.predict(input_data) # 予測モデルのencoderにinput_dataをわたし、学習済みのLSTMで予測。出力は、内部状態h, cの2つが出力される y_decoder = np.zeros((1, 1, 1)) for i in range(0, n_rnn): y, h, c = decoder_model.predict([y_decoder] + state_value) # 1つ前の時刻の出力(最初は空)と、状態（内部状態hとc）をdecoder_modelの学習済みLSTMとDenceで予測、 y = y[0][0][0] # 出力yから翻訳された結果を抽出 translated.append(y) y_decoder[0][0][0] = y # 次の時刻に渡す値 state_value = [h, c] # 次の時刻に渡す状態 return translated コサイン関数をサイン関数に翻訳123456789idices = range(0, 40)for indice in idices: x = x_encoder[indice:indice+1] # 入力を一部取り出す y = translate(x) plt.plot(x_ax[indice:indice+n_rnn], x.reshape(-1), color=\"b\") # 翻訳前を青い線 plt.plot(x_ax[indice:indice+n_rnn], y, color=\"r\") # 翻訳後は赤い線 plt.show() 翻訳の結果としては少々いまいちでした。 epoc数を30ではなく50に増やして再度翻訳してみます。 まだ微妙ですね。思い切ってepoc数を100に増やして再度実施してみます。 収束しきっているようなしていないような微妙な感じです。翻訳までさせてみると以下のような感じです。 どうやらこの三次元的なコサインカーブはどうにもならないみたいですね。 こんな時は、最適化アルゴリズムをsgdではなく別のものを適用すると改善される可能性が高いです。もしくは、通常のニューラルネットワークとかですと、中間層のニューロン数を増やしたり、層を増やしたりするのもある程度完全が見込めるかもしれません。最終手段としてはデータの中心化（バッチノーマリゼーション）と言われる処理をするとよくなるパタンが多いそうです。 今回は、KerasのDocumentationにて記載のある最適化アルゴリズムの中で、Adagradという最適化アルゴリズムを適用してみたいと思います。 以下のように、Adagradという風にするだけです。エポック数は100のままにしています。 1model.compile(loss=\"mean_squared_error\", optimizer=\"Adagrad\") 誤差の収束具合は以下の通りです。（さっきと全然違う） 肝心の翻訳結果は以下の通りです。すごい、ちゃんとコサインカーブになりました。 ここまでの知識を活用して、実際に日本語や英語を活用した翻訳にもチャレンジしたい方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。視聴期限無しで一流講師への質問も可能です。また講座料金については、30日以内では返金可能ですのでお気軽に試していただければと思います。 &gt;&gt; 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"PyTorch自然言語処理プログラミング word2vec\\/LSTM\\/seq2seq\\/BERTで日本語テキスト解析! (impress top gearシリーズ)\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51lOfrXdjxL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4295011134\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4295011134\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/PyTorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%20word2vec%2FLSTM%2Fseq2seq%2FBERT%E3%81%A7%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A7%A3%E6%9E%90!%20(impress%20top%20gear%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=PyTorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%20word2vec%2FLSTM%2Fseq2seq%2FBERT%E3%81%A7%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A7%A3%E6%9E%90!%20(impress%20top%20gear%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"XPofi\",\"s\":\"s\"}); リンク","link":"/seq2seq-study/"},{"title":"【厳選】風邪を予防する最強サプリメントはビタミンCとグルタミンだった","text":"こんにちは、omathinと申します。 風邪予防に効果的なサプリメントは、ビタミンCとグルタミンが最強っていう話ご存知ですか？ 私はビタミンCとグルタミンのおかげで、約５年間ほど風邪になっておりません。 以下のような悩みがある方は、もしかしたら「ビタミンC」「グルタミン」で解決するかもしれませんので、ぜひ一読ください。 こんな悩みが解決する！ ・子供から良く風邪をうつされる ・疲れが取れにくくなった ・肌荒れが気になる 目次 ダルビッシュ有投手も認める「ビタミンC」と「グルタミン」の効果 風邪予防だけでなく体の土台を作るなら「マルチビタミン＆ミネラル」がオススメ 免疫細胞のエネルギー源：「グルタミン」 まとめ: 「ビタミン」と「グルタミン」で毎日を健康に！ 参考 ダルビッシュ有投手も認める「ビタミンC」と「グルタミン」の効果 「ビタミンC」と「グルタミン」を摂取する効果については、プロ野球選手のダルビッシュ有投手も認めています！ 体が資本の超一流プロ野球選手も実践しているんだね！2つだけでいいなら続けられそう！ 5年前から私もこれらのサプリメントを取っているのですが、1度も風邪で寝込んでいません。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ディアナチュラ ビタミンC・亜鉛・乳酸菌・ビタミンB2・ビタミンB6 120粒 (60日分)\",\"b\":\"ディアナチュラ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/41oGNtIYkxL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07GSD97L2\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07GSD97L2\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%87%E3%82%A3%E3%82%A2%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3C%E3%83%BB%E4%BA%9C%E9%89%9B%E3%83%BB%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B2%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B6%20120%E7%B2%92%20(60%E6%97%A5%E5%88%86)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%87%E3%82%A3%E3%82%A2%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3C%E3%83%BB%E4%BA%9C%E9%89%9B%E3%83%BB%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B2%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B6%20120%E7%B2%92%20(60%E6%97%A5%E5%88%86)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"A6vBy\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"マイプロテイン L‐ グルタミン パウダー500g (ノンフレーバー)\",\"b\":\"マイプロテイン\",\"t\":\"MyProtein L-Glutamine 500g\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31rXJNWOn8L._SL500_.jpg\",\"\\/41+rG3afJIL._SL500_.jpg\",\"\\/31C4U0-JLEL._SL500_.jpg\",\"\\/31qXsyI2EzL._SL500_.jpg\",\"\\/51l+2oF2qwL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"TbCZz\",\"s\":\"s\"}); リンク 風邪予防だけでなく体の土台を作るなら「マルチビタミン＆ミネラル」がオススメ 普段の健康維持や体の土台を作るという意味では、ビタミンCではなく「マルチビタミン＆ミネラル」を朝と夜に1粒飲むのがオススメです。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"大塚製薬 ネイチャーメイド スーパーマルチビタミン\\u0026ミネラル 120粒 120日分\",\"b\":\"NATUREMADE(ネイチャーメイド)\",\"t\":\"513711\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51oMrAx9t8L._SL500_.jpg\",\"\\/51kcfRLihQL._SL500_.jpg\",\"\\/51O-ZMoYaZL._SL500_.jpg\",\"\\/51ZIVhqYnRL._SL500_.jpg\",\"\\/51HVx9rF-6L._SL500_.jpg\",\"\\/51ywC+XgrhL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00516RULK\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00516RULK\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9E%E3%83%AB%E3%83%81%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%26%E3%83%9F%E3%83%8D%E3%83%A9%E3%83%AB%20120%E7%B2%92%20120%E6%97%A5%E5%88%86\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9E%E3%83%AB%E3%83%81%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%26%E3%83%9F%E3%83%8D%E3%83%A9%E3%83%AB%20120%E7%B2%92%20120%E6%97%A5%E5%88%86\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"CrQNW\",\"s\":\"s\"}); リンク 「ミネラル」も必要なの？ 例えば、ミネラルの代表であるカルシウムやリン、マグネシウムなどは骨や歯をつくります。 また、鉄やリン、硫黄はたんぱく質や脂質などと結びついて体やエネルギーの成分になると言われています。 加えて、筋肉や骨、髪の毛、肌、内臓など、体を作り上げる成分の元となるたんぱく質等は、いったん代謝性物質に変換される必要があるのですが、この代謝性物質に変えるためにビタミンB群が必要になるようです。 つまり、 体を作るためにはビタミンC以外のビタミンB、そしてミネラルも必要 ということなので私は全部まとめて摂ってしまおうと思い、マルチビタミン＆ミネラルを摂っています。 免疫細胞のエネルギー源：「グルタミン」 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"マイプロテイン L‐ グルタミン パウダー500g (ノンフレーバー)\",\"b\":\"マイプロテイン\",\"t\":\"MyProtein L-Glutamine 500g\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31rXJNWOn8L._SL500_.jpg\",\"\\/41+rG3afJIL._SL500_.jpg\",\"\\/31C4U0-JLEL._SL500_.jpg\",\"\\/31qXsyI2EzL._SL500_.jpg\",\"\\/51l+2oF2qwL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"TbCZz\",\"s\":\"s\"}); リンク 「あの旨味成分のやつ？」と思われる人が多いですが、旨味成分と思われるものはグルタミン\"酸\"であり、グルタミンとは全く別ものだよ！ グルタミンは、非必須アミノ酸とよばれる体の中で作ることができるアミノ酸であり、簡単に言うと、体の中に入ってくる菌やウィルスと戦ってくれる免疫細胞のエネルギー源です。 菌やウィルスと戦ってくれる免疫細胞が生き生きと活動してくれれば風邪になりにくくなるというのは直感的にも理解しやすいと思います。 グルタミンの摂取方法は各々の生活スタイルに合わせて摂取すれば良いですが、基本的には朝と寝る前にグルタミンをスプーン一杯分を摂取すればOKです。 これだけで高い抵抗力を維持することができ、風邪にかかりにくくなります。 また寝る前にグルタミンを経口摂取することで成長ホルモンの分泌が高まる、という報告があります[1]。 成長ホルモンが分泌されると以下のような効果が期待できます。 グルタミンにはこんな効果も！ 1. 体脂肪の燃焼を促す。 2. コラーゲンの合成を高める。 つまり、風邪の予防だけでなく、ダイエットや美肌効果につながる、というまさに一石二鳥のサプリメントです。 そもそもグルタミンってサプリメントで取る必要はあるの？非必須アミノ酸ならわざわざ経口摂取しなくても良いのでは？ 結論としてはグルタミンはサプリメントで取るべきだとおもいます。 理由は2つあります。 グルタミンをサプリメントで取るべき理由 1. グルタミンは普段の生活のストレスや運動で消費され、慢性的に不足状態になっていることが多い。 2. グルタミンを含む食品は生の魚やアーモンドが主であり普段の食事から補うのは難しい。 皆さんの周りにこんな人、いませんか？ 普段からランニングをはじめとした運動が好きな人に限ってよく風邪を引く人って周りにいませんか？ 「運動」というのは、健康的なイメージを持たれると思います。 しかしその行為自体は、筋肉にダメージや負荷を与える行為であり、肉体的にはストレスをかけていることと同じなのです。 普段から運動をしている人がよく風邪にかかってしまうのは、このグルタミンが慢性的に不足している状態になっていることに他ならないのです。 またグルタミンは運動だけでなく普段の仕事のストレスを感じることでも消費されます。 大きいストレスがかかると体調を崩すのも、グルタミンが消費され抵抗力が下がってしまうことが一つの原因であると考えられます。 理由2.「グルタミンを含む食品は生の魚やアーモンドが主であり普段の食事から補うのは難しい。」は文字通りで、普段からお刺身などを食べる生活は現実的ではないですよね。 参考 [1] Increased plasma bicarbonate and growth hormone after an oral glutamine load.Am J Clin Nutr. 1995 May;61(5):1058-61 強力な免疫を確保せよ！～グルタミンの多彩な効果とは | サプリメント最前線 | DESIRE TO EVOLUTION | DNS ZONE まとめ: 「ビタミン」と「グルタミン」で毎日を健康に！ 風邪予防には、マルチビタミン＆ミネラルとグルタミンがおすすめ プロ野球選手（ダルビッシュ有選手）も推奨 グルタミンは体脂肪の減少や美肌効果も期待できる。 ビタミン、ミネラル、グルタミンは、普段の食事から摂ることは難しいためサプリメントを活用するのが現実的 朝と夜に、マルチビタミン＆ミネラル1粒づつとグルタミンを小さいスプーン1杯分飲めば良いんだね！こりゃ楽だ！ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ディアナチュラ ビタミンC・亜鉛・乳酸菌・ビタミンB2・ビタミンB6 120粒 (60日分)\",\"b\":\"ディアナチュラ\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/41oGNtIYkxL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07GSD97L2\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07GSD97L2\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%87%E3%82%A3%E3%82%A2%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3C%E3%83%BB%E4%BA%9C%E9%89%9B%E3%83%BB%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B2%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B6%20120%E7%B2%92%20(60%E6%97%A5%E5%88%86)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%87%E3%82%A3%E3%82%A2%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3C%E3%83%BB%E4%BA%9C%E9%89%9B%E3%83%BB%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B2%E3%83%BB%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3B6%20120%E7%B2%92%20(60%E6%97%A5%E5%88%86)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"A6vBy\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"マイプロテイン L‐ グルタミン パウダー500g (ノンフレーバー)\",\"b\":\"マイプロテイン\",\"t\":\"MyProtein L-Glutamine 500g\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31rXJNWOn8L._SL500_.jpg\",\"\\/41+rG3afJIL._SL500_.jpg\",\"\\/31C4U0-JLEL._SL500_.jpg\",\"\\/31qXsyI2EzL._SL500_.jpg\",\"\\/51l+2oF2qwL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00JAJY6IY\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20L%E2%80%90%20%E3%82%B0%E3%83%AB%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%91%E3%82%A6%E3%83%80%E3%83%BC500g%20(%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"TbCZz\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"大塚製薬 ネイチャーメイド スーパーマルチビタミン\\u0026ミネラル 120粒 120日分\",\"b\":\"NATUREMADE(ネイチャーメイド)\",\"t\":\"513711\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51oMrAx9t8L._SL500_.jpg\",\"\\/51kcfRLihQL._SL500_.jpg\",\"\\/51O-ZMoYaZL._SL500_.jpg\",\"\\/51ZIVhqYnRL._SL500_.jpg\",\"\\/51HVx9rF-6L._SL500_.jpg\",\"\\/51ywC+XgrhL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00516RULK\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00516RULK\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9E%E3%83%AB%E3%83%81%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%26%E3%83%9F%E3%83%8D%E3%83%A9%E3%83%AB%20120%E7%B2%92%20120%E6%97%A5%E5%88%86\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E5%A4%A7%E5%A1%9A%E8%A3%BD%E8%96%AC%20%E3%83%8D%E3%82%A4%E3%83%81%E3%83%A3%E3%83%BC%E3%83%A1%E3%82%A4%E3%83%89%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9E%E3%83%AB%E3%83%81%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%26%E3%83%9F%E3%83%8D%E3%83%A9%E3%83%AB%20120%E7%B2%92%20120%E6%97%A5%E5%88%86\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"CrQNW\",\"s\":\"s\"}); リンク 参考 楽痩せダイエットメソッドが知りたい方は以下の記事も参照いただければと思います。運動不要。怠け者向け よく読まれている記事 2020-01-11【未経験OK】プログラミング学習はProgate→SkillHacks→UdemyがおすすめIT","link":"/vitamins-and-glutamine/"},{"title":"【解説】外部結合の方法を学ぶ | データサイエンス100本ノック【問38〜問40 回答】","text":"目次 この記事の対象者 第38問目: 左外部結合 第39問目: 完全外部結合 第40問目: クロス結合 まとめ: 外部結合の方法を学びました。 この記事の対象者 ・ データサイエンティストを目指している人 ・ Pythonで外部結合の方法を学びたい人 以降はデータサイエンス100本ノックの問題を題材に、外部結合の方法について学んでいきます。 データサイエンス100本ノックの始め方は、以下の記事を参考にしていただければと思います。 &gt;&gt;データサイエンス100本ノックの始め方を確認する 第38問目: 左外部結合 P-038: 顧客データフレーム（df_customer）とレシート明細データフレーム（df_receipt）から、各顧客ごとの売上金額合計を求めよ。ただし、買い物の実績がない顧客については売上金額を0として表示させること。また、顧客は性別コード（gender_cd）が女性（1）であるものを対象とし、非会員（顧客IDが’Z’から始まるもの）は除外すること。なお、結果は10件だけ表示させれば良い。 「各顧客ごと」のデータだからgroupbyメソッドを使うんだね！ そのとおり！この問題ではgroupby()メソッドを使います。 groupby()の使い方を忘れてしまった方は、以下の記事を参照してください。 &gt;&gt;groupby()メソッドの使い方を復習する また2つのデータフレームを結合して各顧客ごとの売上金額合計を求めることになるので、merge()メソッドも活用することが想定されます そして最終的に出力すべきカラムは、customer_idと各customer_id毎の売上金額合計の2カラムです。 このように、最終的な出力を意識しながら問題を解いていきましょう。 df_customerについては、いくつか条件が指定されているの後回しにします。 まずはdf_receiptにおいてgroupby()メソッドを用いて、各顧客ごとの売上金額の合計を表示します。 表示の仕方は2通りあります。どちらでも構いません。 パタン112df_amount_sum1 = df_receipt.groupby('customer_id').agg({'amount':'sum'}).reset_index()df_amount_sum1 パタン1の出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 ZZ000000000000 123950038307 rows × 2 columns パタン212df_amount_sum2 = df_receipt.groupby('customer_id').amount.sum().reset_index()df_amount_sum2 パタン2の出力12345678910111213 customer_id amount0 CS001113000004 12981 CS001114000005 6262 CS001115000010 30443 CS001205000004 19884 CS001205000006 3337... ... ...8302 CS051513000004 5518303 CS051515000002 2658304 CS052212000002 1928305 CS052514000001 1788306 ZZ000000000000 123950038307 rows × 2 columns 次に、df_customerにおいて、性別コードであるgender_cdが女性(1)であるレコードだけを抽出し、非会員(顧客IDが”Z”からはじまるもの)を除外します。 条件を満たしたレコードを抽出するには、query()メソッドを使います。 &gt;&gt;queryメソッドの使い方を復習する 性別コードが1のみを抽出し非会員を除外12df_tmp = df_customer.query('gender_cd == &quot;1&quot; and not customer_id.str.startswith(&quot;Z&quot;)', engine='python')df_tmp 出力12345678910111213 customer_id customer_name gender_cd gender birth_day age postal_cd address application_store_cd application_date status_cd0 CS021313000114 大野 あや子 1 女性 1981-04-29 37 259-1113 神奈川県伊勢原市粟窪********** S14021 20150905 0-00000000-02 CS031415000172 宇多田 貴美子 1 女性 1976-10-04 42 151-0053 東京都渋谷区代々木********** S13031 20150529 D-20100325-C3 CS028811000001 堀井 かおり 1 女性 1933-03-27 86 245-0016 神奈川県横浜市泉区和泉町********** S14028 20160115 0-00000000-04 CS001215000145 田崎 美紀 1 女性 1995-03-29 24 144-0055 東京都大田区仲六郷********** S13001 20170605 6-20090929-26 CS015414000103 奥野 陽子 1 女性 1977-08-09 41 136-0073 東京都江東区北砂********** S13015 20150722 B-20100609-B... ... ... ... ... ... ... ... ... ... ... ...21965 CS042513000030 三宅 ヒカル 1 女性 1959-01-19 60 231-0865 神奈川県横浜市中区北方町********** S14042 20181114 0-00000000-021966 CS002512000474 市村 夏希 1 女性 1959-10-12 59 185-0034 東京都国分寺市光町********** S13002 20171110 0-00000000-021967 CS029414000065 上村 怜奈 1 女性 1970-10-19 48 279-0043 千葉県浦安市富士見********** S12029 20150313 F-20101028-F21969 CS033512000184 池谷 華子 1 女性 1964-06-05 54 245-0016 神奈川県横浜市泉区和泉町********** S14033 20160206 0-00000000-021970 CS009213000022 稲垣 咲 1 女性 1996-08-16 22 154-0012 東京都世田谷区駒沢********** S13009 20150424 0-00000000-017918 rows × 11 columns 最後に内部結合を行います。customer_idにdf_amount_sum1データフレームを左内部結合を行います。 &gt;&gt;内部結合と外部結合を学びたい方はこちら &gt;&gt;mergeメソッドの使い方を復習する df_tmpのcustomer_idカラムに対してdf_amount_sum1を左内部結合1pd.merge(df_tmp['customer_id'], df_amount_sum1, how='left', on='customer_id').fillna(0).head(10) 出力1234567891011 customer_id amount0 CS021313000114 0.01 CS031415000172 5088.02 CS028811000001 0.03 CS001215000145 875.04 CS015414000103 3122.05 CS033513000180 868.06 CS035614000014 0.07 CS011215000048 3444.08 CS009413000079 0.09 CS040412000191 210.0 第39問目: 完全外部結合 P-039: レシート明細データフレーム（df_receipt）から売上日数の多い顧客の上位20件と、売上金額合計の多い顧客の上位20件を抽出し、完全外部結合せよ。ただし、非会員（顧客IDが’Z’から始まるもの）は除外すること。 まずはdf_receiptがどんなデータフレームか確認してみます。 1df_receipt 出力12345678910111213 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...104676 20180221 1519171200 S13043 1132 2 ZZ000000000000 P050101001 1 40104677 20190911 1568160000 S14047 1132 2 ZZ000000000000 P071006005 1 218104678 20170311 1489190400 S14040 1122 1 CS040513000195 P050405003 1 168104679 20170331 1490918400 S13002 1142 1 CS002513000049 P060303001 1 148104680 20190423 1555977600 S13016 1102 2 ZZ000000000000 P050601001 1 138104681 rows × 9 columns どういった処理が必要なのかを明確にするために、まずは特定の顧客IDを指定して、どのようなデータフレーム構造になっているかを確認します。 1df_receipt.query('customer_id == &quot;CS001113000004&quot;') 出力1234sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount31349 20190308 1552003200 S13001 112 1 CS001113000004 P071001012 1 9835811 20190308 1552003200 S13001 112 2 CS001113000004 P071401009 1 1200 上記の出力をみてみると、20190308という日付で、1人の客CS001113000004の情報が2つ表示されていますね。 CS001113000004という顧客の売上日数は、本来は2019年3月8日の１回のみなのですが、現状のデータフレームのままだと2回とカウントされてしまいます。 CS001113000004という顧客は20190308という日時に1回の買い物をしたことにしないといけません。 そのため、上記のような情報は、2行ではなく1行にまとめなければなりません。 重複した行を抽出するにはどうすれば良いだろう？ 重複した行を抽出するにはduplicated()メソッドを使えばOKです。 duplicated()メソッドを使うと重複した行をTrueで返却します。 duplicated()引数に何も指定しない場合は、データフレームのすべての列の要素が一致しているときに重複行であるとみなされます。 duplicated()メソッドの引数としてsubsetがあります。 subsetを用いて重複を判定する列を指定することが出来ます。 subsetは、リストで複数の列を指定することが可能です。 指定した全ての列の要素が一致しているときに重複したとみなし、Trueを返却します。 ここでは、重複していないデータのみを抽出したデータフレームを作成し、完全外部結合させたいので、論理否定演算子である~を用いて、重複していない場合Trueを返すようにします。 12df_sales_ymd = df_receipt[~df_receipt.duplicated(subset=['customer_id', 'sales_ymd'])]df_sales_ymd 出力12345678910111213 sales_ymd sales_epoch store_cd receipt_no receipt_sub_no customer_id product_cd quantity amount0 20181103 1541203200 S14006 112 1 CS006214000001 P070305012 1 1581 20181118 1542499200 S13008 1132 2 CS008415000097 P070701017 1 812 20170712 1499817600 S14028 1102 1 CS028414000014 P060101005 1 1703 20190205 1549324800 S14042 1132 1 ZZ000000000000 P050301001 1 254 20180821 1534809600 S14025 1102 2 CS025415000050 P060102007 1 90... ... ... ... ... ... ... ... ... ...103599 20180701 1530403200 S14023 1102 1 CS023514000014 P060702014 1 108103694 20170714 1499990400 S14028 1152 1 CS028514000011 P090404005 1 288103699 20190109 1546992000 S13016 1182 2 CS016515000072 P070202006 1 138103818 20180521 1526860800 S12030 1182 2 CS030415000050 P090403001 1 248104294 20170809 1502236800 S14024 1142 1 CS024415000002 P060303001 1 14833445 rows × 9 columns customer_idとsales_ymd両方の要素の重複を除いたレシート明細データフレーム（df_sales_ymd）を取得することができました。 df_sales_ymdにおいて顧客ごとの売上日数の合計を求めたいので、groupby()メソッドを使います。groupby()メソッドの引数には、customer_idを指定し、売上日のカウントはsales_ymd.count()で算出します。 また、この処理をする際にindexが消滅してしまうので、reset_indexを用いてindexを付与します。 &gt;&gt;reset_indexメソッドの使い方を復習したい人はこちら 12df_sales_ymd = df_sales_ymd.groupby('customer_id').sales_ymd.count().reset_index()df_sales_ymd 出力12345678910111213 customer_id sales_ymd0 CS001113000004 11 CS001114000005 22 CS001115000010 33 CS001205000004 54 CS001205000006 6... ... ...8302 CS051513000004 18303 CS051515000002 18304 CS052212000002 18305 CS052514000001 18306 ZZ000000000000 10348307 rows × 2 columns 次に、顧客IDをが”Z”から始まるものを除外していきます。 特定の条件を満たしたレコードを抽出して処理を施すメソッドはquery()メソッドでしたね。 文字列の前方一致は、カラム名.str.startswith('文字列')とすることで、特定の文字列で始まる行のみを抽出できます。 &gt;&gt;文字列の前方一致について復習する 12df_sales_ymd = df_sales_ymd.query('not customer_id.str.startswith(&quot;Z&quot;)', engine='python')df_sales_ymd 12345678910111213 customer_id sales_ymd0 CS001113000004 11 CS001114000005 22 CS001115000010 33 CS001205000004 54 CS001205000006 6... ... ...8301 CS051212000001 18302 CS051513000004 18303 CS051515000002 18304 CS052212000002 18305 CS052514000001 18306 rows × 2 columns 上位20件を表示するために降順でソートします。 &gt;&gt;ソートの方法を復習する 12df_sales_ymd = df_sales_ymd.sort_values('sales_ymd', ascending=False).head(20)df_sales_ymd 出力123456789101112131415161718192021 customer_id sales_ymd7986 CS040214000008 233488 CS015415000185 222429 CS010214000010 222428 CS010214000002 215908 CS028415000007 213899 CS017415000097 203682 CS016415000141 206502 CS031414000051 193225 CS014214000023 194883 CS022515000226 194716 CS021515000172 197881 CS039414000052 194693 CS021514000045 194865 CS022515000028 186254 CS030214000008 184703 CS021515000056 183299 CS014415000077 184720 CS021515000211 186747 CS032415000209 186505 CS031414000073 18 最後に、作成した２つのデータフレームを完全外部結合すれば完成です。 1pd.merge(df_sum, df_sales_ymd, how='outer', on='customer_id') 出力1234567891011121314151617181920212223242526272829303132333435customer_id amount sales_ymd0 CS017415000097 23086.0 20.01 CS015415000185 20153.0 22.02 CS031414000051 19202.0 19.03 CS028415000007 19127.0 21.04 CS001605000009 18925.0 NaN5 CS010214000010 18585.0 22.06 CS016415000141 18372.0 20.07 CS006515000023 18372.0 NaN8 CS011414000106 18338.0 NaN9 CS038415000104 17847.0 NaN10 CS035414000024 17615.0 NaN11 CS021515000089 17580.0 NaN12 CS032414000072 16563.0 NaN13 CS016415000101 16348.0 NaN14 CS011415000006 16094.0 NaN15 CS034415000047 16083.0 NaN16 CS007514000094 15735.0 NaN17 CS009414000059 15492.0 NaN18 CS030415000034 15468.0 NaN19 CS015515000034 15300.0 NaN20 CS040214000008 NaN 23.021 CS010214000002 NaN 21.022 CS014214000023 NaN 19.023 CS022515000226 NaN 19.024 CS021515000172 NaN 19.025 CS039414000052 NaN 19.026 CS021514000045 NaN 19.027 CS022515000028 NaN 18.028 CS030214000008 NaN 18.029 CS021515000056 NaN 18.030 CS014415000077 NaN 18.031 CS021515000211 NaN 18.032 CS032415000209 NaN 18.033 CS031414000073 NaN 18.0 第40問目: クロス結合 P-040: 全ての店舗と全ての商品を組み合わせると何件のデータとなるか調査したい。店舗（df_store）と商品（df_product）を直積した件数を計算せよ。 まずは、df_storeとdf_productを確認しましょう。 まずはdf_storeです。 1df_store 出力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area0 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.01 S13002 国分寺店 13 東京都 東京都国分寺市本多二丁目 トウキョウトコクブンジシホンダニチョウメ 042-123-4008 139.4802 35.70566 1735.02 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.04 S14036 相模原中央店 14 神奈川県 神奈川県相模原市中央二丁目 カナガワケンサガミハラシチュウオウニチョウメ 042-123-4045 139.3716 35.57327 1679.05 S13051 板橋大原店 13 東京都 東京都板橋区大原町 トウキョウトイタバシクオオハラチョウ 03-0123-4029 139.6980 35.76788 1045.06 S13015 南砂店 13 東京都 東京都江東区南砂二丁目 トウキョウトコウトウクミナミスナニチョウメ 03-0123-4014 139.8229 35.67066 1337.07 S14040 長津田店 14 神奈川県 神奈川県横浜市緑区長津田みなみ台五丁目 カナガワケンヨコハマシミドリクナガツタミナミダイゴチョウメ 045-123-4046 139.4994 35.52398 1548.08 S13044 南六郷店 13 東京都 東京都大田区南六郷二丁目 トウキョウトオオタクミナミロクゴウニチョウメ 03-0123-4028 139.7207 35.54604 1379.09 S14050 阿久和西店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4053 139.4961 35.45918 1830.010 S13019 小茂根店 13 東京都 東京都板橋区小茂根一丁目 トウキョウトイタバシクコモネイッチョウメ 03-0123-4018 139.6795 35.74468 1004.011 S13052 森野店 13 東京都 東京都町田市森野三丁目 トウキョウトマチダシモリノサンチョウメ 042-123-4030 139.4383 35.55293 1087.012 S14028 二ツ橋店 14 神奈川県 神奈川県横浜市瀬谷区二ツ橋町 カナガワケンヨコハマシセヤクフタツバシチョウ 045-123-4042 139.4963 35.46304 1574.013 S13031 初台店 13 東京都 東京都渋谷区初台二丁目 トウキョウトシブヤクハツダイニチョウメ 03-0123-4020 139.6862 35.67616 986.014 S13038 東葛西店 13 東京都 東京都江戸川区東葛西九丁目 トウキョウトエドガワクヒガシカサイキュウチョウメ 03-0123-4024 139.8826 35.65366 1184.015 S13001 仲六郷店 13 東京都 東京都大田区仲六郷二丁目 トウキョウトオオタクナカロクゴウニチョウメ 03-1234-4007 139.7132 35.55135 1796.016 S14012 本牧和田店 14 神奈川県 神奈川県横浜市中区本牧和田 カナガワケンヨコハマシナカクホンモクワダ 045-123-4034 139.6582 35.42156 1341.017 S13004 鷺宮店 13 東京都 東京都中野区鷺宮三丁目 トウキョウトナカノクサギノミヤサンチョウメ 03-0123-4010 139.6421 35.72348 947.018 S14046 北山田店 14 神奈川県 神奈川県横浜市都筑区北山田一丁目 カナガワケンヨコハマシツヅキクキタヤマタイッチョウメ 045-123-4049 139.5916 35.56189 831.019 S14022 逗子店 14 神奈川県 神奈川県逗子市逗子一丁目 カナガワケンズシシズシイッチョウメ 046-123-4036 139.5789 35.29642 1838.020 S14011 日吉本町店 14 神奈川県 神奈川県横浜市港北区日吉本町四丁目 カナガワケンヨコハマシコウホククヒヨシホンチョウヨンチョウメ 045-123-4033 139.6316 35.54655 890.021 S13016 小金井店 13 東京都 東京都小金井市本町一丁目 トウキョウトコガネイシホンチョウイッチョウメ 042-123-4015 139.5094 35.70018 1399.022 S14034 川崎野川店 14 神奈川県 神奈川県川崎市宮前区野川 カナガワケンカワサキシミヤマエクノガワ 044-123-4044 139.5998 35.57693 1318.023 S13008 成城店 13 東京都 東京都世田谷区成城三丁目 トウキョウトセタガヤクセイジョウサンチョウメ 03-0123-4012 139.5966 35.63614 883.024 S13020 十条仲原店 13 東京都 東京都北区十条仲原三丁目 トウキョウトキタクジュウジョウナカハラサンチョウメ 03-0123-4019 139.7186 35.76686 801.025 S13043 南品川店 13 東京都 東京都品川区南品川三丁目 トウキョウトシナガワクミナミシナガワサンチョウメ 03-0123-4027 139.7436 35.60981 845.026 S14048 中川中央店 14 神奈川県 神奈川県横浜市都筑区中川中央二丁目 カナガワケンヨコハマシツヅキクナカガワチュウオウニチョウメ 045-123-4051 139.5758 35.54912 1657.027 S12007 佐倉店 12 千葉県 千葉県佐倉市上志津 チバケンサクラシカミシヅ 043-123-4001 140.1452 35.71872 1895.028 S14026 辻堂西海岸店 14 神奈川県 神奈川県藤沢市辻堂西海岸二丁目 カナガワケンフジサワシツジドウニシカイガンニチョウメ 046-123-4040 139.4466 35.32464 1732.029 S13041 八王子店 13 東京都 東京都八王子市大塚 トウキョウトハチオウジシオオツカ 042-123-4026 139.4235 35.63787 810.030 S13017 高円寺南店 13 東京都 東京都杉並区高円寺南四丁目 トウキョウトスギナミクコウエンジミナミヨンチョウメ 03-0123-4016 139.6513 35.70273 841.031 S14049 川崎大師店 14 神奈川県 神奈川県川崎市川崎区中瀬三丁目 カナガワケンカワサキシカワサキクナカゼサンチョウメ 044-123-4052 139.7327 35.53759 962.032 S14023 川崎店 14 神奈川県 神奈川県川崎市川崎区本町二丁目 カナガワケンカワサキシカワサキクホンチョウニチョウメ 044-123-4037 139.7028 35.53599 1804.033 S13018 清瀬店 13 東京都 東京都清瀬市松山一丁目 トウキョウトキヨセシマツヤマイッチョウメ 042-123-4017 139.5178 35.76885 1220.034 S13035 用賀四丁目店 13 東京都 東京都世田谷区用賀四丁目 トウキョウトセタガヤクヨウガヨンチョウメ 03-0123-4022 139.6318 35.63029 988.035 S14027 南藤沢店 14 神奈川県 神奈川県藤沢市南藤沢 カナガワケンフジサワシミナミフジサワ 046-123-4041 139.4896 35.33762 1521.036 S14021 伊勢原店 14 神奈川県 神奈川県伊勢原市伊勢原四丁目 カナガワケンイセハラシイセハラヨンチョウメ 046-123-4035 139.3129 35.40169 962.037 S14047 相模原店 14 神奈川県 神奈川県相模原市千代田六丁目 カナガワケンサガミハラシチヨダロクチョウメ 042-123-4050 139.3748 35.55959 1047.038 S12013 習志野店 12 千葉県 千葉県習志野市芝園一丁目 チバケンナラシノシシバゾノイッチョウメ 047-123-4002 140.0220 35.66122 808.039 S13032 仲六郷店 13 東京都 東京都大田区仲六郷三丁目 トウキョウトオオタクナカロクゴウサンチョウメ 03-0123-4021 139.7123 35.54682 1354.040 S14042 新山下店 14 神奈川県 神奈川県横浜市中区新山下二丁目 カナガワケンヨコハマシナカクシンヤマシタニチョウメ 045-123-4047 139.6593 35.43894 1044.041 S13039 南荻窪店 13 東京都 東京都杉並区南荻窪四丁目 トウキョウトスギナミクミナミオギクボヨンチョウメ 03-0123-4025 139.6152 35.70045 1133.042 S12030 八幡店 12 千葉県 千葉県市川市八幡三丁目 チバケンイチカワシヤワタサンチョウメ 047-123-4005 139.9240 35.72318 1162.043 S13009 用賀店 13 東京都 東京都世田谷区用賀二丁目 トウキョウトセタガヤクヨウガニチョウメ 03-0123-4013 139.6382 35.62720 1243.044 S14025 大和店 14 神奈川県 神奈川県大和市下和田 カナガワケンヤマトシシモワダ 046-123-4039 139.4680 35.43414 1011.045 S14045 厚木店 14 神奈川県 神奈川県厚木市中町二丁目 カナガワケンアツギシナカチョウニチョウメ 046-123-4048 139.3651 35.44182 980.046 S13005 白鷺店 13 東京都 東京都中野区白鷺三丁目 トウキョウトナカノクシラサギサンチョウメ 03-0123-4011 139.6307 35.72246 1259.047 S12029 東野店 12 千葉県 千葉県浦安市東野一丁目 チバケンウラヤスシヒガシノイッチョウメ 047-123-4004 139.8968 35.65086 1101.048 S13003 狛江店 13 東京都 東京都狛江市和泉本町四丁目 トウキョウトコマエシイズミホンチョウヨンチョウメ 03-0123-4009 139.5668 35.64462 1529.049 S12053 高洲店 12 千葉県 千葉県浦安市高洲五丁目 チバケンウラヤスシタカスゴチョウメ 047-123-4006 139.9176 35.63755 1555.050 S13037 南砂一丁目店 13 東京都 東京都江東区南砂一丁目 トウキョウトコウトウクミナミスナイッチョウメ 03-0123-4023 139.8215 35.67898 814.051 S14024 三田店 14 神奈川県 神奈川県川崎市多摩区三田四丁目 カナガワケンカワサキシタマクミタヨンチョウメ 044-123-4038 139.5424 35.60770 972.052 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 続いて、df_productを確認します。 1df_product 出力12345678910111213 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 P040101001 04 0401 040101 198.0 149.01 P040101002 04 0401 040101 218.0 164.02 P040101003 04 0401 040101 230.0 173.03 P040101004 04 0401 040101 248.0 186.04 P040101005 04 0401 040101 268.0 201.0... ... ... ... ... ... ...10025 P091503001 09 0915 091503 280.0 210.010026 P091503002 09 0915 091503 680.0 510.010027 P091503003 09 0915 091503 1080.0 810.010028 P091503004 09 0915 091503 1130.0 848.010029 P091503005 09 0915 091503 1280.0 960.010030 rows × 6 columns 各データフレームのデータの数（行の数）は、df_storeが52件、df_productは10030件で有ることが分かります。全ての組み合わせのパタンなので、53 ×100030 = 531590が答えになることが予想されます。 これを導いていきましょう。 方法としては、2つのデータフレームにおいて全ての組み合わせでくっつけたデータフレームを新たに作成し、そのレコード数を数えていきたいと思います。 まず2つのデータフレームを結合する上で着目する共通カラムですが、今回に関しては共通カラムがありません。 2つのデータフレームを結合する上で、共通的なカラムデータを擬似的に作成し、擬似的に作成した共通カラムデータを指定して、merge()メソッドを用いて結合していきます。 結合方式は、全ての組み合わせパタンになるので、完全外部結合を適用します。完全外部結合とは、「両方のテーブルの全データを取り出して、くっつけられる範囲でくっつける」方式です。 まずは、各データフレームのコピーを作成し、共通的なカラムデータとしてkeyカラムを作成していきます。 12df_store_tmp = df_store.copy()df_product_tmp = df_product.copy() keyカラムには、全て0を代入します。 12df_store_tmp['key'] = 0df_product_tmp['key'] = 0 作成した各データフレームを確認していきましょう。 1df_store_tmp.head(5) 出力1234567store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area key0 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 01 S13002 国分寺店 13 東京都 東京都国分寺市本多二丁目 トウキョウトコクブンジシホンダニチョウメ 042-123-4008 139.4802 35.70566 1735.0 02 S14010 菊名店 14 神奈川県 神奈川県横浜市港北区菊名一丁目 カナガワケンヨコハマシコウホククキクナイッチョウメ 045-123-4032 139.6326 35.50049 1732.0 03 S14033 阿久和店 14 神奈川県 神奈川県横浜市瀬谷区阿久和西一丁目 カナガワケンヨコハマシセヤクアクワニシイッチョウメ 045-123-4043 139.4961 35.45918 1495.0 04 S14036 相模原中央店 14 神奈川県 神奈川県相模原市中央二丁目 カナガワケンサガミハラシチュウオウニチョウメ 042-123-4045 139.3716 35.57327 1679.0 0 1df_product_tmp.head(5) 出力123456 product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost key0 P040101001 04 0401 040101 198.0 149.0 01 P040101002 04 0401 040101 218.0 164.0 02 P040101003 04 0401 040101 230.0 173.0 03 P040101004 04 0401 040101 248.0 186.0 04 P040101005 04 0401 040101 268.0 201.0 0 取得した２つのデータフレームを完全外部結合していきます。 12df_result = pd.merge(df_store_tmp, df_product_tmp, how='outer', on='key')df_result 出力12345678910111213 store_cd store_name prefecture_cd prefecture address address_kana tel_no longitude latitude floor_area key product_cd category_major_cd category_medium_cd category_small_cd unit_price unit_cost0 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 0 P040101001 04 0401 040101 198.0 149.01 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 0 P040101002 04 0401 040101 218.0 164.02 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 0 P040101003 04 0401 040101 230.0 173.03 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 0 P040101004 04 0401 040101 248.0 186.04 S12014 千草台店 12 千葉県 千葉県千葉市稲毛区千草台一丁目 チバケンチバシイナゲクチグサダイイッチョウメ 043-123-4003 140.1180 35.63559 1698.0 0 P040101005 04 0401 040101 268.0 201.0... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...531585 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 0 P091503001 09 0915 091503 280.0 210.0531586 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 0 P091503002 09 0915 091503 680.0 510.0531587 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 0 P091503003 09 0915 091503 1080.0 810.0531588 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 0 P091503004 09 0915 091503 1130.0 848.0531589 S14006 葛が谷店 14 神奈川県 神奈川県横浜市都筑区葛が谷 カナガワケンヨコハマシツヅキククズガヤ 045-123-4031 139.5633 35.53573 1886.0 0 P091503005 09 0915 091503 1280.0 960.0531590 rows × 17 columns これで完成です。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Pythonデータサイエンスハンドブック ―Jupyter、NumPy、pandas、Matplotlib、scikit-learnを使ったデータ分析、機械学習\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51bYwxwQSLL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118417\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Python%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF%20%E2%80%95Jupyter%E3%80%81NumPy%E3%80%81pandas%E3%80%81Matplotlib%E3%80%81scikit-learn%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2}],\"eid\":\"thkUY\",\"s\":\"s\"}); リンク まとめ: 外部結合の方法を学びました。本記事は、「【Python】外部結合の方法を学ぶ | データサイエンス100本ノック【問38〜問40 回答】」というテーマでまとめました。 外部結合だけでなく、ソートや前方一致などの方法の復習になったと思います。 &gt;&gt; 続きはこちら","link":"/100knock-38-40/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで②[手術後～退院まで]","text":"別の記事で、前十字靭帯再建手術後までの記事をまとめました。 本記事ではその続きとして、手術後1週間後の退院までのリハビリ等について、経験をまとめたいと思います。 以下のような悩みや疑問があれば、読んで損はないと思います。 ・そもそもリハビリに対してどのような気持ちで臨めばよいのか？ ・手術直後のリハビリって何が辛い？痛い？ ・手術直後のリハビリで気を付けることは？ 注意点ですが、以降は、あくまで私の実体験に基づいた内容です。 リハビリの進め方は、一人ひとり膝の状態や体質によって取り組み方は変わると思います。 基本的には、担当の理学療法士さんや医師とも相談しながらリハビリは進めてください。 ✓目次 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる 元プロ野球の小久保裕紀選手の例 手術後から退院までの1週間のリハビリ概要 松葉杖は思っていたよりも難しい 膝の皿動かし 足の上げ下げ 超音波当て EMS リハビリ以外で大事なこと①：アイシング リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない リハビリ以外で大事なこと③：入浴はできない リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請 まとめ: 前向きにリハビリに取り組もう！ 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる 「リハビリ」ってマイナスのイメージありませんか？ 「辛い」、「しんどい」、「地味な動きの繰り返し」、「ストレスが溜まる」等、マイナスのイメージを強く持たれると思います。 私も同じようなイメージを持ってました。 しかし、実際にリハビリを終えた私の立場から言えるのは、決してそんなことはありません。 ケガの治療以外にリハビリを行うことによって得られるメリットは、以下だと思っています。 リハビリを頑張るメリット 1. 正しい体の使い方を知ることでケガする前よりも高いパフォーマンスを発揮できる。2. 体の痛みや変化、ケガの予防に注意を払う習慣が身に付く3. 結果的に健康にスポーツができる期間を長くさせることができる。 なお、これらのメリットは私だけが感じていることではありません。 元プロ野球の小久保裕紀選手の例 元プロ野球選手の小久保裕紀選手は、2003年に「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という、私とは比べ物にならないくらいの大けがを負いました。 しかし、懸命のリハビリを乗り越え、復帰直後の2004年に、キャリアハイの打率.314, 41本塁打, OPS1.013という成績を残しました。 加えて小久保選手は、この大けがのおかげで体のことを学び、練習法から食事の面まで見直すことができ、結果的に現役選手生活を伸ばすことにつながった、と述べています。 ‘03年、地元福岡でのオープン戦でのことだ。本塁クロスプレーで相手捕手と交錯し、右膝を潰された。前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷。シーズンを完全に棒に振る、いや、選手生命を脅かすほどの大ケガ—-。 だが、小久保はこの出来事が選手寿命を伸ばしたと言い切るのだ。 「あれで体のことを学び、練習法から食事の面まで見直すことができた。当時は体を大きくすることだけを考えてトレーニングしていたが、アメリカでのリハビリを通じて、体幹部のバランスの重要性を学んだ。ただ体をデカくして、失敗した選手も野球界には多いから、俺もそうなっていたかもしれない」 自分に降りかかることに無駄なことはない。決して下を向かないと決めた。小久保裕紀(ソフトバンクホークス)「逆境を愛し、愛されたキャプテン」| 現代ビジネス | 講談社（3/5）より 私自身も別記事でまとめていますが、リハビリを通じて、食事や栄養、ケガの予防について学ぶ良いきっかけになりました。 辛かったリハビリの経験が、健康にスポーツを楽しむための健康寿命を延ばすことにつながっているのではないかと感じています。 ケガしたこと、リハビリをしていることに対して悲観的になる必要は無いのではないかと思います。 「より良い体作り、怪我する前よりも良いパフォーマンスを発揮するための特別なトレーニングに取り組んでいるんだ」という前向きな気持ちで取り組められることを願っております。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"一瞬に生きる | 小久保裕紀\",\"b\":\"小学館\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51FIuAGqgPL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4093882843\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4093882843\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E4%B8%80%E7%9E%AC%E3%81%AB%E7%94%9F%E3%81%8D%E3%82%8B\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E4%B8%80%E7%9E%AC%E3%81%AB%E7%94%9F%E3%81%8D%E3%82%8B\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"fXgmS\",\"s\":\"s\"}); リンク 手術後から退院までの1週間のリハビリ概要 以下に取り組みを退院まで毎日やりました。基本的に退院までは膝を無理に動かすようなリハビリは少なかったと思います。 手術後から退院までのリハビリメニュー 松葉づえで移動する練習 平地 階段の上り下り 膝の皿動かし 上下左右斜め8方向まんべんなく手で動かす 足の上げ下げ 仰向けで足上げ 横向きで足上げ 超音波を当てる 手術の傷跡周辺をまんべんなく EMS 手術した後の膝は炎症が強いため、いかにこの炎症を抑えるかが目的になります。 また超音波などを活用して皮膚や関節内部の回復を促進する治療が行われます。 基本的には、受診されている病院様の計画に沿って進めていく形になりますので、異なる点はあると思います。 ここからは、私が経験したことベースで、辛かったこと/驚いたこと/大事にすべきことを中心にまとめたいと思います。 松葉杖は思っていたよりも難しい トイレに自分で行けるように、まずは理学療法士の方と共に松葉づえで平地の移動と階段の上り降りの練習行います。 手術後の足は、「ニーブレース」と呼ばれる厚手のサポーターでガチガチ固められおり、重量があります。 そのため松葉づえを使った移動は、かなり大変です。 特に階段の上り降りは、最初のうちは難しいです。 特に、階段の下り移動は難しく危険なので最初のうちは一人で階段を使っての移動は控えたほうが良いと思います。 基本的にエレベーターを使うのが無難だと思いました。 もう一つ知っておいたほう良いことがあります。 手術後の右膝内部では、まだ出血が続いている状態です。 そのため、松葉づえで歩く際、血液が足先にじわじわ溜まっていく嫌な感覚があります。 この嫌な感覚は、手術してから大体2～3週間くらいはあったと思います。 松葉づえでの移動は、正直体力的にかなりしんどいです。 体重が両脇・腕に重くのしかかるので、両腕の筋肉痛もありました。 腕と脇の負担を軽減するためのクッションカバーや厚手のタオルでサポートすると良いと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"shttown 松葉杖カバー 脇 腕にかかるストレスからフリーに 快適お出掛け 松葉杖 4枚セット 黒 クッションカバー グリップカバー\",\"b\":\"shttown\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41fx6UagWOL._SL500_.jpg\",\"\\/41r36L78wrL._SL500_.jpg\",\"\\/51oaUoGbGDL._SL500_.jpg\",\"\\/51P4g5NzwvL._SL500_.jpg\",\"\\/51GsNedBojL._SL500_.jpg\",\"\\/5141mreUkTL._SL500_.jpg\",\"\\/617gz-Vq2wL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08WN7Z84Y\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08WN7Z84Y\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/shttown%20%E6%9D%BE%E8%91%89%E6%9D%96%E3%82%AB%E3%83%90%E3%83%BC%20%E8%84%87%20%E8%85%95%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%82%B9%E3%83%88%E3%83%AC%E3%82%B9%E3%81%8B%E3%82%89%E3%83%95%E3%83%AA%E3%83%BC%E3%81%AB%20%E5%BF%AB%E9%81%A9%E3%81%8A%E5%87%BA%E6%8E%9B%E3%81%91%20%E6%9D%BE%E8%91%89%E6%9D%96%204%E6%9E%9A%E3%82%BB%E3%83%83%E3%83%88%20%E9%BB%92%20%E3%82%AF%E3%83%83%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%AB%E3%83%90%E3%83%BC%20%E3%82%B0%E3%83%AA%E3%83%83%E3%83%97%E3%82%AB%E3%83%90%E3%83%BC\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=shttown%20%E6%9D%BE%E8%91%89%E6%9D%96%E3%82%AB%E3%83%90%E3%83%BC%20%E8%84%87%20%E8%85%95%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%82%B9%E3%83%88%E3%83%AC%E3%82%B9%E3%81%8B%E3%82%89%E3%83%95%E3%83%AA%E3%83%BC%E3%81%AB%20%E5%BF%AB%E9%81%A9%E3%81%8A%E5%87%BA%E6%8E%9B%E3%81%91%20%E6%9D%BE%E8%91%89%E6%9D%96%204%E6%9E%9A%E3%82%BB%E3%83%83%E3%83%88%20%E9%BB%92%20%E3%82%AF%E3%83%83%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%AB%E3%83%90%E3%83%BC%20%E3%82%B0%E3%83%AA%E3%83%83%E3%83%97%E3%82%AB%E3%83%90%E3%83%BC\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"G0cuN\",\"s\":\"s\"}); リンク 膝の皿動かし 無理のない範囲で自分の指で手術したほうの膝のお皿をまんべんなく動かします。 手術したばかりなので最初は恐る恐る膝を動かしてみる感じです。 細かいやり方は理学療法士の先生に指導いただきながら実施していただければと思います。 理学療法士の先生の指導を忠実に守りましょうね！ 足の上げ下げ 横向きで足を10回～20回。うつ伏せで足を10回～20回上げるトレーニングを行います。 ニーブレースをつけているので足全体が重く結構きついです。 私はトレーニング用のマットの上で足の上げ下げをしました。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Gruper ヨガマット 6mm エクササイズマット フィットネスマット トレーニングマットTPEリング保護素材 軽量 耐久性 肌に優しい 両面の滑り止 屋内運動 ピラティスマット持ち運び 収納簡単 商品名称\",\"b\":\"Gruper\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41TrwzngUEL._SL500_.jpg\",\"\\/51d8nDdd3oL._SL500_.jpg\",\"\\/51zPROl4ugL._SL500_.jpg\",\"\\/519OAzodtNL._SL500_.jpg\",\"\\/41SdzCWLXnL._SL500_.jpg\",\"\\/51d3ihCBvlL._SL500_.jpg\",\"\\/51GG0KzK7pL._SL500_.jpg\",\"\\/51QIQlUGP5L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07H4G664R\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07H4G664R\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Gruper%20%E3%83%A8%E3%82%AC%E3%83%9E%E3%83%83%E3%83%88%206mm%20%E3%82%A8%E3%82%AF%E3%82%B5%E3%82%B5%E3%82%A4%E3%82%BA%E3%83%9E%E3%83%83%E3%83%88%20%E3%83%95%E3%82%A3%E3%83%83%E3%83%88%E3%83%8D%E3%82%B9%E3%83%9E%E3%83%83%E3%83%88%20%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%83%9E%E3%83%83%E3%83%88TPE%E3%83%AA%E3%83%B3%E3%82%B0%E4%BF%9D%E8%AD%B7%E7%B4%A0%E6%9D%90%20%E8%BB%BD%E9%87%8F%20%E8%80%90%E4%B9%85%E6%80%A7%20%E8%82%8C%E3%81%AB%E5%84%AA%E3%81%97%E3%81%84%20%E4%B8%A1%E9%9D%A2%E3%81%AE%E6%BB%91%E3%82%8A%E6%AD%A2%20%E5%B1%8B%E5%86%85%E9%81%8B%E5%8B%95%20%E3%83%94%E3%83%A9%E3%83%86%E3%82%A3%E3%82%B9%E3%83%9E%E3%83%83%E3%83%88%E6%8C%81%E3%81%A1%E9%81%8B%E3%81%B3%20%E5%8F%8E%E7%B4%8D%E7%B0%A1%E5%8D%98%20%E5%95%86%E5%93%81%E5%90%8D%E7%A7%B0\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Gruper%20%E3%83%A8%E3%82%AC%E3%83%9E%E3%83%83%E3%83%88%206mm%20%E3%82%A8%E3%82%AF%E3%82%B5%E3%82%B5%E3%82%A4%E3%82%BA%E3%83%9E%E3%83%83%E3%83%88%20%E3%83%95%E3%82%A3%E3%83%83%E3%83%88%E3%83%8D%E3%82%B9%E3%83%9E%E3%83%83%E3%83%88%20%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%83%9E%E3%83%83%E3%83%88TPE%E3%83%AA%E3%83%B3%E3%82%B0%E4%BF%9D%E8%AD%B7%E7%B4%A0%E6%9D%90%20%E8%BB%BD%E9%87%8F%20%E8%80%90%E4%B9%85%E6%80%A7%20%E8%82%8C%E3%81%AB%E5%84%AA%E3%81%97%E3%81%84%20%E4%B8%A1%E9%9D%A2%E3%81%AE%E6%BB%91%E3%82%8A%E6%AD%A2%20%E5%B1%8B%E5%86%85%E9%81%8B%E5%8B%95%20%E3%83%94%E3%83%A9%E3%83%86%E3%82%A3%E3%82%B9%E3%83%9E%E3%83%83%E3%83%88%E6%8C%81%E3%81%A1%E9%81%8B%E3%81%B3%20%E5%8F%8E%E7%B4%8D%E7%B0%A1%E5%8D%98%20%E5%95%86%E5%93%81%E5%90%8D%E7%A7%B0\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"ifu8J\",\"s\":\"s\"}); リンク このトレーニングマットは、復帰までに自宅で行うリハビリでも重宝しました。 超音波当て スポーツ界では有名な伊藤超短波株式会社様の超音波機を手術した膝の傷口周辺に当てていきます。 これが実は周波数にもよるが結構いたかったです 膝の中からジワジワ熱を持った痛みが沸き起こってくる感じでした。 もちろん痛い場合は、周波数を下げる or 休み休み超音波を当てる感じで対応していました。もちろん痛いときは理学療法士の方に言いましょう。 超音波の専門家ではないので詳しいことはわかりませんが、膝の手術をした膝周辺は癒着が起こる場合があります。 超音波は幹部の治療を促進させるとともに、癒着を防いで関節の可動化を確保することを目的としているようです。 私はこの癒着がそれなりにあったので、この超音波治療を積極的に行いました。周りを見ると私だけでなく多くの人が各々の目的で超音波治療を受けていましたので、大半の人はこの治療を経験する可能性が高いと思います。 治療を受けた実感としては、確かに超音波を当てた後は、膝周りが軽いというか健康な膝に近づいた感覚が得られました。 しかしながら、前述した通り、なんともいえない痛みがともなうため、私はあまり好きではありませんでした。。。 EMS 通販でおなじみの電流を流して筋肉を動かすやつです。 膝のお皿の上部に張り付けて、電流で筋肉を収縮させ、筋力をつけることを目的にした治療だったと思います。 基本的に前十字靭帯再建手術を受けた後のリハビリは、太ももの筋肉をつけることが主軸になります。 筋トレは、鍛えている筋肉の箇所を意識することが大事なので、太ももの筋肉に意識を集中させるのが大事だと思います。 AmazonでもポケットサイズのEMSが購入できます。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"techno trade(テクノトレード) スーパーポケスリム EMS ブラック 4560334793109 ブラック\",\"b\":\"techno trade(テクノトレード)\",\"t\":\"4560334793109\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41EOB3K3tXL._SL500_.jpg\",\"\\/41Tga+yvvJL._SL500_.jpg\",\"\\/41h6wamzWbL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B01H3KYMO4\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B01H3KYMO4\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/techno%20trade(%E3%83%86%E3%82%AF%E3%83%8E%E3%83%88%E3%83%AC%E3%83%BC%E3%83%89)%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9D%E3%82%B1%E3%82%B9%E3%83%AA%E3%83%A0%20EMS%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%204560334793109%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=techno%20trade(%E3%83%86%E3%82%AF%E3%83%8E%E3%83%88%E3%83%AC%E3%83%BC%E3%83%89)%20%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%83%9D%E3%82%B1%E3%82%B9%E3%83%AA%E3%83%A0%20EMS%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%204560334793109%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"cer1T\",\"s\":\"s\"}); リンク リハビリ以外で大事なこと①：アイシング 手術直後は膝の炎症を抑えるためにアイシングが重要になります。 退院後も積極的なアイシングが必要になるので、氷嚢は購入しておいたほうが良いと思います。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"氷嚢 大口径 アイスバック 氷のう 2個セット スポーツ用 応急処置 氷のう アイシング 冷温両用 アイシングバッグ 水漏れ防止 家庭常備品 熱中症 発熱 生理痛 ねんざ だぼく 肩ケア 肘 膝 足首 頭 ケガ アウトドア 暑さ対策 アイシング用品 (ブルー)\",\"b\":\"Aimyui\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41e309lluFL._SL500_.jpg\",\"\\/517ehAEzhcL._SL500_.jpg\",\"\\/519V6C3S47L._SL500_.jpg\",\"\\/51MdTrjvaqL._SL500_.jpg\",\"\\/51xHNjRNkzL._SL500_.jpg\",\"\\/512dLGdWpnL._SL500_.jpg\",\"\\/51O0-3na-GL._SL500_.jpg\",\"\\/51OoSKrEefL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B091BQKD9Z\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B091BQKD9Z\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E6%B0%B7%E5%9A%A2%20%E5%A4%A7%E5%8F%A3%E5%BE%84%20%E3%82%A2%E3%82%A4%E3%82%B9%E3%83%90%E3%83%83%E3%82%AF%20%E6%B0%B7%E3%81%AE%E3%81%86%202%E5%80%8B%E3%82%BB%E3%83%83%E3%83%88%20%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84%E7%94%A8%20%E5%BF%9C%E6%80%A5%E5%87%A6%E7%BD%AE%20%E6%B0%B7%E3%81%AE%E3%81%86%C2%A0%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%C2%A0%E5%86%B7%E6%B8%A9%E4%B8%A1%E7%94%A8%C2%A0%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%90%E3%83%83%E3%82%B0%C2%A0%E6%B0%B4%E6%BC%8F%E3%82%8C%E9%98%B2%E6%AD%A2%C2%A0%E5%AE%B6%E5%BA%AD%E5%B8%B8%E5%82%99%E5%93%81%C2%A0%E7%86%B1%E4%B8%AD%E7%97%87%C2%A0%E7%99%BA%E7%86%B1%C2%A0%E7%94%9F%E7%90%86%E7%97%9B%C2%A0%E3%81%AD%E3%82%93%E3%81%96%20%E3%81%A0%E3%81%BC%E3%81%8F%20%E8%82%A9%E3%82%B1%E3%82%A2%20%E8%82%98%20%E8%86%9D%20%E8%B6%B3%E9%A6%96%20%E9%A0%AD%20%E3%82%B1%E3%82%AC%20%E3%82%A2%E3%82%A6%E3%83%88%E3%83%89%E3%82%A2%20%E6%9A%91%E3%81%95%E5%AF%BE%E7%AD%96%20%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%E7%94%A8%E5%93%81%20(%E3%83%96%E3%83%AB%E3%83%BC)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E6%B0%B7%E5%9A%A2%20%E5%A4%A7%E5%8F%A3%E5%BE%84%20%E3%82%A2%E3%82%A4%E3%82%B9%E3%83%90%E3%83%83%E3%82%AF%20%E6%B0%B7%E3%81%AE%E3%81%86%202%E5%80%8B%E3%82%BB%E3%83%83%E3%83%88%20%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84%E7%94%A8%20%E5%BF%9C%E6%80%A5%E5%87%A6%E7%BD%AE%20%E6%B0%B7%E3%81%AE%E3%81%86%C2%A0%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%C2%A0%E5%86%B7%E6%B8%A9%E4%B8%A1%E7%94%A8%C2%A0%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%90%E3%83%83%E3%82%B0%C2%A0%E6%B0%B4%E6%BC%8F%E3%82%8C%E9%98%B2%E6%AD%A2%C2%A0%E5%AE%B6%E5%BA%AD%E5%B8%B8%E5%82%99%E5%93%81%C2%A0%E7%86%B1%E4%B8%AD%E7%97%87%C2%A0%E7%99%BA%E7%86%B1%C2%A0%E7%94%9F%E7%90%86%E7%97%9B%C2%A0%E3%81%AD%E3%82%93%E3%81%96%20%E3%81%A0%E3%81%BC%E3%81%8F%20%E8%82%A9%E3%82%B1%E3%82%A2%20%E8%82%98%20%E8%86%9D%20%E8%B6%B3%E9%A6%96%20%E9%A0%AD%20%E3%82%B1%E3%82%AC%20%E3%82%A2%E3%82%A6%E3%83%88%E3%83%89%E3%82%A2%20%E6%9A%91%E3%81%95%E5%AF%BE%E7%AD%96%20%E3%82%A2%E3%82%A4%E3%82%B7%E3%83%B3%E3%82%B0%E7%94%A8%E5%93%81%20(%E3%83%96%E3%83%AB%E3%83%BC)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"FsKAw\",\"s\":\"s\"}); リンク 膝のアイシングは、2つの氷のうで膝上と膝裏の両面をまとめて冷やしたほうが良いです。 リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない 例えば足を組んだり、手術した足に負荷をかけるような姿勢や動作をしないように注意を受けます。 もちろん地面に足をつけることもNGでした。 再建手術直後の靭帯は、とても弱く繊細なんだ。。。 リハビリ以外で大事なこと③：入浴はできない 入浴は浴槽に入る際に転んだりする危険性があるので基本的にNGでした。 シャワーも不可でした。 ただし、洗面台で髪の毛を洗うのは可能です。 体は濡れたタオルで拭く形で対応します。 正直、怪我した足を引きずって洗面台まで移動し、体を折り曲げてシャンプーするのは苦痛です。 私は以下の商品を購入してシャンプーをしました。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"髪のカット、スタイリング、シャンプーのためのヘアカット理容室ケープカバー、防水プロフェッショナルサロン岬、,ブラウン\",\"b\":\"YWXKA\",\"t\":\"109-768-388\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/41m2QN07UJL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B086QZS8WZ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B086QZS8WZ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E9%AB%AA%E3%81%AE%E3%82%AB%E3%83%83%E3%83%88%E3%80%81%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%AA%E3%83%B3%E3%82%B0%E3%80%81%E3%82%B7%E3%83%A3%E3%83%B3%E3%83%97%E3%83%BC%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%83%98%E3%82%A2%E3%82%AB%E3%83%83%E3%83%88%E7%90%86%E5%AE%B9%E5%AE%A4%E3%82%B1%E3%83%BC%E3%83%97%E3%82%AB%E3%83%90%E3%83%BC%E3%80%81%E9%98%B2%E6%B0%B4%E3%83%97%E3%83%AD%E3%83%95%E3%82%A7%E3%83%83%E3%82%B7%E3%83%A7%E3%83%8A%E3%83%AB%E3%82%B5%E3%83%AD%E3%83%B3%E5%B2%AC%E3%80%81%2C%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E9%AB%AA%E3%81%AE%E3%82%AB%E3%83%83%E3%83%88%E3%80%81%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%AA%E3%83%B3%E3%82%B0%E3%80%81%E3%82%B7%E3%83%A3%E3%83%B3%E3%83%97%E3%83%BC%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%83%98%E3%82%A2%E3%82%AB%E3%83%83%E3%83%88%E7%90%86%E5%AE%B9%E5%AE%A4%E3%82%B1%E3%83%BC%E3%83%97%E3%82%AB%E3%83%90%E3%83%BC%E3%80%81%E9%98%B2%E6%B0%B4%E3%83%97%E3%83%AD%E3%83%95%E3%82%A7%E3%83%83%E3%82%B7%E3%83%A7%E3%83%8A%E3%83%AB%E3%82%B5%E3%83%AD%E3%83%B3%E5%B2%AC%E3%80%81%2C%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"fJfR0\",\"s\":\"s\"}); リンク リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請 高額医療費控除や保険関連の書類、現金の対応が必要になります。 この辺は病院のスタッフの方や勤務先の会社、保険会社に問い合わせて、書類を用意しましょう。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"令和3年3月申告用 一目でわかる医療費控除\",\"b\":\"清文社\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/51J8tEkIDTL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4433703206\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4433703206\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E4%BB%A4%E5%92%8C3%E5%B9%B43%E6%9C%88%E7%94%B3%E5%91%8A%E7%94%A8%20%E4%B8%80%E7%9B%AE%E3%81%A7%E3%82%8F%E3%81%8B%E3%82%8B%E5%8C%BB%E7%99%82%E8%B2%BB%E6%8E%A7%E9%99%A4\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E4%BB%A4%E5%92%8C3%E5%B9%B43%E6%9C%88%E7%94%B3%E5%91%8A%E7%94%A8%20%E4%B8%80%E7%9B%AE%E3%81%A7%E3%82%8F%E3%81%8B%E3%82%8B%E5%8C%BB%E7%99%82%E8%B2%BB%E6%8E%A7%E9%99%A4\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"p9zFr\",\"s\":\"s\"}); リンク まとめ: 前向きにリハビリに取り組もう！ リハビリは体の使い方や体のケアを学ぶ有益な取り組み。復帰後、ケガする前以上に高いパフォーマンスを発揮できたり、結果的に現役でいられる時間を長くさせる結果につながります。私自身がそうだったように、前向きな気持ちで取りくめば、良い結果が付いてくると思います。 手術後はしばらく安静。膝の炎症を抑えることが最優先。リハビリは基本的に膝の状態を見ながら理学療法士の指示に従い忠実に取り組みましょう。 松葉づえの移動では、階段の下り移動に気を付けよう。（階段を使うのはなるべく避けましょう） 超音波治療は地味に痛いが効果を実感できるのでちゃんとやったほうが良い。 アイシングが大事。靭帯に負荷をかけないように注意が必要。 入浴はできないが、洗面台で頭を洗うことは可能。 以上です。 次は、松葉づえを卒業し本格的なリハビリに入るところをまとめたいと思います。以下にまとめました。 この機会に体質改善をしたい方向け 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/knee-surgery-2/"},{"title":"【2021最新】リモートワークエンジニアがおすすめするローテーブル7選！","text":"本記事では、「リモートワークエンジニアがおすすめするローテーブル7選！」というテーマでまとめていきます。 目次 エンジニア向けおすすめローテーブルの仕様 エンジニア向けおすすめローテーブル | 比較一覧表 エンジニア向けおすすめローテーブル7選 1. サンワダイレクト 100-DESKH023BK 2. サンワダイレクト 100-DESKL003BR 3. Need AC14CB-P2 4. サンワダイレクト 100-DESKL009M 5. Bauhutte BHD-1200L-WD 6. SAKODA ゲーミングデスク ローデスク SGD-L1200 BK 7. ゲキカグ パソコンデスク ロータイプ(150cm幅) DKW150020 結局何を購入したのか: ゲキカグ パソコンデスク ロータイプ(150cm幅) DKW150020を購入 記事の信頼性(自己紹介) omathin ・某通信系IT企業のアーキテクト|研究者.（完全リモートワーク） ・Udemyを中心に100以上のオンライン講座を受講。※半分以上趣味です。・ハッカソン入賞 | 研究で賞等獲得 エンジニア向けおすすめローテーブルの仕様まずは購入するローテーブルの要件を整理します。 普段からプログラミングやドキュメントの読み込みをする関係上、ディアルディスプレイとモニターアームは必須！ ブログ執筆も快適に行えるような環境を目指して以下のような要件にしました。 ローデスクの要件 1. 足を伸ばしてリラックスしたいのでバックパネル無し or 奥行き70cm以上!2. デスクに31.5インチの4Kモニタを置きたいので横幅のサイズは120cm以上！3. デスク天板の耐荷重は最低20kg以上！4. 可能であれば姿勢によって高さが変えられる昇降式!5. 肩こり防止のためにモニターアームが付けられる!6. 価格はちょっと分罰して30,000円！ その他、保証が付随しているか、Amazonの口コミも見ていきます。 エンジニア向けおすすめローテーブル | 比較一覧表 サンワダイレクト 100-DESKH023BK サンワダイレクト 100-DESKL003BR Need AC14CB-P2 サンワダイレクト 100-DESKL009M Bauhutte BHD-1200L-WD SAKODA ゲーミングデスク ローデスク SGD-L1200 BK ゲキカグ パソコンデスク ロータイプ(150cm幅) DKW150020 バックパネル有無 有 有(上部に横棒あり) 無 有 無 無 有 横幅/奥行き/高さ(cm) 120/56/38シェルフが着いているため横幅は実質62.7cm 110/50/36.4L字のローデスクのため横幅は実質75cm 120/60/39 95/45/40〜55高さは40, 47.5, 55と3段階調整 120/55/39〜48.5 120/60/38〜51 150/75/40 耐荷重 50kg 30kg 100kg 30kg 40kg未満 100kg 30kg 昇降式有無 無 無 無 有（3段階） 有 有 無 モニターアームの装着可否 可(口コミより) 可? 不可?(工夫が必要) 可(口コミより) 可 可 可 価格2021年7月時点 ¥7,980 ¥8,980 ¥16,990 ¥8,980 ¥24,200 ¥29,800 ¥17,980 保証 初期不良のみ 初期不良のみ 保証なし(?) 初期不良のみ 商品到着日から1年間。初期不良対応期間は商品到着日から7日以内。 1年の品質保証 初期不良のみ 評判(主に悪い評判) 天板の角が欠けている、ネジが合わない等品質に難あり（？）重たく組み立てにくい足を伸ばせない 天板が割れている等品質に難あり(?)角が尖っていてぶつけると痛い 臭い(?)小物入れが邪魔 品質に難あり(?)足が金属で角がありぶつけると痛い 梱包があまい高さの調節が難しい(4つの足の高さが合わなければぐらつく) 昇降操作も天板に力を加えないと動かないので非力な人では動かないそもそも口コミが少ない 組み立てが大変運ぶのが大変 エンジニア向けおすすめローテーブル7選 ここからは比較一覧表で紹介した各製品毎に評価結果をまとめていきます。 1. サンワダイレクト 100-DESKH023BK (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"サンワダイレクト ローデスク 幅120cm 収納棚付き 左右入れ替え対応 パソコンデスク ロータイプ ブラック 100-DESKH023BK\",\"b\":\"サンワダイレクト\",\"t\":\"100-DESKH023BK\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41rtYuNw96L._SL500_.jpg\",\"\\/51fYFP3Ke6L._SL500_.jpg\",\"\\/51PaH8aiNNL._SL500_.jpg\",\"\\/51x7apVeXKL._SL500_.jpg\",\"\\/51E8+ndV+HL._SL500_.jpg\",\"\\/51Bjmm2gPUL._SL500_.jpg\",\"\\/51ayhT7BM3L._SL500_.jpg\",\"\\/51mXQZyO9FL._SL500_.jpg\",\"\\/61TdEADLz5L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07G7L1FRM\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07G7L1FRM\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E5%B9%85120cm%20%E5%8F%8E%E7%B4%8D%E6%A3%9A%E4%BB%98%E3%81%8D%20%E5%B7%A6%E5%8F%B3%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E5%AF%BE%E5%BF%9C%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%20100-DESKH023BK\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E5%B9%85120cm%20%E5%8F%8E%E7%B4%8D%E6%A3%9A%E4%BB%98%E3%81%8D%20%E5%B7%A6%E5%8F%B3%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E5%AF%BE%E5%BF%9C%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97%20%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%20100-DESKH023BK\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"35kOj\",\"s\":\"s\"}); リンク Amazonで「ローテーブル」で検索すると先頭の方に出てきます。 価格もお手頃で良いですが、バックパネルが有るため本記事で定めた要件は満たさなそうです。 今回はこちらのローテーブルの購入は断念しましたが、シェルフは収納やおしゃれな雰囲気を出してくれるので良いと思います。 2. サンワダイレクト 100-DESKL003BR (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"サンワダイレクト ローデスク L字型 幅75cm＋50cm 木製 パソコンデスク コーナーデスク ダークブラウン 100-DESKL003BR\",\"b\":\"サンワダイレクト\",\"t\":\"100-DESKL003BR\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31v1pxi2cjL._SL500_.jpg\",\"\\/51vE1bft3YL._SL500_.jpg\",\"\\/51JZ6EB5mWS._SL500_.jpg\",\"\\/51T5w0RVRzS._SL500_.jpg\",\"\\/51aO2QwdjWS._SL500_.jpg\",\"\\/412gNLTHoSS._SL500_.jpg\",\"\\/51olQKFDPlS._SL500_.jpg\",\"\\/513GZ7u1z6S._SL500_.jpg\",\"\\/5122z+mzGSS._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07651X4CN\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07651X4CN\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20L%E5%AD%97%E5%9E%8B%20%E5%B9%8575cm%EF%BC%8B50cm%20%E6%9C%A8%E8%A3%BD%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E3%82%B3%E3%83%BC%E3%83%8A%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%80%E3%83%BC%E3%82%AF%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20100-DESKL003BR\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20L%E5%AD%97%E5%9E%8B%20%E5%B9%8575cm%EF%BC%8B50cm%20%E6%9C%A8%E8%A3%BD%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E3%82%B3%E3%83%BC%E3%83%8A%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%80%E3%83%BC%E3%82%AF%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20100-DESKL003BR\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"iGImf\",\"s\":\"s\"}); リンク こちらもAmazonで「ローテーブル」で検索すると先頭の方に出てきます。 L字型であり、かつLの屈折点に支柱が無いため広く机が使えそうです。 しかしL字であるが故に横幅は実質75cmであり、モニターアームの装着ができるか否かが不明確でしたので、こちらも購入は断念しました。 価格も手頃で良いですし横幅のスペースを求めなければこちらのローテーブルでも良いかと思います。 3. Need AC14CB-P2 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Need ローデスク パソコンデスク 幅120cm 奥行60cm ゲーミングデスク ロータイプ pcローデスク LEDマウスパッド\\/モニター台など付き (ブラック)\",\"b\":\"Need\",\"t\":\"AC14CB-P2(120*60*39)PRO\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31s6Up1+bgL._SL500_.jpg\",\"\\/41BKJ2zhEDL._SL500_.jpg\",\"\\/41f-PnBOnEL._SL500_.jpg\",\"\\/31R8mSCsbiL._SL500_.jpg\",\"\\/51Em2p0qCbL._SL500_.jpg\",\"\\/41M0jl8F5zL._SL500_.jpg\",\"\\/51SMVjz44SL._SL500_.jpg\",\"\\/41lNxAEEDXL._SL500_.jpg\",\"\\/31QfRWhb64L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B083DFGZ38\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B083DFGZ38\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Need%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E5%B9%85120cm%20%E5%A5%A5%E8%A1%8C60cm%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97%20pc%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20LED%E3%83%9E%E3%82%A6%E3%82%B9%E3%83%91%E3%83%83%E3%83%89%2F%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E5%8F%B0%E3%81%AA%E3%81%A9%E4%BB%98%E3%81%8D%20(%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Need%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%83%87%E3%82%B9%E3%82%AF%20%E5%B9%85120cm%20%E5%A5%A5%E8%A1%8C60cm%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97%20pc%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20LED%E3%83%9E%E3%82%A6%E3%82%B9%E3%83%91%E3%83%83%E3%83%89%2F%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E5%8F%B0%E3%81%AA%E3%81%A9%E4%BB%98%E3%81%8D%20(%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"pYuMI\",\"s\":\"s\"}); リンク 「ローテーブル ゲーミング」で検索すると出力されるローテーブル。 横幅は要件を満たす120cmと広々としたサイズで、バックパネルも無いため足を伸ばせそうです。 しかしながら、テーブルの両サイドのカップ入れ（小物入れ）の穴が２つ空いています。 口コミをみると「小物入れが邪魔」というコメントがあり、「確かに邪魔になりそう。。。」と思い購入は断念しました。 値段も手頃ですし、小物入れさえなければ購入するローテーブル最有力候補だったと思います。 4. サンワダイレクト 100-DESKL009M (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"サンワダイレクト ローデスク 3段階高さ調整 幅95cm×奥行45cm ケーブル配線口 タップ受け ブラウン 100-DESKL009M\",\"b\":\"サンワダイレクト\",\"t\":\"100-DESKL009M\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31LxEJQ1GRL._SL500_.jpg\",\"\\/516JvEUOfKL._SL500_.jpg\",\"\\/41zsr2cQSpL._SL500_.jpg\",\"\\/41iFTpGWIKL._SL500_.jpg\",\"\\/51OonTKYACL._SL500_.jpg\",\"\\/41ZrmFr6tFL._SL500_.jpg\",\"\\/51GgKpG+y3L._SL500_.jpg\",\"\\/418yt5MagtL._SL500_.jpg\",\"\\/51pa+etvOUL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08PDW246B\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08PDW246B\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%203%E6%AE%B5%E9%9A%8E%E9%AB%98%E3%81%95%E8%AA%BF%E6%95%B4%20%E5%B9%8595cm%C3%97%E5%A5%A5%E8%A1%8C45cm%20%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%E9%85%8D%E7%B7%9A%E5%8F%A3%20%E3%82%BF%E3%83%83%E3%83%97%E5%8F%97%E3%81%91%20%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20100-DESKL009M\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%B5%E3%83%B3%E3%83%AF%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%203%E6%AE%B5%E9%9A%8E%E9%AB%98%E3%81%95%E8%AA%BF%E6%95%B4%20%E5%B9%8595cm%C3%97%E5%A5%A5%E8%A1%8C45cm%20%E3%82%B1%E3%83%BC%E3%83%96%E3%83%AB%E9%85%8D%E7%B7%9A%E5%8F%A3%20%E3%82%BF%E3%83%83%E3%83%97%E5%8F%97%E3%81%91%20%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20100-DESKL009M\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"UQmiO\",\"s\":\"s\"}); リンク サンワダイレクトさんの格安の昇降式ローデスク。 モニターアームの装着も可能なようですが、足を伸ばすのはちょっと厳しそうな作り。 横幅としては95cmともう少し幅がほしいところ。 ということでこちらも購入は断念しました。 5. Bauhutte BHD-1200L-WD (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Bauhutte(バウヒュッテ) ローデスク 昇降式 (幅120×奥行き55㎝) 木目 BHD-1200L-WD\",\"b\":\"Bauhutte(バウヒュッテ)\",\"t\":\"BHD-1200L-WD\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31Ajxt1oM1L._SL500_.jpg\",\"\\/51LbrGbZJJL._SL500_.jpg\",\"\\/51Ft4Th5rlL._SL500_.jpg\",\"\\/51L6FBm9sfL._SL500_.jpg\",\"\\/511vw7GTzVL._SL500_.jpg\",\"\\/51JZ6fGCquL._SL500_.jpg\",\"\\/519yRpxmezL._SL500_.jpg\",\"\\/51WjoHlCc+L._SL500_.jpg\",\"\\/41d83mr8LoL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B082F7T4V6\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B082F7T4V6\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Bauhutte(%E3%83%90%E3%82%A6%E3%83%92%E3%83%A5%E3%83%83%E3%83%86)%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E6%98%87%E9%99%8D%E5%BC%8F%20(%E5%B9%85120%C3%97%E5%A5%A5%E8%A1%8C%E3%81%8D55%E3%8E%9D)%20%E6%9C%A8%E7%9B%AE%20BHD-1200L-WD\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Bauhutte(%E3%83%90%E3%82%A6%E3%83%92%E3%83%A5%E3%83%83%E3%83%86)%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E6%98%87%E9%99%8D%E5%BC%8F%20(%E5%B9%85120%C3%97%E5%A5%A5%E8%A1%8C%E3%81%8D55%E3%8E%9D)%20%E6%9C%A8%E7%9B%AE%20BHD-1200L-WD\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"np4Gd\",\"s\":\"s\"}); リンク Bauhutte(バーヒュッテ)の昇降式ローテーブルです。 横幅120cmと大きさは文句なしです。 モニターアームも装着可能で、安心の1年間保証付きです。 バックパネルも無いことから足も十分伸ばせる仕様かとおもいます。 6. SAKODA ゲーミングデスク ローデスク SGD-L1200 BK (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"SAKODA ゲーミングデスク 昇降式 ガス圧 机 pcデスク 120cm×60cm ローデスク ワンタッチ 無段階 昇降 ゲーム パソコン デスク テーブル シンプル 黒 (ブラック, ロータイプ)\",\"b\":\"SAKODA\",\"t\":\"SGD\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/31r3ZenenjL._SL500_.jpg\",\"\\/51egZdMX8JL._SL500_.jpg\",\"\\/51AwrFLCNUL._SL500_.jpg\",\"\\/41z9DUOC0tL._SL500_.jpg\",\"\\/514FG64uchL._SL500_.jpg\",\"\\/41T8bQgQ5JL._SL500_.jpg\",\"\\/51vbVyEp-mL._SL500_.jpg\",\"\\/51myTBooFHL._SL500_.jpg\",\"\\/51pkCEyYFwL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08TQQH9B5\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08TQQH9B5\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/SAKODA%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%87%E3%82%B9%E3%82%AF%20%E6%98%87%E9%99%8D%E5%BC%8F%20%E3%82%AC%E3%82%B9%E5%9C%A7%20%E6%9C%BA%20pc%E3%83%87%E3%82%B9%E3%82%AF%20120cm%C3%9760cm%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AF%E3%83%B3%E3%82%BF%E3%83%83%E3%83%81%20%E7%84%A1%E6%AE%B5%E9%9A%8E%20%E6%98%87%E9%99%8D%20%E3%82%B2%E3%83%BC%E3%83%A0%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%20%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%20%E3%82%B7%E3%83%B3%E3%83%97%E3%83%AB%20%E9%BB%92%20(%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%2C%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=SAKODA%20%E3%82%B2%E3%83%BC%E3%83%9F%E3%83%B3%E3%82%B0%E3%83%87%E3%82%B9%E3%82%AF%20%E6%98%87%E9%99%8D%E5%BC%8F%20%E3%82%AC%E3%82%B9%E5%9C%A7%20%E6%9C%BA%20pc%E3%83%87%E3%82%B9%E3%82%AF%20120cm%C3%9760cm%20%E3%83%AD%E3%83%BC%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%AF%E3%83%B3%E3%82%BF%E3%83%83%E3%83%81%20%E7%84%A1%E6%AE%B5%E9%9A%8E%20%E6%98%87%E9%99%8D%20%E3%82%B2%E3%83%BC%E3%83%A0%20%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%20%E3%83%87%E3%82%B9%E3%82%AF%20%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%20%E3%82%B7%E3%83%B3%E3%83%97%E3%83%AB%20%E9%BB%92%20(%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%2C%20%E3%83%AD%E3%83%BC%E3%82%BF%E3%82%A4%E3%83%97)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"0thvd\",\"s\":\"s\"}); リンク SAMADAの昇降式ゲーミングローデスクです。 こちらも横幅120cmと文句なし！ モニターアームも装着可能とオフィシャルに述べられています。 耐荷重も100kgと頑丈すぎるくらい頑丈ですね。 Amazonの口コミが少ないのが気になりますが、安心の1年保証付きなので安心かと思います。 7. ゲキカグ パソコンデスク ロータイプ(150cm幅) DKW150020パソコンデスク ロータイプ ローデスク 木製 デスク 150cm幅 PCデスク パソコン台 収納 机 事務机 平机 文机 パソコン机 長机 ワークデスク 仕事机 勉強机 テーブル ダークブラウン コンセント 白 ナチュラル ホワイト ワイド ラック付 棚価格：17980円（税込、送料無料) (2021/7/14時点)楽天で購入 ゲキカグの横幅150cmのローテーブルです。 幅は圧巻の150cmと大型のローテーブル。 バックパネルがありますが、奥行きが75cmと十分足を伸ばせる奥行きがあります。 またこちらのYoutubeで紹介されている動画を見ると、山善コーヒーテーブルと組み合わせてL字型にできます。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"山善(YAMAZEN) コーヒーテーブル(90×45cm) ダークブラウン TCT-9045(DBR)\",\"b\":\"山善(YAMAZEN)\",\"t\":\"QE871\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41LOquOasML._SL500_.jpg\",\"\\/51LeTool9SL._SL500_.jpg\",\"\\/51ojpV-n+bL._SL500_.jpg\",\"\\/51zJWNxhjLL._SL500_.jpg\",\"\\/51bJs8B0iWL._SL500_.jpg\",\"\\/511i9W090gL._SL500_.jpg\",\"\\/51537IK43gL._SL500_.jpg\",\"\\/31u+45gRFlL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00B7VSP3A\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00B7VSP3A\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E5%B1%B1%E5%96%84(YAMAZEN)%20%E3%82%B3%E3%83%BC%E3%83%92%E3%83%BC%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB(90%C3%9745cm)%20%E3%83%80%E3%83%BC%E3%82%AF%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20TCT-9045(DBR)\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E5%B1%B1%E5%96%84(YAMAZEN)%20%E3%82%B3%E3%83%BC%E3%83%92%E3%83%BC%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB(90%C3%9745cm)%20%E3%83%80%E3%83%BC%E3%82%AF%E3%83%96%E3%83%A9%E3%82%A6%E3%83%B3%20TCT-9045(DBR)\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"2RkjW\",\"s\":\"s\"}); リンク また注目すべきは値段です。 なんと¥17,980！ 楽天ポイントや10% OFFクーポンを活用すれば1万円弱で購入することも可能かと思います。 結局何を購入したのか: ゲキカグ パソコンデスク ロータイプ(150cm幅) DKW150020を購入パソコンデスク ロータイプ ローデスク 木製 デスク 150cm幅 PCデスク パソコン台 収納 机 事務机 平机 文机 パソコン机 長机 ワークデスク 仕事机 勉強机 テーブル ダークブラウン コンセント 白 ナチュラル ホワイト ワイド ラック付 棚価格：17980円（税込、送料無料) (2021/7/14時点)楽天で購入 結論としてはこちらのローテーブルを購入しました。 決め手は以下のとおりです。 150cmの横幅 75cmの奥行き 価格の安さ モニターアームの到着が可能 山善コーヒーテーブルと組み合わせたL字テーブルへのカスタマイズが可能 ちなみに購入価格ですが楽天ポイントと10% OFFクーポンを活用して1万円弱となりました。 2021年7月時点では、注文して手元に届くまでに2週間ほどかかります。 実際に使用してみた感想やレビューについても、後日記事にまとめたいと思います。 合わせて読みたい記事 &gt;&gt;【2021年最新】ITエンジニアが高級マウスを徹底比較(4製品)して購入した話 &gt;&gt; 【31.5インチ】目に優しい大型4Kモニター(4社製品)をITエンジニアが徹底比較して購入した話","link":"/low-table/"},{"title":"【2021年】人工甘味料不使用！おすすめホエイプロテインを比較評価して分析！","text":"本記事では、人気のある主要7社のプロテインの比較を行いコスパ最強のプロテインはどれかを分析します。 本記事は以下の方に向けた記事になります。 ・人工甘味料を含まない安心・安全でコスパの良いホエイプロテインがほしい人 それではまとめていきます。 プロテインを比較評価する考え方: 低価格で人工甘味料を含まないプロテイン 候補となるプロテインの選定 ビーレジェンド ホエイプロテイン FIXIT プロテイン THINK SIMPLE グリコ パワープロダクション ホエイプロテイン Choice GOLDEN WHEY GronG ホエイプロテイン100 マイプロテイン ホエイ・Impact ハルクファクター ホエイプロテイン 1.05kg 【7種類】各プロテインを比較評価します 【結論①】プレーン味のプロテインを購入する場合: 「GronG ホエイプロテイン」 【結論②】フレーバー付きプロテインを購入する場合: 「FIXIT プロテイン」or 「Choice GOLDEN WHEY」 まとめ: プレーン味ならGronG、フレーバー有ならFIXIT or Choice プロテインを比較評価する考え方: 低価格で人工甘味料を含まないプロテイン プロテインというと「安かろう悪かろう」の世界かとおもいますが、可能な限り低価格で安心して飲み続けられるプロテインを選びたいと思います。 ここで言う安心して飲み続けられるプロテインとは、人工甘味料や香料といった、体の中で代謝することが出来ない物質が含まれていないプロテインのことを指します。 本記事では以下の評価基準で各社のプロテインを比較していきたいと思います。 ・ 価格は5000円程度 ・ 内容量は1kg程度 ・ 人工甘味料が含まれていない ・ 味（フレーバー）は基本となるプレーンで比較 ・ フレーバーの種類 ・ ビタミンなども含まれているか ・ 口コミの悪評の内容 候補となるプロテインの選定まずは、Amazonで該当しそうなプロテインをピックアップしていきます。 ビーレジェンド ホエイプロテイン (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ビーレジェンド ホエイプロテイン ナチュラル 1Kg グラスフェッドホエイ使用\",\"b\":\"ビーレジェンド(be LEGEND)\",\"t\":\"BLD0001\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51F714KFMBL._SL500_.jpg\",\"\\/51I3BbERKyL._SL500_.jpg\",\"\\/51tvKfLqquL._SL500_.jpg\",\"\\/519uhGo6+bL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0060GI8DE\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0060GI8DE\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%93%E3%83%BC%E3%83%AC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%89%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201Kg%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%E3%83%9B%E3%82%A8%E3%82%A4%E4%BD%BF%E7%94%A8\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%93%E3%83%BC%E3%83%AC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%89%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201Kg%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%E3%83%9B%E3%82%A8%E3%82%A4%E4%BD%BF%E7%94%A8\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"hZjJa\",\"s\":\"s\"}); リンク Amazonで「プロテイン プレーン 1kg」で検索すると、一番上位に出てくるホエイプロテイン。 基本となるナチュラル味をベースに、メロン、アップル、キャラメル珈琲、コーラ、など多くのフレーバーが用意されているのが特長です。 FIXIT プロテイン THINK SIMPLE (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"FIXIT プロテイン ホエイ プロテイン THINK SIMPLE 1kg WPI (プレーン) 人工甘味料不使用\",\"b\":\"Fix It\",\"t\":\"FIXIT_ts_wpi\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41h8UcBxhDL._SL500_.jpg\",\"\\/51zz-jZzIjL._SL500_.jpg\",\"\\/51RforF9a0L._SL500_.jpg\",\"\\/51jzCfMUo+L._SL500_.jpg\",\"\\/51nGuLcP2rL._SL500_.jpg\",\"\\/510PvUTFe2L._SL500_.jpg\",\"\\/51GiwxBKVFL._SL500_.jpg\",\"\\/51mjs1jaKiL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07H79VZZM\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07H79VZZM\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/FIXIT%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20THINK%20SIMPLE%201kg%20WPI%20(%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3)%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=FIXIT%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20THINK%20SIMPLE%201kg%20WPI%20(%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3)%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"o5Yhn\",\"s\":\"s\"}); リンク タイトルに「人工甘味料不使用」と記載されているプロテイン。 乳頭をほぼ取り除いているのが特長で、牛乳を飲むとお腹がゆるくなる人でも利用が可能です。 グリコ パワープロダクション ホエイプロテイン (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"グリコ パワープロダクション ホエイプロテイン高たんぱく低糖質 プレーン味 800g【使用目安 40食分】WPI たんぱく質含有率95%(無水物換算値)カルシウム 鉄 ビタミン マグネシウム\",\"b\":\"パワープロダクション\",\"t\":\"G76035\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51-ZX8DumLL._SL500_.jpg\",\"\\/51hZqRwPMgL._SL500_.jpg\",\"\\/51OtX+MeH3L._SL500_.jpg\",\"\\/41noZnqe-GL._SL500_.jpg\",\"\\/513TtTLNghL._SL500_.jpg\",\"\\/517zjGEa9BL._SL500_.jpg\",\"\\/61dIzXjOXmL._SL500_.jpg\",\"\\/61akI-UMigL._SL500_.jpg\",\"\\/61dtD5eh6qL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0792SZGFQ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B0792SZGFQ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%B0%E3%83%AA%E3%82%B3%20%E3%83%91%E3%83%AF%E3%83%BC%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E4%BD%8E%E7%B3%96%E8%B3%AA%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%E5%91%B3%20800g%E3%80%90%E4%BD%BF%E7%94%A8%E7%9B%AE%E5%AE%89%2040%E9%A3%9F%E5%88%86%E3%80%91WPI%20%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%E5%90%AB%E6%9C%89%E7%8E%8795%25(%E7%84%A1%E6%B0%B4%E7%89%A9%E6%8F%9B%E7%AE%97%E5%80%A4)%E3%82%AB%E3%83%AB%E3%82%B7%E3%82%A6%E3%83%A0%20%E9%89%84%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%9E%E3%82%B0%E3%83%8D%E3%82%B7%E3%82%A6%E3%83%A0\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%B0%E3%83%AA%E3%82%B3%20%E3%83%91%E3%83%AF%E3%83%BC%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E4%BD%8E%E7%B3%96%E8%B3%AA%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%E5%91%B3%20800g%E3%80%90%E4%BD%BF%E7%94%A8%E7%9B%AE%E5%AE%89%2040%E9%A3%9F%E5%88%86%E3%80%91WPI%20%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%E5%90%AB%E6%9C%89%E7%8E%8795%25(%E7%84%A1%E6%B0%B4%E7%89%A9%E6%8F%9B%E7%AE%97%E5%80%A4)%E3%82%AB%E3%83%AB%E3%82%B7%E3%82%A6%E3%83%A0%20%E9%89%84%20%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%20%E3%83%9E%E3%82%B0%E3%83%8D%E3%82%B7%E3%82%A6%E3%83%A0\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"yG802\",\"s\":\"s\"}); リンク 日本で知らない人はほぼいないメーカ、「グリコ」さんが提供しているホエイプロテイン。 タンパク質以外にも、カルシウム、鉄、ビタミン、マグネシウムなどの栄養素が含まれているようです。 Choice GOLDEN WHEY (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Choice GOLDEN WHEY ( ゴールデンホエイ ) ホエイプロテイン プレーン 1kg [ 人工甘味料 GMOフリー ] グラスフェッド プロテイン 国内製造\",\"b\":\"CHOICE NUTRITION ( チョイス ニュートリション )\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41L-nOUqsbL._SL500_.jpg\",\"\\/510grQRnu3L._SL500_.jpg\",\"\\/510VbDmVX9L._SL500_.jpg\",\"\\/51DwwNSwe7L._SL500_.jpg\",\"\\/51pS01MFz4L._SL500_.jpg\",\"\\/416ZVMKhgyL._SL500_.jpg\",\"\\/41HC5DjPIdL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016M0YCFK\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016M0YCFK\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Choice%20GOLDEN%20WHEY%20(%20%E3%82%B4%E3%83%BC%E3%83%AB%E3%83%87%E3%83%B3%E3%83%9B%E3%82%A8%E3%82%A4%20)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%201kg%20%5B%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%20GMO%E3%83%95%E3%83%AA%E3%83%BC%20%5D%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E5%9B%BD%E5%86%85%E8%A3%BD%E9%80%A0\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Choice%20GOLDEN%20WHEY%20(%20%E3%82%B4%E3%83%BC%E3%83%AB%E3%83%87%E3%83%B3%E3%83%9B%E3%82%A8%E3%82%A4%20)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%201kg%20%5B%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%20GMO%E3%83%95%E3%83%AA%E3%83%BC%20%5D%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E5%9B%BD%E5%86%85%E8%A3%BD%E9%80%A0\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"tDPSB\",\"s\":\"s\"}); リンク ニュージーランド牧草牛の乳清を使用したホエイプロテイン。 天然甘味料のステビアを使用した５つのフレーバーが用意されており、GMO（遺伝子組み換え作物）を一切使用していない、安心安全のプロテインであることが特長かと思います。 GronG ホエイプロテイン100 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"GronG(グロング) ホエイプロテイン100 スタンダード 人工甘味料・香料無添加 ナチュラル 1kg\",\"b\":\"GronG(グロング)\",\"t\":\"GS0006\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51deUDekDnL._SL500_.jpg\",\"\\/61TF-lcnx0L._SL500_.jpg\",\"\\/51PYmKRaziL._SL500_.jpg\",\"\\/51PIFDnxOeL._SL500_.jpg\",\"\\/512xzNRx7fL._SL500_.jpg\",\"\\/61-28hOl7BL._SL500_.jpg\",\"\\/511wOuUWI3L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07N8H8WRB\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07N8H8WRB\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/GronG(%E3%82%B0%E3%83%AD%E3%83%B3%E3%82%B0)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3100%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%80%E3%83%BC%E3%83%89%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E3%83%BB%E9%A6%99%E6%96%99%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201kg\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=GronG(%E3%82%B0%E3%83%AD%E3%83%B3%E3%82%B0)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3100%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%80%E3%83%BC%E3%83%89%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E3%83%BB%E9%A6%99%E6%96%99%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201kg\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"rzs7l\",\"s\":\"s\"}); リンク 人工甘味料・香料・保存料・着色料を一切使用しておらず、国内製造で品質確保もバッチリなプロテイン。 価格もかなり低く設定されており、パッと見た限り一番コスパが良さそうです。 マイプロテイン ホエイ・Impact (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"マイプロテイン ホエイ・Impact ホエイプロテイン アイソレート ノンフレーバー 1kg\",\"b\":\"マイプロテイン\",\"t\":\"MYP1022\\/100\\/211\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\",\"p\":[\"\\/images\\/I\\/31OMPfVdxoL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00L4ACMAQ\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B00L4ACMAQ\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%BBImpact%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%82%A2%E3%82%A4%E3%82%BD%E3%83%AC%E3%83%BC%E3%83%88%20%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC%201kg\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%9E%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%BBImpact%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%82%A2%E3%82%A4%E3%82%BD%E3%83%AC%E3%83%BC%E3%83%88%20%E3%83%8E%E3%83%B3%E3%83%95%E3%83%AC%E3%83%BC%E3%83%90%E3%83%BC%201kg\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"OVyCS\",\"s\":\"s\"}); リンク プロテイン界隈ではコスパ最強と言われているマイプロテイン。フレーバーも様々な種類があります。 ハルクファクター ホエイプロテイン 1.05kg (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"モンドセレクション最高金賞 ウマイ ホエイプロテイン 1.05kg チョコ味 ハルクファクター 高たんぱく質 26g 国産 11種のビタミン配合\",\"b\":\"ハルクファクター(HULX-FACTOR)\",\"t\":\"8000hu10501\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41rv5RfnyyS._SL500_.jpg\",\"\\/51GEDcrp5nS._SL500_.jpg\",\"\\/51So1DoUMaS._SL500_.jpg\",\"\\/51dUL9cIxNS._SL500_.jpg\",\"\\/51T0Ozo8XyS._SL500_.jpg\",\"\\/51eXK-pQXXS._SL500_.jpg\",\"\\/51nDuInqNwS._SL500_.jpg\",\"\\/5106Hb+e48S._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08JFTKHF2\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08JFTKHF2\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%83%A2%E3%83%B3%E3%83%89%E3%82%BB%E3%83%AC%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E6%9C%80%E9%AB%98%E9%87%91%E8%B3%9E%20%E3%82%A6%E3%83%9E%E3%82%A4%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%201.05kg%20%E3%83%81%E3%83%A7%E3%82%B3%E5%91%B3%20%E3%83%8F%E3%83%AB%E3%82%AF%E3%83%95%E3%82%A1%E3%82%AF%E3%82%BF%E3%83%BC%20%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%2026g%20%E5%9B%BD%E7%94%A3%2011%E7%A8%AE%E3%81%AE%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%E9%85%8D%E5%90%88\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%83%A2%E3%83%B3%E3%83%89%E3%82%BB%E3%83%AC%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E6%9C%80%E9%AB%98%E9%87%91%E8%B3%9E%20%E3%82%A6%E3%83%9E%E3%82%A4%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%201.05kg%20%E3%83%81%E3%83%A7%E3%82%B3%E5%91%B3%20%E3%83%8F%E3%83%AB%E3%82%AF%E3%83%95%E3%82%A1%E3%82%AF%E3%82%BF%E3%83%BC%20%E9%AB%98%E3%81%9F%E3%82%93%E3%81%B1%E3%81%8F%E8%B3%AA%2026g%20%E5%9B%BD%E7%94%A3%2011%E7%A8%AE%E3%81%AE%E3%83%93%E3%82%BF%E3%83%9F%E3%83%B3%E9%85%8D%E5%90%88\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"Hiqv8\",\"s\":\"s\"}); リンク モンドセレクション最高金賞を獲得した国産プロテイン 11種のビタミンが配合されており、「100%ナチュラルホエイ」という記述がされています。 【7種類】各プロテインを比較評価しますなお口コミの悪評に関しては、Amazonの★1〜★2のものを参照しています。悪評の中でも「味が不味い」という評価は、個人の見解になるので、比較評価では省きます。 ビーレジェンド FIXIT プロテイン グリコパワープロダクション Choice GOLDEN WHEY GronG ホエイプロテイン マイプロテイン ハルクファクター 内容量 1kg 1kg 800g 1kg 1kg 1kg 1.05kg 人工甘味料などの含有 甘味料（スクラロース） 全フレーバー不使用 プレーンのみ不使用 全フレーバー不使用 プレーンのみ不使用 甘味料（スクラロース） 甘味料(ステビア、アセスルファムK、スクラロース) フレーバーの種類 13種類(メロン、アップル、チョコレート、コーラなど) 6種類(バニラ、ストロベリー、バナナ、コヒー、フルーツミックス、抹茶) 4種類(サワーミルク、チョコ、いちご) 6種類(ココア、抹茶、シナモン、珈琲、ストロベリー) 16種類(抹茶、バニラ、ココア、バナナ、キュアラメルなど) 35種類(ブルーベリーチーズケーキ、チョコレートスムース、クッキー&amp;クリームなど) 1種類(チョコ) ビタミンなどの他栄養素の有無 ビタミンC(39.8mg),ビタミンB6(1.0mg) BCAA(23.8g/タンパク質原料100g) 水酸化Ca、炭酸Mg、V.C、ナイアシン、パントテン酸Ca、ピロリン酸鉄、V.B1、V.E、V.B2、V.B6、葉酸、V.A、V.B12、V.D、(一部に乳成分・大豆を含む) 特になし ビタミンA, D, E, B1, B2, B6, B12, C, ナイアシン, 葉酸, パントテン酸 特になし V.C、V.E、ナイアシン、パントテン酸Ca、V.B1、V.B6、V.A、V.B2、葉酸、V.D、V.B12 その他特長 グラスフェッドホエイアミノ酸スコア100 乳糖除去 - グラスフェッドホエイ、GMO準拠工場, GMO不使用 本品製造工場では小麦、卵を含む製品を生産 グラスフェッドホエイ, 乳糖除去 GMP認定工場で製造、香料は小麦由来 口コミ（悪評中心) 計量スプーンが入ってない(?) ダマになりやすい。泡立つ 泡立つ ダマになりやすい ダマになりやすい チャックが閉まらない(?) ダマになる｜ 価格(2021年8月9日時点) ¥3,480 ¥3,780 ¥5,169 ¥4,480 ¥2,580 ¥3,920 ¥3,980 【結論①】プレーン味のプロテインを購入する場合: 「GronG ホエイプロテイン」 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"GronG(グロング) ホエイプロテイン100 スタンダード 人工甘味料・香料無添加 ナチュラル 1kg\",\"b\":\"GronG(グロング)\",\"t\":\"GS0006\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/51deUDekDnL._SL500_.jpg\",\"\\/61TF-lcnx0L._SL500_.jpg\",\"\\/51PYmKRaziL._SL500_.jpg\",\"\\/51PIFDnxOeL._SL500_.jpg\",\"\\/512xzNRx7fL._SL500_.jpg\",\"\\/61-28hOl7BL._SL500_.jpg\",\"\\/511wOuUWI3L._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07N8H8WRB\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B07N8H8WRB\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/GronG(%E3%82%B0%E3%83%AD%E3%83%B3%E3%82%B0)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3100%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%80%E3%83%BC%E3%83%89%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E3%83%BB%E9%A6%99%E6%96%99%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201kg\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=GronG(%E3%82%B0%E3%83%AD%E3%83%B3%E3%82%B0)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3100%20%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%80%E3%83%BC%E3%83%89%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E3%83%BB%E9%A6%99%E6%96%99%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E3%83%8A%E3%83%81%E3%83%A5%E3%83%A9%E3%83%AB%201kg\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"rzs7l\",\"s\":\"s\"}); リンク プレーン味で人工甘味料不使用のプロテインを購入する場合は、圧倒的に「GronG ホエイプロテイン」が良いかと思いました。 なんと言っても、1gあたり2円という安さは目を引きます。 また、プロテイン以外にビタミン類が含まれていることも魅力的です。 【結論②】フレーバー付きプロテインを購入する場合: 「FIXIT プロテイン」or 「Choice GOLDEN WHEY」 味付きのプロテインを購入する場合は、「FIXIT プロテイン」か「Choice GLDEN WHEY」のどちらかになると思いました。 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"FIXIT プロテイン グラスフェッド 抹茶 1kg 無添加 人工甘味料不使用 高タンパク ホエイプロテイン プロテイン ホエイ ホエイ100 ケト whey 飲料 顆粒 サプリメント\",\"b\":\"Fix It\",\"t\":\"feel_natural\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41inuFSRq9L._SL500_.jpg\",\"\\/61AsFrJ9OnL._SL500_.jpg\",\"\\/51Yk8oVohCL._SL500_.jpg\",\"\\/51cyJ5S1XcL._SL500_.jpg\",\"\\/51A7s1aTBhL._SL500_.jpg\",\"\\/51789NUDP7L._SL500_.jpg\",\"\\/51CSD-s2QZL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08KH8V43N\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B08KH8V43N\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/FIXIT%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20%E6%8A%B9%E8%8C%B6%201kg%20%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8%20%E9%AB%98%E3%82%BF%E3%83%B3%E3%83%91%E3%82%AF%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%20%E3%83%9B%E3%82%A8%E3%82%A4100%20%E3%82%B1%E3%83%88%20whey%20%E9%A3%B2%E6%96%99%20%E9%A1%86%E7%B2%92%20%E3%82%B5%E3%83%97%E3%83%AA%E3%83%A1%E3%83%B3%E3%83%88\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=FIXIT%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20%E6%8A%B9%E8%8C%B6%201kg%20%E7%84%A1%E6%B7%BB%E5%8A%A0%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8%20%E9%AB%98%E3%82%BF%E3%83%B3%E3%83%91%E3%82%AF%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E3%83%9B%E3%82%A8%E3%82%A4%20%E3%83%9B%E3%82%A8%E3%82%A4100%20%E3%82%B1%E3%83%88%20whey%20%E9%A3%B2%E6%96%99%20%E9%A1%86%E7%B2%92%20%E3%82%B5%E3%83%97%E3%83%AA%E3%83%A1%E3%83%B3%E3%83%88\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"LDlwz\",\"s\":\"s\"}); リンク (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"Choice GOLDEN WHEY ( ゴールデンホエイ ) ホエイプロテイン 抹茶 1kg [ 乳酸菌ブレンド \\/ 人工甘味料不使用 ] GMOフリー タンパク質摂取 グラスフェッド ( プロテイン \\/ 国内製造 ) 天然甘味料 ステビア 飲みやすい\",\"b\":\"CHOICE NUTRITION ( チョイス ニュートリション )\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/41CqCDP-KyL._SL500_.jpg\",\"\\/510grQRnu3L._SL500_.jpg\",\"\\/61OPw00DfsL._SL500_.jpg\",\"\\/51DwwNSwe7L._SL500_.jpg\",\"\\/51pS01MFz4L._SL500_.jpg\",\"\\/51xO3JWEX2L._SL500_.jpg\",\"\\/41PBQZVy2iL._SL500_.jpg\",\"\\/51KSUW+txlL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016M1P45G\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/B016M1P45G\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/Choice%20GOLDEN%20WHEY%20(%20%E3%82%B4%E3%83%BC%E3%83%AB%E3%83%87%E3%83%B3%E3%83%9B%E3%82%A8%E3%82%A4%20)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E6%8A%B9%E8%8C%B6%201kg%20%5B%20%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%96%E3%83%AC%E3%83%B3%E3%83%89%20%2F%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8%20%5D%20GMO%E3%83%95%E3%83%AA%E3%83%BC%20%E3%82%BF%E3%83%B3%E3%83%91%E3%82%AF%E8%B3%AA%E6%91%82%E5%8F%96%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20(%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%2F%20%E5%9B%BD%E5%86%85%E8%A3%BD%E9%80%A0%20)%20%E5%A4%A9%E7%84%B6%E7%94%98%E5%91%B3%E6%96%99%20%E3%82%B9%E3%83%86%E3%83%93%E3%82%A2%20%E9%A3%B2%E3%81%BF%E3%82%84%E3%81%99%E3%81%84\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=Choice%20GOLDEN%20WHEY%20(%20%E3%82%B4%E3%83%BC%E3%83%AB%E3%83%87%E3%83%B3%E3%83%9B%E3%82%A8%E3%82%A4%20)%20%E3%83%9B%E3%82%A8%E3%82%A4%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%E6%8A%B9%E8%8C%B6%201kg%20%5B%20%E4%B9%B3%E9%85%B8%E8%8F%8C%E3%83%96%E3%83%AC%E3%83%B3%E3%83%89%20%2F%20%E4%BA%BA%E5%B7%A5%E7%94%98%E5%91%B3%E6%96%99%E4%B8%8D%E4%BD%BF%E7%94%A8%20%5D%20GMO%E3%83%95%E3%83%AA%E3%83%BC%20%E3%82%BF%E3%83%B3%E3%83%91%E3%82%AF%E8%B3%AA%E6%91%82%E5%8F%96%20%E3%82%B0%E3%83%A9%E3%82%B9%E3%83%95%E3%82%A7%E3%83%83%E3%83%89%20(%20%E3%83%97%E3%83%AD%E3%83%86%E3%82%A4%E3%83%B3%20%2F%20%E5%9B%BD%E5%86%85%E8%A3%BD%E9%80%A0%20)%20%E5%A4%A9%E7%84%B6%E7%94%98%E5%91%B3%E6%96%99%20%E3%82%B9%E3%83%86%E3%83%93%E3%82%A2%20%E9%A3%B2%E3%81%BF%E3%82%84%E3%81%99%E3%81%84\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"jhoZZ\",\"s\":\"s\"}); リンク 上記のリンクは、抹茶味になります。 価格的に両者ともに同じくらいの金額です。 強いて言えば、FIXITプロテインは、BCAAが含まれている点がいいかなと思いました。牛乳でお腹の調子が悪くなる方もFIXITのプロテインが良いかなと思います。 まとめ: プレーン味ならGronG、フレーバー有ならFIXIT or Choice 本記事は、「【2021年】人工甘味料不使用！おすすめホエイプロテインを比較評価して分析！」というテーマでまとめました。 本記事での比較評価を参考に、自分の体にふさわしいプロテインを選んでいただければと思います。 こちらの記事も見ていってください &gt;&gt;【ダイエットメニュー】プロテイン＋冷凍ブルーベリーが脂肪燃焼に最適だった &gt;&gt;【厳選】風邪を予防する最強サプリメントはビタミンCとグルタミンだった","link":"/protein-comparison/"},{"title":"【自然言語処理】Google Colaboratoryでdoc2vecを実装してみよう！","text":"本記事では、doc2vecを実装していきます。 doc2vecとはなにか？については、以下の記事でまとめています。 実装の全体像 1. doc2vecを実装する環境を用意する 2. Livedoorニュースのファイルをダウンロードしカテゴリ数と内容を確認する 3. 類似度計算するドキュメントを抽出 4.抽出したドキュメントを分かち書き処理 5. Doc2Vecの実装 6. 類似度計算の実施 まとめ: Doc2vecを実装しながら学びました。 1. doc2vecを実装する環境を用意する 本記事では、Google Colaboratoryを使用します。 Goofle Colaboratoryとは、ブラウザ上でPythonを記述し実行できる環境です。 Googleのアカウントを持っていいればすぐに利用できます。 GPUも無料で利用できるなど、嬉しい機能がたくさん備わっています。 もし、ローカルの環境に、Google Colaboratoryと似たような開発環境を用意したい場合は、以下の記事を参照いただければと思います。Anaconda Navigatorを用いてjupyter notebookを利用する方法です。 2. Livedoorニュースのファイルをダウンロードしカテゴリ数と内容を確認する 本記事では、Livedoor newsコーパスというテキストコーパスを使用します。 Livedoor newsコーパスファイルをダウンロードし、カテゴリ数と内容を確認する方法は、以下のword2vecを実装する記事にまとめていますので、こちらを参照してください。 3. 類似度計算するドキュメントを抽出 本記事では、Livedoor newsコーパスから、5つほどドキュメントを取り出し、類似度を比較していきます。 まずは、対象となる5つのドキュメントを確認します。 類似度比較する5つのドキュメントを抽出123456789101112131415161718192021222324252627282930313233343536373839404142import globfrom janome.tokenizer import Tokenizerfrom gensim.models import word2vecdef load_livedoor_news_corpus(): category = { &quot;dokujo-tsushin&quot;: 1, &quot;it-life-hack&quot;:2, &quot;kaden-channel&quot;: 3, &quot;livedoor-homme&quot;: 4, &quot;movie-enter&quot;: 5, &quot;peachy&quot;: 6, &quot;smax&quot;: 7, &quot;sports-watch&quot;: 8, &quot;topic-news&quot;:9 } docs = [] labels = [] for c_name, c_id in category.items(): files = glob.glob(&quot;./data/livedoor/text/{c_name}/{c_name}*.txt&quot;.format(c_name=c_name)) for file in files: with open(file, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f: lines = f.read().splitlines() url = lines[0] datetime = lines[1] subject = lines[2] body = &quot;&quot;.join(lines[3:]) text = subject + body docs.append(text) labels.append(c_id) return docs, labelsdocs, labels = load_livedoor_news_corpus()print(&quot;\\nlabel: &quot;, labels[0], &quot;\\ndocs:\\n&quot;, docs[0])print(&quot;\\nlabel: &quot;, labels[1], &quot;\\ndocs:\\n&quot;, docs[1])print(&quot;\\nlabel: &quot;, labels[2], &quot;\\ndocs:\\n&quot;, docs[2])print(&quot;\\nlabel: &quot;, labels[3], &quot;\\ndocs:\\n&quot;, docs[3])print(&quot;\\nlabel: &quot;, labels[4], &quot;\\ndocs:\\n&quot;, docs[4]) 上記のコードを実行すると以下のような出力が得られるかと思います。 コンソール12345678910111213141516171819label: 1 docs: 東京23区女ひとり風呂 vol.03「台東区・銭湯でアレ発見！」Presented by ゆるっとcafe独女のみなさん、こんにちは。突然ですが、江戸時代の銭湯って、男女混浴だったんですって！老若男女入り乱れ、ここもアソコも洗いあい、奥ではイチャイチャしてる人影。相手もないのにムラムラしちゃったら、垢を掻いてくれる湯女が別室でサービスしてくれて…。砂っぽかった江戸の町は、日に2度3度と銭湯につかることも多かったそうですから、いやはや、想像するだけでワクワクしちゃいますよねぇ！え…私、飢えすぎ？ そ、そんなことは…… こんな話をしたワケは、先日訪れた台東区の「燕湯」に、金精様があったからなんです。金精様とは、男性器の形をした神様。子宝の神として各地に祀られているほか、昔はたくさんの女湯に、チン座…いや、鎮座ましましていたそうです。銭湯めぐりを始めてから、いつご対面できるかと心待ちにしていたんですが、どこの銭湯にも、カゲもカタチもなし。これだから近代的理性ってヤボだわと思っていた矢先、ようやく、謁見がかないました。いやー、心願成就！ ところでこの金精様、温泉に祀られることも多かったそうです。古来より女陰の象徴とされている温泉に男根を祀ることで、その湯が尽きぬように祈っていたんですね。銭湯もこれにあやかっていると考えて、間違いはなさそう。つまり銭湯は、男女のマグワイの象徴であり、混浴であり、湯女のいる場であり…。まーなんだ、生と性の巨大な隠喩でもあったのではないか、と。 そう考えると、銭湯もただの風呂ではないワケで、今から混浴に戻せというのはムリでも、金精様の存在は、もうちょっと重きを置いてもいいんじゃないかと思うのです。 …いや、女湯に金精様があったら楽しいなって、それだけの話なんですけどね… それはともかく、一緒に燕湯に行った担当編集のＮ島さんの、臆面もない金精様の撫でっぷりはすごかった。私なんて、口だけだものね。やっぱり子持ちは違うなぁと感じた、独女の小沢でありました。●小沢カオル：独身アラフォー漫画家。ダメ男にひっかかりやすい。現在の恋人は小次郎（柴犬）。主に突撃取材系のマンガを執筆。「あやしい取材に逝ってきました。」「あやしい男と失恋ってきました。」（ともに秋田書店）「あやしい人に遭ってきました。」（ぶんか社）絶賛発売中。label: 1 docs: 意外と知らない我が家のルーツ！ 新年会でご先祖様トークはいかが？新年会などで、祖父母や親戚と顔を合わせる機会が多いお正月。「結婚はまだ？」「そろそろ両親を安心させてあげたら」といった話題にうんざりして、話の流れを変えたくなったとき、意外と役立つのが一族のルーツやご先祖様のお話だ。祖父母や親戚の年長者を話の中心にすることで、新年会の雰囲気も変わるだろう。昨年のお正月、久しぶりに親戚の新年会に出席した美也子さん(38歳・看護士）は、父方の伯父から一族のルーツを初めて聞いた。「伯父によると、大昔、私たちのご先祖様は都でおこった仏教派と国神派の戦いに負けて、武蔵国に追われてきたそうです。負けた側への罰として名前を変えられて、今の名字になったのだとか。後で調べてみたら、飛鳥時代に仏教の礼拝を巡って起こった『丁未の乱』という内乱があったんですよ。これだ！ と思いました」武蔵国に来た美也子さんのご先祖様は、やがて広大な土地を手にいれ豊かな暮らしをしていたのだが、長い歴史の中には博打好きの人もいて、土地のほとんどを失ったらしい…。古い家系図もあったが預けていたお寺の火災で焼けてしまい、今となっては詳細なことはわからない…。「正直なところ、どこまで本当なのかわかりませんが、自分の家系が遥か昔から続いていると思うだけでワクワクします」と美也子さんは話してくれた。ここまで歴史をさかのぼる話はそうそう多くはないだろう。しかし、30代の独女なら祖父のそのまた祖父の時代は幕末か明治初頭くらい。小説やドラマでしか知らない時代に、自分のご先祖様や縁のある人が生きていたというだけでも、なんだか嬉しくなってくる。先日、都内で編集の仕事をしている真琴さん（42歳）は、伯母に「仕事で鹿児島へよく行く」と話したところ「あら、ウチのご先祖様にも鹿児島の人がいるのよ」と言われたそうだ。「明治の初めに、埼玉で先祖代々農家を続けている曾祖父の父の元に、薩摩藩の江戸屋敷で生まれ育った女性が嫁いできたそうです。廃藩置県で一度は鹿児島に戻ったものの、言葉もわからず鹿児島の生活にも馴染めなくて、江戸に戻ってきたのだとか。実は、近所に徳川に縁のある神社があるんですよ。もしかしたら篤姫が、その女性の嫁ぎ先として曾祖父の父を選んでくれたのかな？ なんて想像しちゃいました」と真琴さんは話してくれた。「食べ物の話題から、曾祖母やその姉妹のことを知った」というのは美鈴さん（30歳・会社員）だ。「子どもの頃にどんなものを食べていたか？ という話になったとき、九州の小さな町で育った祖父（90歳）が『子どもの頃から、カレーやシチューを食べていたよ』と言いはじめて…。よくよく話を聞いたら、曾祖母とその姉妹は結婚するまでの間、中国大陸で旅館の仕事を手伝っていて、そこでカレーやシチューの作り方を覚えたということがわかりました」旅館の主なお客様は軍関係者で、味付けは関東風だったとか。「九州の祖父の家で食べるお雑煮は関東風なんです。料理の味付けにも、曾祖母の体験というか人生が関わっているんですね」と美鈴さんは話してくれた。今、自分がここにいるのは両親がいて、祖父母がいて、曾祖父母がいて…。そう思うだけで、たくさんの人に守られているような気がしてくる。親戚が顔を会わせるお正月だからこそ、改めてご先祖様トークをしてみよう。子どもの頃は理解できなかったルーツや、今まで知らなかったご先祖様の武勇伝が飛び出すかもしれない。（オフィスエムツー／神田はるひ）label: 1 docs: 既婚の女友達にムカッ！とすること片や仕事を辞め、育児に真っ最中の主婦。片やしばらく結婚の予定のない独身のキャリアウーマン。かつてはよき友情関係を育んでいた者同士が、違う立場に置かれて久しく時間が経つと、会話がかみ合わなくなってしまうことがある地方に嫁いだ友人の家族トークにうんざりしたのは好美さん（34歳）。「出張の帰りだったんですが、久しぶりに会いたくなって彼女の家まで足を延ばしたんです。ところが共通の友人のことなど、どんな話題を持ち出しても彼女はほとんどスルー。自分の子どもの話にしか興味を示さないので、どうしていいかわからなくなりました。確かに子どもはかわいいのですが、他人は、他人の子に親以上の興味は持たないもの。もう少し配慮をしてほしかった」赤ちゃんを産んだ元同級生の家に遊びに行った晴美さん（33歳）は、発育相談をもちかけられて返答に困ったという。「友人に『子どもがまだ寝返りができないの』と言われたので『そのうちするんじゃない？』と気楽に答えたら、『親の気持ちがわからない』とムッとした表情で返されました。赤ちゃんが寝返りする時期なんて知らないし、子どもがいないので、正直、心配するママの気持ちもよくわからない。なんて回答すればよかったんでしょうか？」育児熱心なのは幸せの裏返しかもしれないが、トークで置いてきぼりにされてはかなわない。とくに独身女性が既婚女性の間に挟まれると、一歩も二歩もおせっかいを焼きたがる人が出てくる。これには既婚者である自分自身も困惑したと、恵美子さん（37才）。「現在彼氏のいない友人・A子は既女から、しょっちゅう『誰かいい人いないの？』と言われています。しまいには、みんなでなぜＡ子には彼がいないかという議論に。『もっと残業減らして婚活したら？』などライフスタイルにまでダメ出しをするんですよね。彼女、かつてはお付き合いしている人もいたんですよ。黙って聞いているけど、内心、うんざりしているのでは」結婚後も仕事を続けている恵美子さんは現在、子どもがいない。なかには「早く産め！」と妊娠・出産をせかしてくる知り合いもいるそうだ。「苦労せず、早くに子どもを産んだ人に多いのが『早く子ども産んだほうがいいよ。年取ると大変だよ』という発言。若いころに授からなかったことを今さら言われても、どうしようもありません。いっぺん、『アンタが今から若返らせてくれんの？』と言い返してみたいですね。ああしたセリフをサラッと言える人は鈍感なのかも」女性の体や育児の負担を考えると、妊娠、出産にベターな時期があるのはたしか。発言する側に悪意はないのかもしれないが、無自覚だからこそ相手を苛立たせることもある。「自分も含めて、既婚女性の発言は知らないうちに独身者を傷つけていることもありそう。自戒しようと思いました」と恵美子さん。一方で、既婚の女友達と上手くつき合っていけるケースもある。明美さん（37才）の場合、「『既婚だから』『子持ちだから』ではなく『友達だから』というスタンスで付き合うこと」を心掛けている。「既婚の女友達と遊ぶ時は、なるべく身軽な自分が動くようにします。時間帯も昼間にするなど、こちらも相手の家族を優先する。あと必要以上に相手の家庭のことを詮索したりはしないようにしていますね。自分から気遣うと、相手もあまり自己中心的な話題に走らない気がします。むしろ無神経で扱いづらいのは既婚の男友達。『結婚しろよ』『早く子ども産めば』って、思い出したように突然言うんですよ。嫌気がさして疎遠になった人もいます」よい本や音楽を見つけると、他人にも薦めたくなる。結婚や出産を促すのも、本人らが「よいもの」と感じてるからなのだろう。だけど結婚うんぬんの話題は、下手したら人生に対する口出しにもなりかねないリスキーなもの。丁重に扱わなければならないと、独身、既婚問わず肝に銘じたい。（来布十和）label: 1 docs: ひょっとして、あなたは浮気相手かもあなたは、彼氏や意中の人の態度や素行に対して「自分は本命なの？」と疑問を抱いたり、直感的に「何かおかしい…」と思ったことはないだろうか？ 一度気になってしまうと、とことん疑いはじめてしまう相手の心。それもそのはず、女性はどんなに小さな出来事も記憶にとどめておき、過去から現在に至るまでの全てをデータベースにおさめる生き物なのだ。“女の勘”の鋭さは霊感並みで、その根底には、このデータベースがあるからと言えるだろう。例えば、歓送迎会など飲み会がかなりの頻度で開催されるこの時期は“女の勘”がフル稼働するのではないだろうか。歓迎会では新しい顔ぶれに妙な新鮮味を覚えてしまったり、送別会で普段は意識しない相手に対して寂寥感を覚えて、つい親密になってしまう、という可能性だって否定はできない。そんな時期だからこそ相手に微妙な変化があると、（急に優しくなったり、あまり目を合わせなくなったり、持ち物・服・食べ物の好みが変わるなど）誰でも不安になるもの。そして女性の多くは、すべてのデータの中から「この納得のいかない違和感は何なのか？」という情報を引き出し、判断の基準にするのだ。恋人がいる方は、そんな不安を抱えずにすむように、相手の気持ちをしっかりと握ることが大切になってくる。しかし、時に“恋は盲目”になるもの。そんな時にこそ気をつけていただきたいのが、自身が浮気・不倫相手になってしまっていないか、ということだ。例えば厚生労働省の「2008年 第4回男女の生活と意識に関する調査(16歳〜49歳の男女1468人を対象)」によれば、既婚男性における「過去1年間に複数のパートナーと性的な関係を持った割合」は35歳未満では4.6%、35歳以上は15.8%にのぼったという。つまり、10人に一人以上の割合で男性は浮気・不倫をしている人がいるということだ。特に最近の若年層の男性におけるセックス離れを考えると、年齢が高くなるにつれて、女性関係が派手な男性が増加しているのではないだろうか。運悪く不倫相手となってしまった場合、男性のパートナー(相手の奥さん)から訴訟を起こされ、損害賠償を請求されることも無い話ではない。ちなみにその慰謝料は心の損害であることから、ケースバイケースになるが、おおよそ50万円から300万円という場合が多いという。独女の方々の中には真剣に生涯のパートナーを探している方も多いだろう。だからこそ、そんな心の隙間に入り込んでくる男性の本性を見破ることはとても難しい。最近では特に結婚していなくても、相手に浮気や不倫のそぶりがあれば、探偵会社に浮気調査を依頼する女性も多いという。1日だけの調査も引き受けてくれるし、クレジットカード払いも可能になるなど意外と身近になってきたのではないだろうか。確かに、万が一にも自分が不倫相手などになってしまった時のリスクを考えれば、こういった調査のプロに依頼してしまうのも一つの賢い選択なのかもしれない。もちろん、そういった行為自体は一時的に相手を疑うことになってしまう。しかし、”シロ”と分かれば、よりいっそうパートナーを信頼する裏付けとなることは間違いないはずだ。■関連リンク探偵会社の詳細はこちらlabel: 1 docs: 髪以外に白髪発見！ あなたはどこに？初めて髪に「白い１本」を見つけたのは20代後半のとき、という優香さん（40歳・コピーライター）。「徹夜もよくしていたし、当時の職場ではいろいろストレスを感じていたので、そのせいかと思ってましたが……」。30代前半で退職しフリーになり、ストレスもなくなったのに白髪はその後も増える一方。白髪染めは欠かせなくなって久しい。年齢的なものかとあきらめてはいるが、友人たちと集まったとき、ついぼやいてしまった。ところが、居合わせた友人からは意外な告白があったという。頭髪の白髪は数本、という智子さん（38歳・デザイナー）は、「髪も気になるけどね、実は……」と切り出した。「鼻の下の産毛が気になっていたから脱毛に通っているのだけど、経過はどうかと鏡を見ていたら、なんと１本、白髪があったのよ〜！」。施術は、黒い毛根にダメージを与える光脱毛というものなので、「白髪だと毛根も白いだろうから、ここだけは脱毛されなさそう……」と残念そうだったという。里美さん（35歳・編集者）は、「私だけじゃなかったんですね！ 私の場合はまゆ毛！ しかもなぜか左だけ。数えたら４本もあってびっくり。髪の毛よりまゆ毛が先に白くなるなんて……」と苦笑。髪は黒々としていて染めてもいない陽子さん（41歳・整体師）も「私はアンダーヘアに１本」と、続々カミングアウト。海外ドラマ『SEX AND THE CITY』ファンの優香さんがそれを聞いて思い出したのは、仲間の最年長のサマンサがアンダーヘアに白髪を見つけショックを受けたエピソード。ドラマでは染めて失敗していたが……。それでみんなはどう対処したのかと聞いてみた。脱毛中の智子さんは、「抜くのは肌によくないとサロンで言われたし、脱毛効果も薄れるので、剃っている」。あとの２人は抜いたという。ちなみに抜いても、またそこから白髪が生えてくるので、抜くのはその場しのぎにしかならない。優香さんはみんなの話を聞いて、「白髪の量でいえば私が一番ですが、頭髪は染めるのが手軽。みんなよりケアは楽な方かも」と思ったという。とはいえ、次にどこに白髪が発見されるかは未知数で、人ごとではない。「男性だったらヒゲに白いものが混じっていても大人の魅力とも取れますが、女はねえ……。数本のうちはまだ笑い飛ばせるけど、これ以上増やさないにはどうしたらいいんだろうって、そのあとずいぶん話が盛り上がりましたよ」。黒々とした髪の陽子さんが「私はよく食べてるけど、黒い食べ物がいいらしいよ。海藻類や黒ごまとか」と言うのが妙に説得力があったそうだ。そのほか、牡蛎やシジミに含まれる亜鉛やカルシウムなどのミネラルもいいという。白髪の原因にはまだ謎が多く、加齢のほか遺伝、ストレス、紫外線によるDNAの損傷など諸説あるが、血流不足も一因といわれている。優香さんは何度かヘッドマッサージを受けたとき、頭が凝っていると言われたことがある。「頭ならマッサージしやすいから自分でもやろう、と思いつつ、なかなか……。でも、これからは心を改めます」と、髪にいいというセサミオイルを購入し、ヘッドマッサージを始めた。まゆ毛に白髪の里美さんも、「まゆ毛周囲はツボもあって押すと気持ちいいし、目の疲れにもいいから、指圧を心掛けるようになりました」。その後の改善につながるかはまだなんともいえないが、体のためにはプラスであるはずだ。自分とはまだまだ関係のない話、と思っているあなたも、ひょっとしたら明日は我が身！？ 偏食や不規則でストレスフルな生活を送っていると、白髪を増やすかも？ 髪もムダ毛も体の一部。白髪になってからではなく、普段からいたわっていきましょう。（オフィスエムツー／オオノマキ） 4.抽出したドキュメントを分かち書き処理 続いて、抽出した5つのドキュメントを分かち書きし、リストに格納します。 抽出した5つのドキュメントを分かち書きしてリストに格納1234token = []t = Tokenizer()for i in range(6): token.append(t.tokenize(docs[i], wakati=True,)) list(token[0])を実施すると以下のような出力が得られ、分かち書きができていることが確認できます。 12345678910111213141516171819202122232425262728293031323334353637383940414243['東京', '23', '区', '女', 'ひとり', '風呂', ' ', 'vol', '.', '03', '「', '台東', '区', '・', '銭湯', 'で', 'アレ', (省略) '）', '「', 'あやしい', '人', 'に', '遭っ', 'て', 'き', 'まし', 'た', '。', '」', '（', 'ぶんか社', '）', '絶賛', '発売', '中', '。'][24]153426 5. Doc2Vecの実装 doc2vecを用いて学習を行い、モデルを作成します。 まずは学習用のデータを整備します。 123456from gensim.models.doc2vec import Doc2Vecfrom gensim.models.doc2vec import TaggedDocumenttraining_docs = []for i in range(6): training_docs.append(TaggedDocument(words=list(token[i]), tags=[&quot;d&quot; + str(i)])) 上記のコードの説明をします。 Doc2Vecの実装には、gensimというモジュールを使用します。 また、学習用のデータを用意するために、TaggedDocumentを使用します。 training_docsという空のリストを作成します。 TaggedDocumentの引数にwords=&quot;分かち書きされた各要素&quot;, tags=[&quot;タグ&quot;]を与えることで、TaggedDocumentクラスのインスタンスを作成することができます。 training_docsというコードを実行すると、以下のような出力が確認できると思います。 出力123456[TaggedDocument(words=['東京', '23', '区', '女', 'ひとり', '風呂', ' ', 'vol', '.', '03', '「', '台東', '区', '・', '銭湯', 'で', 'アレ', '発見', '！', '」', 'Presented', ' ', 'by', ' ', 'ゆる', 'っと', 'cafe', '独', '女', 'の', 'みなさん', '、', 'こんにちは', '。', '突然', 'です', 'が', '、', '江戸', '時代', 'の', '銭湯', 'って', '、', '男女', '混浴', 'だっ', 'た', 'ん', 'です', 'って', '！', '老若男女', '入り乱れ', '、', 'ここ', 'も', 'アソコ', 'も', '洗い', 'あい', '、', '奥', 'で', 'は', 'イチャイチャ', 'し', 'てる', '人影', '。', '相手', 'も', 'ない', 'のに', 'ムラムラ', 'し', 'ちゃっ', 'たら', '、', '垢', 'を', '掻い', 'て', 'くれる', '湯女', 'が', '別室', 'で', 'サービス', 'し', 'て', 'くれ', 'て', '…', '。', '砂', 'っぽかっ', 'た', '江戸', 'の', '町', 'は', '、', '日', 'に', '2', '度', '3', '度', 'と', '銭湯', 'に', 'つかる', 'こと', 'も', '多かっ', 'た', 'そう', 'です', 'から', '、', 'いや', 'はや', '、', '想像', 'する', 'だけ', 'で', 'ワクワク', 'し', 'ちゃい', 'ます', 'よ', 'ねぇ', '！', 'え', '…', '私', '、', '飢え', 'すぎ', '？', '\\u3000', 'そ', '、', 'そんな', 'こと', 'は', '…', '…', '\\u3000', '\\u3000', 'こんな', '話', 'を', 'し', 'た', 'ワケ', 'は', '、', '先日', '訪れ', 'た', '台東', '区', 'の', '「', '燕', '湯', '」', 'に', '、', '金', '精', '様', 'が', 'あっ', 'た', 'から', 'なん', 'です', '。', '金', '精', '様', 'と', 'は', '、', '男性', '器', 'の', '形', 'を', 'し', 'た', '神様', '。', '子宝', 'の', '神', 'として', '各地', 'に', '祀ら', 'れ', 'て', 'いる', 'ほか', '、', '昔', 'は', 'たくさん', 'の', '女', '湯', 'に', '、', 'チン', '座', '…', 'いや', '、', '鎮座', 'まし', 'まし', 'て', 'い', 'た', 'そう', 'です', '。', '銭湯', 'めぐり', 'を', '始め', 'て', 'から', '、', 'い', 'つ', 'ご', '対面', 'できる', 'か', 'と', '心待ち', 'に', 'し', 'て', 'い', 'た', 'ん', 'です', 'が', '、', 'どこ', 'の', '銭湯', 'に', 'も', '、', 'カゲ', 'も', 'カタチ', 'も', 'なし', '。', 'これ', 'だ', 'から', '近代', '的', '理性', 'って', 'ヤボ', 'だ', 'わ', 'と', '思っ', 'て', 'い', 'た', '矢先', '、', 'ようやく', '、', '謁見', 'が', 'かない', 'まし', 'た', '。', 'いやー', '、', '心願', '成就', '！', '\\u3000', 'ところで', 'この', '金', '精', '様', '、', '温泉', 'に', '祀ら', 'れる', 'こと', 'も', '多かっ', 'た', 'そう', 'です', '。', '古来', 'より', '女', '陰', 'の', '象徴', 'と', 'さ', 'れ', 'て', 'いる', '温泉', 'に', '男根', 'を', '祀る', 'こと', 'で', '、', 'その', '湯', 'が', '尽き', 'ぬ', 'よう', 'に', '祈っ', 'て', 'い', 'た', 'ん', 'です', 'ね', '。', '銭湯', 'も', 'これ', 'に', 'あやかっ', 'て', 'いる', 'と', '考え', 'て', '、', '間違い', 'は', 'な', 'さ', 'そう', '。', 'つまり', '銭湯', 'は', '、', '男女', 'の', 'マグワイ', 'の', '象徴', 'で', 'あり', '、', '混浴', 'で', 'あり', '、', '湯女', 'の', 'いる', '場', 'で', 'あり', '…', '。', 'ま', 'ー', 'な', 'ん', 'だ', '、', '生', 'と', '性', 'の', '巨大', 'な', '隠喩', 'でも', 'あっ', 'た', 'の', 'で', 'は', 'ない', 'か', '、', 'と', '。', '\\u3000', 'そう', '考える', 'と', '、', '銭湯', 'も', 'ただ', 'の', '風呂', 'で', 'は', 'ない', 'ワケ', 'で', '、', '今', 'から', '混浴', 'に', '戻せ', 'と', 'いう', 'の', 'は', 'ムリ', 'でも', '、', '金', '精', '様', 'の', '存在', 'は', '、', 'もう', 'ちょっと', '重き', 'を', '置い', 'て', 'も', 'いい', 'ん', 'じゃ', 'ない', 'か', 'と', '思う', 'の', 'です', '。', '\\u3000', '…', 'いや', '、', '女', '湯', 'に', '金', '精', '様', 'が', 'あっ', 'たら', '楽しい', 'なっ', 'て', '、', 'それだけ', 'の', '話', 'な', 'ん', 'です', 'けど', 'ね', '…', '\\u3000', 'それ', 'は', 'ともかく', '、', '一緒', 'に', '燕', '湯', 'に', '行っ', 'た', '担当', '編集', 'の', 'Ｎ', '島', 'さん', 'の', '、', '臆面', 'も', 'ない', '金', '精', '様', 'の', '撫で', 'っぷり', 'は', 'すごかっ', 'た', '。', '私', 'なんて', '、', '口', 'だけ', 'だ', 'もの', 'ね', '。', 'やっぱり', '子持ち', 'は', '違う', 'なぁ', 'と', '感じ', 'た', '、', '独', '女', 'の', '小沢', 'で', 'あり', 'まし', 'た', '。', '●', '小沢', 'カオル', '：', '独身', 'アラフォー', '漫画', '家', '。', 'ダメ', '男', 'に', 'ひっかかり', 'やすい', '。', '現在', 'の', '恋人', 'は', '小次郎', '（', '柴犬', '）', '。', '主', 'に', '突撃', '取材', '系', 'の', 'マンガ', 'を', '執筆', '。', '「', 'あやしい', '取材', 'に', '逝っ', 'て', 'き', 'まし', 'た', '。', '」', '「', 'あやしい', '男', 'と', '失恋', 'って', 'き', 'まし', 'た', '。', '」', '（', 'ともに', '秋田', '書店', '）', '「', 'あやしい', '人', 'に', '遭っ', 'て', 'き', 'まし', 'た', '。', '」', '（', 'ぶんか社', '）', '絶賛', '発売', '中', '。'], tags=['d0']), TaggedDocument(words=['意外と', '知ら', 'ない', '我が家', 'の', 'ルーツ', '！', ' ', '新年', '会', 'で', 'ご', '先祖', '様', 'トーク', 'は', 'いかが', '？', '新年', '会', 'など', 'で', '、', '祖父母', 'や', '親戚', 'と', '顔', 'を', '合わせる', '機会', 'が', '多い', 'お正月', '。', '「', '結婚', 'は', 'まだ', '？', '」', '「', 'そろそろ', '両親', 'を', '安心', 'さ', 'せ', 'て', 'あげ', 'たら', '」', 'といった', '話題', 'に', 'うんざり', 'し', 'て', '、', '話', 'の', '流れ', 'を', '変え', 'たく', 'なっ', 'た', 'とき', '、', '意外と', '役立つ', 'の', 'が', '一族', 'の', 'ルーツ', 'や', 'ご', '先祖', '様', 'の', 'お話', 'だ', '。', '祖父母', 'や', '親戚', 'の', '年長', '者', 'を', '話', 'の', '中心', 'に', 'する', 'こと', 'で', '、', '新年', '会', 'の', '雰囲気', 'も', '変わる', 'だろ', 'う', '。', '昨年', 'の', 'お正月', '、', '久しぶり', 'に', '親戚', 'の', '新年', '会', 'に', '出席', 'し', 'た', '美也子', 'さん', '(', '38', '歳', '・', '看護', '士', '）', 'は', '、', '父方', 'の', '伯父', 'から', '一族', 'の', 'ルーツ', 'を', '初めて', '聞い', 'た', '。', '「', '伯父', 'に', 'よる', 'と', '、', '大昔', '、', '私', 'たち', 'の', 'ご', '先祖', '様', 'は', '都', 'で', 'おこっ', 'た', '仏教', '派', 'と', '国神', '派', 'の', '戦い', 'に', '負け', 'て', '、', '武蔵', '国', 'に', '追わ', 'れ', 'て', 'き', 'た', 'そう', 'です', '。', '負け', 'た', '側', 'へ', 'の', '罰', 'として', '名前', 'を', '変え', 'られ', 'て', '、', '今', 'の', '名字', 'に', 'なっ', 'た', 'の', 'だ', 'と', 'か', '。', '後で', '調べ', 'て', 'み', 'たら', '、', '飛鳥', '時代', 'に', '仏教', 'の', '礼拝', 'を', '巡っ', 'て', '起こっ', 'た', '『', '丁未', 'の', '乱', '』', 'という', '内乱', 'が', 'あっ', 'た', 'ん', 'です', 'よ', '。', 'これ', 'だ', '！', ' ', 'と', '思い', 'まし', 'た', '」', '武蔵', '国', 'に', '来', 'た', '美也子', 'さん', 'の', 'ご', '先祖', '様', 'は', '、', 'やがて', '広大', 'な', '土地', 'を', '手', 'に', 'いれ', '豊か', 'な', '暮らし', 'を', 'し', 'て', 'い', 'た', 'の', 'だ', 'が', '、', '長い', '歴史', 'の', '中', 'に', 'は', '博打', '好き', 'の', '人', 'も', 'い', 'て', '、', '土地', 'の', 'ほとんど', 'を', '失っ', 'た', 'らしい', '…', '。', '古い', '家系', '図', 'も', 'あっ', 'た', 'が', '預け', 'て', 'い', 'た', 'お寺', 'の', '火災', 'で', '焼け', 'て', 'しまい', '、', '今', 'と', 'なっ', 'て', 'は', '詳細', 'な', 'こと', 'は', 'わから', 'ない', '…', '。', '「', '正直', 'な', 'ところ', '、', 'どこ', 'まで', '本当', 'な', 'の', 'か', 'わかり', 'ませ', 'ん', 'が', '、', '自分', 'の', '家系', 'が', '遥か', '昔', 'から', '続い', 'て', 'いる', 'と', '思う', 'だけ', 'で', 'ワクワク', 'し', 'ます', '」', 'と', '美也子', 'さん', 'は', '話し', 'て', 'くれ', 'た', '。', 'ここ', 'まで', '歴史', 'を', 'さかのぼる', '話', 'は', 'そう', 'そう', '多く', 'は', 'ない', 'だろ', 'う', '。', 'しかし', '、', '30', '代', 'の', '独', '女', 'なら', '祖父', 'の', 'その', 'また', '祖父', 'の', '時代', 'は', '幕末', 'か', '明治', '初頭', 'くらい', '。', '小説', 'や', 'ドラマ', 'で', 'しか', '知ら', 'ない', '時代', 'に', '、', '自分', 'の', 'ご', '先祖', '様', 'や', '縁', 'の', 'ある', '人', 'が', '生き', 'て', 'い', 'た', 'と', 'いう', 'だけ', 'でも', '、', 'なんだか', '嬉しく', 'なっ', 'て', 'くる', '。', '先日', '、', '都内', 'で', '編集', 'の', '仕事', 'を', 'し', 'て', 'いる', '真琴', 'さん', '（', '42', '歳', '）', 'は', '、', '伯母', 'に', '「', '仕事', 'で', '鹿児島', 'へ', 'よく', '行く', '」', 'と', '話し', 'た', 'ところ', '「', 'あら', '、', 'ウチ', 'の', 'ご', '先祖', '様', 'に', 'も', '鹿児島', 'の', '人', 'が', 'いる', 'の', 'よ', '」', 'と', '言わ', 'れ', 'た', 'そう', 'だ', '。', '「', '明治', 'の', '初め', 'に', '、', '埼玉', 'で', '先祖', '代', '々', '農家', 'を', '続け', 'て', 'いる', '曾祖父', 'の', '父', 'の', '元', 'に', '、', '薩摩', '藩', 'の', '江戸', '屋敷', 'で', '生まれ', '育っ', 'た', '女性', 'が', '嫁い', 'で', 'き', 'た', 'そう', 'です', '。', '廃藩置県', 'で', '一', '度', 'は', '鹿児島', 'に', '戻っ', 'た', 'ものの', '、', '言葉', 'も', 'わから', 'ず', '鹿児島', 'の', '生活', 'に', 'も', '馴染め', 'なく', 'て', '、', '江戸', 'に', '戻っ', 'て', 'き', 'た', 'の', 'だ', 'と', 'か', '。', '実は', '、', '近所', 'に', '徳川', 'に', '縁', 'の', 'ある', '神社', 'が', 'ある', 'ん', 'です', 'よ', '。', 'もしか', 'し', 'たら', '篤', '姫', 'が', '、', 'その', '女性', 'の', '嫁ぎ', '先', 'として', '曾祖父', 'の', '父', 'を', '選ん', 'で', 'くれ', 'た', 'の', 'か', 'な', '？', ' ', 'なんて', '想像', 'し', 'ちゃい', 'まし', 'た', '」', 'と', '真琴', 'さん', 'は', '話し', 'て', 'くれ', 'た', '。', '「', '食べ物', 'の', '話題', 'から', '、', '曾祖母', 'や', 'その', '姉妹', 'の', 'こと', 'を', '知っ', 'た', '」', 'という', 'の', 'は', '美鈴', 'さん', '（', '30', '歳', '・', '会社', '員', '）', 'だ', '。', '「', '子ども', 'の', '頃', 'に', 'どんな', 'もの', 'を', '食べ', 'て', 'い', 'た', 'か', '？', ' ', 'という', '話', 'に', 'なっ', 'た', 'とき', '、', '九州', 'の', '小さな', '町', 'で', '育っ', 'た', '祖父', '（', '90', '歳', '）', 'が', '『', '子ども', 'の', '頃', 'から', '、', 'カレー', 'や', 'シチュー', 'を', '食べ', 'て', 'い', 'た', 'よ', '』', 'と', '言い', 'はじめ', 'て', '…', '。', 'よく', 'よく', '話', 'を', '聞い', 'たら', '、', '曾祖母', 'と', 'その', '姉妹', 'は', '結婚', 'する', 'まで', 'の', '間', '、', '中国', '大陸', 'で', '旅館', 'の', '仕事', 'を', '手伝っ', 'て', 'い', 'て', '、', 'そこで', 'カレー', 'や', 'シチュー', 'の', '作り方', 'を', '覚え', 'た', 'という', 'こと', 'が', 'わかり', 'まし', 'た', '」', '旅館', 'の', '主', 'な', 'お客様', 'は', '軍', '関係', '者', 'で', '、', '味付け', 'は', '関東', '風', 'だっ', 'た', 'と', 'か', '。', '「', '九州', 'の', '祖父', 'の', '家', 'で', '食べる', 'お', '雑煮', 'は', '関東', '風', 'な', 'ん', 'です', '。', '料理', 'の', '味付け', 'に', 'も', '、', '曾祖母', 'の', '体験', 'という', 'か', '人生', 'が', '関わっ', 'て', 'いる', 'ん', 'です', 'ね', '」', 'と', '美鈴', 'さん', 'は', '話し', 'て', 'くれ', 'た', '。', '今', '、', '自分', 'が', 'ここ', 'に', 'いる', 'の', 'は', '両親', 'が', 'い', 'て', '、', '祖父母', 'が', 'い', 'て', '、', '曾祖', '父母', 'が', 'い', 'て', '…', '。', 'そう', '思う', 'だけ', 'で', '、', 'たくさん', 'の', '人', 'に', '守ら', 'れ', 'て', 'いる', 'よう', 'な', '気', 'が', 'し', 'て', 'くる', '。', '親戚', 'が', '顔', 'を', '会わ', 'せる', 'お正月', 'だ', 'から', 'こそ', '、', '改めて', 'ご', '先祖', '様', 'トーク', 'を', 'し', 'て', 'みよ', 'う', '。', '子ども', 'の', '頃', 'は', '理解', 'でき', 'なかっ', 'た', 'ルーツ', 'や', '、', '今', 'まで', '知ら', 'なかっ', 'た', 'ご', '先祖', '様', 'の', '武勇', '伝', 'が', '飛び出す', 'かも', 'しれ', 'ない', '。', '（', 'オフィスエムツー', '／', '神田', 'はる', 'ひ', '）'], tags=['d1']), TaggedDocument(words=['既婚', 'の', '女', '友達', 'に', 'ムカッ', '！', 'と', 'する', 'こと', '片や', '仕事', 'を', '辞め', '、', '育児', 'に', '真っ最中', 'の', '主婦', '。', '片や', 'しばらく', '結婚', 'の', '予定', 'の', 'ない', '独身', 'の', 'キャリアウーマン', '。', 'かつて', 'は', 'よき', '友情', '関係', 'を', '育ん', 'で', 'い', 'た', '者', '同士', 'が', '、', '違う', '立場', 'に', '置か', 'れ', 'て', '久しく', '時間', 'が', '経つ', 'と', '、', '会話', 'が', 'かみ合わ', 'なく', 'なっ', 'て', 'しまう', 'こと', 'が', 'ある', '地方', 'に', '嫁い', 'だ', '友人', 'の', '家族', 'トーク', 'に', 'うんざり', 'し', 'た', 'の', 'は', '好美', 'さん', '（', '34', '歳', '）', '。', '「', '出張', 'の', '帰り', 'だっ', 'た', 'ん', 'です', 'が', '、', '久しぶり', 'に', '会い', 'たく', 'なっ', 'て', '彼女', 'の', '家', 'まで', '足', 'を', '延ばし', 'た', 'ん', 'です', '。', 'ところが', '共通', 'の', '友人', 'の', 'こと', 'など', '、', 'どんな', '話題', 'を', '持ち出し', 'て', 'も', '彼女', 'は', 'ほとんど', 'スルー', '。', '自分', 'の', '子ども', 'の', '話', 'に', 'しか', '興味', 'を', '示さ', 'ない', 'ので', '、', 'どうして', 'いい', 'か', 'わから', 'なく', 'なり', 'まし', 'た', '。', '確か', 'に', '子ども', 'は', 'かわいい', 'の', 'です', 'が', '、', '他人', 'は', '、', '他人', 'の', '子', 'に', '親', '以上', 'の', '興味', 'は', '持た', 'ない', 'もの', '。', 'もう少し', '配慮', 'を', 'し', 'て', 'ほしかっ', 'た', '」', '赤ちゃん', 'を', '産ん', 'だ', '元', '同級生', 'の', '家', 'に', '遊び', 'に', '行っ', 'た', '晴美', 'さん', '（', '33', '歳', '）', 'は', '、', '発育', '相談', 'を', 'もちかけ', 'られ', 'て', '返答', 'に', '困っ', 'た', 'と', 'いう', '。', '「', '友人', 'に', '『', '子ども', 'が', 'まだ', '寝返り', 'が', 'でき', 'ない', 'の', '』', 'と', '言わ', 'れ', 'た', 'ので', '『', 'そのうち', 'する', 'ん', 'じゃ', 'ない', '？', '』', 'と', '気楽', 'に', '答え', 'たら', '、', '『', '親', 'の', '気持ち', 'が', 'わから', 'ない', '』', 'と', 'ムッ', 'と', 'し', 'た', '表情', 'で', '返さ', 'れ', 'まし', 'た', '。', '赤ちゃん', 'が', '寝返り', 'する', '時期', 'なんて', '知ら', 'ない', 'し', '、', '子ども', 'が', 'い', 'ない', 'ので', '、', '正直', '、', '心配', 'する', 'ママ', 'の', '気持ち', 'も', 'よく', 'わから', 'ない', '。', 'なんて', '回答', 'すれ', 'ば', 'よかっ', 'た', 'ん', 'でしょ', 'う', 'か', '？', '」', '育児', '熱心', 'な', 'の', 'は', '幸せ', 'の', '裏返し', 'かも', 'しれ', 'ない', 'が', '、', 'トーク', 'で', '置いてきぼり', 'に', 'さ', 'れ', 'て', 'は', 'かなわ', 'ない', '。', 'とくに', '独身', '女性', 'が', '既婚', '女性', 'の', '間', 'に', '挟ま', 'れる', 'と', '、', '一', '歩', 'も', '二', '歩', 'も', 'おせっかい', 'を', '焼き', 'た', 'がる', '人', 'が', '出', 'て', 'くる', '。', 'これ', 'に', 'は', '既婚', '者', 'で', 'ある', '自分', '自身', 'も', '困惑', 'し', 'た', 'と', '、', '恵美子', 'さん', '（', '37', '才', '）', '。', '「', '現在', '彼氏', 'の', 'い', 'ない', '友人', '・', 'A', '子', 'は', '既', '女', 'から', '、', 'しょっちゅう', '『', '誰', 'か', 'いい', '人', 'い', 'ない', 'の', '？', '』', 'と', '言わ', 'れ', 'て', 'い', 'ます', '。', 'しまいに', 'は', '、', 'みんな', 'で', 'なぜ', 'Ａ子', 'に', 'は', '彼', 'が', 'い', 'ない', 'か', 'という', '議論', 'に', '。', '『', 'もっと', '残業', '減らし', 'て', '婚', '活', 'し', 'たら', '？', '』', 'など', 'ライフスタイル', 'に', 'まで', 'ダメ', '出し', 'を', 'する', 'ん', 'です', 'よ', 'ね', '。', '彼女', '、', 'かつて', 'は', 'お', '付き合い', 'し', 'て', 'いる', '人', 'も', 'い', 'た', 'ん', 'です', 'よ', '。', '黙っ', 'て', '聞い', 'て', 'いる', 'けど', '、', '内心', '、', 'うんざり', 'し', 'て', 'いる', 'の', 'で', 'は', '」', '結婚', '後', 'も', '仕事', 'を', '続け', 'て', 'いる', '恵美子', 'さん', 'は', '現在', '、', '子ども', 'が', 'い', 'ない', '。', 'なか', 'に', 'は', '「', '早く', '産め', '！', '」', 'と', '妊娠', '・', '出産', 'を', 'せかし', 'て', 'くる', '知り合い', 'も', 'いる', 'そう', 'だ', '。', '「', '苦労', 'せ', 'ず', '、', '早く', 'に', '子ども', 'を', '産ん', 'だ', '人', 'に', '多い', 'の', 'が', '『', '早く', '子ども', '産ん', 'だ', 'ほう', 'が', 'いい', 'よ', '。', '年取る', 'と', '大変', 'だ', 'よ', '』', 'という', '発言', '。', '若い', 'ころ', 'に', '授から', 'なかっ', 'た', 'こと', 'を', '今さら', '言わ', 'れ', 'て', 'も', '、', 'どう', 'しよう', 'も', 'あり', 'ませ', 'ん', '。', 'いっぺん', '、', '『', 'アンタ', 'が', '今', 'から', '若返ら', 'せ', 'て', 'くれ', 'ん', 'の', '？', '』', 'と', '言い返し', 'て', 'みたい', 'です', 'ね', '。', 'ああ', 'し', 'た', 'セリフ', 'を', 'サラッ', 'と', '言える', '人', 'は', '鈍感', 'な', 'の', 'かも', '」', '女性', 'の', '体', 'や', '育児', 'の', '負担', 'を', '考える', 'と', '、', '妊娠', '、', '出産', 'に', 'ベター', 'な', '時期', 'が', 'ある', 'の', 'は', 'たしか', '。', '発言', 'する', '側', 'に', '悪意', 'は', 'ない', 'の', 'かも', 'しれ', 'ない', 'が', '、', '無自覚', 'だ', 'から', 'こそ', '相手', 'を', '苛立た', 'せる', 'こと', 'も', 'ある', '。', '「', '自分', 'も', '含め', 'て', '、', '既婚', '女性', 'の', '発言', 'は', '知ら', 'ない', 'うち', 'に', '独身', '者', 'を', '傷つけ', 'て', 'いる', 'こと', 'も', 'あり', 'そう', '。', '自戒', 'しよ', 'う', 'と', '思い', 'まし', 'た', '」', 'と', '恵美子', 'さん', '。', '一方', 'で', '、', '既婚', 'の', '女', '友達', 'と', '上手く', 'つき合っ', 'て', 'いける', 'ケース', 'も', 'ある', '。', '明美', 'さん', '（', '37', '才', '）', 'の', '場合', '、', '「', '『', '既婚', 'だ', 'から', '』', '『', '子持ち', 'だ', 'から', '』', 'で', 'は', 'なく', '『', '友達', 'だ', 'から', '』', 'という', 'スタンス', 'で', '付き合う', 'こと', '」', 'を', '心掛け', 'て', 'いる', '。', '「', '既婚', 'の', '女', '友達', 'と', '遊ぶ', '時', 'は', '、', 'なるべく', '身軽', 'な', '自分', 'が', '動く', 'よう', 'に', 'し', 'ます', '。', '時間', '帯', 'も', '昼間', 'に', 'する', 'など', '、', 'こちら', 'も', '相手', 'の', '家族', 'を', '優先', 'する', '。', 'あと', '必要', '以上', 'に', '相手', 'の', '家庭', 'の', 'こと', 'を', '詮索', 'し', 'たり', 'は', 'し', 'ない', 'よう', 'に', 'し', 'て', 'い', 'ます', 'ね', '。', '自分', 'から', '気遣う', 'と', '、', '相手', 'も', 'あまり', '自己', '中心', '的', 'な', '話題', 'に', '走ら', 'ない', '気', 'が', 'し', 'ます', '。', 'むしろ', '無', '神経', 'で', '扱い', 'づらい', 'の', 'は', '既婚', 'の', '男', '友達', '。', '『', '結婚', 'しろ', 'よ', '』', '『', '早く', '子ども', '産め', 'ば', '』', 'って', '、', '思い出し', 'た', 'よう', 'に', '突然', '言う', 'ん', 'です', 'よ', '。', '嫌気', 'が', 'さして', '疎遠', 'に', 'なっ', 'た', '人', 'も', 'い', 'ます', '」', 'よい', '本', 'や', '音楽', 'を', '見つける', 'と', '、', '他人', 'に', 'も', '薦め', 'たく', 'なる', '。', '結婚', 'や', '出産', 'を', '促す', 'の', 'も', '、', '本人', 'ら', 'が', '「', 'よい', 'もの', '」', 'と', '感じ', 'てる', 'から', 'な', 'の', 'だろ', 'う', '。', 'だけど', '結婚', 'うんぬん', 'の', '話題', 'は', '、', '下手', 'し', 'たら', '人生', 'に対する', '口出し', 'に', 'も', 'なり', 'かね', 'ない', 'リスキー', 'な', 'もの', '。', '丁重', 'に', '扱わ', 'なけれ', 'ば', 'なら', 'ない', 'と', '、', '独身', '、', '既婚', '問わ', 'ず', '肝', 'に', '銘じ', 'たい', '。', '（', '来', '布', '十', '和', '）'], tags=['d2']), TaggedDocument(words=['ひょっと', 'し', 'て', '、', 'あなた', 'は', '浮気', '相手', 'かも', 'あなた', 'は', '、', '彼氏', 'や', '意中', 'の', '人', 'の', '態度', 'や', '素行', 'に対して', '「', '自分', 'は', '本命', 'な', 'の', '？', '」', 'と', '疑問', 'を', '抱い', 'たり', '、', '直感', '的', 'に', '「', '何', 'か', 'おかしい', '…', '」', 'と', '思っ', 'た', 'こと', 'は', 'ない', 'だろ', 'う', 'か', '？', '\\u3000', '一度', '気', 'に', 'なっ', 'て', 'しまう', 'と', '、', 'とことん', '疑い', 'はじめ', 'て', 'しまう', '相手', 'の', '心', '。', 'それ', 'も', 'その', 'はず', '、', '女性', 'は', 'どんなに', '小さな', '出来事', 'も', '記憶', 'に', 'とどめ', 'て', 'おき', '、', '過去', 'から', '現在', 'に', '至る', 'まで', 'の', '全て', 'を', 'データベース', 'に', 'おさめる', '生き物', 'な', 'の', 'だ', '。', '“', '女', 'の', '勘', '”', 'の', '鋭さ', 'は', '霊感', '並み', 'で', '、', 'その', '根底', 'に', 'は', '、', 'この', 'データベース', 'が', 'ある', 'から', 'と', '言える', 'だろ', 'う', '。', '例えば', '、', '歓送', '迎', '会', 'など', '飲み', '会', 'が', 'かなり', 'の', '頻度', 'で', '開催', 'さ', 'れる', 'この', '時期', 'は', '“', '女', 'の', '勘', '”', 'が', 'フル', '稼働', 'する', 'の', 'で', 'は', 'ない', 'だろ', 'う', 'か', '。', '歓迎', '会', 'で', 'は', '新しい', '顔ぶれ', 'に', '妙', 'な', '新鮮味', 'を', '覚え', 'て', 'しまっ', 'たり', '、', '送別', '会', 'で', '普段', 'は', '意識', 'し', 'ない', '相手', 'に対して', '寂寥', '感', 'を', '覚え', 'て', '、', 'つい', '親密', 'に', 'なっ', 'て', 'しまう', '、', 'という', '可能', '性', 'だって', '否定', 'は', 'でき', 'ない', '。', 'そんな', '時期', 'だ', 'から', 'こそ', '相手', 'に', '微妙', 'な', '変化', 'が', 'ある', 'と', '、', '（', '急', 'に', '優しく', 'なっ', 'たり', '、', 'あまり', '目', 'を', '合わせ', 'なく', 'なっ', 'たり', '、', '持ち物', '・', '服', '・', '食べ物', 'の', '好み', 'が', '変わる', 'など', '）', '誰', 'でも', '不安', 'に', 'なる', 'もの', '。', 'そして', '女性', 'の', '多く', 'は', '、', 'すべて', 'の', 'データ', 'の', '中', 'から', '「', 'この', '納得', 'の', 'いか', 'ない', '違和感', 'は', '何', 'な', 'の', 'か', '？', '」', 'という', '情報', 'を', '引き出し', '、', '判断', 'の', '基準', 'に', 'する', 'の', 'だ', '。', '恋人', 'が', 'いる', '方', 'は', '、', 'そんな', '不安', 'を', '抱え', 'ず', 'に', 'すむ', 'よう', 'に', '、', '相手', 'の', '気持ち', 'を', 'しっかり', 'と', '握る', 'こと', 'が', '大切', 'に', 'なっ', 'て', 'くる', '。', 'しかし', '、', '時に', '“', '恋', 'は', '盲目', '”', 'に', 'なる', 'もの', '。', 'そんな', '時', 'に', 'こそ', '気', 'を', 'つけ', 'て', 'いただき', 'たい', 'の', 'が', '、', '自身', 'が', '浮気', '・', '不倫', '相手', 'に', 'なっ', 'て', 'しまっ', 'て', 'い', 'ない', 'か', '、', 'という', 'こと', 'だ', '。', '例えば', '厚生', '労働省', 'の', '「', '2008', '年', '\\u3000', '第', '4', '回', '男女', 'の', '生活', 'と', '意識', 'に関する', '調査', '(', '16', '歳', '〜', '49', '歳', 'の', '男女', '1468', '人', 'を', '対象', ')」', 'に', 'よれ', 'ば', '、', '既婚', '男性', 'における', '「', '過去', '1', '年間', 'に', '複数', 'の', 'パートナー', 'と', '性的', 'な', '関係', 'を', '持っ', 'た', '割合', '」', 'は', '35', '歳', '未満', 'で', 'は', '4', '.', '6', '%、', '35', '歳', '以上', 'は', '15', '.', '8', '%', 'に', 'のぼっ', 'た', 'と', 'いう', '。', 'つまり', '、', '10', '人', 'に', '一', '人', '以上', 'の', '割合', 'で', '男性', 'は', '浮気', '・', '不倫', 'を', 'し', 'て', 'いる', '人', 'が', 'いる', 'という', 'こと', 'だ', '。', '特に', '最近', 'の', '若年', '層', 'の', '男性', 'における', 'セックス', '離れ', 'を', '考える', 'と', '、', '年齢', 'が', '高く', 'なる', 'につれて', '、', '女性', '関係', 'が', '派手', 'な', '男性', 'が', '増加', 'し', 'て', 'いる', 'の', 'で', 'は', 'ない', 'だろ', 'う', 'か', '。', '運', '悪く', '不倫', '相手', 'と', 'なっ', 'て', 'しまっ', 'た', '場合', '、', '男性', 'の', 'パートナー', '(', '相手', 'の', '奥さん', ')', 'から', '訴訟', 'を', '起こさ', 'れ', '、', '損害', '賠償', 'を', '請求', 'さ', 'れる', 'こと', 'も', '無い', '話', 'で', 'は', 'ない', '。', 'ちなみに', 'その', '慰謝', '料', 'は', '心', 'の', '損害', 'で', 'ある', 'こと', 'から', '、', 'ケースバイケース', 'に', 'なる', 'が', '、', 'おおよそ', '50', '万', '円', 'から', '300', '万', '円', 'という', '場合', 'が', '多い', 'と', 'いう', '。', '独', '女', 'の', '方々', 'の', '中', 'に', 'は', '真剣', 'に', '生涯', 'の', 'パートナー', 'を', '探し', 'て', 'いる', '方', 'も', '多い', 'だろ', 'う', '。', 'だからこそ', '、', 'そんな', '心', 'の', '隙間', 'に', '入り込ん', 'で', 'くる', '男性', 'の', '本性', 'を', '見破る', 'こと', 'は', 'とても', '難しい', '。', '最近', 'で', 'は', '特に', '結婚', 'し', 'て', 'い', 'なく', 'て', 'も', '、', '相手', 'に', '浮気', 'や', '不倫', 'の', 'そ', 'ぶり', 'が', 'あれ', 'ば', '、', '探偵', '会社', 'に', '浮気', '調査', 'を', '依頼', 'する', '女性', 'も', '多い', 'と', 'いう', '。', '1', '日', 'だけ', 'の', '調査', 'も', '引き受け', 'て', 'くれる', 'し', '、', 'クレジットカード', '払い', 'も', '可能', 'に', 'なる', 'など', '意外と', '身近', 'に', 'なっ', 'て', 'き', 'た', 'の', 'で', 'は', 'ない', 'だろ', 'う', 'か', '。', '確か', 'に', '、', '万が一', 'に', 'も', '自分', 'が', '不倫', '相手', 'など', 'に', 'なっ', 'て', 'しまっ', 'た', '時', 'の', 'リスク', 'を', '考えれ', 'ば', '、', 'こう', 'いっ', 'た', '調査', 'の', 'プロ', 'に', '依頼', 'し', 'て', 'しまう', 'の', 'も', '一つ', 'の', '賢い', '選択', 'な', 'の', 'かも', 'しれ', 'ない', '。', 'もちろん', '、', 'そういった', '行為', '自体', 'は', '一時', '的', 'に', '相手', 'を', '疑う', 'こと', 'に', 'なっ', 'て', 'しまう', '。', 'しかし', '、', '”', 'シロ', '”', 'と', '分かれ', 'ば', '、', 'より', 'いっそう', 'パートナー', 'を', '信頼', 'する', '裏付け', 'と', 'なる', 'こと', 'は', '間違い', 'ない', 'はず', 'だ', '。', '■', '関連', 'リンク', '探偵', '会社', 'の', '詳細', 'は', 'こちら'], tags=['d3']), TaggedDocument(words=['髪', '以外', 'に', '白髪', '発見', '！', ' ', 'あなた', 'は', 'どこ', 'に', '？', '初めて', '髪', 'に', '「', '白い', '１', '本', '」', 'を', '見つけ', 'た', 'の', 'は', '20', '代', '後半', 'の', 'とき', '、', 'という', '優香', 'さん', '（', '40', '歳', '・', 'コピーライター', '）', '。', '「', '徹夜', 'も', 'よく', 'し', 'て', 'い', 'た', 'し', '、', '当時', 'の', '職場', 'で', 'は', 'いろいろ', 'ストレス', 'を', '感じ', 'て', 'い', 'た', 'ので', '、', 'その', 'せい', 'か', 'と', '思っ', 'て', 'まし', 'た', 'が', '…', '…', '」', '。', '30', '代', '前半', 'で', '退職', 'し', 'フリー', 'に', 'なり', '、', 'ストレス', 'も', 'なくなっ', 'た', 'のに', '白髪', 'は', 'その後', 'も', '増える', '一方', '。', '白髪染め', 'は', '欠か', 'せ', 'なく', 'なっ', 'て', '久しい', '。', '年齢', '的', 'な', 'もの', 'か', 'と', 'あきらめ', 'て', 'は', 'いる', 'が', '、', '友人', 'たち', 'と', '集まっ', 'た', 'とき', '、', 'つい', 'ぼやい', 'て', 'しまっ', 'た', '。', 'ところが', '、', '居合わせ', 'た', '友人', 'から', 'は', '意外', 'な', '告白', 'が', 'あっ', 'た', 'と', 'いう', '。', '頭髪', 'の', '白髪', 'は', '数', '本', '、', 'という', '智子', 'さん', '（', '38', '歳', '・', 'デザイナー', '）', 'は', '、', '「', '髪', 'も', '気', 'に', 'なる', 'けど', 'ね', '、', '実は', '…', '…', '」', 'と', '切り出し', 'た', '。', '「', '鼻', 'の', '下', 'の', '産毛', 'が', '気', 'に', 'なっ', 'て', 'い', 'た', 'から', '脱毛', 'に', '通っ', 'て', 'いる', 'の', 'だ', 'けど', '、', '経過', 'は', 'どう', 'か', 'と', '鏡', 'を', '見', 'て', 'い', 'たら', '、', 'なんと', '１', '本', '、', '白髪', 'が', 'あっ', 'た', 'の', 'よ', '〜', '！', '」', '。', '施術', 'は', '、', '黒い', '毛根', 'に', 'ダメージ', 'を', '与える', '光', '脱毛', 'という', 'もの', 'な', 'ので', '、', '「', '白髪', 'だ', 'と', '毛根', 'も', '白い', 'だろ', 'う', 'から', '、', 'ここ', 'だけ', 'は', '脱毛', 'さ', 'れ', 'な', 'さ', 'そう', '…', '…', '」', 'と', '残念', 'そう', 'だっ', 'た', 'と', 'いう', '。', '里美', 'さん', '（', '35', '歳', '・', '編集', '者', '）', 'は', '、', '「', '私', 'だけ', 'じゃ', 'なかっ', 'た', 'ん', 'です', 'ね', '！', ' ', '私', 'の', '場合', 'は', 'まゆ毛', '！', ' ', 'しかも', 'なぜ', 'か', '左', 'だけ', '。', '数え', 'たら', '４', '本', 'も', 'あっ', 'て', 'びっくり', '。', '髪の毛', 'より', 'まゆ毛', 'が', '先', 'に', '白く', 'なる', 'なんて', '…', '…', '」', 'と', '苦笑', '。', '髪', 'は', '黒', '々', 'として', 'い', 'て', '染め', 'て', 'も', 'い', 'ない', '陽子', 'さん', '（', '41', '歳', '・', '整体', '師', '）', 'も', '「', '私', 'は', 'アンダー', 'ヘア', 'に', '１', '本', '」', 'と', '、', '続々', 'カミングアウト', '。', '海外', 'ドラマ', '『', 'SEX', ' ', 'AND', ' ', 'THE', ' ', 'CITY', '』', 'ファン', 'の', '優香', 'さん', 'が', 'それ', 'を', '聞い', 'て', '思い出し', 'た', 'の', 'は', '、', '仲間', 'の', '最年長', 'の', 'サマンサ', 'が', 'アンダー', 'ヘア', 'に', '白髪', 'を', '見つけ', 'ショック', 'を', '受け', 'た', 'エピソード', '。', 'ドラマ', 'で', 'は', '染め', 'て', '失敗', 'し', 'て', 'い', 'た', 'が', '…', '…', '。', 'それで', 'みんな', 'は', 'どう', '対処', 'し', 'た', 'の', 'か', 'と', '聞い', 'て', 'み', 'た', '。', '脱毛', '中', 'の', '智子', 'さん', 'は', '、', '「', '抜く', 'の', 'は', '肌', 'に', 'よく', 'ない', 'と', 'サロン', 'で', '言わ', 'れ', 'た', 'し', '、', '脱毛', '効果', 'も', '薄れる', 'ので', '、', '剃っ', 'て', 'いる', '」', '。', 'あと', 'の', '２', '人', 'は', '抜い', 'た', 'と', 'いう', '。', 'ちなみに', '抜い', 'て', 'も', '、', 'また', 'そこ', 'から', '白髪', 'が', '生え', 'て', 'くる', 'ので', '、', '抜く', 'の', 'は', 'その', '場', 'しのぎ', 'に', 'しか', 'なら', 'ない', '。', '優香', 'さん', 'は', 'みんな', 'の', '話', 'を', '聞い', 'て', '、', '「', '白髪', 'の', '量', 'で', 'いえ', 'ば', '私', 'が', '一番', 'です', 'が', '、', '頭髪', 'は', '染める', 'の', 'が', '手軽', '。', 'みんな', 'より', 'ケア', 'は', '楽', 'な', '方', 'かも', '」', 'と', '思っ', 'た', 'と', 'いう', '。', 'と', 'は', 'いえ', '、', '次に', 'どこ', 'に', '白髪', 'が', '発見', 'さ', 'れる', 'か', 'は', '未知数', 'で', '、', '人', 'ごと', 'で', 'は', 'ない', '。', '「', '男性', 'だっ', 'たら', 'ヒゲ', 'に', '白い', 'もの', 'が', '混じっ', 'て', 'い', 'て', 'も', '大人', 'の', '魅力', 'と', 'も', '取れ', 'ます', 'が', '、', '女', 'は', 'ねえ', '…', '…', '。', '数', '本', 'の', 'うち', 'は', 'まだ', '笑い飛ばせる', 'けど', '、', 'これ', '以上', '増やさ', 'ない', 'に', 'は', 'どう', 'し', 'たら', 'いい', 'ん', 'だろ', 'う', 'って', '、', 'その', 'あと', 'ずいぶん', '話', 'が', '盛り上がり', 'まし', 'た', 'よ', '」', '。', '黒', '々', 'と', 'し', 'た', '髪', 'の', '陽子', 'さん', 'が', '「', '私', 'は', 'よく', '食べ', 'てる', 'けど', '、', '黒い', '食べ物', 'が', 'いい', 'らしい', 'よ', '。', '海藻', '類', 'や', '黒', 'ごま', 'とか', '」', 'と', '言う', 'の', 'が', '妙', 'に', '説得', '力', 'が', 'あっ', 'た', 'そう', 'だ', '。', 'その', 'ほか', '、', '牡蛎', 'や', 'シジミ', 'に', '含ま', 'れる', '亜鉛', 'や', 'カルシウム', 'など', 'の', 'ミネラル', 'も', 'いい', 'と', 'いう', '。', '白髪', 'の', '原因', 'に', 'は', 'まだ', '謎', 'が', '多く', '、', '加', '齢', 'の', 'ほか', '遺伝', '、', 'ストレス', '、', '紫外線', 'による', 'DNA', 'の', '損傷', 'など', '諸説', 'ある', 'が', '、', '血', '流', '不足', 'も', '一因', 'と', 'いわ', 'れ', 'て', 'いる', '。', '優香', 'さん', 'は', '何', '度', 'か', 'ヘッド', 'マッサージ', 'を', '受け', 'た', 'とき', '、', '頭', 'が', '凝っ', 'て', 'いる', 'と', '言わ', 'れ', 'た', 'こと', 'が', 'ある', '。', '「', '頭', 'なら', 'マッサージ', 'し', 'やすい', 'から', '自分', 'で', 'も', 'やろ', 'う', '、', 'と', '思い', 'つつ', '、', 'なかなか', '…', '…', '。', 'でも', '、', 'これから', 'は', '心', 'を', '改め', 'ます', '」', 'と', '、', '髪', 'に', 'いい', 'という', 'セサミオイル', 'を', '購入', 'し', '、', 'ヘッド', 'マッサージ', 'を', '始め', 'た', '。', 'まゆ毛', 'に', '白髪', 'の', '里美', 'さん', 'も', '、', '「', 'まゆ毛', '周囲', 'は', 'ツボ', 'も', 'あっ', 'て', '押す', 'と', '気持ちいい', 'し', '、', '目', 'の', '疲れ', 'に', 'も', 'いい', 'から', '、', '指圧', 'を', '心掛ける', 'よう', 'に', 'なり', 'まし', 'た', '」', '。', 'その後', 'の', '改善', 'に', 'つながる', 'か', 'は', 'まだ', 'なんとも', 'いえ', 'ない', 'が', '、', '体', 'の', 'ため', 'に', 'は', 'プラス', 'で', 'ある', 'はず', 'だ', '。', '自分', 'と', 'は', 'まだまだ', '関係', 'の', 'ない', '話', '、', 'と', '思っ', 'て', 'いる', 'あなた', 'も', '、', 'ひょっとしたら', '明日', 'は', '我が身', '！', '？', '\\u3000', '偏食', 'や', '不規則', 'で', 'ストレス', 'フル', 'な', '生活', 'を', '送っ', 'て', 'いる', 'と', '、', '白髪', 'を', '増やす', 'かも', '？', '\\u3000', '髪', 'も', 'ムダ', '毛', 'も', '体', 'の', '一部', '。', '白髪', 'に', 'なっ', 'て', 'から', 'で', 'は', 'なく', '、', '普段', 'から', 'いたわっ', 'て', 'いき', 'ましょ', 'う', '。', '（', 'オフィスエムツー', '／', 'オオノマキ', '）'], tags=['d4']), TaggedDocument(words=['広がる', 'お', 'ひとり', 'さま', 'の', '行動', '網', '！', '一', '人', 'で', 'ライブ', '参戦', '！', '着実', 'に', '広がり', 'つつ', 'ある', '女性', 'たち', 'の', '一', '人', '行動', '網', '。', '今や', '一', '人', 'カフェ', 'は', '当たりまえ', 'だ', 'し', '、', '一', '人', '牛', '丼', 'や', '一', '人', '焼き肉', '、', '一', '人', '居酒屋', 'が', 'OK', 'という', '女性', 'も', '確実', 'に', '増え', 'て', 'いる', '。', '6', '月', '3', '日', 'に', '放送', 'さ', 'れ', 'た', 'NHK', '「', '50', 'ボイス', '」', 'で', 'は', '、', '一', '人', 'で', 'キャンプ', 'や', '登山', 'など', '、', 'アウトドア', 'を', '楽しむ', '女性', 'が', '次々', 'に', '紹介', 'さ', 'れ', '、', 'その', '行動', '力', 'や', '明る', 'さ', 'に', '驚かさ', 'れ', 'た', '。', 'そんな', '中', '、', '私', 'が', '気', 'に', 'なっ', 'て', 'いる', 'の', 'は', '、', '一', '人', 'で', 'ライブ', 'に', '参加', 'する', '女性', 'たち', 'の', 'こと', '。', ' ', '行く', '前', 'と', '後で', 'は', '、', '敷居', 'の', '高', 'さ', 'が', '驚く', 'ほど', '変わる', 'らしい', '。', '「', '話す', '人', 'が', 'い', 'ない', '寂し', 'さ', 'を', '感じる', 'の', 'は', '、', 'ライブ', 'が', '始まる', '前', 'くらい', '。', 'それ', 'も', 'メール', 'を', 'し', 'たり', '、', '音楽', 'を', '聞い', 'たり', 'すれ', 'ば', 'あっという間', 'です', '。', 'ライブ', 'が', '始まっ', 'て', 'しまえ', 'ば', '、', '楽しい', '！', ' ', 'だけ', 'です', 'よ', '」', 'と', '話し', 'て', 'くれ', 'た', 'の', 'は', '、', '今年', '5', '月', '、', '初めて', '一', '人', 'で', '「', 'ライブ', '参戦', '」', 'し', 'て', 'き', 'た', 'ナナ', 'さん', '（', '28', '歳', '・', '会社', '員', '）', '。', '今', 'まで', '彼', 'や', '友だち', 'と', '一緒', 'に', 'ライブ', 'に', '行く', 'こと', 'は', 'あっ', 'た', 'そう', 'だ', 'が', '…', '。', '「', '一', '人', 'で', 'ライブ', 'に', '来', 'て', 'いる', '人', 'を', '見る', '度', 'に', '、', 'なんか', '寂し', 'そう', 'って', '思っ', 'て', 'い', 'た', 'から', '、', '一', '人', 'で', '参加', 'する', 'の', 'は', '抵抗', 'が', 'あり', 'まし', 'た', '。', 'でも', '、', '実際', 'に', '行っ', 'て', 'み', 'たら', '、', '一緒', 'に', '行っ', 'た', '人', 'が', '楽しん', 'で', 'いる', 'か', 'どう', 'か', '気', 'に', 'し', 'なく', 'て', 'いい', 'ので', '気', 'が', '楽', '！', ' ', '思い切り', '楽しめ', 'まし', 'た', '」', '（', 'ナナ', 'さん', '）', 'ここ', '1', '〜', '2', '年', '、', '一', '人', 'で', 'の', '「', 'ライブ', '参戦', '」', 'が', '増え', 'て', 'いる', 'ムツ', 'ミ', 'さん', '（', '33', '歳', '・', '派遣', '）', 'の', '場合', 'は', '、', '10', '歳', '年下', 'の', '従姉妹', 'が', 'きっかけ', '。', '「', '久しぶり', 'に', '会っ', 'た', '従姉妹', 'から', '、', '一', '人', 'で', '武道', '館', 'や', '味の素', 'スタジアム', 'の', 'ライブ', 'に', '行っ', 'て', 'いる', 'と', '聞い', 'て', 'ビックリ', 'し', 'まし', 'た', '。', '『', '一', '人', 'で', '行っ', 'て', '恐く', 'ない', '？', '』', 'って', '聞い', 'て', '笑わ', 'れ', 'まし', 'た', 'よ', '。', '『', '一', '人', 'で', '来', 'て', 'いる', '女の子', 'も', '普通', 'に', '見かける', 'よ', '』', 'って', '言わ', 'れ', 'ちゃい', 'まし', 'た', '」', 'と', 'ムツ', 'ミ', 'さん', '。', 'その後', '、', '一', '人', 'で', 'ライブ', 'に', '行く', 'コツ', 'を', '従姉妹', 'から', '教わっ', 'た', 'の', 'だ', 'と', 'か', '。', '「', '初めて', '一', '人', 'で', 'ライブ', 'に', '行く', 'なら', '、', '小さい', '会場', 'より', '大きな', '会場', '、', 'スタンディング', 'より', '座席', '指定', 'が', 'いい', 'とか', 'アドバイス', 'し', 'て', 'もらい', 'まし', 'た', '。', '『', '大好き', 'な', 'アーティスト', 'の', 'ライブ', 'を', '一緒', 'に', '行く', '人', 'が', 'い', 'ない', 'っていう', 'だけ', 'で', '、', 'あきらめ', 'たく', 'ない', 'じゃ', 'ない', '』', 'という', '従姉妹', 'の', '言葉', 'が', '忘れ', 'られ', 'ませ', 'ん', '」', '最近', 'は', '、', 'SNS', 'や', 'ファン', 'サイト', 'の', '掲示板', 'を', '上手', 'に', '使っ', 'て', '、', 'ライブ', 'を', '楽しん', 'で', 'いる', '女性', 'も', '多い', '。', 'アサコ', 'さん', '（', '28', '歳', '・', '医療', '関連', '）', 'も', 'そんな', '女性', 'の', '一', '人', '。', '「', '私', 'の', '場合', 'は', '、', '身近', 'に', '同じ', 'アーティスト', 'を', '好き', 'な', '友だち', 'が', 'い', 'ない', 'ので', '、', '基本', 'は', '『', '一', '人', '参戦', '』', 'です', 'が', '、', '会場', 'で', 'mixi', 'の', 'コミュニティ', 'で', '知り合っ', 'た', '北海道', 'や', '大阪', 'の', '友だち', 'と', '会う', 'こと', 'も', '多い', 'です', '。', '普段', 'は', 'ネット', 'で', '話し', 'て', 'いる', '友だち', 'と', 'リアル', 'で', '会える', 'の', 'も', '、', 'ライブ', 'の', '楽しみ', 'の', 'ひとつ', 'です', '」', 'と', '話し', 'て', 'くれ', 'た', '。', 'アサコ', 'さん', 'は', '、', '一', '人', 'で', 'ライブ', 'に', '来', 'て', 'いる', 'らしい', '女性', 'を', '見かける', 'と', '積極', '的', 'に', '声', 'を', 'かける', '。', '「', '同じ', 'アーティスト', 'が', '好き', 'だ', 'から', '、', 'すぐ', 'に', '意気投合', 'する', 'こと', 'が', '多い', 'です', 'し', '、', 'ライブ', 'の', '後', '、', '初対面', 'の', '人', 'と', '駅', 'まで', '語りあっ', 'た', 'こと', 'も', 'あり', 'ます', '。', '最近', 'は', '、', '韓国', '人', 'の', '女の子', 'と', '知り合い', 'に', 'なり', 'まし', 'た', '。', 'その', 'アーティスト', 'が', '大好き', 'で', '、', '日本', 'に', '留学', 'し', 'て', 'いる', 'そう', 'です', '。', '初対面', 'で', 'も', 'お互い', '一', '人', 'だ', 'から', '話し', 'やすい', 'の', 'かも', 'しれ', 'ませ', 'ん', '」', '（', 'アサコ', 'さん', '）', 'アーティスト', 'によって', 'ライブ', 'の', '雰囲気', 'は', 'かなり', '違う', '。', 'ファン', 'の', '年齢', '層', 'によって', 'も', '、', '雰囲気', 'も', '変わっ', 'て', 'くる', '。', '始めて', '会っ', 'た', 'ファン', '同士', 'で', 'も', '、', 'すぐ', 'に', '意気投合', 'できる', 'ライブ', 'も', '少なく', 'ない', '。', 'ただ', '、', 'コア', 'な', 'ファン', 'で', 'ガッチリ', '固め', 'られ', 'た', 'ライブ', 'の', '場合', 'は', '、', '「', '一', '人', 'ライブ', '初心者', '」', 'に', 'は', 'ハードル', 'が', '高い', 'だろ', 'う', '。', 'また', '、', '「', 'ファン', 'の', 'マナー', 'が', '悪い', '」', 'という', '評判', 'が', 'ある', 'ライブ', 'に', '「', '一', '人', '参戦', '」', 'する', 'とき', 'は', '、', 'それなり', 'の', '注意', 'が', '必要', 'かも', 'しれ', 'ない', '。', 'ライブ', 'の', '雰囲気', 'が', '気', 'に', 'なる', 'とき', 'は', '、', 'アーティスト', '名', '+', 'ライブ', '、', 'もしくは', 'ライブ', 'レポート', 'で', '検索', 'する', 'の', 'が', 'お', 'ススメ', '。', 'ライブ', 'レポート', 'が', '書か', 'れ', 'た', 'ブログ', 'が', '多数', 'ヒット', 'する', 'だろ', 'う', '。', '50', '代', 'の', '知人', '女性', 'は', '、', '今年', '始め', 'て', '一', '人', 'で', 'B', &quot;'&quot;, 'z', 'の', 'ライブ', 'に', '行く', 'と', 'いう', '。', '偶然', '見', 'た', 'B', &quot;'&quot;, 'z', 'の', '情報', '交換', 'サイト', 'で', '、', '同', '世代', 'の', '人', 'が', 'ライブ', 'に', '参加', 'し', 'て', 'いる', 'って', '知っ', 'て', '、', 'い', 'て', 'も', '立っ', 'て', 'も', 'い', 'られ', 'なく', 'なっ', 'た', 'そう', 'だ', '。', '「', 'ファン', '歴', 'は', '長い', 'のに', '、', 'ライブ', 'に', '行く', 'チャンス', 'が', 'なかっ', 'た', 'の', '。', '20', '代', 'の', '頃', 'だっ', 'たら', '、', 'とても', '一', '人', 'で', '行く', '勇気', 'は', 'なかっ', 'た', 'けど', '、', '人生', 'は', '一', '度', 'きり', 'だ', 'と', '思っ', 'たら', '絶対', 'に', '行き', 'たい', 'と', '思っ', 'た', 'の', 'よ', '」', 'と', '話し', 'て', 'くれ', 'た', '。', 'もうすぐ', '夏', 'フェス', 'の', '季節', 'が', 'やってくる', '。', 'チケット', 'を', '入手', 'し', 'たら', '、', '事前', 'の', '情報', 'を', '十分', 'チェック', '！', ' ', '熱中', '症', '対策', 'も', '抜かり', 'なく', '！', ' ', 'お', 'ひとり', 'さま', 'だって', 'ライブ', 'を', '思い切り', '楽しも', 'う', '！', '（', 'オフィスエムツー', '／', '神田', 'はる', 'ひ', '）', ' ', '■', '関連', '記事', '・', 'ランクづけ', 'に', '見る', '独', '女', 'たち', 'の', 'プライド', '・', '悩ましき', '女', '友だち', 'と', 'の', '格差', '問題', '・', '【', '独', '女', '的', 'コミック', 'レビュー', '】', 'vol', '.', '4', '『', '遠野', '物語', '』', '・', '独', '女', '的', '映画', 'レビュー', ' ', 'vol', '.', '11', '\\u3000', '『', '食べ', 'て', '、', '祈っ', 'て', '、', '恋', 'を', 'し', 'て', '』', '・', 'キス', 'シーン', 'だらけ', 'の', 'DVD', '、', 'あなた', 'は', 'ウットリ', 'し', 'ます', 'か', '？'], tags=['d5'])] 続いて、Doc2Vecを実装します。 先ほどimportしたDoc2Vecをつかって学習するのですが、その際にdocumentsに、配列データとして組み込んだtraining_docsを指定します。 Doc2Vecの実装123456model = Doc2Vec(documents=training_docs, vector_size=100, min_count=1, window=5, epochs=20, dm=1) 各引数は、以下のとおりです。 vector_size: 分散表現の次元数 window: 対象単語を中心とした前途の単語数 min_count: 学習に使う単語の最低出現回数 epochs: エポック数 dm: 学習モデルの指定。dm=0でDBoW。dm=1でdmpv。 6. 類似度計算の実施 作成したdoc2vecのモデルを用いて、類似度計算してみましょう。 ここでは簡単に、doc[0]の文章（「東京23区女ひとり風呂 vol.03「台東区・銭湯でアレ発見！」・・・・」）に対して、他の4つの文章のどれが最も類似度の高いかを算出してみます。 model.docvecs.most_similar(0)とすることで、IDが0の文章、すなわち最初の文章と最も類似度の高い文章が表示されます。 1print(model.docvecs.most_similar(0)) 以下のように出力されるかと思います。 1[('d1', 0.8035883903503418), ('d4', 0.7881282567977905), ('d2', 0.6919220685958862), ('d3', 0.6860525608062744), ('d5', 0.5887612104415894)] このことからid:1の文章が、もっとも類似度が高いことが分かります。 &gt;&gt;自然言語処理を詳しく学ぶならアイデミープレミアムプランがオススメ まとめ: Doc2vecを実装しながら学びました。 本記事は、「【自然言語処理】Google Colaboratoryでdoc2vecを実装してみよう！」というテーマでまとめました。 本ブログでは、word2vecについても実装しながらまとめていますので、興味のある方は以下の記事も参照してください。 &gt;&gt;Word2vecも学ぶ (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20210203\",\"msmaflink\"); msmaflink({\"n\":\"ゼロから作るDeep Learning ❷ ―自然言語処理編\",\"b\":\"オライリー・ジャパン\",\"t\":\"\",\"d\":\"https:\\/\\/m.media-amazon.com\",\"c_p\":\"\\/images\\/I\",\"p\":[\"\\/512wqsxOrsL._SL500_.jpg\",\"\\/41SU1ckdllL._SL500_.jpg\",\"\\/51lj+MrP2qL._SL500_.jpg\",\"\\/51vI04+pgsL._SL500_.jpg\",\"\\/41J-T-vrSOL._SL500_.jpg\",\"\\/51ftkwMoDtL._SL500_.jpg\",\"\\/41V4vxS+N0L._SL500_.jpg\",\"\\/414c8n2HVNL._SL500_.jpg\",\"\\/41cY4JSsbUL._SL500_.jpg\"],\"u\":{\"u\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118360\",\"t\":\"amazon\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"Amazonで見る\",\"u_bc\":\"#f79256\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/dp\\/4873118360\",\"a_id\":2391505,\"p_id\":170,\"pl_id\":27060,\"pc_id\":185,\"s_n\":\"amazon\",\"u_so\":1},{\"id\":2,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/search.rakuten.co.jp\\/search\\/mall\\/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep%20Learning%20%E2%9D%B7%20%E2%80%95%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E7%B7%A8\\/\",\"a_id\":2390941,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":2},{\"id\":3,\"u_tx\":\"Yahoo!ショッピングで見る\",\"u_bc\":\"#66a7ff\",\"u_url\":\"https:\\/\\/shopping.yahoo.co.jp\\/search?first=1\\u0026p=%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep%20Learning%20%E2%9D%B7%20%E2%80%95%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E7%B7%A8\",\"a_id\":2391506,\"p_id\":1225,\"pl_id\":27061,\"pc_id\":1925,\"s_n\":\"yahoo\",\"u_so\":3}],\"eid\":\"EciGF\",\"s\":\"s\"}); リンク また、基礎から応用まで自然言語処理を学んでみたいという方は、以下のUdemyの講座がおすすめです。 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 Udemyは、30日間返金保証付きで、視聴期限が無期限のオンライン学習プラットフォームです。 自然言語処理以外にも、世界中の一流エンジニアが様々なICT技術に関する講義動画を提供してくれていますので、興味のある方はUdemyが提供している講座を確認してみてください。","link":"/doc2vec-python/"}],"tags":[{"name":"datascience","slug":"datascience","link":"/tags/datascience/"},{"name":"4Kディスプレイ","slug":"4Kディスプレイ","link":"/tags/4K%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"ダイエット","slug":"ダイエット","link":"/tags/%E3%83%80%E3%82%A4%E3%82%A8%E3%83%83%E3%83%88/"},{"name":"サプリメント","slug":"サプリメント","link":"/tags/%E3%82%B5%E3%83%97%E3%83%AA%E3%83%A1%E3%83%B3%E3%83%88/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"自然言語処理","slug":"自然言語処理","link":"/tags/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86/"},{"name":"doc2vec","slug":"doc2vec","link":"/tags/doc2vec/"},{"name":"ニューラルネットワーク","slug":"ニューラルネットワーク","link":"/tags/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"},{"name":"エラー","slug":"エラー","link":"/tags/%E3%82%A8%E3%83%A9%E3%83%BC/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"コンテナ","slug":"コンテナ","link":"/tags/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A/"},{"name":"OpenShift","slug":"OpenShift","link":"/tags/OpenShift/"},{"name":"ブログ","slug":"ブログ","link":"/tags/%E3%83%96%E3%83%AD%E3%82%B0/"},{"name":"landscape","slug":"landscape","link":"/tags/landscape/"},{"name":"instagram","slug":"instagram","link":"/tags/instagram/"},{"name":"BULMA","slug":"BULMA","link":"/tags/BULMA/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"前十字靭帯","slug":"前十字靭帯","link":"/tags/%E5%89%8D%E5%8D%81%E5%AD%97%E9%9D%AD%E5%B8%AF/"},{"name":"リハビリ","slug":"リハビリ","link":"/tags/%E3%83%AA%E3%83%8F%E3%83%93%E3%83%AA/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"育児","slug":"育児","link":"/tags/%E8%82%B2%E5%85%90/"},{"name":"子育て","slug":"子育て","link":"/tags/%E5%AD%90%E8%82%B2%E3%81%A6/"},{"name":"勉強","slug":"勉強","link":"/tags/%E5%8B%89%E5%BC%B7/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"VisualStudioCode","slug":"VisualStudioCode","link":"/tags/VisualStudioCode/"},{"name":"git bash","slug":"git-bash","link":"/tags/git-bash/"},{"name":"twitter","slug":"twitter","link":"/tags/twitter/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"word2vec","slug":"word2vec","link":"/tags/word2vec/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"management","slug":"management","link":"/tags/management/"},{"name":"プログラミング","slug":"プログラミング","link":"/tags/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/"},{"name":"Writing","slug":"Writing","link":"/tags/Writing/"},{"name":"minikube","slug":"minikube","link":"/tags/minikube/"},{"name":"コマンド","slug":"コマンド","link":"/tags/%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/"},{"name":"chair","slug":"chair","link":"/tags/chair/"},{"name":"remotework","slug":"remotework","link":"/tags/remotework/"},{"name":"在宅","slug":"在宅","link":"/tags/%E5%9C%A8%E5%AE%85/"},{"name":"楽痩せ","slug":"楽痩せ","link":"/tags/%E6%A5%BD%E7%97%A9%E3%81%9B/"},{"name":"レアジョブ","slug":"レアジョブ","link":"/tags/%E3%83%AC%E3%82%A2%E3%82%B8%E3%83%A7%E3%83%96/"},{"name":"仕事","slug":"仕事","link":"/tags/%E4%BB%95%E4%BA%8B/"},{"name":"トレーニング","slug":"トレーニング","link":"/tags/%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/"},{"name":"EPA","slug":"EPA","link":"/tags/EPA/"},{"name":"葉酸","slug":"葉酸","link":"/tags/%E8%91%89%E9%85%B8/"},{"name":"ブルーベリー","slug":"ブルーベリー","link":"/tags/%E3%83%96%E3%83%AB%E3%83%BC%E3%83%99%E3%83%AA%E3%83%BC/"},{"name":"オブジェクト指向","slug":"オブジェクト指向","link":"/tags/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/"},{"name":"クラス","slug":"クラス","link":"/tags/%E3%82%AF%E3%83%A9%E3%82%B9/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"keras","slug":"keras","link":"/tags/keras/"},{"name":"Rails","slug":"Rails","link":"/tags/Rails/"},{"name":"Ruby","slug":"Ruby","link":"/tags/Ruby/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Mouse","slug":"Mouse","link":"/tags/Mouse/"},{"name":"Udemy","slug":"Udemy","link":"/tags/Udemy/"},{"name":"SkillHacks","slug":"SkillHacks","link":"/tags/SkillHacks/"},{"name":"Keyboard","slug":"Keyboard","link":"/tags/Keyboard/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"},{"name":"手術","slug":"手術","link":"/tags/%E6%89%8B%E8%A1%93/"},{"name":"RaspberryPi","slug":"RaspberryPi","link":"/tags/RaspberryPi/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"seq2seq","slug":"seq2seq","link":"/tags/seq2seq/"},{"name":"風邪予防","slug":"風邪予防","link":"/tags/%E9%A2%A8%E9%82%AA%E4%BA%88%E9%98%B2/"},{"name":"Table","slug":"Table","link":"/tags/Table/"}],"categories":[{"name":"IT","slug":"IT","link":"/categories/IT/"},{"name":"Goods","slug":"Goods","link":"/categories/Goods/"},{"name":"Health","slug":"Health","link":"/categories/Health/"},{"name":"Method","slug":"Method","link":"/categories/Method/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"English","slug":"English","link":"/categories/English/"}]}