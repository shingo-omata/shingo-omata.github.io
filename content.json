{"pages":[{"title":"","text":"Sorry…現在、構築中です。。。","link":"/404.html"}],"posts":[{"title":"本ブログについて","text":"本ページをご覧いただきありがとうございます。 IT系企業に勤める技術者が、様々な経験や勉強を通じて得られたこと、学んだことを情報発信するブログです。 著者について学生時代は、無機材料化学の分野の研究者でした。 大学院修士卒業後、IT・通信企業に就職。（IT関連の知識0の状態で入社。） 独学でプログラミング、ネットワーク、クラウド、AI関連技術を身に着けてきた経験をベースに、効率よく低コストで無理なく学習する方法や、知見などをお届けしたいと思っています。 また、健康、サプリメントに関する資格と日々の論文調査をベースに、ダイエットや健康に関する情報も発信したいと思います。","link":"/2020/01/08/about-this-blog/"},{"title":"【Hexo】Icarusテーマで作成される記事のタイトル、h2、h3のデザインを変更","text":"Hexoで作成した記事を読みやすいデザインにしませんか？ 本ブログはIcarus(v3.0)というテーマを採用しておりますが、h2タグやh3タグにborder-leftをつけて記事の可読性を上げたいな、とおもっていました。 本記事では、それらのカスタマイズ方法をまとめました。 ✓目次 この記事の対象者 読みやすい記事とは h2タグ、h3タグのデザイン変更 記事タイトルをsemi-boldに変更 この記事の対象者 HexoにIcarusテーマを適用している方。Icarusはv 3.0.0。 基本的なHTML, CSSを理解している方 読みやすい記事とはそもそも読みやすい記事って、どんな記事なのか。 やはりブログで多くのお金を稼いでいる方のデザインなのかなと思います。 Icarusテーマの配色に近いデザインを用いている有名ブロガーさんとして、manablogさんのデザインを参考（というかほぼ丸パクリ）にしてデザインを当ててみたいと思います。 h2タグ、h3タグのデザイン変更編集するファイルは、\\themes\\icarus\\include\\style\\article.stylです。 以下のように設定すればOKです。 \\themes\\icarus\\include\\style\\article.styl1234567891011121314151617181920212223242526h2 font-size: 25px background: #f7f7f7; padding: 20px 15px 18px border-left: 9px solid #4865b2; line-height: 40px; margin-top: 60pxh3 font-size: 20px letter-spacing: 1.6px; padding: 10px 15px 10px; border-left: 9px solid #4865b2; font-weight: 600 margin-top: 60px;h4 font-size: 16px letter-spacing: 1.6px; padding: 5px 15px 5px; border-left: 9px solid #4865b2; font-weight: 400 margin-top: 60px; ファイルの編集が終わったら、ファイルを保存し、hexo cleanコマンドでキャッシュなどを削除。 hexo generateコマンドを実施し、hexo serverでlocalhost:4000にアクセスしてみましょう。 ちゃんとh2タグ、h3タグにデザインが当てられていればOKです。 記事タイトルをsemi-boldに変更記事のタイトルは\\themes\\icarus\\layout\\common\\article.jsxファイルを変更します。 titleクラスにhas-text-weight-semiboldを追記します。 \\themes\\icarus\\layout\\common\\article.jsx1234{/* Title */}&lt;h1 class=\"title is-3 is-size-4-mobile has-text-weight-semibold\"&gt; {index ? &lt;a class=\"link-muted\" href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title}&lt;/h1&gt; IcarusはBulmaというCSSフレームワークを使っています。 以下に、fontに関連するhelperのリンクを張っておきますので、semibold以外のフォントにしたい場合は、こちらを参照してください。 Typography helpers | Bulma: Free, open source, and modern CSS framework based on Flexbox その他、Icarusのデザイン変更に関する記事","link":"/2020/05/05/Icarus-h2h3title-change/"},{"title":"【簡単】Anaconda Navigatorによるpython環境構築","text":"プログラミング環境の構築で挫折したことありませんか？ 絶対に挫折しない環境構築方法を紹介します。 人気No1プログラミング言語ともいわれるPythonを学ぶための環境構築は、Anacondaを使えば安心です。 人工知能や自然言語処理の勉強のために必要なライブラリのインストール方法もまとめています。 ニューラルネットワークや自然言語処理の勉強のために、Anacondaを使って環境構築したのでその方法をまとめます。 ✓目次 使用しているPCとAnacondaのバージョン 手順①：Anaconda Navigatorのインストール 手順②：ライブラリの導入 使用しているPCとAnacondaのバージョンWindows10 proAnaconda Navigator 1.9.12 手順①：Anaconda Navigatorのインストール anaconda.comにアクセス トップページにDownloadsのリンクがあるのでこれをクリック&lt;br&gt; 環境を選択(Win, Mac, Linux) Python 3.6のバージョンを選択。ダウンロードが始まる。 インストーラがダウンロードされているのでダブルクリック。指示されたとおりにプロセスを進める。 MS VScodeをインストールするかを聞かれるが必要であればOK。すでにVScodeをインストール済みであれば無視してよい。 インストールが完了したら、Anaconda-Navigator.appを開く。 手順②：ライブラリの導入ライブラリは以下を導入しました。(お好みで他のライブラリを導入してもOKです。) NumPy matplotlib TensorFlow Keras nomkl gensim Janome 以降、実際の手順をまとめます。 Anaconda navigatorを起動。Enviromentsを選択。以下のような画面になります。 画面下にある、「create」をクリックする。 新しい仮想環境の名前を聞かれるので任意の名前を設定し、pythonにチェックを入れて、バージョンを3.6に設定する。 createをクリックすると、creating environmetという表記と共に、仮想環境の作成が開始されます。仮想環境の構築が完了したら、タブを「installed」にし、”numpy”と入力して検索。何も表示されない場合、numpyがインストールされていないことを示しています。 タブを「Not installed」に変更して”numpy”と入力するとnumpyが見つかります。numpyを選択して、「Apply」をクリック。 再びApplyをクリックするとnumpyのインストールが開始されます。 この要領で、matplotlib、tensorflow、Keras、gensimをインストール。gensimはword2vecを使うためのライブラリ。 nomklをインストールする際、Enviromentsにnomklが表示されません。(Anaconda Navigatorのバージョンによっては表示されるかもしれません。) Enviromentsにインストールしたいライブラリが表示されない場合は、Anaconda navigatorのterminalからインストールします。terminalは、▶ボタンをクリックして「open terminal」をクリックするとterminalが開きます。 今回はconda install -c anaconda nomklコマンドでインストールします。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950(test_env) C:\\Users\\user&gt;conda install -c anaconda nomklCollecting package metadata (repodata.json): doneSolving environment: done## Package Plan ## environment location: C:\\Users\\omashi\\Anaconda3\\envs\\nlp_bot added / updated specs: - nomklThe following packages will be downloaded: package | build ---------------------------|----------------- ca-certificates-2020.1.1 | 0 165 KB anaconda certifi-2020.4.5.1 | py36_0 159 KB anaconda nomkl-2.0 | 0 2 KB anaconda openssl-1.1.1 | he774522_0 5.7 MB anaconda ------------------------------------------------------------ Total: 6.1 MBThe following NEW packages will be INSTALLED: nomkl anaconda/win-64::nomkl-2.0-0The following packages will be UPDATED: openssl pkgs/main::openssl-1.1.1f-he774522_0 --&gt; anaconda::openssl-1.1.1-he774522_0The following packages will be SUPERSEDED by a higher-priority channel: ca-certificates pkgs/main --&gt; anaconda certifi pkgs/main --&gt; anacondaProceed ([y]/n)? yDownloading and Extracting Packagesopenssl-1.1.1 | 5.7 MB | ############################################################################ | 100%nomkl-2.0 | 2 KB | ############################################################################ | 100%ca-certificates-2020 | 165 KB | ############################################################################ | 100%certifi-2020.4.5.1 | 159 KB | ############################################################################ | 100%Preparing transaction: doneVerifying transaction: doneExecuting transaction: done(test_env) C:\\Users\\user&gt; janomeも同様にterminalからインストールします。janomeは、pip install janomeコマンドでインストールします。 123456(test_env) C:\\Users\\user&gt;pip install janomeCollecting janome Downloading Janome-0.3.10-py2.py3-none-any.whl (21.5 MB) |████████████████████████████████| 21.5 MB 3.3 MB/sInstalling collected packages: janomeSuccessfully installed janome-0.3.10 これで完了です。 自然言語処理の学習にオススメの教材 以下のUdemyのコースはとてもオススメ 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/04/15/anaconda-enviroment/"},{"title":"【比較】糖質制限 vs 脂質制限","text":"糖質制限ダイエットと脂質制限ダイエットについてまとめてみました。 ✓目次 結論 論文の内容を簡単にまとめる 結論低炭水化物ダイエットの効果は低脂肪ダイエットと同じ 低脂肪ダイエットと低炭水化物ダイエットの減量効果と参加者の遺伝子パターンやインスリン分泌との関係を調べた結果、減量効果に有意差はなく、遺伝子やインスリンとの関連もみられなかった、という米国スタンフォード大学からの研究報告がありました。 『米国医学会誌(JAMA)』https://jamanetwork.com/ https://www.wsj.com/articles/SB10001424052748703862704575099742545274032 論文の内容を簡単にまとめる18-50才の糖尿病ではなく、BMIが28-40の609名を対象に、2013年1月から2015年4月にかけて介入試験を実施し、その後2016年5月まで追跡調査した結果がまとめられています。 参加者はランダムに、健康的な低脂肪食（HLF）群と健康的な低炭水化物食（HLC）群に振り分けられ12か月間モニタリングを行ったようです。 (色々難しいことは省いて、、、) 介入の結果、12月で、HLF群で平均-5.3kg、HLC群で平均-6.0kgの体重変化が観察されたが、両群間には有意差が見られなかった。また、食事と遺伝子パターン、または食事とインスリン分泌能と、12か月間の体重変化の間にも有意な関連は認められなかったという。 筆頭研究者のクリストファー・ガードナー教授によれば、本研究結果の最大の収穫は、減量においては低脂肪食も低炭水化物食でも、その基本的な戦略が類似していた点であるという。 砂糖を減らし、精製穀類を減らし、野菜を可能な限りたくさん食べる。加工度の低い食品（Whole foods）を主に食べるようにする。 どちらのダイエットでも、最も体重を減らした人々が語っていたのは、様々な食べ物に対する知識、そしてそれらをどのように食べるかについてもっとよく考えるようになったことが大事ということだと筆者(Christopher Gardner氏)は述べています。 ボディメイクのプロの人は、最初に油を断ち切って体重を減らし、それでも目標値まで落ちなかった場合は糖質を制限するというのが一般的であると述べていました。 ダイエット効果が同じなら、油を制限する方を選びますが、結局はバランスよく、加工度の低い食品を自分で選んで食べるのが一番であるということですね。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/04/15/cbnoildiet/"},{"title":"青年期の食生活が中年期以降の認知機能に影響を与える【全粒粉は肝臓にもいい】","text":"認知症予防についてまとめてみました。 ✓目次 青年期の食生活が中年期以降の認知機能に影響を与えることが分かりました。 全粒粉は肝臓にも良い 全粒粉食材 まとめ 青年期の食生活が中年期以降の認知機能に影響を与えることが分かりました。以下の論文の報告によると、ビタミンB6と全粒粉類の摂取量は、年齢、人種、性別、総カロリー摂取量を補正しても、認知機能の改善に直接的な影響を与えていたようです。 研究論文:The American Journal of Clinical Nutrition, Volume 109, Issue 6, June 2019, Pages 1656?1663,https://academic.oup.com/ajcn/article/109/6/1656/5479238 こちらの論文では、認知機能に対する食生活の潜在的影響を評価しています。 中年期までの516人を追跡調査した結果がまとめられています。 多変量調整線形回帰モデルを当てはめ、食生活の因子と認知機能の関係性における傾向を評価した結果、青年期の食生活が中年期以降の認知機能に影響を与える、という結論に至ったようです。 また、この研究結果から、揚げ物や加工肉は、認知症の発症確立を上げる可能性があると述べており、食べ過ぎないほうが良いでしょう。 全粒粉は肝臓にも良い以下の論文の報告によると、全粒粉の12週間の摂取により、肝臓脂肪の増加が抑制されていたことが分かりました。 研究論文：A 12-wk whole-grain wheat intervention protects against hepatic fat: the Graandioos study, a randomized trial in overweight subjects. - PubMed - NCBI 研究班は45歳から70歳までの男性及び閉経後女性の50名を対象とし、無作為に2群割付け、全粒粉製品あるいは精麦製品を1日あたり98グラム摂取させる12週間の二重盲験比較対照試験を実施しています。 その結果、全粒粉の摂取は肝臓血清アミロイドA蛋白（p=0.057）やCRP（p=0.064）の空腹時血中濃度を抑制する傾向が認められた、とされています。 全粒粉食材 全粒粉パスタ 私もよく食べている全粒粉パスタはオススメです。 炭水化物の中でもGI値が低いで有名なパスタですが、全粒粉パスタを用いてより健康な食事をするのはいかがでしょうか。 まとめ結局は若いうちから食事に気を付けようということです。特に、揚げ物や加工肉は、食べ過ぎないようにしましょう。 論文では、「さまざまな要因が複雑に絡み合っている可能性も排除できない」とも言っています。 食事だけでなく運動や睡眠、ストレスの有無も関係あるのではないかと思います。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/04/16/dementia-and-diet/"},{"title":"本ブログの免責事項","text":"https://omathin.com/（以下、「当サイト」とします。）における免責事項は、下記の通りです。 コメントについて次の各号に掲げる内容を含むコメントは、当サイト管理人の裁量によって承認せず、削除する事があります。 特定の自然人または法人を誹謗し、中傷するもの 極度にわいせつな内容を含むもの 禁制品の取引に関するものや、他者を害する行為の依頼など、法律によって禁止されている物品、行為の依頼や斡旋などに関するもの その他、公序良俗に反し、または管理人によって承認すべきでないと認められるもの 当サイトの情報の正確性について当サイトのコンテンツや情報において、可能な限り正確な情報を掲載するよう努めています。しかし、誤情報が入り込んだり、情報が古くなったりすることもあります。必ずしも正確性を保証するものではありません。また合法性や安全性なども保証しません。 損害等の責任について当サイトに掲載された内容によって生じた損害等の一切の責任を負いかねますので、ご了承ください。また当サイトからリンクやバナーなどによって他のサイトに移動された場合、移動先サイトで提供される情報、サービス等について一切の責任も負いません。当サイトの保守、火災、停電、その他の自然災害、ウィルスや第三者の妨害等行為による不可抗力によって、当サイトによるサービスが停止したことに起因して利用者に生じた損害についても、何ら責任を負うものではありません。当サイトを利用する場合は、自己責任で行う必要があります。 当サイトで掲載している画像の著作権や肖像権等について当サイトで掲載している画像の著作権や肖像権等は、各権利所有者に帰属します。万が一問題がある場合は、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 無断転載の禁止について当サイトに存在する、文章や画像、動画等の著作物の情報を無断転載することを禁止します。引用の範囲を超えるものについては、法的処置を行います。転載する際には、お問い合わせよりご連絡いただけますよう宜しくお願い致します。 Amazonアソシエイトについて当サイトは、amazon.co.jpを宣伝しリンクすることによってサイトが紹介料を獲得できる手段を提供することを目的に設定されたアフィリエイト宣伝プログラムである、 Amazonアソシエイト・プログラムの参加者です 2020年1月6日 策定2020年4月24日 改訂","link":"/2020/01/08/disclaimer/"},{"title":"【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説","text":"本記事では、doc2vecというものについてまとめてみます。 ✓目次 doc2vecとは、word2vecを拡張したもの dmpv DBOW dmpvとDBOWの比較 参考にした記事など doc2vecとは、word2vecを拡張したものdoc2vecとは、word2vecを単語レベルではなく、文または文章でも扱えるように拡張したものです。 word2vecって何？何ができるの？という方は、以下の記事を参照いただければと思います。 doc2vecを用いることで何ができるのかというと、文や文章をベクトル化することができます。word2vecを学んだ人向けに言い換えれば、文や文章に対して、分散表現を獲得することができる、ということです。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法でしたね。 word2vecでは、CBOWとskip-gramという、2つのニューラルネットワークを用いますが、doc2vecでは、下記2つのいずれかのニューラルネットワークが用いられます。 dmpv(distributed memory) DBOW(distributed bag-of-words) 以降、dmpv, DBOWについてまとめたいと思います。 dmpvdmpvは、入力層、中間層、出力層があり、入力層と中間層の間と、中間層と出力層の間に重みを表す行列が存在します。 word2vecのCBOWに似ているように見えますが、違いは、入力に各単語とは別に、緑色の四角の文書IDがあることです。 文書IDというのは、この図でいうと、「となりのトトロ」という文章に付与されているID(“012”)というものをone-hot表現で表したものを指しています。※ちょっとややこしい。 文書IDを入力層に加えることで、文書自体をベクトルとして表すことが可能となり、文脈を加味した学習が可能となったのです。 簡単な例で述べましたが、これはあくまでイメージとしてとらえていただければと思います。実際は大量の文章と、文書IDを用いて学習され、dmpvをはじめとする学習モデルが作成されることで、文章のベクトル化がされます。 DBOWDBOWは、word2vecのskip-gramに似ており、入力は文書IDのone-hot表現のみであるのが特徴です。 該当文章内に含まれる単語を予測するように学習が行われ、dmpvと同様に、文書自体を分散表現で表すことができる。 dmpvとDBOWの比較DBOWの方が、シンプルなモデルでメモリをあまり使わないため、高速に計算することが可能と報告されています。しかし、dmpvの方が精度の面で優れているとされています。 [1507.07998] Document Embedding with Paragraph Vectors 参考にした記事など Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル - DeepAge gensimでDoc2Vec - 機械学習・自然言語処理の勉強メモ 以下のUdemyのコースはとてもオススメ 基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/04/29/doc2vec-overview/"},{"title":"【Hexo】ブログカード内のファビコンが表示されない問題の対処","text":"Hexo(Icarusテーマ)で、はてなブログカードを使用した際に、faviconがうまく表示されなかったので、解消法を備忘録的にまとめます。 ✓目次 エラーの事象 使用しているプラグイン 原因 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨 対処その②：適用しているIcarus(v3.0)テーマの修正 検証 エラーの事象以下のように、faviconが出てきません。 使用しているプラグインshundroidさんが提供してくれているプラグインを使用させていただきました。 以下のコマンドでインストール可能です。 terminal1npm install shundroid/hexo-embed-hatena-blog-card --save https://kimamamemo.com/Hexo/1563580702/ 記事を作成する際に実施するhexo new &quot;{記事名}&quot;コマンドで生成されるマークダウンファイルに｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝という風に、｛% hatenablogcard (記事のURL) %｝と記述していました。 しかしながら、本記事の冒頭の通り、faviconだけが表示されませんでした。 原因画像のパスがhttps://となっていると、faviconが表示されない場合があるようです。※セキュリティ的によろしくない。 **Icarus v3.0においてOpen Graph Protocolが正常に適用できない状態になっていたようです。 対処その①：faviconの画像パスをhttpsからhttpに変更 ※非推奨自身のブログ記事をChromeで表示し、F12で正常に表示されていないFaviconの箇所を確認すると、以下の通りとなっていました。 html12&lt;img src=\"https://cdn-ak.favicon.st-hatena.com?url=https%3A%2F%2Fomathin.com%2F2020%2F02%2F01%2Fmatsuba%2F\" alt=\"omathin.com\" title=\"omathin.com\" class=\"favicon\"&gt; Chromeのデベロッパーツール上で、試しに、?url= httpsとなっている部分を、?url=httpという形に変更すると、Faviconが表示されました。 よって、ブログ記事を作成するマークダウンファイル上で、｛% hatenablogcard https://omathin.com/2020/01/16/knee-surgery/ %｝と記載していた箇所を、｛% hatenablogcard http://omathin.com/2020/01/16/knee-surgery/ %}という風に、https:形式からhttp:に変更すれば、ブログカード内にFaviconが表示されるようです。 しかしながら、これはセキュリティ的にあまりよろしくないですよね。 他に対策はないのか、とOpen Graph Protocolなどを調査してみると、なんと私が現在使用しているIcarus(v3.0)では、Open Graph Protocolが正常に適用できない状態になっているバグがあったようです。 対処その②：適用しているIcarus(v3.0)テーマの修正私が適用していたIcarusのバージョン3.0では、Open Graph Protocolが正常に適用できない状態になっていたそうです。 修正するコードはgithubを参照し、以下のように修正すればOKです。 layout/common/head.jsx123456789 author={open_graph.author || config.author} description={open_graph.description || page.description || page.excerpt || page.content || config.description} keywords={page.keywords || (page.tags &amp;&amp; page.tags.length ? page.tags : undefined) || config.keywords}- url={open_graph.url || url}+ url={open_graph.url || page.permalink || url} images={openGraphImages} siteName={open_graph.site_name || config.title} language={language} package.json12345678 \"bulma-stylus\": \"0.8.0\", \"deepmerge\": \"^4.2.2\", \"hexo\": \"^4.2.0\",- \"hexo-component-inferno\": \"^0.2.3\",+ \"hexo-component-inferno\": \"^0.2.4\", \"hexo-log\": \"^1.0.0\", \"hexo-pagination\": \"^1.0.0\", \"hexo-renderer-inferno\": \"^0.1.3\", 検証本ブログの別記事のブログカードを以下に張り付けてみると問題なく画像が表示されました。","link":"/2020/04/19/hatenablocard-favicon-error/"},{"title":"docker-compose run web rails dbconsoleができない問題の対処","text":"タイトルに記載したコマンドを実行したらうまくいかなかったので備忘録的にまとめます。 ✓目次 環境 問題（エラー内容） エラーの原因 対処 参考記事 環境Windows10 proRuby 2.4.5MySQLの5.7 問題（エラー内容） 以下のようなエラーが発生 terminal1234$ docker-compose run web rails dbconsoleStarting b74e972d_db_1 ... doneCouldn't find database client: mysql, mysql5. Check your $PATH and try again. エラーの原因 ローカルにMySQLアカウントがないからと想定 対処エラーが発生する場合のdockerfileは以下の通り dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 以下のように修正 dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev postgresql-client nodejsRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app buildを実施 terminal1$ docker-compose build 同じエラーが発生。dockerfileを以下の通り、修正する。 Dockerfile123456789FROM ruby:2.4.5RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs mysql-clientRUN mkdir /appWORKDIR /appCOPY Gemfile /app/GemfileCOPY Gemfile.lock /app/Gemfile.lockRUN bundle installCOPY . /app 再度buildを実施 terminal1$ docker-compose build 成功したので、dbconsoleを実行 terminal1$ docker-compose run web rails dbconsole パスワードを聞かれた場合は、dokcer-compose.ymlに記載されている、MYSQL_ROOT_PASSWORD: に記述されているパスワードを入力。 これで成功するはず。 参考記事 docker-compose で Rails の開発環境を作る - Qiita docker-composeで、rails dbconsoleが使えなくてハマった話。 - Qiita Dockerを専門に学ぶためのオンライン学習講座 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/01/27/docker-compose-run-web-rails-dbconsole-error/"},{"title":"[Hexo landscape]スマホで閲覧した際にInstagramの幅がはみ出る","text":"Hexo landscape themeで、Instagramの投稿を埋め込んだ記事を、スマートフォンで閲覧すると、幅があってない時の対処方法を記載します。 結論としては、/theme/landscape/source/css/_partial/配下のmobile.stylファイルを修正すればOKです。 12$ cd /thema/landscape/source/css/_partial/$ vim mobile.styl 以下のコードを一番下に追記。 mobile.styl12345678910@media screen and (max-width: 728px){ .instagram-media{ width:414px !important; max-width: 100% !important; min-width: initial !important; }} 完了したらhexo d -gでデプロイすればOKです。","link":"/2020/01/19/hexo-landscape-instagram-modify/"},{"title":"Hexo＋github pagesで構築したブログをBoostnoteを用いて更新する方法","text":"備忘的記事です。 Boostnoteのバージョンは、Boostnote 0.11.13です。 _config.ymlの記述 post_asset_folder: falseの状態にしておく。 123456789101112131415161718192021222324(省略)# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: enable: true # Open external links in new tab field: site # Apply to the whole site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: false(省略) [ステップ1]ページの作成 以下のコマンドでページを作成する。ここではimageというページを作成する例。 12$ hexo new &quot;image&quot;INFO Created: ~\\usr\\source\\_posts\\image.md [ステップ2]boostnoteで記事を作成する。 画像を張り付けるなど、boostnoteのお作法で好きなように記事を作成する [ステップ3]記事を出力 File→export→MarkDownを選択 この際、先ほど作成したimage.mdを上書きする形でexportと保存を実行 上述の_config.ymlの44行目のようにpost_asset_folder: falseとなっている場合、以下のようなフォルダ構成になるようにする。 作業としては、sourceフォルダの配下にimagesフォルダを新規作成する。 [ステップ4]画像が出力されるようにファイル編集 上書きする形でexportしたimage.mdを下記のように編集する。適当なエディタを使ってください。 attachements/xxxxx.pngとなっているのを/images/xxxx.pngに変更 attachementsフォルダに配置されているxxxx.pngを/source/images/配下にコピーする。 [ステップ5]記事の確認 hexo serverコマンドで起動し、localhost:4000で確認。 1$ hexo server [ステップ6]記事のアップロード 問題なければ以下のコマンドでgithubにpushする 1$ hexo d -g これで画像が表示されているはずです。 備考githubにpushした際、ページが表示されなくなる場合ブログのドメイン名を記載したCNAMEファイルが、githubのリポジトリから消えている為です。 githubにpushする前に、hexo cleanコマンドでキャッシュの削除をすると、publicフォルダが丸々削除されてしまい、publicフォルダにCNAMEファイルが削除されてしまったことが原因だと思われる。 CNAMEファイルを作成し、publicフォルダに配置し、再度hexo d -gコマンドでgithubにpushしましょう。 またads.txtファイルもpublicフォルダから削除されているので、こちらもpublicフォルダに配置してgithubにpushしましょう。 参考ページNode.js製の静的サイトジェネレータ「Hexo」で無料ブログ開発 vol.1 | dotstudio HEXOを使ってブログを構築しました。 その1 | ant magazine","link":"/2020/01/06/hexo_post/"},{"title":"【Hexo】Icarusテーマで強調メッセージブロックを使う方法","text":"Hexo(Icarus)+Github pagesで無料ブログを作成した際、記事の中でページの一部を強調するために色付きのメッセージブロックを使いたくなる時があります。IcarusはBULMAというCSSフレームワークが適用されているので簡単に導入できます。 本記事の対象者 ・ Hexo + Github pagesでテーマはIcarusの人 ・ Icarusのv3.0.0以上の人 以下のコードをコピペすればOKです。hexo new &quot;hogehoge&quot;(hogehogeはファイル名)でジェネレートしたマークダウンファイル内部に、以下のコードをコピペして、&lt;div class=&quot;message-body&quot;&gt;と&lt;/div&gt;の間に文章などを記述すればOKです。 12345678&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Info&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. &lt;strong&gt;Pellentesque risus mi&lt;/strong&gt;, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum &lt;a&gt;felis venenatis&lt;/a&gt; efficitur. Aenean ac &lt;em&gt;eleifend lacus&lt;/em&gt;, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. &lt;/div&gt;&lt;/article&gt; 上記のコードを使うと以下のような形になります。 Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque risus mi, tempus quis placerat ut, porta nec nulla. Vestibulum rhoncus ac ex sit amet fringilla. Nullam gravida purus diam, et dictum felis venenatis efficitur. Aenean ac eleifend lacus, in mollis lectus. Donec sodales, arcu et sollicitudin porttitor, tortor urna tempor ligula, id porttitor mi magna a neque. Donec dui urna, vehicula et sem eget, facilisis sodales sem. 文章だけでなく、はてなブログカードを埋め込んだり、アフィリエイトリンクを埋め込むことも可能です。 例えば、以下のようなコードでマークダウンファイルに記述した場合、、、 1234567891011&lt;article class=\"message is-info\"&gt; &lt;div class=\"message-header\"&gt; &lt;p&gt;Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓&lt;/p&gt; &lt;/div&gt; &lt;div class=\"message-body\"&gt;{% hatenablogcard https://omathin.com/2020/05/05/Icarus-h2h3title-change/ %} &lt;/div&gt;&lt;/article&gt; 以下のようになります。 Icarusテーマでh2, h3タグのデザインを変更したい方はこちら↓ いくらか見栄えがいい感じになりますね。 ちなみに、はてなブログカードのプラグインは、以下のnpmコマンドで導入が可能です。 1npm install shundroid/hexo-embed-hatena-blog-card --save https://kimamamemo.com/Hexo/1563580702/ 他の色を使いたい場合はBULMAのドキュメントを参照してくださいメッセージブロックについては、以下のページに記述されているコードを参照しコピペしながら使いましょう。 こちらも参考になるかもしれません。 積極的にBULMAを活用して、視認性の高い記事を作っていきましょう！ おしまい","link":"/2020/05/19/icarus-bulma/"},{"title":"Hexoのicarusテーマのフォントの変え方","text":"Icarusのテーマを早速適用してみると、中国語っぽいフォントになっているので変更したいな、と思いました。 例えば、「所」だと下図の左側のような表記になっており、日本人からすると「読めなくはないけど変だな」という文字になっています。◆中国語の漢字「簡体字」について（その３） ｜ Chinese－Lab ～中文研究網～ 基本的にChromeのF12キーで編集したい箇所を指定して、どのようなCSSが割り当てられているのかを調べる。 想定通りfont-familyにMicrosoft YaHeiが含まれているのが大きな原因のようでした。 icarusフォルダ内の、どのファイルを変更すればよいかを、icarusのgithubページのリポジトリで検索。ひとまず、”Microsoft YaHei”と入力して検索してみる。 このようにbase.stylファイルか、cyberpunk.stylが該当することが分かる。 パラメータを変更しながら、どちらのファイルを変更すればよいのかを探り、正解はbase.stylであることが分かる。他の人気ブロガーの方のフォントを参考にfamily-sans = Noto, Hiragino Sans, Helvetica, Arial, sans-serifという風に、Microsoft Yaheiがない形式に変更したら、中国語の漢字で表示されなくなりました。 \\themes\\icarus\\include\\style\\base.styl123456789101112131415161718/* --------------------------------- * Override Bulma CSS Framework * --------------------------------- */$body-size ?= 14px$body-background-color ?= #f7f7f7$family-sans-serif ?= Noto, Hiragino Sans, Helvetica, Arial, sans-serif # ←このように変更すればOK$family-code ?= 'Source Code Pro', monospace, 'Microsoft YaHei'$primary ?= $blue$custom-colors ?= { grey-lightest: { '1': $grey-lightest '2': $grey-darker }}","link":"/2020/04/11/icarus-theme-change/"},{"title":"【Hexo】Icarusテーマのサムネイル位置やサイズを変更する方法","text":"サムネイルの位置を変更する方法をまとめました。 デフォルトの設定では、以下のようにタイトルの上部にサムネイル画像が配置されます。 このサムネイルの位置をタイトルの下に配置されるように変更したので、その方法をまとめました。 ✓目次 サムネイルの設定方法 サムネイル位置の変更方法 サムネイルのサイズ変更 サムネイルの設定方法まずサムネイルは、記事を作成するマークダウンファイルの上部にthumbnail: {画像ファイルのパス}を記載することで設定されます。 例えば、以下のような記載になります。 1234567891011121314---title: &quot;【自然言語処理】doc2vecとは何か?dmpv, DBOWも解説&quot;date: 2020-04-29 10:48:30update: categories:- AItags:- 自然言語処理- doc2vec- ニューラルネットワークdescription: &quot;doc2vecとは何か。dmpv, DBOWというdoc2vecの理解に必要な技術をわかりやすくまとめてみました。&quot;thumbnail: images/hogehoge.webp--- Hexoのテーマの一つであるIcarus(v 3.0.0)だと、タイトルの上にサムネイル画像が設置されますが、これをタイトル下に設置するように変更します。 サムネイル位置の変更方法hexo-theme-icarus/layout/common/article.jsxファイルを編集することで、サムネイルの位置を変更することができます。 まず、タイトル上部に表示されるサムネイル画像を非表示にするには、以下のコードの{/* Thumbnail */}というコードブロックを削除すればOKです。 1234567891011121314 return &lt;Fragment&gt; {/* Main content */} &lt;div class=\"card\"&gt;- {/* Thumbnail */}- {has_thumbnail(page) ? &lt;div class=\"card-image\"&gt;- {index ? &lt;a href={url_for(page.link || page.path)} class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/a&gt; : &lt;span class=\"image is-7by3\"&gt;- &lt;img class=\"thumbnail\" src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;- &lt;/span&gt;}- &lt;/div&gt; : null} {/* Metadata */} &lt;article class={`card-content article${'direction' in page ? ' ' + page.direction : ''}`} role=\"article\"&gt; {page.layout !== 'page' ? &lt;div class=\"article-meta size-small is-uppercase level is-mobile\"&gt; 次に、記事タイトルの下にサムネイルを表示されるには、hexo-theme-icarus/layout/common/article.jsxファイルの{/* Title */}というコードブロックの下に、{/* Thumbnail */}コードブロックを追記すればOKです。 123456789101112 {/* Title */} &lt;h1 class=&quot;title is-3 is-size-4-mobile&quot;&gt; {index ? &lt;a class=&quot;link-muted&quot; href={url_for(page.link || page.path)}&gt;{page.title}&lt;/a&gt; : page.title} &lt;/h1&gt;+ {/* Thumbnail */}+ {has_thumbnail(page) ? &lt;div class=&quot;card-image&quot;&gt;+ {index ? &lt;a href={url_for(page.link || page.path)} class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/a&gt; : &lt;span class=&quot;image is-7by3&quot;&gt;+ &lt;img class=&quot;thumbnail&quot; src={get_thumbnail(page)} alt={page.title || get_thumbnail(page)} /&gt;+ &lt;/span&gt;}+ &lt;/div&gt; : null} 以下のように、タイトルの下にサムネイルが表示されるようになりました。 サムネイルのサイズ変更サムネイルの配置を変えましたが、サムネイルの画像サイズによっては、以下のように上下がカットされてしまったり、記事タイトルの文章が見えている状態になっています。 これをうまい具合に変更したい場合は、include/style/article.stylファイルを変更します。 以下のように変更します。 12345.thumbnail object-fit: contain width: 100% !important height: 100% !important background-color: #fff 変更後、以下のようになります。 オススメ Webの仕事に関わる人なら誰でも必要な、「HTML/CSS」とプログラミング言語「JavaScript」の知識をこれ一本で。基礎の基礎から、jQuery/Vue.jsまで学ぶことができます。Hexoブログを自分が思うがままにカスタマイズしたい方は、受講したほうが良い講座だと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXxoT1x\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/html-css-js/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1334522_9c8b_3.jpg\"}}); [HTML/CSS/JavaScript] フロントエンドエンジニアになりたい人の Webプログラミング入門","link":"/2020/04/29/icarus-thumbnail-custom/"},{"title":"EPAと葉酸は精神疾患に有用である可能性がある","text":"EPAと葉酸が精神疾患に有用であることが分かりました。精神疾患の患者数は厚生労働省の発表によると増加傾向にあり、うつや自殺の対策が求められています。EPA、葉酸が一助になるかもしれません。 EPAと葉酸は精神疾患に有用である可能性がある。脳機能の改善や認知症予防にサプリメントの活用が注目されつつあるようです。 学術誌World Psychiatry(世界精神医学誌)の以下の論文で、EPAや葉酸が精神疾患に有用である可能性を指摘しています。 (PDF) The efficacy and safety of nutrient supplements in the treatment of mental disorders: a meta-review of meta-analyses of randomized controlled trials In conclusion, clinicians should be informed of the nutrient supplements with established efficacy for certain conditions (such as eicosapentaenoic acid in depression), but also made aware of those currently lacking evidentiary support. Future research should aim to determine which individuals may benefit most from evidence‐based supplements, to further elucidate the underlying mechanisms. EPAは魚の油です。EPAとは何かについて以下のページで詳しく解説されています。 EPAとは？ | サラサラ生活向上委員会 | ニッスイ EPAとは「エイコサペンタエン酸」の略称です。いわし・さば・あじなどの青魚に多く含まれるn-3系脂肪酸のひとつです。主に青魚の油に多く含まれるEPA（エイコサペンタエン酸）は、体内でほとんど作ることができない「必須脂肪酸」の一種です。必須脂肪酸にはほかに、同じく魚油に含まれるDHA（ドコサヘキサエン酸）、肉やリノール酸（植物油のひとつ）に偏った食事により体内に増加するAA（アラキドン酸）などがあります。 要するに魚の油ですね。 精神疾患だけでなく、血液をサラサラにしてくれたりする効果もあるようです。 毎日魚を食べるのもしんどいので、私はサプリメントで摂取しています。 葉酸は枝豆、鶏レバー、焼きのりに多く含まれている。葉酸とは：どの食べ物に含まれているの？種類や適正量は？｜エレビット (Elevit)｜バイエル薬品 葉酸を多く含む食べ物は、野菜ではえだまめ、肉は鶏レバー、海藻では焼きのり…などが特に葉酸を多く含む食べ物です。他にも豆類や果物など、多くの食べ物に葉酸は含まれている 日常的にえだまめ、や鶏レバーを取るのも正直しんどいですよね。こちらも手軽にサプリメントで取ってしまいましょう。400円前後で購入できます。 おしまい ダルビッシュ有投手も実践する風邪を引かないサプリメントについては以下の記事を参照ください。私もこれを始めてから風邪で寝込んでいません。","link":"/2020/05/15/spl-mental-health/"},{"title":"「子供を勉強させるにはどうすればいいの？」","text":"「うちの子供、全然勉強しないんだけど、どうすればいいかな？」 保育園や子供の習い事の送り迎えの立ち話で、こんなワードが出てきます。 そんな時は 親である貴方が勉強してないからじゃないの？というと大体納得する親が多い気がしました。 次に出てくるワードも大体見えていて、 「何を勉強すれば良いかな？」 or 「忙しくて勉強する暇がない」 なんですよね。 まず「何を勉強すれば良いかな？」という問いに対しては、 「好きな事というよりかは嫌いじゃない事が何かを整理して、続けられそうなトピックを勉強すれば良いのでは？」と答えます。 たぶん、勉強したいこと、やりたいこと、好きなこと、とかって、基本的になんとなく生活を送っていると、なかなかないものだと思います。 やりたいこと、とか、好きなこと、というのは、「自分ができること」の延長線上にあることが多い例えば、 野球ができる→野球の勉強したい、野球をもっとやりたい 料理ができる→栄養の勉強がしたい、サプリの勉強がしたい 運転ができる→レーサーになりたい、タクシーの運転手になりたい プログラミングができる→ITの仕事をしたい、プログラミングの勉強がしたい 気象予報士の資格を持っている→気象予報士になりたい 介護の資格を持っている→リハビリの勉強をしたい、介護の仕事をしたい という感じで、なんとなく始めた習い事とか学校で取った資格や学んだ知識の延長線上で、やりたいこととかを考えるのが一般的なのだと思います。 あの、東進ハイスクールの林先生も同様のことを言っています。※youtubeで検索すると出てくるかも。 なので、特にやりたいこととか好きなことが無い場合は、まずは、この「できる」という項目をとにかく増やす、という目的で、嫌いじゃないトピックを勉強すれば良いと思います。 私自身も、大学では化学を専門にしていましたが、就職先は、希望の化学系の部署に行けずにIT・通信関連の部署に配属になりました。 最初は何も分からなく挫折の毎日でしたが、プログラミングとかサーバの設定とかは、嫌いではなかったので地道に勉強していきました。 結果、「IT系の仕事で良かったな」と思っています。 言いたいこととしては、特にやりたいことがない、という人は、なんでも良いので嫌いじゃない領域を見つけて、勉強を始めてみるのが良いと思います。 「忙しくて勉強する暇がない」という人もいらっしゃると思います。 でもよくよく考えてみてください。 YoutubeやUdemy等、インターネットとスマホがあれば、いつでもどこでも好きなだけ学べる時代になった今、「忙しくて勉強する暇がない」といわれると、申し訳ないのですが「本当に？」と思ってしまうのです。 私自身も、子供の保育園の送り迎え等をしていますが、Udemyで数十個の講座を受講し、できることの幅を広げられています。学ぶことで、やりたいことが見つけられる、ということを信じて今すぐ勉強を始めてみるのはいかがでしょうか？ 世界最大級のオンライン学習サイトUdemy それでも「これ！」ってものがない場合のおすすめですが、私としては、これからは5Gの時代もやってくることも考えると、やはり動画の編集能力とか、需要が高くなる可能性が高いと思っています。 私もこれから、Udemyのキャンペーンのタイミングで以下の講座を受講して、動画の編集スキルを身に着けたいなとおもっているところです。 業界最先端の動画制作テクニックを制覇！Adobe Premiere Pro オンライン講座 少し値は張るかもしれませんが、以下のMovieHacksも良いと思います。Skill Hacksがとても良かったので、信頼度高めです。 -Movie Hacks- YouTubeに特化した動画編集講座 おしまい","link":"/2020/01/12/study-for-child/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで③[自宅安静～抜糸～松葉づえ卒業まで]","text":"前の記事で前十字靭帯再建手術後、退院までの1週間をまとめました。 本記事では、その続きとして松葉づえが取れるまでの手術後約1か月をまとめたいと思います。 前の記事は、こちらを参照ください。 以下のようなことが知りたければ参考になると思います。 実体験に基づいた松葉づえが取れるまでの生活を具体的に知りたい 抜糸は痛いのかどうか？？ 自宅での生活は？？ 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 退院直後の生活(退院～抜糸まで) 抜糸後の生活 リハビリで重視されたのは「膝の力入れ」 膝の状態、感覚 松葉づえの卒業 まとめ 退院直後の生活(退院～抜糸まで)基本的に自宅で膝のアイシング、痛み止めを飲みながら、膝を心臓よりも高くして安静です。 自宅では、時間を見つけては膝のお皿を上下左右斜めに動かしたりします。 抜糸は、手術してから2週間後くらいだったと思います。 抜糸自体は少しチクチクするくらいで、そんなに痛くありません。※手術前の麻酔のアレルギーチェックや尿道の管を抜くときのほうが全然痛いです。 尿道の管の苦しさを乗り越えたのなら、全く問題ないと思います。 抜糸したあとも、基本的には傷口にテーピングをして置きます。このとき、傷口に対して垂直にテープを張ると傷跡が残りにくくなるそうです。 抜糸後の生活松葉づえが取れるまでは、手術から40日くらいがたった頃だったと思います。足はものすごい勢いで細くなります。 リハビリは、1週間に2回 or 3回のペースで通院しましたが、自宅でも積極的にリハビリをすることが大事です。膝のお皿動かしや、膝の力入れを積極的にしました。 病院までの通院は、電車やバスなどは使わずになるべく車で送り迎えをしてもらいましょう。電車やバスの場合、急な揺れや人との接触による危険があるため、車で送り迎えしてもらうのが良いと思います。 1回のリハビリは約1時間～1.5時間ほどで、理学療法士によるマッサージ、足上げによる筋トレ、EMS、超音波、患部側の足に体重を徐々にかける練習、歩く練習、あたりがメインでした。 ちなみに、手術後に手術した方の足に体重を乗せるのは緊張するものです。 松葉づえを卒業するためには、最終的に手術したほうの足に全体重が乗っても大丈夫な状態にならなければなりません。 いきなり全体重をかけるのではなく、最初は自分の体重の1/4, 1/2, , 全体重、という風に段階を踏んで徐々に進めていきます。 リハビリで重視されたのは「膝の力入れ」基本的に炎症を抑えることについて変わらないのです。膝を曲げる角度も時期に応じて制限があるので理学療法士の人の指導に従うべきだと思います。 とはいうものの、リハビリのなかでも、膝の力入れは、結構徹底されました。 膝の裏に丸めたタオルを入れて、太ももの前の筋肉を意識して、そのタオルを押しつぶすように力を入れる動作です。ちょっと言い過ぎなのでは？とも思いましたが、「100回でも200回でもいいからいくらでもやりましょう」というぐらいの勢いです。 (実はこの膝の力入れを本気でやることの重要性を、後々知るのでした。このあたりは、続きの記事でまとめようと思います) 注意事項など、参考になる良い動画がYoutubeにあったので、ここに載せておきます。 膝の状態、感覚退院直後は膝からの出血もあるため、松葉づえでトイレに行くときに血液が足先にたまっていく嫌な感覚がありますが、代替術後2週間くらいになるとで嫌な感覚がなくなります。 ※本記事冒頭のように、ふくらはぎ周辺に出血の跡を意味する黄色いシミみたいなのができてきます。 松葉づえの卒業手術してから約1ヵ月後くらいに、手術した方の足に、全体重が乗せられるようになり、かつ、ある程度松葉づえなしで歩けるようになれば、松葉づえ1本の卒業が認められました。 松葉づえなしで歩けるといっても、長い距離を歩いたり、走ったりは全くできないので、1本は持っておいた方が良いだろうという判断でした。 特に下り坂は膝に負担がかかるらしく、結構きつい。。。。そのため、手術から1ヵ月後に会社に復帰する際は、念のため松葉づえをもって出社しました。電車やバスで急な揺れにも備えたほうが良いという判断を理学療法士の方としました。 朝の満員電車はなかなか席を譲ってくれないパタンも多いので、松葉づえを持っていきましょう。 まとめ 松葉づえ期間も基本的には安静。 リハビリは膝の皿動かし、膝の力入れ、EMS、超音波、など。皿動かし、膝の力入れは積極的に自宅でも行いました。 松葉づえの卒業は1ヵ月以上かかる。リハビリや通勤はなるべく車で送迎してもらえると良い。 抜糸は痛くない。 以上です。次は、復帰を早めるためにリハビリ中に工夫したこと、辛かったことなどをまとめようと思います。以下に、7か月のリハビリについてまとめました。 体質改善したいひとにオススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/02/01/matsuba/"},{"title":"ベジタリアンは健康なのか？","text":"本記事では、以下の論文で報告されている内容を基に、「菜食主義が健康や長寿に好影響をおよぼすのかどうか」についてまとめたいと思います。 Veganism, aging and longevity: new insight into old concepts. - PubMed - NCBI ✓目次 結論：野菜中心の食事は健康と関連しているが、必ずしも死亡率を低下させるものではない。 概要 まとめ 結論：野菜中心の食事は健康と関連しているが、必ずしも死亡率を低下させるものではない。結局どっちなの？って感じです。 以下、論文で報告されている内容を簡単にまとめます。 概要そもそも、菜食主義に関する研究は、多く報告されていないのが現状のようです。 疫学的研究において、菜食主義はがんや心血管疾患の罹患率の低下などが報告されていまます。 菜食主義が、一貫して病気の発生リスクが低いことが示唆されているものの、死亡率にいては、菜食主義とときどき肉食機会のある場合で大きな差は認められていない。 菜食主義となることの効果は以下の通り。 タンパク質制限や特定のアミノ酸(ロイシンまたはメチオニン)の制限などは、潜在的に寿命の延伸をもたらすと考えられる。 インスリン抵抗性と脂質代謝異常や、その関連疾患を改善する可能性がある 腸内細菌が多様性に富み、健康に寄与すると考えられている 一方で、菜食主義の食事は、栄養のバランスを崩しがちでもある。適切なサプリメントを摂取する必要がある。特に、子供、妊婦、または高齢者では、菜食主義は健康の要件を満たせないリスクを考慮すべきである。 まとめ菜食主義は、一般的に寿命の延伸や特定の健康維持や改善につながるものの、栄養の偏りがあるので、死亡率自体に大きな影響や優位性はない、ということと理解しました。 体質改善したい方にオススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです* 楽にダイエットしたい！という方は以下の記事もおすすめです*","link":"/2020/04/18/veganism/"},{"title":"[打率3割必達]野球で自分にあったバッティングフォームを確定させる方法","text":"私なりに考え抜いて行き着いた、自分のバッティングフォームの確立の仕方をまとめてみました。 好調、不調の波が少なくなりました。 私は毎週末に草野球をしています。 しかし、チームの中ではクリーンナップを打つような強打者ではありませんでした。 打率は良くて2割前半。長打もたまにしか打てない。そんな感じです。 しかし、2019年は、打率.350でチーム2位。OPSはチームトップの1.169、という驚異的な数字を残すことができました。 ・「草野球をやっているが、打率は1割～2割。3割バッターになりたい。」・「Youtubeや本で勉強したが、色々な理論があって良くわからない」・「自分なりの打撃理論を確立して、打撃フォームを固めたい」 このような思いを持っている人に読んでいただきたいと思います。 ✓目次 ✓この記事を読むとどうなるのか 本記事の信憑性 [全体]取り組んだこと 共通項を実現するための手段や意識を構造化して文章化する 構造化した内容を試合や練習で実践し、その様子を動画で撮影する 撮影した動画を確認し、共通項が実践出来ているかを確認 2に戻って、3. 4. 5. を繰り返す 実際の打撃フォームの連続写真 最後に使うバットについて ✓この記事を読むとどうなるのか 自分の理想の打撃フォームを確立することができる。 打撃成績がアップする。3割も夢じゃない！ チームの中心選手になれる(かもしれない) 本記事の信憑性参考までに、私が所属する草野球チームのページの私の個人成績のページを載せます。 城山Jacks｜teams 2017年よりも前は成績を掲載していませんが、2012年から5年間ずっと打率2割前半、ひどいときは1割なんて時もありました。ちなみに2017年は、シーズン途中に右膝前十字靭帯を断裂するという大けがを負いました。。。。(これも別途記事にします) [全体]取り組んだことここからは、なぜ大きく成績を向上させることができたのかを解説したいと思います。 私は以下のような順番で自分の打撃フォームを確立していきました。 3割打者の共通項を抽出 共通項を実現するための手段や意識を構造化して文章化する。 構造化した内容を試合や練習で実践し、その様子を動画で撮影する 撮影した動画を確認し、共通項が実践出来ているかを確認 2に戻って、3. 4. 5. を繰り返す。 ちょっと分かりにくいと思うので、1.～5.をそれぞれ具体的に説明したいと思います。 ちなみに、大事なのは1. と2. だと思います。 色々な草野球人を見てきましたが、1. と2. をやらないまま、むやみに打撃練習をしても、効果は薄く、悩みに悩んで打撃フォームがコロコロ変わってしまい、迷走、、、、というパタンに走るような気がします。 3割打者の共通項を抽出 私は右打者なので、Youtubeで3割 or 30本以上の本塁打を放った、いわゆる超一流打者を参考にしました。 例えば、現役の日本のプロ野球選手だと、巨人の坂本選手、ヤクルトの山田選手、広島の鈴木選手、ソフトバンクの内川選手、あたりでしょうか。 メジャーリーガーも含めると、ミゲルカブレラ選手も参考にしたと思います。 各々、フォームは異なるものの、それぞれ比較し共通して言えることは以下だと思いました。 たった3つです。 [全体]終始、頭が動かない [構え]力みのない構え [溜め]軸足体重 [スイング]水平～アッパースイング 「なんだ、こんなのあたり前じゃないか。」 と思うかもしれませんが、 試合で打席に立っている自分の打撃フォームを見てみると、大体の人はこれができてません。 この当たり前を、ちゃんと試合でできるようにすることが大事なのです。 それでは次のステップに移ります。 共通項を実現するための手段や意識を構造化して文章化する「構造化」とは、言い換えれば「分解する」とか「詳細化する」ということです。 つまり、先ほどの3つの共通項をどのようにしたら自分のフォームに反映できるのかの手段や意識を考え文章にしましょう、ということです。 ここからは、人によって感覚や意識が違うので、「こうすればできます！」というのは正直言い切ることはできません。 だから、皆の打撃フォームは異なるのです。 では、先ほどまとめた共通項を例に、参考で私の中で考え構造化して文章化したものを記載します。 [全体]終始、頭が動かない スイングするぎりぎりまで軸足に体重を乗せる。 頭から地面に1本の棒が通っている感覚を持ちながら打つ。 [構え]力みのない構え 打席に立ったら深呼吸。 体全体をゆっくり動かしリラックス。 [溜め]軸足体重 右足つま先体重 右足に体重を乗せることを意識するために少し右ひざを曲げて体重を乗せる。 [スイング]水平～アッパースイング。力強いスイング。 ０だった力を一気に100に。ただし頭がブレない程度に。 ネクストバッターズサークルでマスコットバットを振る。 このように、抽出した共通項を体現するために、どのようにすればよいのかの手段を構造化（詳細化）していくのです。 そして、この構造化した文章をスマホに入れて試合や練習の前に確認しましょう。 構造化した内容を試合や練習で実践し、その様子を動画で撮影する読んで字のごとく、自分が打っている姿を撮影しましょう。自分のスマホを友人に渡し撮影してもらえば良いと思います。 撮影した動画を確認し、共通項が実践出来ているかを確認自分の打撃を動画で見ながら、抽出した共通項が実演できているか確認しましょう。思っていた以上にできていない可能性が高いと思います（(笑)） 2に戻って、3. 4. 5. を繰り返す動画を見ながら、「もうちょっと、軸足体重のほうが良いかな？」「構えの位置は、もう少し浅いほうが良いかな」などなど色々と思うことがあると思います。 色々試しながら、 「足を上げない打ち方のほうが頭が動いてない」 とか 「○○な意識をもったら、軸足体重になった。」 などなど、新たな発見があるはずです。それらをすべて、構造化した文章に書き加えましょう。 こんな感じです。 [全体]終始、頭が動かない スイングするぎりぎりまで軸足に体重を乗せる。 頭から地面に1本の棒が通っている感覚を持ちながら打つ。 足を上げない意識 [構え]力みのない構え 打席に立ったら深呼吸。 体全体をゆっくり動かしリラックス。 [溜め]軸足体重 右足つま先体重 右足に体重を乗せることを意識するために少し右ひざを曲げて体重を乗せる。 ○○な意識を持つ。 [スイング]水平～アッパースイング。力強いスイング。 ０だった力を一気に100に。ただし頭がブレない程度に。 ネクストバッターズサークルでマスコットバットを振る。 これを地道に繰り返しましょう。 おのずと、あなたの打撃フォームの軸が確固たるものになるはずです。 実際の打撃フォームの連続写真 内角低めの球を救い上げるような形で打ったので、右肩が下がっている(?)気がしますが、「頭の位置を変えない」、「力みのない構え」、「軸足体重」、「水平～アッパースイング」、この辺りはちゃんと再現できていると思いました。 こちらは、左中間に推定飛距離110mの3塁打を放った時のフォームです。 最後に使うバットについて肝心のバットですが、よほどのこだわりがなければ、ビヨンドマックスシリーズを購入しましょう。 ちなみにおすすめはビヨンドマックスギガキング02です。 今の草野球会においてバットのテクノロジーの進化は凄まじく、バットの質で打球の強さが天と地ほど変わります。 打球に鋭さが生まれれば、早く強いゴロになり、三遊間や二遊間の間を抜けるヒットが生まれやすくなります。 ちなみに私は2019年に、ビヨンドマックスギガキング02をAmazonで購入しました。(それまでは、ビヨンドマックスキングを使ってました。) 結果は、最初にお伝えした通り、長打率が.391だったのが、.717に上がりしました。 少々値は張りますが、「無駄にしたくない！」という気持ちが、打撃に対する姿勢に反映されるような気もしますので、ぜひ購入を検討してみてください。","link":"/2020/01/22/baseball_batting/"},{"title":"Dockerとは何か、メリット&#x2F;デメリットまとめ","text":"✓目次 この記事の対象者 仮想環境とは Dockerとは 従来の仮想化とコンテナ型仮想化の違い ホスト型仮想化 vs コンテナ型仮想化 その①：「仮想化のオーバーヘッド」 その②： 「アプリケーション実行の再現性」 その③： 「OSの自由度」 その④： 「分離レベル」 DockerイメージとDockerコンテナ Dockerイメージとは Dockerコンテナとは [参考]Docker Hubとは まとめ この記事の対象者 「仮想化」、「Docker」、聞いたことあってなんとなくわかるけど、ちゃんと理解していない気がする人向け だけど細かい内容ではなく概要レベルで何なのか、何がうれしいのかを知りたい、という人向け 仮想環境とは シンプルに言ってしまえば、下図におけるゲストとアプリの部分が「仮想環境」と述べることが多いです。 ホストOSというのは、我々が普段使っているノートPCのOSを指します。 そのPCにOracle VirtualBoxとかVMWare Workstation Playerというソフトウェアをインストールし、その中にUbuntuとかCentOSと呼ばれるゲストOSを導入してアプリを動作させている、という構成の場合、ゲストOSからアプリのことを仮想環境といいます。 この辺りは、実際に環境構築して手を動かしてみるとよくわかると思います。 Dockerとは Docker社が提供しているコンテナ型アプリケーション実行環境 Docker自体はGoで作られている。 Dockerには、Docker Community Edition(Docker CE)とDocker Enterprise Edition(Docker EE)が存在する Docker EEは有料版で、Docker CEは無償版 有料版は、Docker社が認定したコンテナやプラグインが利用できたり、イメージのセキュリティスキャンが行われる等の恩恵が受けられる。 基本的なDockerの機能は、無償版と有償版、共に利用できる。 無償版は、さらに Stable版と、Edge版の2種類が存在する。 Stable版は4半期ごとにリリースされ、Edge版は1か月ごとにリリースされる。 最新版を使いたい場合は、Edge版を選択する。 従来の仮想化とコンテナ型仮想化の違い 従来のホスト型仮想化とコンテナ型仮想化の違いは、コンテナ型仮想化は、ゲストOSを持たない、という点です。 ホスト型仮想化は、ハイパーバイザというミドルウェア上に各々のアプリを動作させるために、専有されたゲストOSを用意する。 コンテナ型仮想化は、ゲストOSを必要とせず、ホストOSのカーネルを用いて(共有して)動作している。 ホスト型仮想化 vs コンテナ型仮想化その①：「仮想化のオーバーヘッド」 ホスト型仮想化 リソース(CPUやメモリの使用率など)の面で、オーバーヘッドが多く、起動や停止に時間がかかる コンテナ型仮想化 コンテナは、アプリケーション実行に必要なものだけを含み、ホストOSのカーネルを使用するため、動作が速くリソースの使用率も少なくて済む。 その②： 「アプリケーション実行の再現性」 ホスト型仮想化 仮想マシンの環境の違いにより、アプリケーションが動作しなくなることが稀に発生する。 コンテナ型仮想化 特定のアプリケーションを動作させるために必要なものは、Dockerイメージにまとまっている。そのため、同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する。Dockerイメージについては後述します。 その③： 「OSの自由度」 ホスト型仮想化 仮想マシン上で任意のOSを動作させることができる。 コンテナ型仮想化 コンテナは、ホストOSのカーネルを使用して動作する。そのため、WindowsOS上で直接Linuxコンテナを動作させることはできない。その逆の、LinuxOS上で直接Windowsコンテナも動作させることもできない。 その④： 「分離レベル」 ホスト型仮想化 ハードウェアレベルで仮想化されており、ホストOSや仮想マシン間の分離レベルが高い。そのため、先ほどの図でいうVM1がVM2に影響を与える、といったことが起こりにくい。 コンテナ型仮想化 OSの機能を使用した仮想化は、ホスト型仮想化に比べて分離レベルが低い。そのため、要求されるセキュリティレベルが高いシステムを構築するには不向きと言われている。 外部から侵入されにくい設定や構成にし、不用意にパブリックなNWに公開しない点に注意する必要がある。また、不必要なパッケージをインストールしない、常にアップデートを心がけるなど、細かいケアが必要になる。 上記の記述を表でまとめると以下の通りです。 項目 ホスト型仮想化 コンテナ型仮想化 オーバーヘッド 多 少 アプリ実行の再現性 低 高 OSの自由度 高 低 分離レベル 高 低 DockerイメージとDockerコンテナ DockerイメージとDockerコンテナの違いを把握しておくことは、今後Dockerを実際に使ったり、kubernetesと言われるコンテナオーケストレーションツールを活用する際など、重要になってきますので、以降で簡単にまとめておきます。 Dockerイメージとは Dockerイメージとは、コンテナ実行に必要なファイルをまとめたファイルシステム Webサーバだったら、Apacheが既に含まれているもの。そのほかRubyの実行環境が入っていたりもする。要するに最初からパッケージ化されていて、実行環境を定義したもの。 aufsなどの特殊なファイルシステムが使用されている。aufs (AnotherUnionFS) は Linux のファイルシステムサービスであり、複数の異なるファイルシステム (ブランチと呼ばれる) のファイルやディレクトリ同士を透過的に重ねる (マージする) ことができる技術。 Dockerコンテナとは Dockerコンテナとは、Dockerイメージを実行してできる実際の実行環境。 Dockerイメージが実行環境のテンプレートであり、Dockerコンテナは、このテンプレートを用いて構築された実際の環境、と理解しておけばよい。 [参考]Docker Hubとは Dockerイメージのレジストリサービス https://hub.docker.com Dockerイメージの公開、検索、ダウンロードができる。 自身のアカウントを作成することで、作成したイメージを公開することもできる。 具体的な使い方については、別記事で今後まとめられればと思います。 まとめ Dockerとは、Docker社が提供しているコンテナ型アプリケーション実行環境 従来のホスト型仮想環境との違いは、ゲストOSを持たない、という点 ホスト型仮想化ではなく、Dockerを活用するメリットは、「動作が速くリソースの使用率も少なくて済む」、「同じDockerイメージからコンテナを起動する限り、環境が変わっても同様に動作する」という点。 一方、ホスト型仮想化と比較した場合のデメリットとしては、「OSの自由度が低い」、「分離レベルが低く、セキュリティ面でケアが必要になる」という点 Dockerイメージはテンプレート。DockerコンテナはDockerイメージを実行してできる実際の実行環境。 Dockerに特化した専門知識を身に着けたい方は以下がオススメ Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/03/14/Docker/"},{"title":"【特保＋楽痩せ食材】食べるだけで痩せる方法","text":"特保飲料と楽痩せ食材で簡単に痩せる方法を紹介。楽痩せこそが、リバウンドしない秘訣です。 この記事を見ている人は以下のような悩みがあるのではないでしょうか。 楽にやせたい 在宅期間中、なるべく運動せずに痩せたい。 バランスの良い食事が大事なのはわかるが、手間のかかる料理はしたくない or する余裕がない。 食べるだけで痩せる料理はどれも手間がかかる。怠け者の私でも実践できる良いものはないだろうか。 お金も時間もなるべくかけずに、食べるだけで痩せる食事を教えてほしい。 一つでも当てはまったら、この記事を読む価値はいくらかあると思いますので、お付き合いください。 かなりの怠け者でも継続して摂取できる食材、かつ、効果が示されているものを厳選してまとめております。 これから紹介する食材を摂取し、健康的な体を手に入れるだけでなく、リバウンドせずに体形をキープできるようになると思います。 ✓目次 本記事の対象者 本記事の信憑性 食材一覧 ✓焼き梅干し ✓ブロッコリースプラウト ✓特茶とからだすこやか茶 まとめ オススメ 本記事の対象者まずこの記事を読んでいる人の対象は以下とします。 医師からメタボリックシンドロームと診断された人 つまり、医学的に普通体系である人が、更に痩せて美しい体形を手に入れるための手法ではありませんので、ご注意ください。 とは言いつつも、実践すれば幾ばくか効果はあるかもしれないので、やってみる価値はあると思います。 本記事の信憑性現に私は、80kgから68kgまでこの方法で痩せました。 また私はビジネスサプリメントアドバイザーをはじめとした資格を持っており、栄養や食に関する知識があります。 そのため、これから紹介する食材がなぜ食べるだけで痩せるのかという理由も明確も示しながらまとめていきたいと思います。 食材一覧結論を言ってしまいます。以下が怠け者でも継続して摂取し続けられるお食事一覧です。 焼き梅干し ブロッコリースプラウト 特茶 からだすこやか茶W 以降は、作り方と効果が得られる理由をそれぞれまとめたいと思います。 ✓焼き梅干し焼き梅干しの作り方はとても簡単です。フライパンに少量の油をかけ、梅干しを投入し、少し焼き色がつくまで熱すればよいだけです。 「なんだよ、フライパンと加熱が必要だなんてめんどくさいじゃないか」 と言いたくなりましたよね？ なぜ焼き梅干しが怠け者向けなのかは、後々説明するとして、ひとまず、なぜ焼き梅干しが良いのかの理由を述べたいと思います。 梅干しには、「バニリン」という物資が含まれており、脂肪燃焼効果が備わっていることが分かっています。参考：脂肪燃焼作用 | 梅(梅干し)・バニリンの効能 | 紀州梅効能研究会 また梅干しには、バニリンによく似た「バニリングリコシド」という物質も多く含まれています。 このバニリングリコシドは、加熱することによって、バニリンに変化します。つまり、梅干しを加熱してから食べたほうが脂肪燃焼効果が高まるということです。 そしてさらに、ここが怠け者でも続けられるポイントなのですが、バニリングリコシドから変化したバニリンは、梅干しが冷めてもバニリングリコシドに戻らないということも明らかになっています。 つまり、、、 梅干しをまとめて加熱した後、冷蔵庫に入れても、バニリンが増えた状態を保つことができる ということです。 なので、梅干しを買ってきたら、全部の梅干しをフライパンで焼いてしまい、その後は冷蔵庫に入れ、隙間時間に食べればよいのです。 私は、朝起きたらとりあえず2粒。夜に小腹がすいたら1粒。みたいな形で食べています。 「塩分が気になる」という方は減塩の梅干しを用いる or 食べる量を控えめにするなどの工夫をしながら実施してみてはいかがでしょうか。 ✓ブロッコリースプラウトこちらは複数のメディアでも紹介されている食材ですね。 「スルフォラファン」という物質が、肝臓の働きを上げ、体質改善やダイエット効果があることが認められています。 怠け者でも続けられるポイントとしては、スルフォラファンを15g程食べた後、その効果が3日間継続する点です。 つまり 3日に1度、少し食べるだけで良い ということです。 また価格も安価でありお財布にも優しい点がGoodポイントだと思います。 サプリメントで手軽にスルフォラファンを取りたい、という方は以下がおすすめです。 ✓特茶とからだすこやか茶最後は、特保飲料の特茶とからだすこやか茶です。 「なぜ2種類なの？」と気になると思います。 理由は、特保飲料には、脂肪の燃焼を助けるタイプと脂肪の吸収を穏やかにするタイプの2種類が存在するということです。 特茶は、「脂肪の燃焼を助けるタイプ」であり、からだすこやか茶は「脂肪の吸収を穏やかにするタイプ」になります。 更に、からだすこやか茶Wは、脂肪だけでなく、糖質の吸収を穏やかにする効果もあるため、白米やラーメンが好きな方は特にこれを飲むことを推奨します。 そのため、私のお勧めは、以下のように飲み分けることです。 特茶→朝の通勤時に飲むからだすこやか茶→食事中 or 食後に飲む まとめ最後にまとめます。 怠け者向けの食べるだけで良いお食事は以下です。 焼き梅干し パックで買ったらまとめて焼いて、適宜食べる ブロッコリースプラウト 3日に1ど15g程度食べる。 特茶 朝にコンビニや自動販売機で買って飲む Amazonでまとめて買えば、ちょっとお得。 からだすこやか茶W コンビニなどで買って飲む Amazonでまとめてかえば、ちょっとお得。 その都度購入しても良いと思いますが、このような食品系は通販などでまとめて購入すると安く済みます。私は特茶やからだすこやか茶Wは、Amazonで購入しています。 ダイエットに成功すると、「もっと引き締まった体にしたい」という欲求が生まれてくると思います。そのような方向けの記事も、今後まとめていこうと思います。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです","link":"/2020/01/09/easy_diet/"},{"title":"マジメすぎると不幸になる話","text":"仕事はまじめに取り組まずにふざけたほうが成果も出るし評価も高くなる仕組みをご存じですか？ 研究結果に基づき、まじめにきっちり仕事をせずに遊び心を持って仕事をするほうが良いことが分かりました。 何のために仕事をしているのか？という疑問に対する答えが見つかるかもしれません。 目次 仕事は何のためにするのでしょうか？ 研究内容と結果 ユーモアは才能ではない まとめ 仕事は何のためにするのでしょうか？メンタリストDaiGoさんもYoutubeの中で以下のように述べています。 そもそも、仕事は何のためにしてますか？お金を稼ぐためですか？お金を稼ぐのは何のためですか？生きるためですか？生きるのって何のためですか？幸せになるためですよね。楽しく生きたいからみんな頑張っているわけですよね。不幸になるために頑張る人はいませんよね。でもこれってみんな見失うんです。私、講演会に呼ばれたりするときに、社長の人とかいっぱいいるんですが、よく聞く質問があるんですよ。「なんで起業したんですか？」って。するとですね、面白いことに、答えられない人が多いんですよ「お金が欲しいから」「成功したいから」って答える人がいるんですけど、「既にお金持ってるじゃないですか。成功してるじゃないですか。何が不満なんですか？」って聞きかえすんです。一見成功している人が幸せなのかというと必ずしもそうではなく漠然とした不安を抱えているんですね。 「何のために仕事をしているのか」という問いに対して、「生活のため」、とか、「仕事をするのは当たり前」というふうに、漠然と何気なく日常を過ごしている人は結構おおいのかな、と思います。 お金があって地位もある人が必ずしも幸せなのかというと、そうでもないな、と思う部分もありますしね。 結局、お金を稼ぐのも、仕事をするのも、幸せな状態でないと意味がないということだと改めて感じさせられます。 では、幸福になるためには何が必要なのでしょう、というのを調べてくれたのがチューリッヒ大学の研究なのです。 Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 研究内容と結果18歳～92最までのドイツ人4100名を対象にしたもので、全員にオンラインでアンケートを実施して、遊び心(Playfulness)が、幸福度に与える還元度を研究したものです。 要するに仕事でも人生でも遊び心を持って、悪い言い方するとふざけて生きている人と、まじめに生きている人とどっちの方が幸せなの？ という研究なんです。 遊び心の定義ですが、「ふざける」と述べましたがすべてを適当にやるというわけではないです。 例えば、自分が苦しい状況、まじめにやらなくちゃいけない状況、緊張している状況でも、周りに楽しさをふりまいたり、ユーモアを周りに与えたり、ということができるかどうか。目の前で起こっていることをいろんな視点で見て、面白さをもって、それを解釈することができるかどうか、ということです。 上手い突込みをいれたりとか、ちょっとぼけてみて周りから突っ込みが入る、みたいなユーモラスに会話ができる人っているじゃないですか。 一方で、上司の言うことを全部真に受けちゃったりとか、人に面白いことを言ったり冗談を言ったりすることをはばかるような人とか、仕事の時に冗談を絶対に言わない人、バカ話しないと決めちゃっている人とかいますよね。 それに対して遊び心がある人がどう影響を与えるかを調べたんですね。 結果として何が分かったかというと、遊び心をあらゆる場面で考えられる感覚は、すべての年齢に対してポジティブな体験を増やす、という効果が判明しました。 つまり、普段からユーモアをふりまいている人とか、ちょっと物事を嫌味にならない程度、反感を買わない程度でちゃかしたりとかができる人は、ポジティブな体験が増えたんですね。 つまり幸せになったということです。 ユーモアは才能ではないポイントは、ただユーモアを秘めている、だけではダメなんです。 少しでも良いから表に出す、というのが大事、とのことです。 笑いのセンスが必要というわけではなく、「茶目っ気があるなぁ」、とか、「遊び心があるなぁ」、というのを表現することが幸福感をあげる、ということなんです。 才能ではない、ということなんですね。 遊び心でを持って、ちょっとしたことを楽しむ、という姿勢が大事、という理解で良いと思います。 まとめ 「何のために仕事をするのか」の答えは、「幸せに生きるため」。今、自分は幸せだろうか。仕事で不幸になっていないだろうか、というのを自問自答してみるといいかもしれない。 仕事はまじめにやりすぎない。ちょっとしたことでもいいから遊び心を持つことが大事。 遊び心を持てることは才能ではない。ちょっとしたことを表現するだけでOK。 ユーモアのある人間に近づくためにオンライン学習をしませんか？ 遊び心を持てるようになれるには、自分のできることや引き出しを増やすことではないでしょうか。「本が苦手」、「毎日が忙しい」という方は、私も普段から取り組んでいるオンライン学習がおすすめです。プログラミングを例に、以下に記事をまとめているので、興味があれば読んでみてください。 エンジニアではなく、ビジネスや営業系の方は、以下の講座がおすすめです。私も受講しましたが、手書きで「誰に、どのような価値を、どのように提供すればよいのか」という思考法やフレームワークが学べます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWB6I0o\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/business_model/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1846780_8afd_2.jpg\"}}); ビジネスモデルを見える化しよう! その場で伝わる手書きの図解スケッチ 参考h3&gt; Playfulness over the lifespan and its relation to happiness: results from an online survey. - PubMed - NCBIhttps://www.ncbi.nlm.nih.gov/pubmed/23982439 https://yuchrszk.blogspot.com/2016/08/blog-post_22.html https://www.youtube.com/watch?v=werZT4hc26A&amp;t=13s","link":"/2020/04/19/happy-method/"},{"title":"[チートシート]minikube, dockerコマンドまとめ","text":"よく使うコマンドを一覧化しました。 ✓目次 Version確認 docker version確認 kubectl version確認 kubernetesクラスタを操作(minikube) minikube起動 minikube停止 状態確認 アドオン操作 アドオン追加 アドオン削除 アドオン一覧確認 リソース作成 リソース確認 リソース削除 Secretリソースのコマンド作成 Podに入ってコンテナ実行 Podとホスト間でファイル転送 ファイル転送(ホスト→Pod) ファイル転送(Pod→ホスト) Podの状態(概況)確認 Podのログ(詳細)を確認 Deploymentにおけるロールアウト履歴確認とロールバック ロールアウト履歴を表示 ロールバック dockerコマンド 指定されたイメージ取得 イメージ一覧 イメージ削除 コンテナ実行 コンテナ停止 コンテナ一覧 コンテナ削除(指定型) コンテナ削除(非指定型) コンテナ・イメージ削除 ビルド Dockerイメージの公開(DockerHub) Dockerイメージにタグ名追加 DockerHubへログイン DockerHubへ公開 Version確認docker version確認1$ docker version kubectl version確認1$ kubectl version kubernetesクラスタを操作(minikube)minikube起動1$ minikube start minikube停止1$ minikube stop 状態確認1$ minikube status ただし、実行環境がVirtualBoxではなくVMWare workstation等の場合は、--vm-driver=noneをコマンドの末尾に付与する必要がある。例えば、移動する場合は以下の通り 1$ minikube start --vm-driver=none アドオン操作 アドオンはminikubeに付属している機能で、様々なオプションを追加削除できる。 アドオン追加1$ minikube addons enable ADDON_NAME アドオン削除1$ minikube addons disable ADDON_NAME アドオン一覧確認1$ minikube addons list リソース作成 マニフェストファイルを作成したら、マニフェストファイルを指定してリソース作成/変更を行う オプション: -f &lt;filename&gt;: マニフェストファイルパス 例：kubectl apply -f hoge.yml 1$ kubectl apply -f &lt;filename&gt; リソース確認 作成したリソースを確認 オプション -f &lt;filename&gt;: マニフェストファイルパス TYPE: リソース種別(pod, replicasetなど) 例：kubectl get pod 1$ kubectl get [-f &lt;filename&gt; [TYPE]] リソース削除 指定したリソースを削除 オプション: -f &lt;filename&gt;: マニフェストファイルパス TYPE/NAME: リソース種別 or リソース名 参考（以下の-o wideオプションなどは、deleteコマンドにかかわらずgetコマンドでも使用可能。） -o [wide|yaml]: 出力形式を指定 wide: 追加情報の表示 yaml: YAML形式で表示 例：kubectl delete -f hoge.yml 例：kubectl get pod -o wide getコマンドに-o wideオプションを付与することでPodのIPアドレスが確認できる。 1$ kubectl delete [-f &lt;filename&gt;] [TYPE/NAME] [-o [wide | yaml]] Secretリソースのコマンド作成 Secretとは機微情報を扱うリソース。Secretのような秘密データは運用として手動登録になる。 引数: NAME: Secretリソース名 OPTION: --from-literal=KEY=VALUE: キーバリューペアを指定して登録 from-file=[KEY=]PATH: ファイルを指定して登録 1$ kubectl create secret generic NAME OPTION Podに入ってコンテナ実行 Podを作成後、作成したPodに入りシェル操作を行えるようにする。 引数: POD: 中に入りたいPod名 1$ kubectl exec -it POD sh Podとホスト間でファイル転送ファイル転送(ホスト→Pod) 指定されたファイルを指定された転送先に送る 引数: src: 転送元ファイル名/フォルダ名。ホスト側のカレントディレクトリからの相対パスでファイルを指定する。 pod-name: 転送先のPod名 dest: 転送先フォルダ名/ファイル名 例：kubectl cp ./hoge.txt debug:/var/tmp/hoge.txt 1$ kubectl cp &lt;src&gt; &lt;pod-name&gt;:&lt;dest&gt; ファイル転送(Pod→ホスト) 指定されたファイルを指定された転送先に送ります 引数: pod-name: 転送元のPod名 src: 転送元ファイル名/フォルダ名 dest: 転送先フォルダ名/ファイル名 例: kubectl cp debug:/root/hoge.txt ./hoge.txt 1$ kubectl cp &lt;pod-name&gt;:&lt;src&gt; &lt;dest&gt; Podの状態(概況)確認 Podがうまく動作しなかったときに必要となる。 引数: TYPE/NAME: リソース種別とリソース名を指定 例：kubectl describe pod/debug 1$ kubectl describe [TYPE/NAME] Podのログ(詳細)を確認 Podがうまく動作しなかったときに必要となる 引数: TYPE/NAME: リソース種別とリソース名を指定 —tail=n: 直近のnレコードだけ取得 例：kubectl logs pod/nginx 1$ kubectl logs [TYPE/NAME] [--tail=n] Deploymentにおけるロールアウト履歴確認とロールバックロールアウト履歴を表示 引数: TYPE: リソース種別 NAME: リソース名 1$ kubectl rollout history TYPE/NAME ロールバック ロールバックの実施 引数: TYPE: リソース種別 NAME: リソース名 —to-revision=N: 指定されたリビジョンに戻す。デフォルトは0(=直前の履歴) 1$ kubectl rollout undo TYPE/NAME --to-revision=N dockerコマンド指定されたイメージ取得 引数： NAME: Dockerイメージ名 TAG: タグ名。省略した場合はlatestになる。 例：docker image pull centos:7 1$ docker image pull NAME[:TAG] 省略コマンドは以下 1$ docker pull イメージ一覧 取得済みDockerイメージ一覧を表示 引数： なし 1$ docker image ls 省略コマンドは以下 1$ docker images イメージ削除 指定されたイメージを削除 引数： IMAGE: DockerイメージID [参考]Dockerイメージの削除にはdocker image pruneというコマンドもある。 これは、使われていないイメージを一括削除してくれるコマンド。 実際に作業するときは、このコマンドが使いやすい。 1$ docker image rm IMAGE 省略コマンドは以下 1$ docker rmi コンテナ実行 指定されたイメージを実行する 引数： OPTION -d:バックグラウンド実行 -it:shell実行する際に合わせて指定する 例：docker container run -it NAME sh -e KEY=VALUE: 環境変数を与える --name NAME: 実行時のコンテナ名を指定 -p CONTANER:HOST: コンテナポートをホストにマッピング COMMAND: 実行時に上書きしたいコマンド COMMANDは、Docker実行時にDockerコンテナに与えるコマンド。 例：docker container run -d nginx:1.17.2-alpine 1$ docker container run [OPTION] NAME[:TAG] [COMMAND] 省略コマンドは以下 1$ docker run コンテナ停止 指定したコンテナを停止する 引数: CONTAINER: コンテナID 1$ docker container stop CONTAINER 省略コマンドは以下 1$ docker stop コンテナ一覧 コンテナを一覧表示する 引数: OPTION -a: 停止中のコンテナも表示 オプション指定しない場合、起動中のコンテナのみが表示される。 1$ docker container ls [OPTION] 省略コマンドは以下 1$ docker ps コンテナ削除(指定型) 指定されたコンテナを削除する 引数: CONTAINER:Dockerコンテナ名 1$ docker container rm CONTAINER 省略コマンドは以下 1$ docker rm コンテナ削除(非指定型) 使用されていないコンテナを削除 引数: なし 1$ docker container prune コンテナ・イメージ削除 使用されていないデータを削除 引数: なし 1$ docker system prune ビルド 指定されたDockerfileを利用してDckerイメージを作詞絵 引数: OPTION: -t: イメージ名を指定する。「ユーザ名/イメージ名:バージョン名」で指定する形式が一般的 例：docker build -f hogehoge/test:v1.0.0 -f: Dockerfileの名前を指定する PATH: Dockerfileが保存されているパス 例:docker build -t test . 1$ docker build [OPTION] PATH Dockerイメージの公開(DockerHub)Dockerイメージにタグ名追加 引数: SRC_NAME: タグ付けしたいDockerイメージ名 TRG_NAME: 追加したいタグ名 1$ docker tag SRC_NAME[:TAG] TRG[:TAG] DockerHubへログイン 引数: -u USER: ユーザ名 -p PASSWORD: パスワード 1$ docker login [-u USER] [-p PASSWORD] DockerHubへ公開 引数: IMAGE_NAME: 公開したいDockerイメージ名 例：docker push hogehoge/test:v1.0.0 1$ docker push IMAGE_NAME[:TAG]","link":"/2020/03/22/commandsheat-docker-minikube/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで①[ケガ→手術→リハビリ開始まで]","text":"右膝前十字靭帯を断裂し、再建手術を受け、復帰に向けたリハビリに入る前までの体験談をまとめました。 以下のような関心事や分からないことがあれば読んでみても損はないと思います。 手術を決意した後、どのような流れで手術を迎えるのか、実体験を基にした具体的な流れが知りたい。 麻酔って、どんな感じなの？痛いの？ 手術中や手術が終わった後って、どんな感じ？ 細かいレベルで辛かったこと、痛かったことを知りたい。 私自身も、前十字靭帯の再建手術を受けました。野球に復帰するまでは10か月くらいかかり、リハビリを卒業するまでは約1年3か月くらいかかりました。 2017年5月: 野球の守備で前十字靭帯を損傷 2017年5月～7月: リハビリ 2017年7月: 再建手術・入院 2018年3月: 復帰※リハビリは続く 2018年8月: リハビリ卒業 順調に回復し現在はケガする前よりも高いパフォーマンスが発揮できるくらいになりました。 復帰に向けたリハビリの際に自分なりに工夫したことなども、今後別記事にまとめたいと思います。 ✓目次 手術を決意するまで 手術当日を迎えるまで 手術当日 翌朝 まとめ 手術を決意するまでケガをしたときは「捻挫かな？」という感じでした。 それなりに歩けましたし、ケガした当日は車も運転しました。 しかし翌日になると、みるみる膝が腫れてきたため、急遽職場近くの病院に行きました。 医者にケガしたときの細かい動作や、ケガをしたときに感覚を伝えると、 前十字靭帯を切ってるかもね。 とのことでした。「注射するから横になって」とすぐに言われたときは、心拍数はMAX。※注射苦手なんです。 注射の針は3cmくらいの長い針で、本当にビビりました。 注射自体はひどい痛みではありませんでした。口でゆっくり呼吸すると痛みが和らぐらしいです。 膝の中にたまった液体は、真っ赤な血液でした。 注射1本分の血液量(たしか50ccくらい)だったと思います。 血液ということは、何らかの健や組織が損傷している証拠らしいです。この時は絶望でした。 血液を抜いたあと、「痛み止めも膝に入れておくね。」と言われ、別の注射器で透明な液体を入れられました。痛み止めを入れてくれたはずなのに、気分が落ち込んだせいか、痛みが増した気がした。 ケガした膝をMRIで撮影し確認したところ、本来ならあるはずの靭帯がありませんでした。orz 「手術しない、という選択肢はあるのでしょうか？」 私の問いに対して医師は、 「今後、激しい運動をしないならそれでもいいけど、そうでないなら手術したほうが良いよ。自然に靭帯が戻ることはほぼ無いし、手術せずに運動したら変形関節症になって歩けなくなるかもしれないよ？」 ということなので、手術を受けることを決意しました。。。 手術当日を迎えるまですぐに手術なのかと思ったら、そうではありませんでした。 ケガによって委縮してしまった筋肉を、なるべくケガする前の状態に戻す必要があるためです。 なぜ手術前にリハビリが必要なのかは、病院のHPや専門の方がまとめている記事を参照いただければと思います。 私の場合、1か月後の7月に手術をするスケジュールで週に1回、3時間ほどのリハビリをしました。 内容は膝のマッサージ、スクワット(両足・片足)、ゴムチューブを使ったレッグカール(前と後ろ)が中心でした。 手術を受ける1週間前になると、手術の説明を受けます。 私の場合、手術は全身麻酔となりました。 入院は1週間。その後は自宅で1か月間、絶対安静ということになりました。 手術の同意書にサインをし、採血。（血液型とかアレルギーの検査の為だったような気がします。） 加えて、「麻酔に対するアレルギーがあるかどうか」を確認するために別室に連れていかれました。 何をするのかというと、腕の皮膚と筋肉の間に少量の麻酔を打ち、アレルギー反応が起こるかどうかを確認するのです。 ちなみにこの麻酔注射は、採血よりも全然痛かったです。 思わず「いててててて！」と声に出してしまいました。。。 特にアレルギーはでなかったので、そのまま帰宅しました。 その後は、保険関連で用意したほうが良い書類とかを確認し、当日を迎えることになります。 手術当日手術当時の朝は、飲み物を含む食事は禁止でした。（というか気分が落ち込みすぎて食欲なかった汗） 病院に向かう道中は、本当に憂鬱です。 麻酔は痛くないだろうか 全身麻酔から覚めなかったらどうしよう 術後の痛みに耐えられるだろうか などなど。 このような気持ちになるのは正直仕方ないかと思います。 病院に到着すると、まずは入院する部屋に案内されます。 そこで、血圧を図ったり、体重を図ったり、膝の状態の確認をされます。マジックでケガしたほうの足に色々書かれます。 そして、麻酔を体に入れるための点滴針も入れられます。これはそんなに痛くなかったです。 体重計に乗って体重を図ったり、膝はどのくらい曲がるのか、等のチェックもその際に行います。 しばらく待機。 すると、看護師さんが 「座薬をいれたいのですが私が入れましょうか？それとも自分で入れます？」 と言ってきました。 人に入れてもらうのは恥ずかしいので自分で入れることにしました。手袋とカプセル型の座薬を渡され、自分でその場でいれました。（なんとも言えない微妙な空気。。。） そしていよいよ手術室に案内されます。手術室には、自分の足で歩いて手術台に横たわります。 「気分はどうですか～。」とか「左腕にバンドを巻きますね～。」とか色々言われながら処置が進み、 麻酔入れますね～。 と言われた瞬間に、天井がぐにゃぐにゃになりました(笑)※みんな同じ感覚なのかな。 そして気が付いた時には手術が終わってました。 手術の時間も含めて、5時間くらい寝ていたと思います。 本当に時間の感覚無く、どれだけ時間がたったのかも分からないくらいの一瞬の出来事で少し恐ろしかったです。 目が覚めると看護師さんから、 「麻酔がまだ少し聞いているので、意識は朦朧してるとおもいますが時間がたてばはっきりしてくるので安心してくださいねー。何かあったらナースコールしてくださいー。あと、手術したほうの足の足首は、頻繁に動かしてくださいね。」 といわれました。 手術後の右足は出血状態が続いており、頻繁に足首を動かして血を循環させたほうが良いそうです。 間もなく先生からも半月板の状態はどうだったか、とか、いろいろ説明があります。 そしてそこで初めて手術後の自分の体がどのような状態になっているのかが分かるのです。 私の場合、体には計5本の管が入っていました。 左腕に点滴の管 右側股関節に痛み止めの管 右ひざのお皿の近くに血抜きの管（その1） 右ひざのお皿の近くに血抜きの管（その2） 尿道に管 ← これが最悪 全体を振り返ると一番つらかった/痛かったのは、この5.尿道の管だったように思います。 常に残尿感がある状態のような感覚でとにかく気持ち悪いし、少し体を動かすだけでチクチク痛いのです。 「（これ、いつか抜くと思うんだけど、絶対に痛い！）」と恐怖したのを今でも覚えています。 なお、膝は手術後の血が足にたまらないように少し高くされており、氷嚢でアイシングされた状態になっています。 この状態のときは全く身動きが取れないので、とにかく寝ることに徹したほうが良いです。（しかしながら、ときおり看護師さんが点滴の入れ替えや、尿の出具合を確認しに来るので、あまり眠れない。。。） ちなみに手術後の痛みは、股関節に入れられている管から入れられている痛み止めが効いているおかげでほとんどありませんでした。 翌朝朝10:00くらいになると、医師と看護師が管を抜きに来ます。 まずは、膝の管。 人によっては痛いようですが、私の場合は痛み止めが効いていたからかわかりませんが、痛みはありませんでした。 次に、股関節の管。この辺も大丈夫。 点滴もこの時に抜かれた気がします。 そして最後の尿道の管。 てきぱきと抜こうとするのでおもわず、「ちょっと待ってください。痛いです汗」と言いました(笑) 看護師さんが、 「口呼吸すると、幾分か痛みが和らぐみたいですよ？」 というので思いっきり口呼吸しました。。。 でもやはり、、、、 痛い！！！ って感じです。 しかし、すべての管がなくなると、本当に身軽になります。 以降は普通に食事もできます。 少ししんどいですが、自ら松葉杖を使ってトイレに行くこともできます。 この経験をすると、”自分でトイレを済ませることができる”ということのありがたみが分かります。介護される側の立場からすると、トイレのお世話をしてもらうのが精神的につらいものがあるのではと思いました。 この経験を忘れないように、自らの健康管理を徹底したいと思っています。 まとめ 手術を決意した後、しばらくリハビリ期間があります。 手術の数週間前に麻酔のアレルギー検査があります。少し痛い。 全身麻酔は怖くない。ただし、手術後が辛い。 特に尿道の管は辛い 自らトイレを済ませることのありがたみを感じられるので良い経験だと思ってください。 以上です。続きは以下の記事にまとめています。 オススメ 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/01/16/knee-surgery/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで②[手術後～退院まで]","text":"別の記事で、前十字靭帯再建手術後までの記事をまとめました。 本記事ではその続きとして、手術後1週間後の退院までのリハビリ等について、経験をまとめたいと思います。 以下のような悩みや疑問があれば、読んで損はないと思います。 そもそもリハビリに対してどのような気持ちで臨めばよいのか？ 手術直後のリハビリって何が辛い？痛い？ 手術直後のリハビリで気を付けることは？ 注意点ですが、以降は、あくまで私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的に担当の理学療法士さんや医師とも相談しながらリハビリは進めていただければと思います。 ✓目次 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる 手術後から退院までの1週間のリハビリ概要 松葉杖は思っていたよりも難しい 膝の皿動かし 足の上げ下げ 超音波当て EMS リハビリ以外で大事なこと①：アイシング リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない リハビリ以外で大事なこと③：入浴はできない リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請 まとめ 【言いたいこと】リハビリを頑張ればケガする前よりも高いパフォーマンスが発揮できる「リハビリ」というと、辛い、しんどい、地味な動きの繰り返し、ストレスが溜まる等、マイナスのイメージを強く持たれると思いますが、私はそうは思いません。 私が思うケガの治療以外にリハビリを行うことによって得られるメリットは、以下だと思っています。 正しい体の使い方を身につけられケガする前よりも高いパフォーマンスを発揮できる。 体の痛みや変化、ケガの予防に注意を払う習慣が身に付き、結果的に健康にスポーツができる期間を長くさせることができる。 なお、これらのメリットは私だけが感じていることではありません。 元プロ野球選手の小久保裕紀選手は、2003年に「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という、私とは比べ物にならないくらいの大けがを負いました。 しかし、懸命のリハビリを乗り越え、復帰直後の2004年に、キャリアハイの打率.314, 41本塁打, OPS1.013という成績を残しました。 加えて小久保選手は、この大けがのおかげで体のことを学び、練習法から食事の面まで見直すことができ、結果的に現役選手生活を伸ばすことにつながった、と述べています。 私自身も別記事でまとめていますが、リハビリを通じて、食事や栄養、ケガの予防について学ぶ良いきっかけになったと思っており、健康寿命を延ばすことにつながっているのではないかと感じています。 なので、ケガしたこと、リハビリをしていることに対して悲観的になる必要は無いのではないかと思います。 「より良い体作り、パフォーマンスを発揮するための特別なトレーニングに取り組んでいるんだ」という前向きな気持ちで取り組められることを願っております。 手術後から退院までの1週間のリハビリ概要以下に取り組みを退院まで毎日やりました。基本的に退院までは膝を無理に動かすようなリハビリは少なかったと思います。 松葉づえで移動する練習 平地 階段の上り下り 膝の皿動かし 上下左右斜め8方向まんべんなく手で動かす 足の上げ下げ 仰向けで足上げ 横向きで足上げ 超音波を当てる 手術の傷跡周辺をまんべんなく EMS 手術した後の膝は炎症が強いため、いかにこの炎症を抑えるかが目的になります。 また超音波などを活用して皮膚や関節内部の回復を促進する治療が行われます。 基本的には、受診されている病院様の計画に沿って進めていく形になりますので、異なる点はあると思いますが、私が経験したことベースで、辛かったこと/驚いたこと/大事にすべきことを中心にまとめたいと思います。 松葉杖は思っていたよりも難しいこの辺りは理学療法士の方のご指導に忠実に従いましょう。 トイレに自分で行けたりするように、まずは理学療法士の方と共に松葉づえで平地の移動と階段の上り降りの練習行います。 手術後の足は、「ニーブレース」と呼ばれる厚手のサポーターでガチガチ固められおり、足自体の自由も効かないため、思っている以上に重量があります。 そのため、松葉づえでの移動は、思った以上にかなり大変です。 特に階段の上り降りは、最初のうちは難しいです。 その中でも階段の下り移動は難しく危険なので最初のうちは一人で階段を使っての移動は控えたほうが良いと思います。 基本的にエレベーターを使うのが無難だと思いました。 またこの際、出血がある為だと思うのですが、松葉づえで歩くときのように、手術した足を心臓よりも低い位置に下すと、血液が足先にじわじわ溜まっていく嫌な感覚があります。 この嫌な感覚は、大体2～3週間くらいはあったと思います。 松葉づえでの移動は、正直体力的にかなりしんどいです。体重が両脇・腕に重くのしかかるので、両腕の筋肉痛がありました。 膝の皿動かし無理のない範囲で自分の指で手術したほうの膝のお皿をまんべんなく動かします。 手術したばかりなので最初は恐る恐る膝を動かしてみる感じです。 細かいやり方は理学療法士の先生に指導いただきながら実施していただければと思います。 足の上げ下げ横向きで足を10回～20回。うつ伏せで足を10回～20回上げるトレーニングを行います。 ニーブレースをつけているので足全体が重く結構きついです。 超音波当てスポーツ界では有名な伊藤超短波株式会社様の超音波機を手術した膝の傷口周辺に当てていきます。 これが実は周波数にもよるが結構いたかったです 膝の中からジワジワ熱を持った痛みが沸き起こってくる感じでした。 もちろん痛い場合は、周波数を下げる or 休み休み超音波を当てる感じで対応していました。もちろん痛いときは理学療法士の方に言いましょう。 超音波の専門家ではないので詳しいことはわかりませんが、膝の手術をした膝周辺は癒着が起こる場合があります。 超音波は幹部の治療を促進させるとともに、癒着を防いで関節の可動化を確保することを目的としているようです。 私はこの癒着がそれなりにあったので、この超音波治療を積極的に行いました。周りを見ると私だけでなく多くの人が各々の目的で超音波治療を受けていましたので、大半の人はこの治療を経験する可能性が高いと思います。 治療を受けた実感としては、確かに超音波を当てた後は、膝周りが軽いというか健康な膝に近づいた感覚が得られました。 しかしながら、前述した通り、なんともいえない痛みがともなうため、私はあまり好きではありませんでした。。。 EMS通販でおなじみの電流を流して筋肉を動かすやつです。 膝のお皿の上部に張り付けて、電流で筋肉を収縮させ、筋力をつけることを目的にした治療だったと思います。 基本的に前十字靭帯再建手術を受けた後のリハビリは、太ももの筋肉をつけることが主軸になります。 筋トレは、鍛えている筋肉の箇所を意識することが大事なので、太ももの筋肉に意識を集中させるのが大事だと思います。 リハビリ以外で大事なこと①：アイシング手術直後は膝の炎症を抑えるためにアイシングが重要になります。 退院後も積極的なアイシングが必要になるので、氷嚢は購入しておいたほうが良いと思います。 リハビリ以外で大事なこと②：前十字靭帯に負荷をかけない例えば足を組んだり、手術した足に負荷をかけるような姿勢や動作をしないように注意を受けます。 もちろん地面に足をつけることもNGでした。 リハビリ以外で大事なこと③：入浴はできない入浴は浴槽に入る際に転んだりする危険性があるので基本的にNGでした。 シャワーも不可でした。 ただし、洗面台で髪の毛を洗うのは可能です。 体は濡れたタオルで拭く形で対応します。 夏は熱くて汗をかくので結構しんどかったです。。。。 リハビリ以外で大事なこと④：高額医療費控除と医療保険の申請高額医療費控除や保険関連の書類、現金の対応が必要になります。 この辺は病院のスタッフの方や勤務先の会社、保険会社に問い合わせて、書類を用意しましょう。 まとめ リハビリは体の使い方や体のケアを学ぶ有益な取り組み。復帰後、ケガする前以上に高いパフォーマンスを発揮できたり、結果的に現役でいられる時間を長くさせる結果につながります。私自身がそうだったように、前向きな気持ちで取りくめば、良い結果が付いてくると思います。 手術後はしばらく安静。膝の炎症を抑えることが最優先。リハビリは基本的に膝の状態を見ながら理学療法士の指示に従い忠実に取り組みましょう。 松葉づえの移動では、階段の下り移動に気を付けよう。（階段を使うのはなるべく避けましょう） 超音波治療は地味に痛いが効果を実感できるのでちゃんとやったほうが良い。 アイシングが大事。靭帯に負荷をかけないように注意が必要。 入浴はできないが、洗面台で頭を洗うことは可能。 以上です。次は、松葉づえを卒業し本格的なリハビリに入るところをまとめたいと思います。以下にまとめました。 この機会に体質改善をしたい方向け 風邪を引きたくない！体の抵抗力を上げたい！という方は以下の記事もおすすめです 楽にダイエットしたい！という方は以下の記事もおすすめです","link":"/2020/01/26/knee-surgery-2/"},{"title":"[プログラミング学習]Progateの後はUdemyかSkillHacksがおすすめ","text":"「プログラミング 初心者 学習法」と検索すると、色々参考になる記事がありますが、参考までに私の経験に基づいた勉強法も記事にしようと思いました。 まず、ここで述べている「初学者」は以下のレベルとします。 パソコンの操作はブラインドタッチくらいならできる。 エクセル、パワーポイントくらいは使ったことがある。 プログラミングはHTMLを少し学校で勉強したくらい。 Progateを少しやってみたが、そのあとどうすれば良いか分からない。 このような方で、以下のような悩みがあれば読んでみても損はないと思います。 Progateはやった。そのあと「何か作れ。」といわれるけど、作りたいものなんてない。 「掲示板とか作ればいいよ？」と言われても、ちょっと腰が重い。 プログラミングスクールは、あまりいきたくない。忙しいし。 私も社会人になってからプログラミングを学びました。 最初は書籍で勉強したが、当然挫折。 少し古い本だとコードの仕様が変わっていたりしてエラーで動かないなんてことが頻発して、すぐに諦めました。 しかしながら、オンライン学習に出会い、取り組み始めてから、ストレス無くプログラミングや様々なITスキルを身に着けることができました。 書籍とは違い、その時々に応じてコードや内容がアップデートされるし、何よりも講師の人に質問ができる。 それも好きな時間、自分の都合の良いタイミングで、好きなだけ学習できるスタイルが私にはぴったりでした。 現在もオンラインでの学習を続けており、（自分でいうのも変ですが）オンライン学習マニアになりつつあります。 そこでこの記事では、プログラミングをこれから学ぼうとする人が第一歩を踏み出せるようなおすすめの講座を、勉強方法と共にまとめていきたいと思います。 プログラミングの勉強の第一歩を踏み出す参考になれば幸いです。 ✓目次 初学者におすすめのオンライン学習講座その①：Skill Hacks 初学者におすすめのオンライン学習講座その②：Udemy(【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論) オンライン学習の勉強方法：ちゃんとノートを取って復習する オンライン学習の効率化のために(Git, Github) まとめ 初学者におすすめのオンライン学習講座その①：Skill Hacks 育児の関係でプログラミングスクールに通い詰めるのも難しそうなのと、時間や課題に縛られたくなかったのと、なによりも挫折したくなかったので、Skill Hacksの受講を決めました。 Webで「Skill Hacks」とGoogle検索すると、賛否両論の記事が出てきますが、私個人の感想としては、Progateでプログラミングの雰囲気を掴んだ後のオンライン学習講座としてはかなり良いと思います。 私が良いと思う理由は以下の３つです。 サービスを作成する際に大切なサービスを作る前の設計方法や思考方法もレクチャーしてくれる。 コードの文法を単純にレクチャーするのではなく、コードを書く際の思考方法も合わせてレクチャーしている。 質問に対するリプライがとにかく早い。 Progateからプログラミングを学び始めた人が特に多いところだと思うのですが、何らかのサービスを作る際、プログラマーは「完成品に向けていきなりコードを書き始める」、と思われる点です。 それはNoで、何らかのサービスを作る際に重要なのは、「設計」なのです。 多くの教材は、この「設計」の考え方がなく、完成品がいきなり提示され、その完成品の作成に向けてプログラミングのレクチャが始まります。 しかしSkill Hacksは、そのようなスタイルではなく、「設計の考え方まで含まれている点が良いのです。」 また、設計後にコードを書く際も、単純にコードの書き方をレクチャーするのではなく、思考も含めてレクチャーがされています。 そして何よりも、エラーで躓いた際のサポートが的確で早い点です。 しかも無制限。聞き放題です。 とはいっても、私自身は2～3回くらいしか質問しなかったです。 それだけ講座の内容が分かりやすく、躓かないように工夫がなされている証拠だと思います。 では、肝心の価格ですが、69,800円（税込）です。※2020年4月時点 少々値は張ると思いますが、この値段で、94本の動画と無制限質問サポートつき。追加料金なしの買い切り価格。 なので、教材としては一生ものになります。 ただし、価格は予告なく上がる可能性があるようです。 近年の、コロナウィルスの影響で、リモートワークが一気に普及しました。 そのため、リモートワークがしやすい、IT企業への就職または転職を目指す人が増えてくるでしょう。 そうなれば、おのずと本講座の受講生は増えるだろうし、それに伴い、受講料も上がる可能性が高いと思います。 7万という価格で一生もののスキルを身に着けられますし、7万なんて正直すぐに回収できる価格なので、個人にとってみればほぼ無料(むしろ得でしかない)価格に等しいので、ぜひ前向きに検討してみてはいかがでしょうか。 初学者におすすめのオンライン学習講座その②：Udemy(【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論) 【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編） あまりお金をかけたくないという方は、こちらの講座が良いと思います。 Udemyは私もIT関連の技術を学ぶために活用しているオンライン学習プラットフォームです。 30日間の返還保証もついており、頻繁に90%の割引セールが行われます。 通常価格は2万円くらいですが、セール中は最安値で1200円で購入することができます。 ちなみに、私はいつも不定期に開催されるセールの時期に、興味のある講座をまとめて購入しています。 数あるUdemyの講座の中でも、「【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論」はオススメです。 理由は、最初に述べたSkill Hacksと同様、プログラミングを書く際の思考が学べる講座だからです。 この講座を実際に受講して、私個人が「いいな」と思ったのは、いきなりコードを書かずに日本語の文章でどのような処理をどうすればよいのかという考え方から入る点です。 これは、実際に仕事でプログラミングをする際にも行うことなのですが、この工程をせずにいきなりコードを書き始める講座がホントに多いんですよね。。。。 どのような設計や構造にすれば、目的のシステムが作れるのかというのを、頭に思い浮かべながらコードを書くことができる人はごく少数です。 大抵は、まず日本語のテキストや絵をつかって、どのようなアルゴリズムで組み立てればよいのかを整理する「設計」から入るのです。 また、この講座の中でも講師の方が何度も言うのですが、「最初から完璧で美しいコードを作ろうとせず、まず動かすことを目指しましょう」という考え方が、とてもGoodだと思いました。 本当にそのとおりで、最初は汚いコードでも動けばOKで、動いてから綺麗なものに成形(リファクタリング)すればよいと思います。 正直、コードの書き方自体は、様々なオンライン講座で学んだ知見＋Google検索を駆使すれば問題ありません。 繰り返しになりますが大事なのは、コードを作成する前の設計や思考と、まずは思った通りに動くものを作る、という考え方が大切だと思っています。 この講座は、Udemyで受講してきた数々の講座の中でも、プログラミングの思考にフォーカスしている講座なので、特におすすめです。 オンライン学習の勉強方法：ちゃんとノートを取って復習するskill hacksに限らず、オンラインの動画でプログラミングなどを勉強する際は、単純に動画の通りに手を動かして進めてもあまり定着しないと考えています。 理由は単純に忘れてしまうからです。。。汗 忘れないためにどうすればよいでしょうか。 動画を何度も見返せばよいでしょうか。 それでは少し非効率なのではと考えています。 私の考えとしては、 どのような思考で1つ1つのコードを書いたのかを、何度も振り返られるようにノートを取る というのが、良いと思っています。 ノートの取り方は各々の環境に合わせてやりやすい方法で良いと思いますが、 私の場合は、Boostnoteというツールを使っています。(無料です) Boostnoteに、コードを書く際の思考の流れと、実際のソースコードを記述し、Githubというコードやテキストファイルなどを保存/管理するプラットフォームに置いて、隙間時間にスマホ等で復習を行うとよいでしょう。 BoostnoteとGithubは、マークダウンという記法を活用すると、コードを色付けしてくれたりして、読みやすくなるのでお勧めです。 最低限まずは、以下の「見出し」と「コードブロック」の書き方を覚えておけば良いでしょう。 Googleで「マークダウン 書き方」と検索すれば、記述方法がまとまった記事が出てくるので、参照してみてください。 最低限、見出しとコードブロックだけ覚えておけばOKです。 オンライン学習の効率化のために(Git, Github)先ほど少し述べましたが、Gitというのは、ドキュメントやソースコードなどの記録を変更履歴とともに管理するシステムで、GitHubは、このGitの仕組みを利用して、プログラムコードやデザインデータなどを保存できるウェブサービスです。 skill hacksで学んだ内容をGitHubに記録すれば、通勤中、奥様のお買い物の付き添い中、（環境にもよりますが）職場でも自分の勉強した内容を復習することができます。 勉強は何よりも復習が大事です。 また、GitとGitHubはエンジニアを目指すのであれば必須の知識です。 学んでおいて全く損はない（むしろ得することばかり）なので、プログラミングの学習と並行して、GitとGitHubも勉強しましょう。 なお、GitHubは、プライベートモードにしておけば、他の人に閲覧されることはないのでご安心ください。 Git, Githubについては、Udemyにも講座がありますので、是非受講してください。以下がおすすめです。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rNlhfWh\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://i.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); Git： もう怖くないGit！チーム開発で必要なGitを完全マスター まとめ プログラミングはコードの書き方ではなく、サービス設計とコードを記載する際の思考が大事 Progateが終わったら、Skill Hacksか【キカガク流】プログラミング力向上のためのPythonで学ぶアルゴリズム論（前編）がおすすめ。 動画を見ながら手を動かすだけではなく、講師が口頭で述べている考え方もちゃんとノートを取ろう。 ノートはBoostnoteがおすすめ。 余力があればGit, GitHubの使い方も勉強し、作成したノートをいつでもどこでもスマホで復習できるようにしよう。 Git, GitHubの勉強も、Udemyのベストセラー講座を活用しよう。 Skill Hacksを終えた方向けにおすすめのUdemy講座をまとめました。","link":"/2020/01/11/programing-study-next-of-progate/"},{"title":"【pipが使えない？】Cloud9でtweepyをインストールする方法","text":"TwitterのAPIを利用するライブラリであるTweepyのインストール方法です。Cloud9環境で実施しています。確認できたエラー、それに対する対応についてもまとめています。 ✓目次 Twitter API登録 Cloud9でTweepyのインストール Cloud9の環境をPython3環境にする Tweepyをインストール Twitter API登録以下の記事が大変参考になります。 Twitter API 登録 (アカウント申請方法) から承認されるまでの手順まとめ ※2019年8月時点の情報 - Qiita customer API keys(API keyとAPI secret key)とAccess token、Access token secretを取得しましょう。 Cloud9でTweepyのインストール以降はAWSが提供しているIDE環境であるCloud9環境での手順になります。 Cloud9の環境をPython3環境にするまずは、cloud9の環境をpython3の環境に変更します。 でなければpipのバージョンとpythonのバージョンがあわなくて、tweepyがインストールできません。以下の記事を参考に、環境設定を行いましょう。 【Python】Cloud9上でPython3系を使うとき絶対にやっておくべき環境設定【AWS】 | Utarog Cloud9のターミナルで、python -Vコマンドを実施し、以下の状態になったらOKです。 12345ec2-user:~\\environment $ python -VPython 3.6.8ec2-user:~\\environment $ pip -Vpip 9.0.3 from \\usr\\lib\\python3.6\\dist-packages (python 3.6)ec2-user:~\\environment $ Tweepyをインストールtweepyをpip install tweepyコマンドでインストールすると、下記エラーになります。 12345678910111213141516171819202122232425ec2-user:~\\environment $ pip install tweepyException:Traceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\basecommand.py\", line 215, in main status = self.run(options, args) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\commands\\install.py\", line 342, in run prefix=options.prefix_path, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_set.py\", line 784, in install **kwargs File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\req\\req_install.py\", line 1064, in move_wheel_files isolated=self.isolated, File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 345, in move_wheel_files clobber(source, lib_dir, True) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\wheel.py\", line 316, in clobber ensure_dir(destdir) File \"\\usr\\lib\\python3.6\\dist-packages\\pip\\utils\\__init__.py\", line 83, in ensure_dir os.makedirs(path) File \"\\usr\\lib64\\python3.6\\os.py\", line 220, in makedirs mkdir(name, mode)PermissionError: [Errno 13] Permission denied: '\\usr\\lib\\python3.6\\dist-packages\\urllib3'You are using pip version 9.0.3, however version 19.3.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command. pipをpip install --upgrade pipコマンドで、アップグレードしなさい、というメッセージなので、 以下のコマンドでpipをアップグレード 1ec2-user:~\\environment $ sudo pip install --upgrade pip pipコマンドを実行してみると、なぜかpipが使えなくなってしまいました。 12345678910111213141516171819202122232425262728ec2-user:~ $ pipTraceback (most recent call last): File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 658, in _build_master ws.require(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 972, in require needed = self.resolve(parse_requirements(requirements)) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 863, in resolve raise VersionConflict(dist, req).with_context(dependent_req)pkg_resources.VersionConflict: (pip 19.3.1 (\\usr\\local\\lib\\python3.6\\site-packages), Requirement.parse('pip==9.0.3'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"\\usr\\bin\\pip\", line 6, in &lt;module&gt; from pkg_resources import load_entry_point File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3049, in &lt;module&gt; @_call_aside File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3033, in _call_aside f(*args, **kwargs) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 3062, in _initialize_master_working_set working_set = WorkingSet._build_master() File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 660, in _build_master return cls._build_from_requirements(__requires__) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 673, in _build_from_requirements dists = ws.resolve(reqs, Environment()) File \"\\usr\\lib\\python3.6\\dist-packages\\pkg_resources\\__init__.py\", line 858, in resolve raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The 'pip==9.0.3' distribution was not found and is required by the application whichコマンドにallオプションをつけてpipの場所を探します。 123ec2-user:~ $ which -a pip\\usr\\local\\bin\\pip\\usr\\bin\\pip pipのインストールディレクトリがおかしかったようです。 この場合、python -m pipという風に-mオプションをつければOKです。 12ec2-user:~ $ python -m pip -Vpip 19.3.1 from \\usr\\local\\lib\\python3.6\\site-packages\\pip (python 3.6) 改めてtweepyをインストール。 --userをつけてね、とエラーが出たので以下のコマンドでTweepyをインストールします。 12345678910111213141516171819202122ec2-user:~ $ python -m pip install tweepy --userCollecting tweepy Using cached https:\\\\files.pythonhosted.org\\packages\\36\\1b\\2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec\\tweepy-3.8.0-py2.py3-none-any.whlRequirement already satisfied: six&gt;=1.10.0 in \\usr\\local\\lib\\python3.6\\site-packages (from tweepy) (1.13.0)Collecting requests&gt;=2.11.1 Using cached https:\\\\files.pythonhosted.org\\packages\\51\\bd\\23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb\\requests-2.22.0-py2.py3-none-any.whlCollecting PySocks&gt;=1.5.7 Using cached https:\\\\files.pythonhosted.org\\packages\\8d\\59\\b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9\\PySocks-1.7.1-py3-none-any.whlCollecting requests-oauthlib&gt;=0.7.0 Using cached https:\\\\files.pythonhosted.org\\packages\\a3\\12\\b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379\\requests_oauthlib-1.3.0-py2.py3-none-any.whlCollecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 Using cached https:\\\\files.pythonhosted.org\\packages\\b4\\40\\a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539\\urllib3-1.25.7-py2.py3-none-any.whlCollecting idna&lt;2.9,&gt;=2.5 Using cached https:\\\\files.pythonhosted.org\\packages\\14\\2c\\cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9\\idna-2.8-py2.py3-none-any.whlCollecting certifi&gt;=2017.4.17 Using cached https:\\\\files.pythonhosted.org\\packages\\b9\\63\\df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99\\certifi-2019.11.28-py2.py3-none-any.whlCollecting chardet&lt;3.1.0,&gt;=3.0.2 Using cached https:\\\\files.pythonhosted.org\\packages\\bc\\a9\\01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\\chardet-3.0.4-py2.py3-none-any.whlCollecting oauthlib&gt;=3.0.0 Using cached https:\\\\files.pythonhosted.org\\packages\\05\\57\\ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704\\oauthlib-3.1.0-py2.py3-none-any.whlInstalling collected packages: urllib3, idna, certifi, chardet, requests, PySocks, oauthlib, requests-oauthlib, tweepySuccessfully installed PySocks-1.7.1 certifi-2019.11.28 chardet-3.0.4 idna-2.8 oauthlib-3.1.0 requests-2.22.0 requests-oauthlib-1.3.0 tweepy-3.8.0 urllib3-1.25.7 ちゃんとインストールされているか確認します。 インタプリタモードで確認します。 12345ec2-user:~ $ pythonPython 3.6.8 (default, Oct 14 2019, 21:22:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import tweepy Tweepyのversionも確認してみます。 12ec2-user:~ $ python -m pip list | grep tweepytweepy 3.8.0 Tweepyがインストールできていることが確認できました。 APIを活用したアプリケーション講座 Rubyでビットコインを自動で売買するプログラムを作成できるようになります。bitFlyerのAPIドキュメントをマスターし、１人で開発ができるようになります。こちらの講座もCloud9を活用しているので、複雑な環境構築などは不要です。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXJ0Y7e\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム 絶対に躓かないオンラインプログラミング講座「SkillHacks」もおすすめです。LINE@による無制限質問サポートで挫折しない仕組みができており、合計94本のしっかりした動画があります。他のプログラミングスクールよりも安くて手頃です。 -Skill Hacks- 動画で学ぶWebアプリ開発講座","link":"/2020/05/01/twitter-api-tweepy-error/"},{"title":"Visual Studio Codeをインストールし、ターミナルをGit bashに変更する手順","text":"✓目次 Visual Studio Codeのインストール Visual Studio Codeの表記を日本語にする フォントサイズやデザインを変えたいとき Git for windows VScodeのターミナルをGit for Windowsのbashにする 参考 Visual Studio Codeのインストール マイクロソフトが開発したエディタ。Googleで検索してダウンロード。 ダウンロードされたファイルをダブルクリック。Visual Studio Codeセットアップウィザードが開く。 「次へ」を押下 ライセンスを確認して「同意」を押下 インストール先はそのままでOK。「次へ」を押下。 追加タスクの選択のパートで以下の項目に✓をいれて「次へ」を押下。これらにチェックを入れておくと便利。 「エクスプローラーのファイルコンテキストメニューに[Codeで開く]アクションを追加する」 「エクスプローラーのディレクトリコンテキストメニューに[Codeで開く]アクションを追加する」 「サポートされているファイルの種類のエディターとして、Codeを登録する」 「インストール」を押下。 Visual Studio Codeの表記を日本語にする Visual Studio Codeを開き、左側のメニューのExtentionを押下 検索窓に「japanese」と入力し、パッケージを選択して「install」を押下してインストールする VScodeの右下に、以下が出力される。再起動が必要です、ということなので「Restart now」を押下 日本語に変化！ フォントサイズやデザインを変えたいとき ファイル→基本設定→設定、を押下。 ここでフォントサイズを変更する。（お好みで） ファイル→基本設定→配色テーマ ここで見た目の配色を変更できる。 Git for windows ここからはターミナルをGit bashに変えたい人向けの設定です。 ダウンロードする Git for Windows インストールを実行。 改行コードの設定に注意する 仮想マシンからファイルを利用することが想定される場合は、仮想マシン側がUnixスタイルになっている。 ダウンロードしたファイルがUnixスタイルにしておく必要がある。 windows環境の git で改行コードの自動変換に注意 - Qiita VScodeのターミナルをGit for Windowsのbashにする 以下の記事が参考になります WindowsのVSCodeでGit Bashをターミナルに設定する - Qiita インストール後の作業 ~/.bashrcをexport TERM=cygwinを設定する Vagrantファイルの言語モードをRubyに設定する場合は、以下のように設定する。 色分けされるので見やすくなる VScodeのsettingを開き、検索画面でfiles.associationsと入力 jsonファイルの編集画面を開き下記のように書き換える Ctrl + s で保存 123456789{ \"terminal.integrated.shell.windows\": \"C:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\" \"files.associations\": { \"Vagrantfile\": \"ruby\" }} 参考 プログラミング学習についてまとめてみました。 Dockerに特化した学習は以下のUdemy講座がおすすめです。質、ボリューム共に豊富です。(私はこの講座を終えるのに2か月かかりましたが、非常に詳しく分かりやすくまとめられた講座です。) a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzatOk\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/docker-k/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1401310_1c83_3.jpg\"}}); ゼロからはじめる Dockerによるアプリケーション実行環境構築 Dockerの基礎や復習に加え、コンテナオーケストレーションを行うKubernetesについて学びたい場合は以下の講座がおすすめです。質、ボリュームもちょうどよく、Kubernetesの各種リソースの解説に加え、Web3層構造(MongoDB, Node.js, Nginx)の環境を構築をするので、実践的なスキルが身につくと思います。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWzbiR3\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/web-application-with-docker-kubernetes/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2331992_6ec8_5.jpg\"}}); Docker + Kubernetes で構築する Webアプリケーション 実践講座","link":"/2020/01/18/vscode-environment-with-gitbash/"},{"title":"【自然言語処理】word2vecとは何か？CBOWとskip-gramも解説","text":"本記事では、word2vecというものについてまとめてみます。 ✓目次 word2vecは言葉をベクトル化するツール CBOW(Continuous bag-of-words)とは skip-gramとは CBOWとskip-gramの比較 参考にした記事等 word2vecは言葉をベクトル化するツールword2vecは、分散表現を作成することができるツールです。 word2vecを活用すると、言語をベクトル化することができます。 ベクトル化することにより、定量的に単語同士がどれだけ似ているかを算出したり、数値計算のように、言葉を合成させたり、言葉を削除したりする、みたいなのができるようになります。 word2vecでは、下記2つのいずれかのニューラルネットワークが用いられます CBOW(continuous bag-of-words) skip-gram そもそも、ニューラルネットワークとは何か、という方は、以下のUdemyのコースがおすすめです。※セールの時期は1000円前後で購入できます。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWtt7KZ\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku-chainer/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356238_e149_4.jpg\"}}); 【キカガク流】現場で使えるChainerによるディープラーニング入門 CBOW(Continuous bag-of-words)とはCBOWとは、前後の単語から対象の単語を予想するニューラルネットワークです。 イメージレベルですが概略は以下のような具合です。 入力層、中間層、出力層があり、入力層と中間層の間と中間層と出力層の間に、重みが存在します。 図1において、青い長方形は、one-hot表現という単語を0と1からなるベクトルで表現されたものが当てはまります。 one-hot表現を「となりのととろ」という文章を例にあらわしてみると、以下のようになります。 「となり」、「の」、「ととろ」という風に単語ごとにIDが割り振られます。 one-hot表現は、該当する単語が位置している箇所を「1」と表して表現します。各単語に割り当てられたIDで表現されるのではなく、あくまでもテーブル表の列の位置で表されている点がポイントです。 そして、one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができるのです。 続いて図1において、黄色の長方形は分散表現というベクトルで表現されたものが当てはまります。 分散表現とは、単語を200個ほどの実数ベクトルで表現する方法です。 200個、のようにたくさんの値の個数で表現されていることを、高次元である、というので、分散表現をかっこよく説明したければ、「単語を高次元の実数ベクトルで表現する技術」と言えばよいです。 具体的なイメージは以下の通りです。 図3では、「男」、「東京」、「Ruby」という3つの単語があります。 これらは全く異なる単語なので、ベクトルは似ていません。もし、単語の類似度や関連性が高ければ、これらの単語同士の分散表現は、似たものになります。 この分散表現を活用すると、どのようなことができるかというと、例えば、 「王様」ー「男性」＋「女性」=「お姫様」 という風に、単語同士の足し算や引き算が可能になり、かつ、類似度の高い単語を見つけることができます。 次に、オレンジ色の長方形は重みを表す行列です。 重みを表す行列とは、例えば、「となりのととろ」の真ん中の単語の「の」を予測できるように学習させた後に生成される、各単語の分散表現が並んだ行列です。 以上のように、CBOWは前後の単語から対象の単語を予測するようにして分散表現を作成するものです。 skip-gramとはskip-gramとは、ある単語から前後の単語を予測するニューラルネットワークです。 CBOWとの違いは、入力が中央の単語で、出力がその前後の単語である点です。 そのため、CBOWとは逆に、中央の単語からその周囲の単語を予測するように学習が行われます。 skip-gramにおいても、CBOWと同様に学習によって、入力層と中間層の重みの行列は、分散表現のベクトルが並んだ行列になります。 CBOWとskip-gramの比較この辺は別記事で実際に比較評価をしてみようと思います。 一般論としては、CBOWよりもskip-gram方が、学習に時間がかかるが精度がよい、とされているようです。 この辺も後々、検証してみたいと思います。 参考にした記事等 分散表現(単語埋め込み) - 岩波データサイエンス [自然言語処理/NLP] Word2Vec触ったので備忘録としてざっくりまとめておく (理論編) | Developers.IO Word2Vecを理解する - Qiita 【まとめ】自然言語処理における単語分散表現（単語ベクトル）と文書分散表現（文書ベクトル） - Qiita 以下のUdemyのコースはとてもオススメa8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/04/18/word2vec-overview/"},{"title":"オブジェクト指向のクラスをシンプルに理解する","text":"プログラミングを学習すると、高い確率で「オブジェクト指向」という言葉に誰しもが悩まされると思います。 本記事では、とてもシンプルにオブジェクト指向のClassの使い方をまとめます。 実際にご自身のプログラミング環境で手を動かしながら勉強してみてください。 ✓目次 この記事の対象者 プログラミングの環境を用意しよう。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態 クラス(設計書)を作成する。 クラス(設計書)の項目にパラメータを設定する。 クラス(設計書)をインスタンス化(実態化)する。 インスタンスに名前と国と年齢を聞いてみる。 クラス（設計書）の設計項目を変数にする。 【発展】インスタンスが挨拶する関数を作ってみる。 【発展】call関数の使い方 最後に この記事の対象者 プログラミングを勉強し始めたがオブジェクト指向、クラス、インスタンスというのが良くわからない人 回りくどい説明が嫌な人 シンプルなコードで、ざっくりと理解したい人 プログラミングの環境を用意しよう。Jupyter Notebookという環境で説明します。 以下、この記事を読まれている方の思考に応じて、2パターンのプログラミング環境の用意の仕方を紹介します。 その1:自分のPCにプログラミング環境を用意したい人 以下の記事を参考に、ご自身のPCに環境構築してみてください。 その2：環境構築とか面倒、という人 Google Colaboratoryがおすすめです。 Google Chromeとgoogleのアカウントを持っていれば、ブラウザ(Google Chrome)のみでプログラミング環境が用意できます。 【結論】クラス：設計書。インスタンス：設計書を基に作られた実態様々な本で同じような説明がされていると思います。 ここからは実際に簡単なソースコードを活用しながらクラスとはどのようなものなのかを理解していただければと思います。 クラス(設計書)を作成する。設計書には、最低限以下の2つを定義しなければいけません。 設計書の名前 設計項目 具体的な例として、人間(Person)という設計書を作っていきましょう。 今回は以下のような設計書を作ろうと思います。 設計書の名前: Person 設計項目 名前: name 国: nationality 年齢: age 早速、Personという設計書として名前, 国, 年齢という3つの設計項目を用意してみます。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"\" # 名前 self.nationality = \"\" # 国 self.age = \"\" # 年齢 このコードをJupyter Notebookのセルに記載して、実行してください。 SHIFTを押しながらEnterキーで実行できます。 これで、「人間」というクラス（設計書）ができました。 クラス(設計書)の項目にパラメータを設定する。次に、この設計書の各項目に値を設定します。 設定する値は、以下のようにしたいと思います 名前：鈴木 国：日本 年齢：10 早速、先ほどの設計書の設計項目に設定していきましょう。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = \"鈴木\" # 名前 self.nationality = \"日本\" # 国 self.age = \"10\" # 年齢 これでOKです。 クラス(設計書)をインスタンス化(実態化)する。ここまで作ってきた人間クラス（人間の設計書）を実体化します。 これも簡単です。 1suzuki = Person() これで、「suzuki」というインスタンス(実体)が作られました。 これまで作ってきたPersonという設計書からsuzukiという名前の人間を作ったのです。 もちろん、suzukiという名前のインスタンスではなく、satoという名前でインスタンス化しても問題ありません。 1sato = Person() ただし、Personという設計書には、”佐藤”ではなく”鈴木”という名前が設定されていました。 それにもかかわらずsatoという名前でインスタンス化してしまうと、外見は佐藤なのに、名前が鈴木という変な人間が作られてしまいます。 これを解決する方法についても後述しますので、読んでみてください。 インスタンスに名前と国と年齢を聞いてみる。suzukiという人間と、satoという人間が作られました。 まずはsuzukiさんに名前を聞いてみましょう。以下のコードで名前を聞くことができます。 1suzuki.name Jupyter notebook環境だと、以下のようになります。 名前と国と年齢をまとめて聞く場合は以下のようにすればOKです。 123print(suzuki.name)print(suzuki.nationality)print(suzuki.age) すると、以下のように出力されるはずです。 satoというインスタンスにも名前を聞いてみます。 想定通り、satoさんにもかかわらず”鈴木”と返ってきました。 でもこれ不便だと思いませんか？ クラス(設計書)の各設計項目に、鈴木、日本、10(歳)、という風に設定しまうと、suzukiというインスタンスしか作れなくなってしまいます。 できるなら、satoの中には、”佐藤”という名前を設定したいし、katoの中には”加藤”という名前を設定してほしくないですか？ これを解決する手段として、クラス(設計書)の設計項目を変数にするというのがあります。 クラス（設計書）の設計項目を変数にする。ここまで作成してきたPersonクラスの各設計項目(名前、国、年齢)には、”鈴木”、”日本”、10と設定していたいましたが、これをnamae, kuni, toshiという変数を設定します。※変数名は何でもOKです。 以下のようになります。 1234567class Person: # Personという名前の設計書ですよ、と宣言 # Personの設計項目の設定 def __init__(self): # selfを忘れないように！ self.name = namae # namaeという変数を設定 self.nationality = kuni # kuniという変数を設定 self.age = toshi # toshiという変数を設定 もう少し改造が必要です。 def __init__(self):の部分に、先ほど設定した3つの変数を追記して、def __init__(self, namae, kuni, toshi):とします。 1234567class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi インスタンス化してみます。 今回は、katoでインスタンス化してみたいと思います。 1kato = Person() すると、以下のようにエラーになると思います。※安心してください、想定通りです。 なぜエラーになったのかというと、インスタンス化する際に、クラス（設計書）の設計項目に設定した変数に代入する値を設定していなかったからです。 つまり、インスタンス化する時は、クラスで規定したnamae, kuni, toshiに代入する値を()に記載しなければいけないということです。 今回は、katoというインスタンスを作成するので、各設計項目に設定する値は以下とします。 名前(namae): 加藤 国(kuni): 日本 年齢(toshi): 30 以下のようにしてkatoというインスタンスを作成しましょう。 1kato = Person(\"加藤\", \"日本\", 30) ついでに、mikeというインスタンスも作成します。 1mike = Person(\"mike\", \"アメリカ\", 20) こうすることで、kato.nameと実行すれば”加藤”というのが出力されますし、mike.nameと実行すれば”mike”というのが出力されます。 【発展】インスタンスが挨拶する関数を作ってみる。発展と言っても難しくないのでご安心ください。 作成したインスタンスに、「こんにちは井上さん。私は鈴木です。」という風な感じで、挨拶をする関数を実装してみます。 以下の通り、9行目と10行目を追記してください。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self): print('こんにちは井上さん。私は鈴木です。') 早速インスタンス化しましょう。 まずはsuzukiさんというインスタンスを作成します。各変数に代入する値の設定を忘れずに！ 1suzuki = Person(&quot;鈴木&quot;, &quot;日本&quot;, 1) 早速、suzukiに挨拶をさせてみましょう。 1suzuki.say_hello() 以下のようにちゃんと挨拶ができました。 では次にbobさんというインスタンスを作成しましょう。この際も、各変数のに代入する値の設定を忘れずに! 1bob = Person(\"ボブ\", \"アメリカ\", 70) bobに挨拶をさせてみましょう。 1bob.say_hello() 以下のように出力されます。 ここまで来たらある程度予測できたのではないでしょうか。 そうです、ボブなのに、「私は鈴木です。」と言ってますね。 理想としては、ボブだったら、「私はボブです。」と挨拶できるようにしたいですよね？ あと、「こんにちは井上さん。」の”井上”の部分も、設定に応じて柔軟に変化できるようにしたいです。 順序が逆になってしまいますが、まずは、「こんにちは井上さん。」の”井上”の部分を柔軟に設定できるように変数化してみたいと思います。 これを解決する方法は、以下のように、say_hello(self, namae):という風に、namaeという変数を追加し、print('こんにちは{}さん。私は鈴木です。'.format(namae))という風に変更/追記すればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は鈴木です。'.format(namae)) 改めて、bobさんというインスタンスを作成し、近藤さんに挨拶をさせてみましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)bob.say_hello(\"近藤\") 以下の通り、「こんにちは近藤さん。私は鈴木です。」という風に、井上さんが近藤さんに代わりました。 最後に、bobというインスタンスの場合は、「私はbobです。」に変換し、tomというインスタンスの場合は「私はtomです。」という風に出力させるように改造します。 まず、”鈴木”の部分を{}に変更しします。 そして、この中括弧に当てはまる変数ですが、ここはインスタンス化する際に設定する名前なので、5行目のself.nameを指定すれば良いです。 selfは”自分自身の”と言い換えればOKです。 12345678910class Person: # Personの設計項目の設定 def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行したら、早速bobインスタンスとtomインスタンスを作成しましょう。 12bob = Person(\"ボブ\", \"アメリカ\", 70)tom = Person(\"トム\", \"アメリカ\", 120) bobとtomに挨拶をさせてみます。 1bob.say_hello('近藤') 1tom.say_hello('山本') 以下の通り、ちゃんと期待通りに挨拶する相手を呼び、自分の名前を言えるようになりました。 【発展】call関数の使い方ここからはさらに発展になるので、「もう限界です。」という方は、ここまででも大丈夫です。 call関数というのは簡単に言うと、関数名を呼び出さずに処理を実行させることができる関数です。 言葉で説明するよりか、実際の動作を見たほうが分かるので、早速使い方を見ていきましょう。 以下のように、__call__という関数名で、say_hello()関数と同様の処理を定義してみます。 12345678910111213class Person: def __init__(self, namae, kuni, toshi):# namae, kuni, toshiを追記 self.name = namae self.nationality = kuni self.age = toshi # call関数でsay_hello()を定義 def __call__(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) def say_hello(self, namae): print('こんにちは{}さん。私は{}です。'.format(namae, self.name)) 上記のコードを実行し、yamadaというインスタンス作成します。 1yamada = Person(\"山田\", \"日本\", 200) そして、yamada.sayhello('大和田')というコードと、yamada.__call__('大和田')というコードを実行してみると、共に、「こんにちは大和田さん。私は山田です。」という出力が得られます。 では次に、yamada('大和田')という風に、関数名を宣言せずに実行してみてください。 すると、同様に、「こんにちは大和田さん。私は山田です。」と出力されます。 つまり、yamada.__call__('大和田')という風にわざわざ書かなくても、yamada('大和田')とするだけで、同様の処理が実行されるのです。 以下の通りです。 便利な関数なので、積極的に使ってみましょう。 最後に 本記事では、クラス、インスタンスの関係に加えて、関数の定義方法やcall関数についてもまとめました。 プログラミング学習については、以下の記事でおすすめの教材や勉強方法をまとめていますので、興味のある方は読んでみてください。","link":"/2020/05/05/class-practice/"},{"title":"【Keras基礎】ニューラルネットワークを作成してsin関数を学習して予測させてみた。","text":"ニューラルネットワークとはどのようなものかをkerasという機械学習を簡単に使うためのライブラリを使ってまとめました。高校の数学でならったsin(サイン)関数をつかって、学習→予測をしてみたいと思います。 ✓目次 本記事の対象者 環境 学習データの準備 入力データxの作成 正解データ（sin関数）の作成とグラフ描画 ニューラルネットワークの構築、学習、予測 ニューラルネットワークの設定 ニューラルネットワークの構築 1セット目(入力層と中間層)の追加 2セット目(中間層と出力層)の追加 コンパイル ニューラルネットワークを用いて学習 学習の推移をグラフで確認 学習済ニューラルネットワークを使用して予測 本記事の対象者 ニューラルネットワーク、というものがなんとなくわかっているが、細かい言葉の定義とかを忘れてしまった人。（順伝播、逆伝播とかを知っている。） 高校の数学（特に三角関数）を理解している。 pythonのプログラミングを、それなりに理解している。（progate等でpythonの使い方を雰囲気程度で理解している） これから本格的に、ニューラルネットワークを学ぶために基本的なことを復習したい人。 環境以下の記事で紹介しているように、Anaconda NavigatorでJupyter notebookの環境を整えてください。 もしくは、Google Colaboratoryという、Google chromeというブラウザのみでプログラミングができる環境を使ってもいいと思います。 https://colab.research.google.com/?hl=ja 学習データの準備本記事では、データの例としてサイン関数を用意したいと思います。 入力データをx, 正解データをtとします。 入力データxの作成まずは入力データとなるxを作成します。 ソースコードは以下の通り。 123456import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1)print(x) numpyとmatplotlibというライブラリをインポート。 入力xとしてnp.linspace(-np.pi, np.pi).reshape(-1, 1)と記載していますが、これは、-πからπまでの値を50行、1列の行列データを作成しています。 linspace()というのは、値の範囲を指定するメソッドです。ここで、-np.pi, np.piとすることで、-π(-3.1415・・・)からπ(3.1415・・・)までの範囲の値を扱うことを宣言しています。 reshape()は、行数と列数を指定して、行列の形を指定したり変更したりするメソッドです。 このコードでは、reshape(-1, 1)、すなわち行数を-1, 列数を1としています。行数が-1ってどのような意味なのかというと、-1を指定することで、「良い具合に自動で列数決めてくださいね。」というメッセージを送っていることになります。 良い具合に、というのは、reshapeの大本であるlinspaceにおけるデフォルト設定のことを指しており、具体的な数値でいうと50が設定されます。 すなわち、-πからπまでの値を50等分した配列データを作成しています。 作成したxをプリントすると以下のようになります。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[[-3.14159265] [-3.01336438] [-2.88513611] [-2.75690784] [-2.62867957] [-2.5004513 ] [-2.37222302] [-2.24399475] [-2.11576648] [-1.98753821] [-1.85930994] [-1.73108167] [-1.60285339] [-1.47462512] [-1.34639685] [-1.21816858] [-1.08994031] [-0.96171204] [-0.83348377] [-0.70525549] [-0.57702722] [-0.44879895] [-0.32057068] [-0.19234241] [-0.06411414] [ 0.06411414] [ 0.19234241] [ 0.32057068] [ 0.44879895] [ 0.57702722] [ 0.70525549] [ 0.83348377] [ 0.96171204] [ 1.08994031] [ 1.21816858] [ 1.34639685] [ 1.47462512] [ 1.60285339] [ 1.73108167] [ 1.85930994] [ 1.98753821] [ 2.11576648] [ 2.24399475] [ 2.37222302] [ 2.5004513 ] [ 2.62867957] [ 2.75690784] [ 2.88513611] [ 3.01336438] [ 3.14159265]] これで入力データは完成です。 正解データ（sin関数）の作成とグラフ描画続いて、正解データであるtを用意します。 ソースコードは以下です。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(-np.pi, np.pi).reshape(-1, 1) print(x)t = np.sin(x) # sin関数plt.plot(x, t)plt.show() 1行目の、%matplotlib inlineですが、実はこれが記載されていないとJupyter Notebook環境でグラフが表示されません。おまじないのように記載しておきましょう。 3行目から7行目は、先ほどの入力データxで説明した箇所なので、説明は省きます。 9行目のt = np.sin(x)で、先ほどの入力データxをサイン関数にいれて、これを正解データtとしています。 そして、plt.plot(x, t)で、横軸をx、縦軸をtとし、plt.show()とすることで、描画したグラフを出力させます。※plt.show()の記述が無くてもグラフが描画されたりしますが、そこは気にしない。 コードを実行すると以下のようにサイン関数のグラフが出力されます。 ニューラルネットワークの構築、学習、予測ここから、Kerasを使ってニューラルネットワークの構築し、sin関数を学習し、入力データを用いて予測を行います。 ここで構築するのは、入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1の3層のニューラルネットワークです。 ニューラルネットワークの設定ソースコードは以下の通りです。 12345678910111213141516from keras.models import Sequentialfrom keras.layers import Dense# ニューラルネットワークの設定n_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数batch_size = 8 # バッチサイズ# 入力層、中間層、出力層の３層のニューラルネットワークを構築model = Sequential()model.add(Dense(n_mid, input_shape=(n_in,), activation=\"sigmoid\")) # 活性化関数にシグモイド関数model.add(Dense(n_out, activation=\"linear\")) # 活性化関数に恒等関数model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 損失関数に二乗誤差、最適化アルゴリズムにSGDを使用してコンパイルprint(model.summary()) 少し複雑に思うかもしれませんが、一つ一つ説明していきます。 入力層のニューロン数が1, 中間層のニューロン数が20、出力層のニューロン数が1、なのでニューラルネットワークの設定として、 入力層のニューロン数をn_in = 1 中間層のニューロン数をn_mid = 20 出力層のニューロン数をn_out = 1 という風に記載します。 続いて、バッチサイズを8と設定しています。 バッチサイズとは、膨大なデータを細かく分割する単位の数です。 例えば、100万個のサンプルがあったとします。 これに対してバッチサイズを100と設定した場合、100万のサンプルを100個ずつ細かく分割し、1万個の小さい100個入りの箱に分けるということです。 この箱の一つ一つをミニバッチといい、ミニバッチに分けて計算することをミニバッチ学習と言います。 ミニバッチ学習をすると何が嬉しいのでしょうか。 100万個のサンプルの計算というのは基本的に多くの時間がかかり、1回の更新を終えるだけで膨大な時間を要します。 しかし、ミニバッチ学習を採用することで、誤差を修正する更新を終える頻度を増やすことができます。 そのため、どのように値が更新されたのかを観察しやすく、かつ、更新頻度を増やすことで、サンプル全体として最適な値を導くことができ、局所解を防ぐことができます。 なお、100万個のサンプル全体の計算を終えて、パラメータの更新が1回終わることを、1epoc(エポック)と言います。 そして、ミニバッチのパラメータを更新することを1 iteration(イテレーション)と言います。 今回の例でいうと、100万サンプルを100ずつ細かく分割し1万の小さい箱に分けているので、1epoch = 1万iterationとなります。 これで、「バッチサイズ」、「ミニバッチ」、「ミニバッチ学習」、「エポック」、「イテレーション」というものの概要が理解できたかと思います。 ニューラルネットワークの構築続いて、入力層、中間層、出力層の３層のニューラルネットワークを構築していきます。 3層のニューラルネットワークを構築する前に、ニューラルネットワークを構築する際の考え方として大事なのは、2層を1セットで考えるということです。 つまり、下図に示すように「入力層と中間層」で1セット、「中間層と出力層」で1セット、合計2セットとして扱うということです。 それぞれの1セットは、Dence()を用いて追加します。 1セット目(入力層と中間層)の追加Denseは、Sequential()を用いてmodelを作成し、addメソッドによって活用されます。 コードでいうと、1セット目(入力層と中間層)の部分はmodel.add(Dense(n_mid, input_shape=(n_in,), activation=&quot;sigmoid&quot;))という風にして追加しています。 Dense({中間層のニューロン数}, {入力の形状}, {活性化関数})という記述になっています。 活性化関数というのは、中間層の各ノード(ニューロン)内で適用されるアルゴリズムで、下図における\\( u \\)から\\( z \\)を求める関数です。 活性化関数は、様々あり、自然言語処理の世界では、シグモイド関数、tanh(ハイパボリックタンジェント)、恒等関数が主となるようです。 今回は、シグモイド関数を使っていますが、他の活性化関数を適用して実験してみてもいいと思います。 また、こちらの\\( u \\)から\\( z \\)への変換を、非線形変換といったります。 線形でない曲線的な関数である、非線形の関数を用いて\\( u \\)から\\( z \\)を変換しているので、非線形変換といいます。 なぜ非線形なのでしょうか。線形変換でもよいのでは？と思うかもしれません。 理由は、ものすごく簡単に言ってしまうと、実際のビジネスでは、非線形なデータの方が多く、非線形変換を行わなければ、実際のビジネスの現場では使えないためです。 2セット目(中間層と出力層)の追加続いて2セット目の層を追加します。 こちらもDenseを用います。 出力層のニューロン数と活性化関数を指定すればOKです。 コードとしては、model.add(Dense(n_out, activation=&quot;linear&quot;))となります。 コンパイルコンパイルというのは、人間が分かる言葉で書いたプログラムのコードを、コンピュータが分かる言葉に変換/翻訳することです。コンピュータが分かる言葉というのは、いわゆる0と1の列です。 コンパイルの際は、損失関数と、最適化アルゴリズム、というのを指定します。コードでいうと、model.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;sgd&quot;)と記載しているところです。 損失関数とは、ニューラルネットワークが予想した値が静価値にどれだけ近いかを評価する関数のことです。 別名、評価関数とも呼びます。 損失関数は２つに分類されます。 回帰(数値を予測) → 二乗誤差 分類(カテゴリを予測) → クロスエントロピー（交差エントロピー） 今回は、数値を予測するので、二乗誤差を指定しています。 最適化アルゴリズムとは、重み\\( w \\)をどのようなルールで変換して正解値に近づけるかを数式化(モデル化)したものです。 SGDとは、確率的勾配降下法というもので、数式としては、以下のようなものになります。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}}以下のページに詳しい説明がまとめられているので、興味のある方は参考にしてください。https://mathwords.net/sgd 先ほどのコードを実行して、構築したモデルのsummary()を表示すると以下の通りとなります。 12345678910111213Model: \"sequential_1\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================dense_1 (Dense) (None, 20) 40 _________________________________________________________________dense_2 (Dense) (None, 1) 21 =================================================================Total params: 61Trainable params: 61Non-trainable params: 0_________________________________________________________________None Output Shapeというのは、各Denseの出力側の形状を示しています。 1セット目(入力層から中間層の部分)のOutput Shapeは、(None, 20)となっているため、中間層のニューロン数が20であることを意味しています。 2セット目(中間層から出力層の部分)のOutput Shapeは、(None, 1)となっているため、出力層のニューロン数が1であることを示しています。 Paramというのは、各層のパラメータ数を示しています。 1セット目のパラメータ数が40(重みの数が20, バイアスの数が20の合計40)で、2セット目のパラメータ数が21(重みの数が20, バイアスの数が1の合計21)であることを示しています。 ニューラルネットワークを用いて学習ここから、構築したニューラルネットワークを用いて学習を行います。 学習は、fit()メソッドを使います。 1history = model.fit(x, t, batch_size=batch_size, epochs=2000, validation_split=0.1) # 10%のデータを検証用に使う modelのfitメソッドに、先ほどの入力xと正解t、バッチサイズ、エポック数、バリデーションスプリットを設定しています。 バリデーションスプリットとは、全データの何%を検証用のデータとして扱うかを指定することができます。今回は10%のデータを検証用に使うので、0.1を設定しています。 こちらのコードを実行すると以下のような出力が得られます。 1234567891011121314151617Train on 45 samples, validate on 5 samplesEpoch 1/200045/45 [==============================] - 0s 5ms/step - loss: 0.5445 - val_loss: 0.0813Epoch 2/200045/45 [==============================] - 0s 295us/step - loss: 0.3997 - val_loss: 0.0355Epoch 3/200045/45 [==============================] - 0s 502us/step - loss: 0.3446 - val_loss: 0.0444Epoch 4/2000(略)45/45 [==============================] - 0s 301us/step - loss: 0.0093 - val_loss: 0.1108Epoch 1999/200045/45 [==============================] - 0s 265us/step - loss: 0.0093 - val_loss: 0.1142Epoch 2000/200045/45 [==============================] - 0s 323us/step - loss: 0.0095 - val_loss: 0.1142 loss: となっている部分は、訓練用データの誤差になります。 10%の検証用データを用いた結果の誤差が、val_loss:として出力されています。 学習の推移をグラフで確認matplotlibを用いて、先ほどのlossとval_lossをグラフとして描画してみます。 123456loss = history.history['loss'] # 訓練用データの誤差vloss = history.history['val_loss'] # 検証用データの誤差plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 以下のようなグラフが表示されます。 検証用のデータは青いラインで、訓練用のデータがオレンジのラインです。 両者ともに、エポック数を重ねると順調に下がっています。 学習済ニューラルネットワークを使用して予測predict()メソッドを用いることで、学習済みのニューラルネットワークを使用して予測を行うことができます。 123plt.plot(x, model.predict(x)) # 予測を行うplt.plot(x, t)plt.show() 最初に、入力xと入力xをpredictメソッドに入れた結果をプロットします。 predictメソッドに入力値を渡すだけで、予測データの出力を得ることができます。 比較のために、入力xと正解値tをプロットしたものを同時に出力したいと思います。 コードを実行すると以下のようなグラフが描画されます。 正解値はオレンジのラインで、学習済みのモデルに入力値を入れて予測したデータが青いラインになります。 正解のオレンジのラインをまねるように、青いラインが描かれていることから、ニューラルネットワークがサイン関数を学習していることが分かります。 参考にしたページや文献など 確率的勾配降下法の大雑把な意味 - 具体例で学ぶ数学 Optimizer : 深層学習における勾配法について - Qiita ニューラルネットワークをちゃんと学びたい！という方は以下のUdemyの講座がおすすめ。Stay Home期間中にオンライン講座でスキルを身に着けるのはいかがでしょうか？ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXZlto6\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku_blackbox_1/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356190_9cbb_6.jpg\"}}); 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - ニューラルネットワークの発展形であるRNNやLSTMを構築して自然言語処理を学びたい方は、以下がおすすめです。本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 プログラミングを0から学びたい、、、という方は絶対に躓かないオンラインプログラミング講座「SkillHacks」もおすすめです。LINE@による無制限質問サポートで挫折しない仕組みができており、合計94本のしっかりした動画があります。他のプログラミングスクールよりも安くて手頃です。 -Skill Hacks- 動画で学ぶWebアプリ開発講座","link":"/2020/05/03/keras-nn-basic/"},{"title":"[実体験]前十字靭帯再建手術を受けて復帰するまで④[長い長いリハビリ]","text":"前の記事で松葉杖の卒業までをまとめました。 本記事では、その続きとして、7か月のリハビリをまとめようと思います。 以下のようなことを意識してまとめたいと思います。 ・ 復帰までの大まかなリハビリの内容 ・ 復帰を早めるためにリハビリ期間中に工夫したことと効果 ・ リハビリ期間中、辛かったことと乗り越え方 繰り返しになりますが、以降はあくまでも私の実体験に基づいた内容です。 一人ひとり膝の状態や体質によって取り組み方は変わると思いますので、基本的には担当の理学療法士さんや医師とも相談しながらリハビリを進めていただければと思います。 ✓目次 復帰までに取り組んだリハビリメニュー(全体像) 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ リハビリでつらかったこと その①：関節拘縮 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 関節拘縮の克服その3：膝伸ばしのリハビリ リハビリでつらかったこと その②：モチベーションの維持 リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 まとめ 復帰までに取り組んだリハビリメニュー(全体像)大きく分けて以下2つに分類されます 1. 膝の回復状態にかかわらず実施したリハビリ 2. 膝の回復状態別のリハビリ 1. 膝の回復状態にかかわらず実施したリハビリ 膝の伸び具合のチェック マッサージ 超音波 電気を当てる ※本記事トップの写真 EMS 2. 膝の回復状態別のリハビリ 歩く練習 両足スクワット 両足を開いて片足スクワット 踏み出してスクワット 片足のみでスクワット 中腰で左右に移動・方向転換 ジャンプして両足着地 ジャンプして方向転換して着地 ジャンプして片足着地 片足ジャンプ 片足ジャンプして方向転換して着地 30％ダッシュ 50%ダッシュ 100%ダッシュ ダッシュからの片足・・・・ という感じで、膝の状態が良くなるにつれて、リハビリ(というかトレーニング)はハードなものになります。 リハビリでつらかったこと その①：関節拘縮私の場合、手術した膝内部の癒着がひどく、リハビリ初期の段階で膝が伸びない状態が予定よりも長く続いてしまいました。 手術後などに関節の動きが制限されてしまうことを関節拘縮と言い、この状態になってしまったのです。 膝関節の中は連続した空間であり、ここに癒着が生じると関節可動域が制限されるのです。 場合によっては、再度、関節鏡視下手術を行い、膝内部の癒着を剥がす処置をしなければなりません。 これは、癒着しやすい人と、そうでない人がいるらしく、私は不幸にも癒着を起こしやすい体質だったようです。 癒着の厄介なところは、仮に癒着をはがす手術をしたとしても、再度癒着してしまう可能性もある点です。 このような懸念もあり、「なんとか工夫をして手術せずに膝の可動域を確保せねば」と思ったのです。 結果として私はこれから紹介する方法で、癒着の剥離手術をせずに、膝の可動域を確保することができましたので、参考になればと思います。もちろん理学療法士の先生とも相談しながら取り組んでください。 関節拘縮の克服その1：美顔ローラを使って膝の癒着を取る 美顔ローラーで膝の癒着部分を皮膚を吸い上げるような具合でコロコロさせると良いです。 これはかなり効果がありました。 癒着をはがすために、指で皮膚をつまみ上げる作業を行うのですが、なかなかしんどいです。 美顔ローラで皮膚を吸い上げることで、効率的に癒着をはがせます。 関節拘縮の克服その2：ヒルドイド軟膏でマッサージ 皮膚を柔らかくする効果があります。膝全体をマッサージするように軟膏を刷り込んで癒着を取る努力をしました。 軟膏自体は、お医者様の診察を受けてから、処方していただいたほうが良いと思います。 関節拘縮の克服その3：膝伸ばしのリハビリ 以下の記事で掲載している膝の力入れリハビリです。 何度も何度も自宅で集中して全力でやりました。 私と同じように、癒着がひどい方は参考になればと思います。 リハビリでつらかったこと その②：モチベーションの維持リハビリ期間中は、プレーしたい思いが先行し、焦りだったり、悲観的になることもあると思います。 しかし、リハビリを通じて、今まで意識しなかった体の正しい動かし方や、ケアの仕方を学ぶ良いきっかけだと思い込むようにしました。 野球選手であれば、小久保裕紀さんの本は、とても勇気づけられると思いますのでお勧めです。 小久保さんは、以下の記事にある通り、「前十字靭帯断裂、内側靭帯損傷、外側半月板損傷、脛骨・大腿骨挫傷」という大けがをしました。 辛いリハビリを乗り越え復帰し、キャリアハイの成績を残した方です。 「けがをしたことは不幸なことだったが、結果として栄養や体のことを学び、選手としての寿命を延ばす結果につながった。」という言葉は、とても勇気づけられました。 なお私自身もリハビリを通じて体のバランスやキレが良くなり、ケガをする前以上のパフォーマンスを発揮できています。 今思えば、このリハビリが自分にとって大きな学びを与えてくれたと思っています。 是非、前向きな気持ちでリハビリに取り組んでください。結果は必ず付いてくるはずです。 リハビリは筋力を取り戻す作業【プロテイン活用がGood!】 リハビリは、筋力の回復が重要視されます。 リハビリの後は、直ちにプロテインを取るのが有効です。 以下の論文によると、タンパク質+炭水化物を摂取したグループが最も筋肉の肥大につながっているとされております。 L. Holm, B. Esmarck, M. Mizuno, H. Hansen, C. Suetta, P. Ho¨lmich, M. Krogsgaard, M. Kjær(2006). “The Effect of Protein and Carbohydrate Supplementation onStrength Training Outcome of Rehabilitation in ACL Patients”. Journal of orthopaedic research, 2114-2123 オンラインでも発行されていました。 https://onlinelibrary.wiley.com/doi/pdf/10.1002/jor.20147 プロテインは、基本的に吸収効率が良いとされるホエイプロテインが良いとされています。 牛乳等を飲むと、おなかが痛くなる方とかは、アミノ酸(BCAA)が良いでしょう。 筋肉が作られる仕組みは、すでに多くのサイトなどでまとめられていますので詳しくはまとめませんが、基本的に筋繊維が破壊された後、30分間がもっとも吸収効率が高いと言われています。 つまり、リハビリを終えた跡、30分の間にタンパク質を摂取することが望ましいということです。 摂取したたんぱく質が筋肉になる流れは以下の通りです。 1. タンパク質が分解されアミノ酸になる 2. アミノ酸がされに分解され代謝性物質になる 3. 代謝性物質が血液で循環され、壊れた筋肉に運ばれる 4. 代謝性物質がアミノ酸に戻りタンパク質となり筋肉になる そして、タンパク質を分解するときに必要になるのが、ビタミンだといわれています。 ここで私は思いました。 「プロテインと一緒にビタミンを取りたいな」、と、、、 プロテインについて調べてみると、1000円くらいで買えるものから、10000円を超えるものまでピンキリです。 よくよく成分表をみてみると、安いものは、純粋にタンパク質の粉末のみのものだったり、人工甘味料を使ってコストが抑えられているものでした。 一方、10000円を超える高級プロテインは、タンパク質だけでなく、多くのアミノ酸、ビタミン、抵抗力を上げるグルタミン、人工甘味料不使用、等々、筋肉をつけるために計算された配合になっていました。 つまりは安かろう悪かろう、という感じです。 私としては、そんなにお金かけて購入したくないな、という一方で、人工甘味料は体によくなさそうだし、可能であれば味がおいしいものがいいな、と思いました。 そして以下のプロテインを購入しました。 成分表は以下の通りです。 御覧の通り、ビタミンが含まれている！ しかしながら、味が抹茶風味ということもあり、少し癖のある味でした。同じシリーズのフルーツ系の味に変更したのですが、ぬるい水とかだと結構飲むのがしんどかった時がありました。 また、よく見てみると人工甘味料が使われていることもあり、あまり気持ちのいいものではありません。 ということでふと目に入ったのが以下のプロテインでした。ゴールデンホエイ（抹茶味）です。 成分表は以下の通りです。 こちらは、ビタミン類は含まれていませんが、人工甘味料が使われていません。ステビアというのは天然植物由来の甘味料であり人工甘味料ではありません。 肝心のビタミンについてですが、アイディアとして、 「抹茶味のプロテインなら、青汁入れて飲めばOKじゃね？」 と思い、早速試してみたところ。 「!?。美味い！！！！」 青汁を入れることで、抹茶の風味が増して、とてもおいしくなりました。 さらに、プロテイン自体がぬるくなってもおいしく飲めるのが最高な点です。 私は３年ほど、こちらの抹茶プロテイン＋青汁を飲んでいます。 ちなみに青汁は以下のやつです。理由は安いということと乳酸菌が含まれていて体に良さそうだからです。（安直な理由。。。） ぜひ、こちらの抹茶プロテイン &amp; 青汁を試してみてください。抹茶月であれば、絶対に後悔しません！ まとめ 膝の回復とともにリハビリはハードになる。 手術後の癒着で膝関節の可動域を確保するのが大変でした。 美顔ローラー、軟膏、膝伸ばしリハビリが有効でした プロテインを活用しよう。 回復が早いという研究結果の論文があります。 おすすめは、ゴールデンホエイ（抹茶味）に青汁を混ぜるオリジナルプロテイン！ この記事で紹介したものはこちら↓です 他のおすすめ記事 ダルビッシュ選手も実践する風邪予防サプリメントが知りたい方はこちら↓ 特保飲料と食べるだけで痩せられる食材を使った楽痩せメソッドを知りたい方はこちら↓","link":"/2020/04/11/rehabilitation/"},{"title":"【プログラミング】SkillHacks受講後にオススメのUdemy講座","text":"SkillHacksを受講した後の学習スケジュールは決まってますか？ SkillHacks同様、オンラインで学習を進めたいという方は、Udemyがおすすめです。 Udemy 不定期に開催されるセール時は、1000円台で講座を購入できるのでお財布にも優しいです。 SkillHacksを受講し終わった方を対象に、数あるUdemyの講座の中で、おすすめの講座をまとめました。 ✓目次 本記事の信頼性について オススメの講座一覧(タイプ別) 1.Ruby/Ruby on Railsの知識を深めたい方 1.1. Rubyで作る! ビットコイン自動売買システム 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 3. インフラの知識を深めたい方 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 3.2. Amazon Web Service マスターコース EC2編 4. 他の言語等を学び知識の幅を広げたい方 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） 4.2. 【JavaScript】：実例でわかる JavaScript 初心者講座 まとめ 本記事の信頼性について こちらで紹介している講座は、筆者が実際に受講した講座の中から選定しております。※筆者が受講済の講座数は、2020年5月時点で、約30講座です。 網羅性という観点で心配されるかと思いますが、Udemyは30日間の返金保証があります。 「受講してみたけど、やっぱり違うな」と感じたら、お金は返ってきますのでご安心ください。 オススメの講座一覧(タイプ別) これから学習したい方向性や考え方別にまとめたいと思います。 SkillHackの講師が「学んだほうが良い」と述べているもの ＋ 今のIT業界の流行という観点で分類しました。 Ruby/Ruby on Railsの知識を深めたい方 現場で絶対に使うGit/Githubの知識を深めたい方 インフラの知識を深めたい方 他の言語等を学び知識の幅を広げたい方 早速、以下にまとめたいと思います。 1.Ruby/Ruby on Railsの知識を深めたい方 SkillHacksで、Ruby/Ruby on Railsを学ばれたかと思いますが、Ruby/Ruby on Railsには、まだまだ深い技術が存在します。 SkillHacksでは扱わなかった技術を補完する or 深めるということにフォーカスして、２つの講座を紹介します。 1.1. Rubyで作る! ビットコイン自動売買システム a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYnOIbA\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/ruby-bitcoin/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1329308_709c_13.jpg\"}}); Rubyで作る! ビットコイン自動売買システム SkillHacksの講師である迫さんが講師を務める講座です。 開発環境がSkillHacksと同じAmazonCloud9であり、かつ、講師が同じなのでスムーズに講義に入れると思います。 講義の中身ですが、SkillHacksでは扱っていないRubyのライブラリやREST APIを用いたアプリケーション開発手法が学べます。 Railsの講義はありませんが、Webアプリケーションを作成する際、外部のAPIを活用して作成する機会は多いです。 API keyの扱い方やJsonの知識もRubyと合わせて学んでおくべきだと思います。 講座の概要欄に「現在，bitFlyerにて新規アカウントの作成が停止されています。」と記載がありますが、2019年7月3日から、bitflyerの新規アカウントの受付が再開されているのでご安心ください。 あわよくば仮想通貨で一攫千金が狙えるかも？ 1.2. フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoetKL\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/rails-kj/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1497262_1c92.jpg\"}}); フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座 即戦力のRailsエンジニアになることを目的とした講座です。 基本的なRubyの基礎から応用まで網羅的にまとめられているので復習もかねて学習が進められると思います。 ”即戦力”というだけあり、コードを綺麗に書く際の考え方に加え、Dockerというコンテナ型仮想化技術や、プログラムが想定した動作をすることをテストするためのプログラムであるテストコード(RSpec)のレクチャもあります。 またSkillHacksでは扱っていない、ログイン、ログアウト機能の実装についても、本講義で扱っています。 かなりのボリュームなので、全部をマスターするには時間がかかると思いますが、この講座の内容を習熟できれば十分即戦力のRuby/Ruby on Railsのエンジニアになれると思います。 2.開発現場で絶対に使うGit/GitHubの知識を深めたい方 Web関連の開発現場では、ソースコード管理ツールGitは必須の知識となります。 開発メンバーにいち早く加わるためにも、GitとGitHubを学びましょう。 2.1. Git： もう怖くないGit！チーム開発で必要なGitを完全マスター a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYolLK2\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/unscared_git/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1142464_9d09_2.jpg\"}}); Git： もう怖くないGit！チーム開発で必要なGitを完全マスター 正直この講座だけでGit/GitHubは問題ありません。 Gitとはなにか、GitHubとはなにか、等、綺麗な図で説明されており、ハンズオンで手を動かしながら学ぶことができます。 GitHub Flowと呼ばれるチーム開発でコードの管理をするための概念を理解したうえで、Gitを扱えるようになっておけば、開発現場のメンバーとしてすぐに加われると思います。 また、自分が作成したアプリのコードをGithubにアップロードしておいて技術をアピールしてもいいかもしれません。 余談ですが、このブログはGithubの機能の一つであるGitHub PagesとHexoという静的ブログジェネレータを用いて作成されています。 3. インフラの知識を深めたい方 インフラ技術は多岐にわたりますが、その中でもAWSを扱う企業が多い印象を受けます。 ここではSkillHacksを学んだRuby on Railsと関わり高いAWS関連の講座を中心にまとめました。 3.1. AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYozwYi\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/aws-and-infra/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2361020_edcc.jpg\"}}); AWS：ゼロから実践するAmazon Web Services。手を動かしながらインフラの基礎を習得 Linuxのコマンドの少々不安がある方は、こちらの講座で基礎から学ぶのが良いと思います。 先ほど紹介した「Git： もう怖くないGit！チーム開発で必要なGitを完全マスター」と同じ講師の方になります。 分かりやすさの観点では断トツに良いです。 AWSの基本的な機能であるEC2, Route53, RDS, S3周辺は、この講座で問題ないかと思います 3.2. Amazon Web Service マスターコース EC2編 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYouKOH\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/amazon-web-service-ec2/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1949062_f23f_2.jpg\"}}); Amazon Web Service マスターコース EC2編 Webサーバの構築やそれなりにAWSを知っている方は、こちらの講座が良いと思います。 EC2を中心にしっかりと学ぶ、という意味では、おそらくこの講座が筆頭であり、詳細な領域まで学ぶことができます。 「フルスタックエンジニアが教える 即戦力Railsエンジニア養成講座」と同じ講師の方の講座になります。 EC2編となっておりますが、VPC編もありますので、余力があればそちらも受講すると良いかと思います。 4. 他の言語等を学び知識の幅を広げたい方 Ruby/Ruby on Rails以外の言語も学びたいという方向けにオススメの講座をまとめました。 特に人気の高いPython, JavaScriptに分けて記載しています。 4.1. 【Python】：【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoFMhf\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/django-beginner/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1213286_dfba_2.jpg\"}}); 【3日でできる】Django 入門 ( Python 3 でウェブアプリを作って AWS EC2 で公開！） ”3日でできる”とタイトルにありますが、たぶん3日で終わらないくらい充実した講座です。 Djangoとは、Ruby on Railsによく似たPythonのWebフレームワークです。 UdemyのプラットフォームもPythonとDjangoで開発されています、 昨今のAIブームから、ニューラルネットワーク用のライブラリが豊富なPythonベースであるDjangoを使う企業も多くなると想定します。 この講座ではブログサービスを構築しており、SkillHacksでも学んだ内容がそのまま活かせる内容になっていておすすめです。 AWSへの公開方法もレクチャーの中で学べます。 SkillHacksで作成した掲示板を、Python on Djangoで作成するとより理解が深まります。※私もやりました。 4.2. 【JavaScript】：実例でわかる JavaScript 初心者講座 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rYoLbht\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/javascript-kouza/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/654658_4489_3.jpg\"}}); 実例でわかる JavaScript 初心者講座 2019年の人気プログラミング言語ランキング1位のJavaScriptを基本的な文法を学びつつ実際に動くアプリを作成して理解を深められる講座です。 作成するアプリは多岐にわたります。その数なんと15個！ 税込み計算アプリ（入力欄から数値を得て計算結果を表示） アウトライン メモ（アウトライン エディタ風に、ネストしたリストを追加） 三択問題アプリ（ユーザーの解答に応じて、結果表示を分岐） 字典アプリ（マウスオーバーで、説明表示を切り替え） テーブル ソート（テーブルを、名前順や数値順で、自在にソート） 連続計算アプリ（複数行入力欄の数式を、行ごとに計算して結果表示） メモ アプリ（Webブラウザに情報を記録したり、取り出したり） HTML自動リンク アプリ（文字列からURLを探し出して、自動でタグを付加） 角丸四角画像生成アプリ（角丸四角のパスを作り、画像を動的に生成） 画像切り抜きアプリ（画像を丸く切り抜いたPNG画像を生成） セピア調アプリ（画像の画素を処理して、セピア調に変換） 音声再生アプリ（音声を読み込み、再生） 動画再生アプリ（動画を読み込み、再生） ストップウォッチ（経過時間を取得して、定期的に表示を更新） 人気Webページ表示（Web APIを利用して情報を得て、リンクボタンを自動生成 どのアプリも普段から使えそうなものばかりですよね。 私は画像の切り抜きアプリは資料作成の際に使ってます。 まとめSkillHacks終了後の学習計画の参考になればと思いUdemyのおすすめ講座をまとめました。 私自身、Udemyで現在進学習中ですので、「これは良い！」と思ったものは積極的に紹介していきたいと思います。 UdemyにはATやIoT、ブロックチェーン、動画編集、ビジネスモデル等を学べる領域は多岐にわたります。 様々な学習を通じて、興味の幅や適応領域を広げ、人生を豊かにしていきましょう。","link":"/2020/05/08/skill-hacks-next-step-udemy/"},{"title":"【抵抗力向上】ダルビッシュ有選手も実践する風邪予防サプリメント","text":"風邪予防は、ビタミンとグルタミンが最強です。 ダルビッシュ有投手も実践する風邪予防サプリメントに興味がありませんか？ 肌荒れ予防にも効果があるようです。 この方法を実践してから、私は風邪で寝込んでいません。 体の抵抗力を上げて、毎日健康ですこやかな毎日を過ごしましょう。 「子供から良く風邪をうつされる」、「疲れが取れにくくなった」、「肌荒れが気になる」、といった悩みがあれば、参考になると思います。 ✓目次 期待できる効果 結論 体の土台を作る：マルチビタミン＆ミネラル 免疫細胞のエネルギー源：グルタミン それでも風邪を引いてしまったら：ビタミンD まとめ 参考 期待できる効果まず、これから紹介するサプリメントを摂取すれば、ほぼ風邪をひかなくなります。 少し言い過ぎかもしれませんが、風邪を引いたとしても重症化せずにすぐに回復すると思います。 また、肌荒れの解消にもつながる可能性があります。 結論以下、2つのサプリメントを摂取しましょう。 マルチビタミン＆ミネラル グルタミン これは、プロ野球選手のダルビッシュ有投手も実践しています。 3年前から私もこれらのサプリメントを取っているのですが、1度も風邪で寝込んでいません。 以降は、私が実際に摂取している製品と合わせて、各々のサプリメントを摂取する意義や摂取するタイミングについても簡単にまとめたいと思います。（怠け者の私でも続けられている方法なのでおすすめです。） 体の土台を作る：マルチビタミン＆ミネラル これを朝と夜に1粒飲むようにしています。 ビタミンが体を作る土台であるということは既にご存じの方も多いと思います。 ミネラルも取るべきなの？と思うかもしれませんが、この辺りは各々の体の状態に合わせてミネラルが含まれていないものを取っていただいてもよいと思います。 ミネラルの重要性は、様々な方が記事にまとめているのでここではあまり述べませんが、カルシウムやリン、マグネシウムなどは骨や歯をつくり、鉄やリン、硫黄はたんぱく質や脂質などと結びついて体やエネルギーの成分となります。 また筋肉や骨、髪の毛、肌、内臓など、体を作り上げる成分の元となるたんぱく質等は、いったん代謝性物質に変換される必要があるのですが、この代謝性物質に変えるためにビタミン（特にビタミンB群）が必要になるようです。 つまり、 体を作るためにはビタミンもミネラルも必要 ということなので私は全部まとめて摂ってしまおうと思い、マルチビタミン＆ミネラルを摂っています。 免疫細胞のエネルギー源：グルタミン グルタミンと聞くと、「あの旨味成分のやつ？」と思われる人が多いですが、旨味成分と思われるものはグルタミン”酸”であり、グルタミンとは全く別ものです。 グルタミンは、非必須アミノ酸とよばれる体の中で作ることができるアミノ酸であり、簡単に言うと、体の中に入ってくる菌やウィルスと戦ってくれる免疫細胞のエネルギー源です。 菌やウィルスと戦ってくれる免疫細胞が生き生きと活動してくれれば風邪になりにくくなるというのは直感的にも理解しやすいと思います。 グルタミンの摂取方法は各々の生活スタイルに合わせて摂取すれば良いですが、基本的には朝と寝る前にグルタミンをスプーン一杯分を摂取すればOKです。 これだけで高い抵抗力を維持することができ、風邪にかかりにくくなります。 また寝る前にグルタミンを経口摂取することで成長ホルモンの分泌が高まる、という報告があります[1]。 成長ホルモンが分泌されると以下のような効果が期待できます。 体脂肪の燃焼を促す。 コラーゲンの合成を高める。 つまり、風邪の予防だけでなく、ダイエットや美肌効果につながる、というまさに一石二鳥のサプリメントです。 「サプリメントで取る必要はあるの？」「非必須アミノ酸ならわざわざ経口摂取しなくても良いのでは？」という疑問を持たれるかと思いますが、結論としてはサプリメントで取るべきだとおもいます。 理由は2つあります。 グルタミンは普段の生活のストレスや運動で消費され、慢性的に不足状態になっていることが多い。 グルタミンを含む食品は生の魚やアーモンドが主であり普段の食事から補うのは難しい。 についていえば、例えば、普段からランニングをはじめとした運動が好きな人に限ってよく風邪を引く人って周りにいませんか？ 「運動」というのは、健康的なイメージを持たれると思いますが、その行為自体は、筋肉にダメージや負荷を与える行為であり、肉体的にはストレスをかけていることと同じなのです。 普段から運動をしている人がよく風邪にかかってしまうのは、このグルタミンが慢性的に不足している状態になっていることに他ならないのです。 またグルタミンは運動だけでなく普段の仕事のストレスを感じることでも消費されます。 大きいストレスがかかると体調を崩すのも、グルタミンが消費され抵抗力が下がってしまうことが一つの原因であると考えられます。 は文字通りで、普段からお刺身などを食べる生活は現実的ではないですよね。 グルタミンが多く含む食品一覧は、以下の記事が参考になります。 参考 [1] Increased plasma bicarbonate and growth hormone after an oral glutamine load.Am J Clin Nutr. 1995 May;61(5):1058-61 強力な免疫を確保せよ！～グルタミンの多彩な効果とは | サプリメント最前線 | DESIRE TO EVOLUTION | DNS ZONE それでも風邪を引いてしまったら：ビタミンDビタミンDを多く摂取することで、免疫力が低下している人が風邪やインフルエンザなどの感染症にかかるリスクを減らし、最終的には抗生物質の使用を減らすことがわかりました。 この研究は、スウェーデンのカロリンスカ大学病院の研究者らによって12ヶ月間に渡って、易感染患者がビタミンD摂取によって気道（呼吸器）感染症の感染予防あるいは治療効果があるかを調査したものです。 https://news.cision.com/karolinska-institutet/r/vitamin-d-can-help-infection-prone-patients-avoid-respiratory-tract-infection,c9348687 易感染とは、免疫機能が低下し、細菌やウイルスなどの病原菌に感染しやすくなっている状態のことを言います。 日光ビタミンとも呼ばれているビタミンＤは、皮膚が日光にあたることにより、体内で生産される。ほとんどの人々が太陽の紫外線B派の放射からこの脂溶性ビタミンＤを得ています。 ビタミンが免疫機能に関係しているというのは、長年にわたって、数多くの研究によって報告されていて、ビタミンD濃度が低いと、感染症にかかるリスクが高まることが分かっています。 冬の季節や家にいる時間が長く、日光を浴びる機会が少なるなると、風邪やインフルエンザにかかる人が増えるのは、ビタミンDが不足していることが一因として考えられるようです。 この研究は、少なくとも研究開始日から42日前までに気道感染症にかかっていた140名の患者らを対象に行われているようです。 高用量のビタミンDを摂取するグループ、もう一方はプラセボを摂取するグループの２つのグループに無作為に振り分け、健康状態を毎日記録して評価しています。 その結果、ビタミンＤを高用量摂取した患者は、気道感染症が約1/4に減少し、抗生物質の使用回数も約半分に減少した。さらにビタミンDは全患者に耐性があり、重大な副作用もなかったようです。 ビタミンＤは、きのこ類や、サケやイワシなどの脂肪の多い魚や卵黄に多く含まれます。 お手軽に摂取したい場合は、やはりサプリメントでの摂取になるかと思います。 まとめ 風邪予防には、マルチビタミン＆ミネラルとグルタミンがおすすめ プロ野球選手（ダルビッシュ有選手）も推奨 グルタミンは体脂肪の減少や美肌効果も期待できる。 ビタミン、ミネラル、グルタミンは、普段の食事から摂ることは難しいためサプリメントを活用するのが現実的 それでも風邪を引いてしまったら、ビタミンDが効果的であるという研究報告があります。 参考 楽痩せダイエットメソッドが知りたい方は以下の記事も参照いただければと思います。運動不要。怠け者向け","link":"/2020/02/10/vitamins-and-glutamine/"},{"title":"【翻訳技術】seq2seqを実装しながら理解してみた","text":"✓目次 本記事の対象者 seq2seqとはなにか 訓練用のデータを作成する。 seq2seqの構築 1. 学習用モデル構築（ライブラリのインポートとモデルの設定） 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 コサイン関数をサイン関数に翻訳 本記事の対象者 ・ RNNとLSTMを理解している人 ・ pythonの基本を理解している人。 ・ Kerasでニューラルネットワークを作ったことがある人 RNNの基礎については以下の記事でまとめているので参照してください。 RNNの基礎を学びたい方はこちら↓ また、実行環境としてはJupyter Notebookになります。以下の記事に従って環境構築していただければと思います。 環境構築はこちら↓ 今回は、Kerasを使ってseq2seqを構築し、コサイン関数をサイン関数に変換（翻訳）してみたいと思います。 seq2seqとはなにかseq2seqは、シーケンスを受け取り別のシーケンスに変換するモデルのことで、文章などの入力を圧縮するencoderと、出力を展開するdecoderからなります。 「私はペンを持っている」という文章を、「I have a pen」という英文に翻訳することが可能となります。 encoderとdecoderに、それぞれRNNの層が構築され、encoderとdecoderが接続させることによってseq2seqが作られます。 seq2seqの仕組みについては以下の記事が大変分かりやすいので、参考にしてください。こちらでまとめられている絵を見ながら、以降の記事を読んでいただくと、それぞれのコードがどの領域の実装なのかがイメージしやすくなると思います。https://sinyblog.com/deaplearning/seq2seq-001/#i 少々複雑に聞こえるかもしれませんが、今回は簡単な例としてcos関数をsin関数に翻訳する形で、その構造を理解したいと思います。 訓練用のデータを作成する。cos関数の値をencoderへの入力、sin関数の値をdecoderへの入力とします。 なお、正解は、sin関数になります。 decoderへの入力というのは正解から1つ後の時刻にずらした値になります。これは、ある時刻におけるdecoderの出力が、次の時刻における入力に近づくように学習をさせるためです。 このように、ある時刻における正解が次の時刻の入力となる手法を強制教師と言います。 まずは、cos関数とsin関数を作成してプロットしてみます。 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_ax = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまでの50つの値cos_data = np.cos(x_ax)sin_data = np.sin(x_ax)plt.plot(x_ax, cos_data)plt.plot(x_ax, sin_data)plt.show() 次に、encoderへの入力、decoderへの入力、decoderの正解を作成します。 今回、時系列の数は10に設定しておきます。 zerosメソッドでエンコーダー、デコーダー、正解の形状を作成します。 今回はすべて同じ形状にする。 1234567891011n_rnn = 10 # 時系列の数n_sample = len(x_ax) - n_rnn # サンプル数x_encoder = np.zeros((n_sample, n_rnn)) # encoderの入力x_decoder = np.zeros((n_sample, n_rnn)) # decoderの入力t_decoder = np.zeros((n_sample, n_rnn)) # decoderの正解print(x_encoder.shape)print(x_decoder.shape)print(t_decoder.shape)# 全部(40, 10) x_encoderには、コサイン関数の値を入れていき、x_decoderにはサイン関数の値を入れていきます。 この時、x_decoderに入れるサイン関数は、1つ後の時刻にずらす必要があります。時系列で1以降の値に代入するので最初の値は0のままということになります。 123456789101112131415161718for i in range(0, n_sample): x_encoder[i] = cos_data[i:i+n_rnn] x_decoder[i, 1:] = sin_data[i:i+n_rnn-1]x_decoder# array([[ 0.00000000e+00, 2.44929360e-16, 2.53654584e-01,# 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01],# [ 0.00000000e+00, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 0.00000000e+00, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01], 続いて正解データであるt_decoderを作成します。 t_decoderには、サイン関数の値をそのまま入れます。 1234567891011121314151617for j in range(0, n_sample): t_decoder[j] = sin_data[j:j+n_rnn]t_decoder# array([[ 2.44929360e-16, 2.53654584e-01, 4.90717552e-01,# 6.95682551e-01, 8.55142763e-01, 9.58667853e-01,# 9.99486216e-01, 9.74927912e-01, 8.86599306e-01,# 7.40277997e-01],# [ 2.53654584e-01, 4.90717552e-01, 6.95682551e-01,# 8.55142763e-01, 9.58667853e-01, 9.99486216e-01,# 9.74927912e-01, 8.86599306e-01, 7.40277997e-01,# 5.45534901e-01],# [ 4.90717552e-01, 6.95682551e-01, 8.55142763e-01,# 9.58667853e-01, 9.99486216e-01, 9.74927912e-01,# 8.86599306e-01, 7.40277997e-01, 5.45534901e-01,# 3.15108218e-01], KerasにおけるRNNの入力の形状にするために、x_encoder, x_decoder, t_decoderの形状を、サンプル数、時系列の数、入力層のニューロン数という形状に変更しておきます。 123x_encoder = x_encoder.reshape(n_sample, n_rnn, 1) # （サンプル数、時系列の数、入力層のニューロン数）x_decoder = x_decoder.reshape(n_sample, n_rnn, 1)t_decoder = t_decoder.reshape(n_sample, n_rnn, 1) これで、データの準備はOKです。 seq2seqの構築Kerasを使ってseq2seqを構築していきます。 seq2seqの特徴は、学習用のモデル構築と予測用のモデル構築の2つのモデル構築を別々で行う点にあります。 学習用のモデルと予測用のモデルの中に、それぞれencoderとdecoderが存在します。 この特徴を踏まえ、以下のような流れで作成を進めていきます。 1. 学習用モデル構築(ライブラリのインポートとモデルの設定) 2. 学習用モデル構築(encoderの構築) 3. 学習用モデル構築(decoderの構築) 4. 学習用モデル構築(モデルのコンパイル) 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施) 6. 学習用モデル構築(学習の推移を確認する。) 7. 予測用モデル構築(encoderのモデルを構築) 8. 予測用モデルの構築(decoderのモデルを構築) 9. 翻訳用の関数を定義 それでは一つ一つ順を追ってseq2seqを構築していきたいと思います。 1. 学習用モデル構築（ライブラリのインポートとモデルの設定）これまで、RNNやLSTMを構築した際は、Sequentialクラスを使用してましたが、今回は、Modelクラスを使います。 Modelクラスを用いることで、複数の経路の入力を持つニューラルネットワークを構築することが可能だからです。 また状態を渡すことでRNN同士を接続することもできます。 今回のseq2seqのRNN部分にはLSTMを使おうと思います。 各種ライブラリをインポートしていますが、今回はInputというのも導入します。 Inputは、入力層を表すライブラリです。 モデルの設定をしていきます。入力層のニューロン数は1、中間層のニューロン数は20、出力層のニューロン数は入力層のニューロン数と同じにします。 123456from keras.models import Modelfrom keras.layers import Dense, LSTM, Inputn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = n_in # 出力層のニューロン数 こちらのコードで各種ライブラリのインポートと、モデルの設定は完了です。 2. 学習用モデル構築(encoderの構築)最初にInputを使ってencoderの入力層を設定します。 Inputを使用する際は、入力の形状を設定する必要があります。時系列数, 入力層のニューロン数を指定しますので、n_rnn, n_inとします。 1encoder_input = Input(shape=(n_rnn, n_in)) 続いてencoderにLSTMを設定します。中間層のニューロン数を設定し、return_stateをTrueに設定します。 return_stateをTrueに設定すると、その時刻における出力と共に状態を得ることができます。 LSTMにおける出力\\(h_{t}\\)と状態であるメモリセルを得ることができるということです。 1encoder_lstm = LSTM(n_mid, return_state=True) そして、このencoderのLSTMに、先ほどのencorderの入力を渡します。その結果得られるのは、encoderの出力とencoderの状態\\(h\\)とencoderの状態\\(c\\)になります。 LSTMの内部に\\(h\\)と\\(c\\)という2つの状態を持っている点については、以下の記事で詳しくまとめらていますので、詳細が知りたい方は参考にしてください。https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca 1encoder_output, encoder_state_h, encoder_state_c = encoder_lstm(encoder_input) この2つの状態\\(t\\)と\\(c\\)は、リストでまとめておき、encoder_stateとしておきます。 1encoder_state = [encoder_state_h, encoder_state_c] これでencoderは完成です。 3. 学習用モデル構築(decoderの構築)まずInputを用いて、decoderの入力層を作ります。 1decoder_input = Input(shape=(n_rnn, n_in)) encoderの時と同様、LSTMの層を作ります。こちらも先ほど同様に、return_stateをTrueにしておきますが、return_sequencesもTrueにしておきます。 このようにすることで、すべての時系列の出力を出力として得ることができます。 1decoder_lstm = LSTM(n_mid, return_sequences=True, return_state=True) decoderのLSTMには、先ほど作成したdecoder_inputを入れます。その際に初期状態であるinitial_stateに先ほどのencoder_stateに設定します。 その結果返ってくるのが、decoderの出力と2つの状態です。 この段階で、decoderから出力された状態は使わないので、とりあえず_をいれておきます。 1decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_state ) LSTM層の次に、全結合層であるDenseを入れます。 Denseには出力層のニューロン数を設定します。活性化関数は、ひとまずlinearとしておきます。linearは恒等関数を意味します。 1decoder_dense = Dense(n_out, activation='linear') そして、このdecoder_denseにdecoder_outputを入れることでdecoderの出力を得ることができます。 1decoder_output = decoder_dense(decoder_output) decoderの構築はこれで完了です。 4. 学習用モデル構築(モデルのコンパイル)まずはseq2seqにおける学習用のモデルを構築していきます。 Modelクラスを用いてモデル構築を行います。 Modelクラスは、全体の入力と出力のみ設定すればOK、という優れものです。 入力が複数存在する場合は、リストを使って設定すればOKです。 入力は、encoder_inputとdecoder_inputの2つになります。 そして全体の出力は、decoder_outputになるので、コードとしては以下となります。 1model = Model([encoder_input, decoder_input], decoder_output) 次にモデルのコンパイルを実施します。 コンパイルの際は、損失関数とと最適化アルゴリズムを指定する必要があります。 損失関数は回帰の場合は、二乗誤差で、分類の場合はクロスエントロピーが提供されるのが一般的です。 今回は、encoderの入力から、学習した結果に基づいて翻訳結果を予測するので、二乗誤差を適用します。 最適化アルゴリズムは、収束しやすいadamでもいいですが、sgdを適用してみたいと思います これでモデル構築は完了なので、print(model.summary())で、構築したモデルの概要を確認したいと思います。 1234567891011121314151617181920212223model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")print(model.summary())# Model: \"model_11\"# __________________________________________________________________________________________________# Layer (type) Output Shape Param # Connected to # ==================================================================================================# input_18 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# input_19 (InputLayer) (None, 10, 1) 0 # __________________________________________________________________________________________________# lstm_9 (LSTM) [(None, 20), (None, 1760 input_18[0][0] # __________________________________________________________________________________________________# lstm_10 (LSTM) [(None, 10, 20), (No 1760 input_19[0][0] # lstm_9[0][1] # lstm_9[0][2] # __________________________________________________________________________________________________# dense_5 (Dense) (None, 10, 1) 21 lstm_10[0][0] # ==================================================================================================# Total params: 3,541# Trainable params: 3,541# Non-trainable params: 0# __________________________________________________________________________________________________# None encoderの入力とdecoderの入力があります。 また、encoderのLSTMとdecoderのLSTMがあります。decoderの方は、全結合層であるDenseを1つ所持していることが確認できます。 5. 学習用モデル構築(構築した学習用モデルを用いて学習を実施)RNNの時と同様にfitメソッドを使用して学習を行います。 入力は、x_encoderとx_decoderとし、正解は、t_decoderを指定します。 バッチサイズを10とし、エポック数を30に設定します。 123history = model.fit([x_encoder, x_decoder], t_decoder, batch_size=8, epochs=30) 6. 学習用モデル構築(学習の推移を確認する。)以下のコードでグラフで誤差の収束具合を確認します。 123loss = history.history['loss']plt.plot(np.arange(len(loss)), loss)plt.show() んー、収束しきってない気がします。 7. 予測用モデル構築(encoderのモデルを構築)seq2seqでは、訓練用のモデルと、予測用のモデルを別々に構築する必要があります。 予測用モデルは、学習済みのオブジェクトから、encoder, decoderのモデルを構築します。 encoderは入力を受け取り状態を返し、decoderは入力と状態を受け取って出力と状態を返すようにします。 まずはModelクラスを用いてencoderのモデルを構築します。 入力としてencoder_input、出力としてencoder_stateを設定します。 encoder_inputとencoder_stateの間には、encoder_lstmが存在する構造をとっています。このencoder_lstmは先ほどの学習済みのLSTMになります。 これだけで、予測用モデルにおけるencoderは完成します。 1encoder_model = Model(encoder_input, encoder_state) 8. 予測用モデルの構築(decoderのモデルを構築)続いて予測用モデルのdecoderを構築します。 入力層は、新規にInputを使って作成します。形状は、時系列の長さ、入力層のニューロン数を設定します。 今回は、時系列の長さは1で入力層のニューロン数はn_inで設定しているので、以下のようになります。なお、時系列の長さが可変である場合は、Noneを設定します。 1decoder_input = Input(shape=(1, n_in)) LSTMには内部に2つの状態を持つので、状態の入力を2つ作ります。 この2つの状態は、decoder_state_in_hとdecoder_state_in_cとします。 それぞれの状態の数は、中間層のニューロンの数と同じになります。 これらは、1つのリストにまとめて、decoder_state_inとしておきます。 123decoder_state_in_h = Input(shape=(n_mid,))decoder_state_in_c = Input(shape=(n_mid,))decoder_state_in = [decoder_state_in_h, decoder_state_in_c] 次に先ほどのdecoder_lstmにdecoder_inputとdecoder_state_inを設定します。decoder_state_inは、初期状態として設定するので、initial_stateとしておきます。 decoder_lstmも同様、既存の学習済みのLSTMになります。 1decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_input, initial_state=decoder_state_in) 得られたdecoder_state_hとdecoder_state_cは、以下のようにリストにし、そのうえで、decoder_denseにdecoder_outputを入れて、decoderの出力を得ることができます。こちらも、すでに学習済みのDenseになります。 12decoder_state = [decoder_state_h, decoder_state_c]decoder_output = decoder_dense(decoder_output) いよいよ、decoderのモデルを構築します。 モデル化の際に、入力として渡すのは、decoder_inputとdecoder_state_inです。 出力は、decoder_outputとdecoder_stateになります。 それぞれ、リストとして値を保持しており、入力として渡す際は、各リストを結合して渡すので、+でリストを結合しています。 1decoder_model = Model([decoder_input] + decoder_state_in, [decoder_output] + decoder_state) 9. 翻訳用の関数を定義コサイン関数を翻訳して、サイン関数に変換するための関数を定義します。 encoderへの入力値であるinput_dataを渡し、予測用モデルに適用した翻訳結果を返す処理を定義します。 12345678910111213def translate(input_data): translated = [] state_value = encoder_model.predict(input_data) # 予測モデルのencoderにinput_dataをわたし、学習済みのLSTMで予測。出力は、内部状態h, cの2つが出力される y_decoder = np.zeros((1, 1, 1)) for i in range(0, n_rnn): y, h, c = decoder_model.predict([y_decoder] + state_value) # 1つ前の時刻の出力(最初は空)と、状態（内部状態hとc）をdecoder_modelの学習済みLSTMとDenceで予測、 y = y[0][0][0] # 出力yから翻訳された結果を抽出 translated.append(y) y_decoder[0][0][0] = y # 次の時刻に渡す値 state_value = [h, c] # 次の時刻に渡す状態 return translated コサイン関数をサイン関数に翻訳123456789idices = range(0, 40)for indice in idices: x = x_encoder[indice:indice+1] # 入力を一部取り出す y = translate(x) plt.plot(x_ax[indice:indice+n_rnn], x.reshape(-1), color=\"b\") # 翻訳前を青い線 plt.plot(x_ax[indice:indice+n_rnn], y, color=\"r\") # 翻訳後は赤い線 plt.show() 翻訳の結果としては少々いまいちでした。 epoc数を30ではなく50に増やして再度翻訳してみます。 まだ微妙ですね。思い切ってepoc数を100に増やして再度実施してみます。 収束しきっているようなしていないような微妙な感じです。翻訳までさせてみると以下のような感じです。 どうやらこの三次元的なコサインカーブはどうにもならないみたいですね。 こんな時は、最適化アルゴリズムをsgdではなく別のものを適用すると改善される可能性が高いです。もしくは、通常のニューラルネットワークとかですと、中間層のニューロン数を増やしたり、層を増やしたりするのもある程度完全が見込めるかもしれません。最終手段としてはデータの中心化（バッチノーマリゼーション）と言われる処理をするとよくなるパタンが多いそうです。 今回は、KerasのDocumentationにて記載のある最適化アルゴリズムの中で、Adagradという最適化アルゴリズムを適用してみたいと思います。 以下のように、Adagradという風にするだけです。エポック数は100のままにしています。 1model.compile(loss=\"mean_squared_error\", optimizer=\"Adagrad\") 誤差の収束具合は以下の通りです。（さっきと全然違う） 肝心の翻訳結果は以下の通りです。すごい、ちゃんとコサインカーブになりました。 以上です。 以下のUdemyのコースを参考にさせていただきました。基礎から応用まで、より詳細に自然言語処理を学びたいという方は、以下のUdemy(オンライン学習プラットフォーム)の講座がおすすめです。不定期で頻繁に開催されるセールの時期は、1000円前後で購入できますし、30日間の返金保証もあるため低コストで高度な技術を学ぶことができます。こちらでまとめたSeq2seqを応用して、文豪の小説文を学習し、入力データに対して、それらしい応答をしてくれるチャットボットの構築をするなど、とても面白い内容になっています！ Seq2seqを活用してAIチャットボットを学びたい方は必見です！ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/05/17/seq2seq-study/"},{"title":"【RNN基礎】RNNとはなにか？Pythonで実装しながらちゃんと理解してみる。","text":"✓目次 本記事の対象者 RNNとはなにか RNNは勾配爆発と勾配消失を起こしやすい RNNを実装してみる 訓練用データを作成する。 ①ノイズ付きサイン関数の作成 ②入力データと正解データの作成 ③入力データと正解データの形状をKerasのRNN仕様に変更する。 RNNの構築 バッチサイズとモデルの設定 モデルを作成し層を追加 構築したRNNのモデルを用いて学習 学習の推移を確認する。 学習済モデルを使ってサイン関数を予測 まとめ 参考にした文献等 本記事の対象者 ニューラルネットワークとは何かを理解している人。 pythonの基本を理解している人。 Kerasでニューラルネットワークを作ったことがある人 以下の記事で、Kerasを使ってニューラルネットワークとはどのようなものかをまとめているので、参考にしてみてください。 RNNとはなにかRNNは「リカレントニューラルネットワーク」の略です。 RNNとは、過去のデータを基に、これからどのような処理をするのかを判断することが得意なニューラルネットワークです。 時系列データを扱うのが得意なニューラルネットワークとも言われ、具体的には以下のような時系列データをあつかったりします。 株価 音声データ 音楽 文書 気象 RNNではこの時系列データを入力および正解として扱います。 RNNの特徴は、以下の図に示すように、中間層がループする構造を取る点です。 中間層がループする構造とは、中間層の出力が入力層からの次の入力とセットで、中間層への入力になるということです。 このように、自ら出力したデータを再び入力データとしてループすることを再帰といいます。 そのためRNNは、「再帰型ニューラルネットワーク」と言い換えられたりもします。 このような特徴から、RNNは過去のデータを保持することになるため、過去のデータを用いて判断を行うことができるのです。 時間\\( t\\)の経過に沿った動作を図で表すと以下のようになります。 時間が経過すればするほど、中間層が何層にもつながり、ある意味深いニューラルネットワークになることが分かります。 順伝播で入力データに対する予測が行われ、逆伝播の際に学習が行われます。 重みの更新は、通常のニューラルネットワークと同様、以下の式で表される勾配に基づいて行われます。 \\overrightarrow{w}\\leftarrow\\overrightarrow{w}-\\eta\\dfrac{\\partial E(\\overrightarrow{w})}{\\partial\\overrightarrow{w}}RNNと通常のニューラルネットワークとの違いは、重みやバイアスのパラメータ更新に、過去のデータからさかのぼってきた情報を利用する点にあります。 つまり、全時刻を通じて誤差をさかのぼり、重みとバイアスを更新するということになります。 RNNは勾配爆発と勾配消失を起こしやすいRNNは時系列データを用いて深いニューラルネットワークになっています。 このような構造を取った場合、何層にもわたって誤差を伝搬させることにより、勾配が大きくなりすぎるという問題が発生します。 勾配が大きくなりすぎてしまうことを勾配爆発と一般的に言い、これが起きてしまうとコンピュータ側で処理できなくなってします。 また、その逆で勾配が小さくなりすぎてしまう、勾配消失（勾配が0になる）というのも起こることがあり、学習できなくなってしまいます。 RNNは、前の時刻からデータを引継ぎ、繰り返し同じ重みを掛け合わせるため、通常のニューラルネットワークと比べて、これらの問題が起こりやすいと考えられています。 勾配爆発の対策としては、勾配クリッピングが有効です。勾配クリッピングとは、勾配の大きさに制限をかけることにより、勾配爆発を抑制することです。 勾配消失の対策としては、活性化関数を変更するか、LSTMというRNNの発展形であるニューラルネットワークを用いるのが良いそうです。 RNNを実装してみるJupyter NotebookでRNNの実装を行います。 ここでは、ノイズを含めたサイン関数を用意し、RNNを構築し、学習させたあと、学習済みモデルを使用して予測を行ってみたいと思います。 訓練用データを作成する。まずは、RNNで用いる訓練用のデータを作成します。 ①ノイズ付きサイン関数の作成サイン関数に代入する値として、\\( -2π\\)から\\( 2π\\)までの値を用意します。 123456%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-2*np.pi, 2*np.pi) # -2πから2πまで値を50個 x_dataは以下のようになっています。 12345678910array([-6.28318531, -6.02672876, -5.77027222, -5.51381568, -5.25735913, -5.00090259, -4.74444605, -4.48798951, -4.23153296, -3.97507642, -3.71861988, -3.46216333, -3.20570679, -2.94925025, -2.6927937 , -2.43633716, -2.17988062, -1.92342407, -1.66696753, -1.41051099, -1.15405444, -0.8975979 , -0.64114136, -0.38468481, -0.12822827, 0.12822827, 0.38468481, 0.64114136, 0.8975979 , 1.15405444, 1.41051099, 1.66696753, 1.92342407, 2.17988062, 2.43633716, 2.6927937 , 2.94925025, 3.20570679, 3.46216333, 3.71861988, 3.97507642, 4.23153296, 4.48798951, 4.74444605, 5.00090259, 5.25735913, 5.51381568, 5.77027222, 6.02672876, 6.28318531]) このx_dataをサイン関数に代入し、np.random.randnにより、乱数でノイズを加えてsin_dataとします。 グラフとして描画も実施します。 1234sin_data = np.sin(x_data) + 0.3*np.random.randn(len(x_data)) # sin関数に乱数でノイズを加えるplt.plot(x_data, sin_data)plt.show() サイン関数にノイズが付いたプロットが表示されました。 ②入力データと正解データの作成続いて入力データと正解データを作りたいと思います。 1234n_rnn = 15 # 時系列の数n_sample = len(x_data)-n_rnn # サンプル数i_data = np.zeros((n_sample, n_rnn)) # 入力c_data = np.zeros((n_sample, n_rnn)) # 正解 まず、時系列の数を設定します。 時系列の数というのは、要するに中間層がループする回数です。 今回は15回中間層がループする設定にします。 サンプル数は、len(x_data)-n_rnnとなり、今回の例でいうと、50 - 15 = 35となります。 これは、入力データと正解データを1セットで1サンプルとしてカウントするためです。 具体的に説明します。 x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、これを入力データとします。 そして、入力データから値を予想するモデルを作るために必要な正解データとして、入力データを1つずらした15個分のデータ1ブロックを正解データとします。 そして1サンプルというのは、先に述べた入力データおよび正解データの2つを1セットにしたものを指します。 図で表すと以下のようなイメージです。 入力データであるi_dataは、numpyのzerosメソッドで、すべて0とし初期化しておきます。 i_dataの行数は、サンプル数であるn_sampleとし、列数は時系列の数であるn_rnnにします。 正解データに関しても同様の配列にします。 i_data.shapeを実行すると(35, 15)、つまり、35行、15列になっていることが分かります。 もちろん配列データの中身は[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]となっています。 次に初期化したi_dataとc_dataに、sin関数にノイズを加えたsin_dataを設定していきます。 123for i in range(0, n_sample): i_data[i] = sin_data[i:i+n_rnn] c_data[i] = sin_data[i+1:i+n_rnn+1] # 時系列を入力よりも一つ後にずらす 入力データi_dataは、iからi+n_rnnまでを1ブロックとして加えたものになります。 正解データc_dataは時系列を入力データよりも1つ後にずらしたものになります。 未来のデータであればsin_data[i+n_rnn+1]の一つだけでも良さそうですが、これではエラーになります。 RNNには2つのタイプがあり、最後の時刻のみの出力を使うタイプと、全ての時刻の出力を使うタイプです。 前者に必要な正解は1つですが、後者は出力の数だけ正解が必要になります。 今回は後者にあたります。 上記のコードを実行し、i_dataの中身を見てみると、以下のようになっています。 12345678array([[-0.03454036, 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603], [ 0.24525829, 0.58367546, 0.78578144, 1.29077749, 0.68850031, 0.81436868, 0.60852433, 1.17917601, 0.83042115, 0.73981007, 0.71591622, 0.20791259, -0.13519872, -0.41113603, -0.52893013], (略) ③入力データと正解データの形状をKerasのRNN仕様に変更する。入力と正解データを作成しましたが、Kerasでは、データの形状を(入力のサンプル数, 時系列の数, 入力層のニューロン数)にする必要があります。 現時点でのi_dataの形状は、(35, 15)になっているので、reshapeを用いて、形状を変更させます。 12i_data = i_data.reshape(n_sample, n_rnn, 1) # KerasにおけるRNNでは、入力を（サンプル数、時系列の数、入力層のニューロン数）にするc_data = c_data.reshape(n_sample, n_rnn, 1) # 今回は入力と同じ形状 i_dataの中身を見てみると以下のようになっており、形状は(35, 15, 1)となります。 それぞれサンプル数、時系列の数、入力層のニューロン数を表しています。 12345678910111213141516171819202122232425262728293031323334array([[[-0.03454036], [ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603]], [[ 0.24525829], [ 0.58367546], [ 0.78578144], [ 1.29077749], [ 0.68850031], [ 0.81436868], [ 0.60852433], [ 1.17917601], [ 0.83042115], [ 0.73981007], [ 0.71591622], [ 0.20791259], [-0.13519872], [-0.41113603], [-0.52893013]], (略) これで、訓練用のデータを作成することができました。 RNNの構築Kerasを使ってRNNを構築します。 Kerasで活用できるRNNは主に以下があります。 SimpleRNN: RNN。全結合の中間層が再帰的になる。 LSTM: RNNの発展版であるLSTMを活用できる。複雑な時系列データを扱えるが学習に時間がかかる。 GRU: LSTMの簡易版のようなもの。LSTMに比べパラメータが少ないので、LSTMに比べて学習に時間がかからない。 お好みに合わせて、何れかのニューラルネットワークを活用すればよいと思います。 バッチサイズとモデルの設定本記事では、Kerasで活用できるRNNの中で一番シンプルな、SimpleRNN層を使います。 バッチサイズ、入力層のニューロン数、中間層のニューロン数、出力層のニューロン数を設定します。 1234567from keras.models import Sequentialfrom keras.layers import Dense, SimpleRNNbatch_size = 5 # バッチサイズn_in = 1 # 入力層のニューロン数n_mid = 20 # 中間層のニューロン数n_out = 1 # 出力層のニューロン数 これでOKです。 モデルを作成し層を追加Sequential()でモデルを作成し、層を追加していきます。 1234567model = Sequential()# SimpleRNN層の追加。return_sequenceをTrueにすると、時系列の全てのRNN層が出力を返す。# return_sequenceをTrueをFalseにすると、最後のRNN層のみが出力を返す。model.add(SimpleRNN(n_mid, input_shape=(n_rnn, n_in), return_sequences=True))model.add(Dense(n_out, activation=\"linear\"))model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # 誤差は二乗誤差、最適化アルゴリズムはSGDprint(model.summary()) まずはSimpleRNNの層を追加します。 SimpleRNN追加の際は、中間層のニューロン数を設定して、入力の形状を設定します。 RNNの場合、入力の形状は、(時系列の数(15), 入力層のニューロン数(1))となります。 return_sequencesはTrueに設定します。Trueにすることで、時系列のすべてのRNN層が出力を返すことになります。これをFalseに設定すると、最後のRNN層のみが、出力を返すことになります。なお、デフォルトでは、この値はFalseになっています。 SimpleRNNの後は、Denceを追加します。 Denceは通常のニューラルネットワークにおける、全結合層になります。 Denceには、出力層のニューロン数を設定し、活性化関数を、linearに設定します。linearは、恒等関数です。 SimpleRNNでは、活性化関数を設定していませんが、SimpleRNNの標準としてtanh(ハイパボリックタンジェント)が設定されます。 最後に、compileを行います。 損失関数は、回帰の場合は二乗誤差を適用し、分類の場合はクロスエントロピーを適用するのが一般的です。今回は、回帰になるので二乗誤差を設定します。 最適化アルゴリズムには、SDGを使用します。 こちらのコードを実行すると、model.summary()によって、以下のような出力を得ることが来ます。 1234567891011121314Model: \"sequential_2\"_________________________________________________________________Layer (type) Output Shape Param # =================================================================simple_rnn_2 (SimpleRNN) (None, 15, 20) 440 _________________________________________________________________dense_2 (Dense) (None, 15, 1) 21 =================================================================Total params: 461Trainable params: 461Non-trainable params: 0_________________________________________________________________None SimpleRNNのOutput Shapeは(None, 15, 20)となっています。15は時系列の数、20は中間層のニューロン数を意味しています。 パラメータの数は、合計で461であることが分かります。 SimpleRNNのパラメータ数は440であることが分かります。440の内訳は以下の通りです。 入力に対しての重み入力の次元数ｘ隠れ状態の次元数 → 1*20 隠れ状態に対しての重み隠れ状態の次元数 x 隠れ状態の次元数→ 20*20 バイアス隠れ状態の次元数→ 20 その他のパタンのパラメータ数の数え方については、以下の記事で分かりやすくまとめられてます。 https://qiita.com/Phoeboooo/items/6c3ea770047c820046f4 DenseのOutput Shapeは(None, 15, 1)となっています。15は時系列の数、1は出力層のニューロン数を意味しています。 参考ですが、重みやバイアスを調べる方法を以下にまとめます。 123456789print(len(model.layers[0].get_weights()))# 3i_weight, h_weight, bias = model.layers[0].get_weights() # lenが3なので、3変数に代入print(i_weight.size)# 20print(h_weight.size)# 400print(bias.size)# 20 構築したRNNのモデルを用いて学習学習は、fitメソッドを用いて行う。 入力データ(i_data)、正解データ(c_data)のほかにエポック数を指定する。 またバッチサイズとバリデーションスプリットも指定を行う。 1history = model.fit(i_data, c_data, epochs=100, batch_size=batch_size, validation_split=0.1) すると以下のように学習が走ります。 12345678910111213141516Train on 31 samples, validate on 4 samplesEpoch 1/10031/31 [==============================] - 0s 5ms/step - loss: 0.3232 - val_loss: 0.2373Epoch 2/10031/31 [==============================] - 0s 631us/step - loss: 0.2265 - val_loss: 0.2034Epoch 3/10031/31 [==============================] - 0s 551us/step - loss: 0.2003 - val_loss: 0.1930(略)Epoch 98/10031/31 [==============================] - 0s 500us/step - loss: 0.1233 - val_loss: 0.1471Epoch 99/10031/31 [==============================] - 0s 505us/step - loss: 0.1233 - val_loss: 0.1467Epoch 100/10031/31 [==============================] - 0s 490us/step - loss: 0.1230 - val_loss: 0.1468 学習の推移を確認する。lossとval_lossを確認していきましょう。 123456loss = history.history['loss']vloss = history.history['val_loss']plt.plot(np.arange(len(loss)), loss)plt.plot(np.arange(len(vloss)), vloss)plt.show() 訓練用のデータ、検証用のデータ、共に収束していることが分かります。 学習済モデルを使ってサイン関数を予測入力データを用います。 入力データ(i_data)とは何なのかをおさらいすると、、x_data（データ数：50）に対して、時系列の数である15個分のデータを1つのブロックとし、このブロックが合計で35個あるデータでした。 i_data.shapeを実行すると(35, 15, 1)と出力されることからも理解ができると思います。 入力データから最初の行列取り出し、reshape(-1)で1次元のベクトルにし、predictedという変数に格納します。 12predicted = i_data[0].reshape(-1) # 入力データの最初の行列データを取り出し、reshape(-1)で一次元のベクトルにする。predicted これを実行すると、以下のように出力されます。 123array([-0.29245656, 0.33761251, 0.73473534, 0.88417973, 0.8520399 , 0.91658402, 1.33572366, 0.84339794, 1.00440569, 0.45843943, 0.56022552, 0.23427566, 0.10704196, -0.65186734, -0.73755624]) 次に、この入力データ(predicted)を学習済みのモデルに入力し、値の予測をさせてみたいと思います。 以下のfor文になります。 123for i in range(0, n_sample): y = model.predict(predicted[-n_rnn:].reshape(1, n_rnn, 1)) # 直近のデータを使って予測を行う predicted = np.append(predicted, y[0][n_rnn-1][0]) # 出力の最後の結果をpredictedに追加する 最初のforループでは、predicted[0:]となるので、predictedに代入されているすべての15データを使って予測をしています。 その後、予測値yの末尾をpredictedに追加しています。 2回目以降のループでは、前回の予測値yの末尾を含んだ直近のデータ15個で予測をしています。 そのため、2回目のループでは、「predictの先頭のデータを除いた14個のデータ」 ＋ 「末尾に加えられた予測値yのデータ」の合計、15個のデータで予測を行っています。 そのため、ループの16回目からは、もともとのpredictのデータは全く使われず、すべて予測値yのデータで、追加予測をしていることになります。 予測結果を確認してみます。比較のために、sin_dataも同時にプロットします。 1234plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")plt.plot(np.arange(len(predicted)), predicted, label=\"Predicted\")plt.legend()plt.show() 青いラインが訓練用のデータで、オレンジのラインが学習済みのRNNのモデルで予測した結果です。 このように、直近の時系列データを使って、次の値を予測できるようになりました。 直近のデータを加えながら予測を行っているため、グラフが右に進めば進むほど、誤差の影響が積み重なるように受けてしまうため、訓練用データとのずれが大きくなっていることが確認できます。 まとめ今回は、sin関数の予測を行いました。 cos関数の予測に挑戦してみたり、各設定値を変えたり、実際の時系列データ（株価等）に適用してみたりすれば、より理解を深められるかもしれません。 参考にした文献等 ニューラルネットワークをちゃんと学びたい！という方は以下のUdemyの講座がおすすめ。Stay Home期間中にオンライン講座でスキルを身に着けるのはいかがでしょうか？ a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rXZlto6\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/course/kikagaku_blackbox_1/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/1356190_9cbb_6.jpg\"}}); 【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - ニューラルネットワークの発展形であるRNNやLSTMを構築して自然言語処理を学びたい方は、以下がおすすめです。本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発 https://note.nkmk.me/python-tensorflow-keras-count-params/ https://note.nkmk.me/python-tensorflow-keras-get-weights-kernel-bias/ https://qiita.com/Phoeboooo/items/6c3ea770047c820046f4 https://nzw0301.github.io/2016/05/comparison-rnn","link":"/2020/05/06/rnn-basic/"},{"title":"【AI】LSTMでサンドウィッチマンの漫才を学習して予測させてみた","text":"本記事では、LSTM(Long short-term memory)というRNNの拡張モデルを活用して、サンドウィッチマンさんの漫才ネタを学習させて、もっともらしい単語の予測をさせてみました。 ツイートした内容としては以下になります。それなりにリアクションあり。 目次 LSTMとは 入力データの準備 データの読み込み 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定 各文字のベクトル化 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 時系列データと予測する文字の抽出 入力と正解をone-hot表現で表す LSTMモデルの構築 文書を生成するための関数を記述し学習 まとめ LSTMとは以下の記事で詳細にまとめられています。 https://qiita.com/t_Signull/items/21b82be280b46f467d1b LSTM(Long short-term memory)は、RNN(Recurrent Neural Network)の拡張として1995年に登場した、時系列データ(sequential data)に対するモデル、あるいは構造(architecture)の1種です。その名は、Long term memory(長期記憶)とShort term memory(短期記憶)という神経科学における用語から取られています。LSTMはRNNの中間層のユニットをLSTM blockと呼ばれるメモリと3つのゲートを持つブロックに置き換えることで実現されています。 要するにRNNの中間層がLSTM層に置き換わったものであるということです。 LSTM層の内部には、記憶セル、入力ゲート、出力ゲート、忘却ゲートという内部要素を保持しており、複雑に絡み合っております。 しかしながらPythonのKerasを用いることでシンプルに実装することができます。 なお、RNNについては以下の記事でまとめているので参考にしてください 入力データの準備今回は、サンドイッチマンさんの漫才ネタをテキストデータとして用意したものを使います。 その中でも私個人的に好きな、ハンバーガー屋のネタ、弔事のネタ、旅行代理店のネタの3つを、テキストで書いたものです。 以下のような感じです・ sand_manzai.txt12345あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。(略)婚活パーティーか、お前。金取れ、女からも。バカたれ！さっ！というわけでねっ。そろそろお時間となってしまいました。何でラジオの終わりみたいになってんの。おかしい。DJみたいになってんじゃん、急に。ホントにねっ。まろやかに眠ってもらいたいです。いやいや。やすらかにだよ、やすらかに。まろやかにってお前、クリープかお前。それではまた、来週のこの時間まで！さようならぁ～！来週もやんのかよ。どういうことだよ、これお前。こんな感じでどうかな？全部書き直せ。もういいぜ。 ハンバーガー屋のネタから弔事のネタまでを、ただ単にテキストで書き連ねただけのデータです。 データの読み込みまずは、このテキストデータをJupyter Notebook環境に読み込みます。 読み込むテキストデータは、実行している.ipynbファイルと同じフォルダに配置しましょう。 12345678import rewith open(\"sand_manzai.txt\", mode=\"r\", encoding=\"utf-8\") as f: sand_original = f.read()sand = re.sub(\"[\\n]\", \"\", sand_original) # 改行の削除 print(sand) これで、テキストデータが表示されればOKです。 時系列の数、バッチサイズ、エポック数、中間層のニューロン数の設定この辺りの値は、実験を繰り返しながら最適な値を設定しました。 以下は、何回か実験を繰り返した結果の最終的な値です。 1234n_rnn = 10 # 時系列の数batch_size = 128 # バッチサイズepochs = 60 # エポック数n_mid = 256 # 中間層のニューロン数の数 入力データに対する時系列の数やバッチサイズって、どのように設定するのがベストプラクティスなのかは、勉強中です。。。 以下の記事によると、少しばかりヒントがありました。https://www.st-hakky-blog.com/entry/2017/11/16/161805 よく論文で見るBatch sizeDeep Learningの論文を読んでいるとどうやって学習をさせたかみたいな話はほぼ乗っているので、そういうのを見ていてよく見かけるのは以下あたりではないかと思います(すみません、私の観測範囲ですが)。 1 32 128 256 512だいたい、1だと完全に確率的勾配降下法になりますし、512だと学習速度をあげたかったのかなという気持ちが見えます。このあたりについてどれにするべきかというところを考察してみたいと思います。 各文字のベクトル化各文字をone-hot表現にします。one-hot表現を用いることで、単語をニューラルネットワークで扱いやすいベクトルの形にすることができます。 各文字をone-hot表現にするには、以下のように処理を行います。 文字の重複を省きlist化 文字がキーでインデックスが値の辞書を作成 インデックスがキーで文字が値の辞書を作成 入力と正解をone-hot表現に変更する 文字の重複を省きlist化まずは、setを使って文字の重複を省き、listにして、sortしたものをcharに格納したいと思います。 1234567import numpy as npchars = sorted(list(set(sand)))print(chars)print(\"文字数(重複なし)\", len(chars))# ['(', ')', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'D', 'J', 'M', 'h', 'i', 'k', 'o', 's', 'y', '…', '※', '♪', '、', '。', '々', '「', '」', 'ぁ', 'あ', 'ぃ', 'い', 'う', 'ぇ', 'え', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'っ', 'つ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ね', 'の', 'は', 'ば', 'ひ', 'び', 'ふ', 'ぶ', 'へ', 'べ', 'ほ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'を', 'ん', 'ァ', 'ア', 'ィ', 'イ', 'ウ', 'ェ', 'エ', 'オ', 'カ', 'ガ', 'キ', 'ク', 'グ', 'ケ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ソ', 'タ', 'ダ', 'チ', 'ッ', 'ツ', 'テ', 'ト', 'ド', 'ナ', 'ニ', 'ハ', 'バ', 'パ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ペ', 'ホ', 'ボ', 'ポ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ュ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ヴ', '・', 'ー', '一', '万', '丈', '三', '上', '下', '不', '世', '両', '中', '予', '事', '二', '京', '人', '今', '仕', '他', '付', '仙', '代', '以', '伊', '休', '会', '何', '作', '使', '修', '俺', '個', '健', '偽', '僕', '優', '兄', '入', '全', '内', '円', '冬', '出', '分', '刺', '削', '前', '加', '助', '勝', '化', '北', '千', '印', '原', '厨', '参', '取', '受', '古', '叩', '召', '台', '各', '合', '同', '名', '向', '周', '品', '員', '商', '喋', '回', '因', '図', '国', '土', '地', '場', '壁', '士', '売', '変', '夏', '外', '多', '夜', '大', '太', '夫', '奇', '奮', '女', '奴', '好', '婚', '季', '安', '定', '客', '宴', '密', '富', '小', '少', '尿', '居', '屋', '山', '岡', '川', '差', '帰', '幌', '年', '康', '式', '弔', '当', '彷', '待', '徨', '念', '怖', '思', '急', '性', '感', '態', '慌', '懐', '房', '手', '払', '投', '担', '拶', '持', '指', '挨', '振', '故', '文', '料', '断', '新', '方', '旅', '日', '早', '昨', '時', '普', '暮', '曲', '書', '最', '月', '期', '本', '札', '来', '東', '根', '桶', '棺', '業', '極', '楽', '構', '様', '樹', '次', '欲', '正', '歩', '歴', '死', '残', '気', '永', '求', '江', '決', '泊', '注', '活', '流', '海', '淳', '渕', '渡', '湯', '澤', '無', '然', '物', '状', '球', '理', '生', '田', '由', '申', '男', '界', '発', '皆', '盛', '目', '直', '相', '真', '眠', '知', '砂', '確', '神', '福', '秘', '稲', '笑', '第', '等', '答', '算', '箸', '米', '粧', '糖', '紀', '約', '終', '結', '続', '綿', '総', '緒', '繰', '置', '考', '者', '耳', '聞', '膳', '自', '興', '若', '草', '菅', '葬', '行', '要', '見', '覚', '触', '言', '診', '詰', '話', '読', '誰', '談', '象', '買', '跡', '踏', '輪', '辞', '近', '返', '通', '造', '週', '過', '達', '遠', '適', '選', '還', '郎', '部', '金', '間', '閣', '阪', '集', '静', '面', '音', '頃', '願', '飛', '食', '飲', '高', '鳩', '鶏', '麗', '麻', '黙', '鼻', '！', '（', '）', '０', '１', '２', '５', '７', '？', 'Ａ', 'Ｌ', 'Ｍ', 'Ｓ', '～']# 文字列(重複なし) 477 文字がキーでインデックスが値の辞書を作成次にchar_indicesという空の辞書を作成し、そこにループでインデックスi, 各文字をcharに格納。 char_indicesのキーとしてcharを指定してiを格納することで、文字がキーでインデックスが値の辞書が完成します。これは後程使います 1234567891011121314151617181920212223242526char_indices = {}for i, char in enumerate(chars): char_indices[char] = ichar_indices# {'(': 0,# ')': 1,# '-': 2,# '0': 3,# '1': 4,# '2': 5,# '3': 6,# '4': 7,# '5': 8,# '6': 9,# '7': 10,# '8': 11,# '9': 12,# 'D': 13,# 'J': 14,# 'M': 15,# 'h': 16,# 'i': 17,# 'k': 18,# 'o': 19,# 's': 20,# 以降は省略 インデックスがキーで文字が値の辞書を作成次に、indices_charというインデックスがキーで文字が値の辞書を作成します。こちらも後程使います。 12345678910111213141516171819202122232425indices_char = {}for i, char in enumerate(chars): indices_char[i] = charindices_char# {0: '(',# 1: ')',# 2: '-',# 3: '0',# 4: '1',# 5: '2',# 6: '3',# 7: '4',# 8: '5',# 9: '6',# 10: '7',# 11: '8',# 12: '9',# 13: 'D',# 14: 'J',# 15: 'M',# 16: 'h',# 17: 'i',# 18: 'k',# 19: 'o',# 以降は省略 時系列データと予測する文字の抽出時系列データはtime_chars、予測する文字はnext_charsに格納します。 テキストの長さから時系列の長さをを引いた分だけループを実施。 time_charsにはテキストのi～i+n_rnn分の長さだけの文字を加えてあります。これで時系列の数の回数分だけ再帰処理する時系列データを用意できます。 next_charsにはtime_charsから予測すべき文字なので、i + n_rnn番目の文字をリストに格納しています。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849time_chars = []next_chars = []for i in range(0, len(sand) - n_rnn): time_chars.append(sand[i: i + n_rnn]) next_chars.append(sand[i + n_rnn]) time_chars# ['あら。昨日の夜まで何',# 'ら。昨日の夜まで何も',# '。昨日の夜まで何もな',# '昨日の夜まで何もなか',# '日の夜まで何もなかっ',# 'の夜まで何もなかった',# '夜まで何もなかったの',# 'まで何もなかったのに',# 'で何もなかったのに、',# '何もなかったのに、急',# 'もなかったのに、急に',# 'なかったのに、急にハ',# 'かったのに、急にハン',# 'ったのに、急にハンバ',# 'たのに、急にハンバー',# 'のに、急にハンバーガ',# 'に、急にハンバーガー',# '、急にハンバーガー屋',# 以降は省略next_chars# ['も',# 'な',# 'か',# 'っ',# 'た',# 'の',# 'に',# '、',# '急',# 'に',# 'ハ',# 'ン',# 'バ',# 'ー',# 'ガ',# 'ー',# '屋',# '出',# '来'# 以下省略 入力と正解をone-hot表現で表すここで、入力\\(x\\)と正解\\(t\\)を作っています。最初はzerosすべての要素を0にします。 入力\\(x\\)の形状は、[time_charsの長さ、時系列データの長さ(n_rnn)、文字数]、となります。今回は、要素は0か1の二通りしかありませんので、データのタイプはbool型にしておきます。 また、正解\\(t\\)ですが、こちらは、[time_charsの長さ、文字数]、の形状にします。こちらも同様にデータのタイプはbool型にしておきます。 time_charsの数だけまずループを行います。 まず、正解に対して値を設定。 indexがiで各要素がt_csになるわけですが、正解な文字が入っているnext_charsから文字を取り出し、char_indicesによりindexに変換します。そして、その要素を1に設定します。 これにより、この要素のみ1で、あとは0になるone-hot表現に変換されることになります。 また、入力の方は、さらにループの入れ子構造を使って設定します。 t_csを使ってループを行っており、この際のインデックスはj, 要素はcharとします。 \\(x\\)のiとjを設定して、そのうえでchar_indicesを使って文字をインデックスに変換します。 この要素を1にします。 こうすることで、入力も同様にone-hot表現で表すことが可能です。 試しに、xを出力してみます。 1234567891011121314151617181920212223242526x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)for i, t_cs in enumerate(time_chars): t[i, char_indices[next_chars[i]]] = 1 # 正解をone-hot表現で表す for j, char in enumerate(t_cs): x[i, j, char_indices[char]] = 1 # 入力をone-hot表現で表す x# array([[[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]],t# Out[9]:# array([[False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# ...,# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False],# [False, False, False, ..., False, False, False]]) xとtの形状も確認してみます。 1234print(\"xの形状\", x.shape)print(\"tの形状\", t.shape)# xの形状 (5408, 10, 477)# tの形状 (5408, 477) これでone-hot表現化は完了です。 LSTMモデルの構築Kerasを使ってLSTMを構築していきます。 SimpleRNN層と同じ方法で構築できます。 損失関数は、複数の分類に適したcategorical_crossentropyを指定し、最適化アルゴリズムは収束しやすいadamを指定したいと思います。 1234567891011121314151617181920212223242526272829303132333435from keras.models import Sequentialfrom keras.layers import Dense, LSTMmodel_lstm = Sequential()model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))model_lstm.add(Dense(len(chars), activation=\"softmax\"))model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")print(model_lstm.summary())# Model: \"sequential_1\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# simple_rnn_1 (SimpleRNN) (None, 20) 440 # _________________________________________________________________# dense_1 (Dense) (None, 1) 21 # =================================================================# Total params: 461# Trainable params: 461# Non-trainable params: 0# _________________________________________________________________# None# Model: \"sequential_2\"# _________________________________________________________________# Layer (type) Output Shape Param # # =================================================================# lstm_1 (LSTM) (None, 20) 1760 # _________________________________________________________________# dense_2 (Dense) (None, 1) 21 # =================================================================# Total params: 1,781# Trainable params: 1,781# Non-trainable params: 0# _________________________________________________________________# None 文書を生成するための関数を記述し学習各エポックが終了した際に、文章を生成するための関数を作成します。 12345678910111213141516171819202122232425262728293031323334353637from keras.callbacks import LambdaCallback def on_epoch_end(epoch, logs): print(\"エポック: \", epoch) beta = 5 # 確率分布を調整する定数 prev_text = sand[0:n_rnn] # 入力に使う文字。「'あら。昨日の夜まで何'」という文字列 created_text = prev_text # 生成されるテキスト print(\"シード: \", created_text) for i in range(400): # 入力をone-hot表現に x_pred = np.zeros((1, n_rnn, len(chars))) for j, char in enumerate(prev_text): x_pred[0, j, char_indices[char]] = 1 # 予測を行い、次の文字を得る y = model.predict(x_pred) # (1, 479)のarray。array([[0.00203636, 0.0020888 , ・・・・・ p_power = y[0] ** beta # 確率分布の調整。y[0]は(479,)のarray。array([0.00203636, 0.0020888 , 0.00209593, ・・・・ next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) # next_indexには、len(p_power)の数値である0～479間のintがランダムで代入される。 next_char = indices_char[next_index] # 'あ'とか'～'とか文字列を得る。 created_text += next_char prev_text = prev_text[1:] + next_char print(created_text) print()# エポック終了後に実行される関数を設定epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)model = model_lstmhistory_lstm = model_lstm.fit(x, t, batch_size=batch_size, epochs=epochs, callbacks=[epock_end_callback]) LambdaCallbackは、エポック終了時等のタイミングで、特定の処理を行うための関数として使用します。 betaという定数が設定されています。これは確率分布を調整する定数です。 確率分布を使用する意図は、最も確率が高い文字だけではなく、それ以外の文字からも確率に従いサンプリングをするためです。結果的に、高い確率の文字が選ばれる頻度が高くなります。これは、入力データに対して、次の文字として最も確率の高い文字を予測する代わりに、確率分布を推定する、ということになります。 prev_textには、テキストの最初から時系列分だけを取り出したサンドウィッチマンのネタの文字列が入ります。これが、モデルに入力される文字列になり、常に直近の時系列データが入るようにします。 created_textは、生成されるテキストです。文章は必ず、prev_textから始まるようにするので、prev_textを入れておきます。そして、created_textがシードになります。これがベースとなって次々と次の文字を予測していくことになります。 今回は400文字の文章を生成する。 入力をone-hot表現に変換するために、入力x_predには、まずnp.zerosで初期化したものを含める。サンプル数が1, 時系列データ, charsの数の形状をしています。 次に予測を行っていきます。model.predictに、x_predを入れて出力のyを得ることができます。 y[0]で各文字に対応する確率分布のリストが得られる。これにbetaを累乗。betaの値は、1より大きいと高い確率がより高くなるように確率分布が調整されます。 次の文字として、next_indexに、特定の確率分布の中からサンプリングされた値(文字のインデックス)が代入される。確率分布pは、p_powerに対して、P_powerを足し合わせたもので割っている。これは、確率分布pが、すべて足しあわされて1にならなければならないためです。確率分布については、以下のchainerチュートリアルのドキュメントが分かりやすいと思います。 https://tutorials.chainer.org/ja/06_Basics_of_Probability_Statistics.html そして、next_indexをキーとして、indices_charに入れることで、次の文字を取り出すことができる。 prev_textは、最初の文字を取り除き、next_charを加えることで、直近の時系列に更新される。 このようにして訓練済みのLSTMのモデルを使って、文章を自動生成することができる。 学習の推移を確認していくと徐々にサンドイッチマンのネタに近づいていきます。途中ずっと「いらっしゃいませこんにちは！」しか言わなったりしますが、、、 123456789101112131415161718192021222324252627282930313233343536373839Epoch 1/605408/5408 [==============================] - 14s 3ms/step - loss: 5.3819エポック: 0シード: あら。昨日の夜まで何あら。昨日の夜まで何ないかんんーんーんんいい。い。ないいいんい、ん、っいんかいんいなかいおいんっん。いかていい、っい、たんな、、いいだのいいいんんいてお、ない、いんーいーいいーーい、いんい。っい、で、ー、いいーー、いいな、。ん、いいなんんいー、ーーいいいんていっおんいいっなんんいーーあ、、ん。だーんんいんん、、んおんい、っない、ー、いっいい、いいいい、ら、んかんん。っないかいいー、。っん、いおおいて、っいっ、いいいー、かんおおーいていん、、んんいいいいすん、おーーー、いい、いい、いんっー、っっいいーーいってんいいいーんいい、ーんいのし、なんんい、、んっいすっんーてーんてーいっなのいーい、、いっ、い、、いんっー。、のなー、いんー、っ、いっ。んいておいいーよいん、んー、ーなー、い、、っんい、いんないんだっ、か、いーなん、、っっいんーてーんいおいんうでいで、んーの。い、、のんんい。ーおしっ、いんんんいんいーいいん。Epoch 10/605408/5408 [==============================] - 11s 2ms/step - loss: 4.1347エポック: 9シード: あら。昨日の夜まで何あら。昨日の夜まで何たたいたいんだよ。。あ、、ののののに・・のにいににいっててん。。。んのく、のののののにののすののですかか？。か？か、、。ちののにののしのの、、いすに。ののののーー、だ、よ。。、れののの方にののにしにいってん。。。ちちののののの、いのののにしにいてんだよ。。あちれしっての。。。あ、、ののにののの方になのたっててん。。。の、のののののの・・・・・で・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・、・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・の・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・Epoch 20/605408/5408 [==============================] - 12s 2ms/step - loss: 2.5751エポック: 19シード: あら。昨日の夜まで何あら。昨日の夜まで何ですかかもにりだよ。おっていいます。何や、ロオーー。そー、知れ。これ、お前。あー、ううらううう。あれ、あうです。やうやでしうから、お前。ないまですか？やや、だオー。ララララ見にてってるてよかな。でんですか？いいんだよ。お前、ちゃんだよ。いいいです。何やからだー、お前。何ですか？？いわ、、なん。持持ちてよ、お前。えってんでよ。どうううってんだよ。あン、これになんだよ。お前、あ、、お前。きやきうららいます。あ、ですも。ううーうう！！！れンンううううう！！ンンンンンンンン！ンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンンEpoch 44/605408/5408 [==============================] - 12s 2ms/step - loss: 0.2862エポック: 43シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってよねうか。お前、あットババナナェイェイで…いやサイでです。こいなににこんらくくちゃいていのお前。なー、じゃあの、こンにに北おおかしなあ。バー。繰イ人人、お前。あ、で婚の人お前っなんか。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言ってるか分かんない。何で何言Epoch 49/605408/5408 [==============================] - 12s 2ms/step - loss: 0.1811エポック: 48シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちはー！いらっしゃいませこんにちEpoch 60/605408/5408 [==============================] - 12s 2ms/step - loss: 0.0870エポック: 59シード: あら。昨日の夜まで何あら。昨日の夜まで何もなかったのに、急にハンバーガー屋出来てるな。興奮してきたな。ちょっと入ってみようか。いらっしゃいませこんにちはー！ブックオフか。うっせぇ、何回も。１回でいいんだよ、１回で。こちらでお召し上がりですか？いや、持って帰るよ。ソルトレイクの方で…。テイクアウトだよ。なんだソルトレイクって。なんで俺冬季オリンピックなんだ。持って帰る、持って帰る。…メニュー、メニュー。お客さん。踏んでますよ。なんで下にあんだよ。上に置いとかな全然見えなかったわ、お前。あー、どうしようかな。じゃあ、ビッグバーガーセットはいかがですか？太るわ。普通なんかサイドメニューみたいな。サイドメニュー？ご一緒に(※ポテトの発音で)ホタテになります。(※ポテトの発音で)ホタテに！あ、いらっしゃちいま。あとち言ーにますらか。な一ににつらっていませま。。あもですぎ。１ぇの！ういいや！１１回！（※でも１をを指両両両のををンン指指を指を 誤差の収束具合をグラフで確認します。 12345678%matplotlib inlineimport matplotlib.pyplot as pltloss_lstm = history_lstm.history['loss']plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")plt.legend()plt.show() ちゃんと誤差が収束に向かっているのが分かります。 まとめLSTMの理解を深めるために、サンドウィッチマンのネタを学習し予測させてみました。 様々なデータに活用し、実験してみていただけると幸いです。 RNNやLSTMを構築して自然言語処理を学びたい方は、以下のUdemy講座がおすすめです。 本記事の作成において、とても参考にさせていただきました。 a8adscript('body').showAd({\"req\": {\"mat\":\"3B51QR+67V08I+3L4M+BWGDT\",\"alt\":\"商品リンク\",\"id\":\"3wqAvAY-g7-rWu087N\"},\"goods\": {\"ejp\":\"h\"+\"ttps://www.udemy.com/share/101WUgB0EfdlZVTXQ=/\",\"imu\":\"h\"+\"ttps://img-a.udemycdn.com/course/240x135/2101146_8cfb.jpg\"}}); 自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発","link":"/2020/05/11/lstm-sandwich/"},{"title":"【Hexo】更新日を表示させる方法","text":"Icarus(v3.0)テーマを適用して記事を作成すると、デフォルト設定では以下のようになってると思います。 御覧の通り、作成日として”3日前”という表記があるだけで、更新日がありません。 これを変更したいと思います。 \\themes\\icarus\\layout\\common\\article.jsxを変更すればOKです。 \\themes\\icarus\\layout\\common\\article.jsx12345 {/* Date */}+ &lt;i class=\"fas fa-clock\"&gt;作成日:&lt;/i&gt; &lt;time class=\"level-item\" dateTime={date_xml(page.date)} title={date_xml(page.date)}&gt;{date(page.date)}&lt;/time&gt;+ &lt;i class=\"fas fa-wrench\"&gt;更新日:&lt;/i&gt;+ &lt;time class=\"level-item\" dateTime={date_xml(page.updated)} title={date_xml(page.updated)}&gt;{date(page.updated)}&lt;/time&gt; こちらのコードを反映すると、以下の通りとなります。 アイコンは、Font Awesomeの参照して、&lt;i class=&quot;fas fa-clock&quot;&gt;&lt;/i&gt;等を使えばアイコンを表示させることができます。 https://fontawesome.com/icons?d=gallery 以上です。","link":"/2020/05/21/hexo-icarus-updated/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"ブログ","slug":"ブログ","link":"/tags/%E3%83%96%E3%83%AD%E3%82%B0/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"自然言語処理","slug":"自然言語処理","link":"/tags/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86/"},{"name":"ダイエット","slug":"ダイエット","link":"/tags/%E3%83%80%E3%82%A4%E3%82%A8%E3%83%83%E3%83%88/"},{"name":"サプリメント","slug":"サプリメント","link":"/tags/%E3%82%B5%E3%83%97%E3%83%AA%E3%83%A1%E3%83%B3%E3%83%88/"},{"name":"食事","slug":"食事","link":"/tags/%E9%A3%9F%E4%BA%8B/"},{"name":"doc2vec","slug":"doc2vec","link":"/tags/doc2vec/"},{"name":"ニューラルネットワーク","slug":"ニューラルネットワーク","link":"/tags/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"},{"name":"エラー","slug":"エラー","link":"/tags/%E3%82%A8%E3%83%A9%E3%83%BC/"},{"name":"landscape","slug":"landscape","link":"/tags/landscape/"},{"name":"instagram","slug":"instagram","link":"/tags/instagram/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"BULMA","slug":"BULMA","link":"/tags/BULMA/"},{"name":"EPA","slug":"EPA","link":"/tags/EPA/"},{"name":"葉酸","slug":"葉酸","link":"/tags/%E8%91%89%E9%85%B8/"},{"name":"育児","slug":"育児","link":"/tags/%E8%82%B2%E5%85%90/"},{"name":"子育て","slug":"子育て","link":"/tags/%E5%AD%90%E8%82%B2%E3%81%A6/"},{"name":"勉強","slug":"勉強","link":"/tags/%E5%8B%89%E5%BC%B7/"},{"name":"前十字靭帯","slug":"前十字靭帯","link":"/tags/%E5%89%8D%E5%8D%81%E5%AD%97%E9%9D%AD%E5%B8%AF/"},{"name":"リハビリ","slug":"リハビリ","link":"/tags/%E3%83%AA%E3%83%8F%E3%83%93%E3%83%AA/"},{"name":"野球","slug":"野球","link":"/tags/%E9%87%8E%E7%90%83/"},{"name":"バッティング","slug":"バッティング","link":"/tags/%E3%83%90%E3%83%83%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"コンテナ","slug":"コンテナ","link":"/tags/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A/"},{"name":"在宅","slug":"在宅","link":"/tags/%E5%9C%A8%E5%AE%85/"},{"name":"楽痩せ","slug":"楽痩せ","link":"/tags/%E6%A5%BD%E7%97%A9%E3%81%9B/"},{"name":"仕事","slug":"仕事","link":"/tags/%E4%BB%95%E4%BA%8B/"},{"name":"minikube","slug":"minikube","link":"/tags/minikube/"},{"name":"コマンド","slug":"コマンド","link":"/tags/%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/"},{"name":"手術","slug":"手術","link":"/tags/%E6%89%8B%E8%A1%93/"},{"name":"プログラミング","slug":"プログラミング","link":"/tags/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/"},{"name":"skill hacks","slug":"skill-hacks","link":"/tags/skill-hacks/"},{"name":"Udemy","slug":"Udemy","link":"/tags/Udemy/"},{"name":"twitter","slug":"twitter","link":"/tags/twitter/"},{"name":"visual studio code","slug":"visual-studio-code","link":"/tags/visual-studio-code/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"git bash","slug":"git-bash","link":"/tags/git-bash/"},{"name":"word2vec","slug":"word2vec","link":"/tags/word2vec/"},{"name":"オブジェクト指向","slug":"オブジェクト指向","link":"/tags/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/"},{"name":"クラス","slug":"クラス","link":"/tags/%E3%82%AF%E3%83%A9%E3%82%B9/"},{"name":"keras","slug":"keras","link":"/tags/keras/"},{"name":"トレーニング","slug":"トレーニング","link":"/tags/%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/"},{"name":"SkillHacks","slug":"SkillHacks","link":"/tags/SkillHacks/"},{"name":"風邪予防","slug":"風邪予防","link":"/tags/%E9%A2%A8%E9%82%AA%E4%BA%88%E9%98%B2/"},{"name":"seq2seq","slug":"seq2seq","link":"/tags/seq2seq/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"}],"categories":[{"name":"IT","slug":"IT","link":"/categories/IT/"},{"name":"Health","slug":"Health","link":"/categories/Health/"},{"name":"Method","slug":"Method","link":"/categories/Method/"},{"name":"Sports","slug":"Sports","link":"/categories/Sports/"}]}